#+TITLE: [HSF] Reasons to be Cheerful by Greg Egan

* [[http://www.utilitarianism.com/greg-egan/Reasons-To-Be-Cheerful.pdf][[HSF] Reasons to be Cheerful by Greg Egan]]
:PROPERTIES:
:Author: 23143567
:Score: 55
:DateUnix: 1452484259.0
:DateShort: 2016-Jan-11
:END:

** Woah.

Greg Egan knows how to bring it.
:PROPERTIES:
:Author: FeepingCreature
:Score: 17
:DateUnix: 1452504547.0
:DateShort: 2016-Jan-11
:END:


** I think the protagonist would have gotten more job offers if he led with "I can rewire my brain to find any task enjoyable, and as such have a literally perfect work ethic."
:PROPERTIES:
:Score: 13
:DateUnix: 1452538412.0
:DateShort: 2016-Jan-11
:END:

*** Yeah, it's ridiculously overpowered when you really think about it, you just need to let go of your preconceived notions of what life is supposed to be like, unlike protagonist. Theoretically you could single-handedly lauch humanity in new and exciting directions of research and engineering, just rewire your brain for that. Everything we see in the world is a result of humans responding to their environmental incentives - with that ability you could have a true rationalists, choosing underfunded areas of development, where human attention easily strays away and thus progress is hard to make.

I'm not saying it would be a cakewalk, but I can't even imagine the range of possibilities since I'm looking at it from my human perspective and that would be game-breaker.
:PROPERTIES:
:Author: 23143567
:Score: 10
:DateUnix: 1452553957.0
:DateShort: 2016-Jan-12
:END:

**** u/deleted:
#+begin_quote
  you just need to let go of your preconceived notions of what life is supposed to be like, unlike protagonist.
#+end_quote

I'm sure this doesn't end in paperclips and table-legs. Totally, completely sure.

/s
:PROPERTIES:
:Score: 5
:DateUnix: 1452793402.0
:DateShort: 2016-Jan-14
:END:


**** u/Roxolan:
#+begin_quote
  Theoretically you could single-handedly lauch humanity in new and exciting directions of research and engineering
#+end_quote

I mean, you could, but why would you want that instead of something else?

This reminds me of LessWrong's Metaethics sequence, e.g. [[http://lesswrong.com/lw/rn/no_universally_compelling_arguments/][No Universally Compelling Argument]]. If you can tweak your own pleasure center, you could motivate yourself into becoming the man of your dreams, but *you need to have dreams first*. This power is only ridiculously overpowered when in the right hands.
:PROPERTIES:
:Author: Roxolan
:Score: 2
:DateUnix: 1453014860.0
:DateShort: 2016-Jan-17
:END:


** I do not understand:

#+begin_quote
  I said, “I think you should do that. Switch it off.”
#+end_quote

How could after the experience that has been conveyed anything on Earth be worse than returning to that?
:PROPERTIES:
:Author: RMcD94
:Score: 12
:DateUnix: 1452523658.0
:DateShort: 2016-Jan-11
:END:


** I forgot that this was fiction for a bit near the beginning. It was very engaging.
:PROPERTIES:
:Author: Schnake_bitten
:Score: 12
:DateUnix: 1452544244.0
:DateShort: 2016-Jan-12
:END:

*** I didn't even realize it was fiction until I got about a quarter of the way in. It felt almost too candid.
:PROPERTIES:
:Author: Drazelic
:Score: 14
:DateUnix: 1452552241.0
:DateShort: 2016-Jan-12
:END:


** Ah, there's nothing quite like Greg Egan's brand of existential dread. Now to find something to cheer me up. Whatever that means.
:PROPERTIES:
:Author: redrach
:Score: 7
:DateUnix: 1452556486.0
:DateShort: 2016-Jan-12
:END:


** To someone who literally considers themselves a three-pound sack of fluid, fat, and neurotransmitters and has no particular problem with it, this is not particularly existential or dreadful. [[#s][]]

#+begin_quote
  I read voraciously, and on one level I could make clear judgments: I could pick the clumsy writers from the skilled, the honest from the fakers, the platitudinous from the inspired. But the prosthesis still wanted me to enjoy everything, to embrace everything, to diffuse out across the dusty shelves until I was no one at all, a ghost in the Library of Babel.
#+end_quote

This, and Beethoven, I have some objections with. Bar practical reasons (interference with non-hedonic terminal goals, if there are such a thing? or simply prioritized terminal goals?), why would you ever want to decrease your enjoyment of something? You're strictly limiting your expected value of experience. I want to be /more/ eclectic than my already-pathologically-eclectic self, not less. The times I come to enjoy some new genre of music or art or fetish is a joy in itself to me, because the world can make me happier without ever having changed.
:PROPERTIES:
:Author: Transfuturist
:Score: 3
:DateUnix: 1452621923.0
:DateShort: 2016-Jan-12
:END:

*** He had the opportunity to be anyone - but because he could be happy with being anyone, he had no reason to try for more. The dreadful bit is that, from within his frame of reference, that was the perfectly logical. It's only horrible from the outside.

It also suggests that there's a level of metacognition above his immediate experience of happiness that allows him to retain his sense of identity - the reason he didn't commit suicide, the intellectual process that allowed him to hope to be cured without having any way of actually experiencing hope.
:PROPERTIES:
:Score: 2
:DateUnix: 1452629311.0
:DateShort: 2016-Jan-12
:END:

**** u/Transfuturist:
#+begin_quote
  he had no reason to try for more
#+end_quote

What do you mean, 'more?' Decreasing aesthetic enjoyment seems, as I said, strictly worse. At most I would recommend small variations to help order your preferences.
:PROPERTIES:
:Author: Transfuturist
:Score: 2
:DateUnix: 1452629740.0
:DateShort: 2016-Jan-12
:END:

***** No, no, that's not what I mean. He could have made himself love anything, tuned his brain to reward him for striving for any goal at all - but he settled on what seemed like an absolutely normal existence to him, because the idea of doing something extraordinary with his life held no special meaning for him. Everything held special meaning for him, so why not mediocrity?
:PROPERTIES:
:Score: 4
:DateUnix: 1452630728.0
:DateShort: 2016-Jan-13
:END:

****** I still don't find that horrible.
:PROPERTIES:
:Author: Transfuturist
:Score: 1
:DateUnix: 1452631185.0
:DateShort: 2016-Jan-13
:END:


****** u/deleted:
#+begin_quote
  He could have made himself love anything, tuned his brain to reward him for striving for any goal at all - but he settled on what seemed like an absolutely normal existence to him, because the idea of doing something extraordinary with his life held no special meaning for him. Everything held special meaning for him, so why not mediocrity?
#+end_quote

I think in order to make sense of this we need much clearer notions of what we mean by "special" and "mediocre".
:PROPERTIES:
:Score: 1
:DateUnix: 1452793584.0
:DateShort: 2016-Jan-14
:END:


** It was a very good read.

It also launched me into armchair (read: uninformed) philosophy. Happiness is arbitrary. Therefore, it may be meaningless? Does this mean one must strive for something else than being happy in life? If so, what? All goals I know about either make me happy or make me happy because they make someone else happy.

After all, if we're bags of cells that call themselves self-aware, that is not meaningful either. We're all like the protagonist, except we cannot consciously move our sliders.

It would appeal to my coolness scale if Greg Egan had not given the protagonist a name. It only appears once anyways.
:PROPERTIES:
:Author: rhaps0dy4
:Score: 2
:DateUnix: 1452521699.0
:DateShort: 2016-Jan-11
:END:

*** All axioms are arbitrary and ergo meaningless; it's in their nature.

There's no goal in existence that means more than another goal so you might as well go with happiness because it makes you feel good and tautologically that's as good as you're going to get, whether you feel good through happiness or moral satisfaction or whatever nuance emotion you want to describe it with.
:PROPERTIES:
:Author: RMcD94
:Score: 10
:DateUnix: 1452523804.0
:DateShort: 2016-Jan-11
:END:


*** u/deleted:
#+begin_quote
  It also launched me into armchair (read: uninformed) philosophy. Happiness is arbitrary. Therefore, it may be meaningless? Does this mean one must strive for something else than being happy in life? If so, what? All goals I know about either make me happy or make me happy because they make someone else happy.
#+end_quote

Things can be arbitrary and meaningful. In fact, since all attempts at "a priori" reasoning are ultimately based in axioms chosen arbitrarily because they happen to seem useful, all "logical" reasoning /must/ be arbitrary.

Or perhaps you just need a new definition of "arbitrary".
:PROPERTIES:
:Score: 1
:DateUnix: 1452793484.0
:DateShort: 2016-Jan-14
:END:

**** Yes. Logical conclusions are as arbitrary as their axioms.

About arbitrary and meaningful things. Other goals, not based on happiness, are not any less arbitrary. Might as well define those based on happiness to be meaningful.

I have not been able to find a new definition of "arbitrary" though.
:PROPERTIES:
:Author: rhaps0dy4
:Score: 1
:DateUnix: 1452815270.0
:DateShort: 2016-Jan-15
:END:

***** u/deleted:
#+begin_quote
  Other goals, not based on happiness, are not any less arbitrary.
#+end_quote

They might be. You don't know until you've got a solid definition of "arbitrary" and "meaningful".
:PROPERTIES:
:Score: 1
:DateUnix: 1452818120.0
:DateShort: 2016-Jan-15
:END:

****** Seconded. Just because goals can be arbitrary doesn't mean they're not meaningful. If there's something you really want to do, like "be happy" or "help people" or "have fun" or "have good relationships", then that's reason enough to do it, even if there isn't another reason behind that reason.

And if you had the ability to change what you really wanted to do, to something you otherwise wouldn't want, then that's a really hard decision to make. Like, what do you want to want to do? What do you want to want to want to do? If you make it a goal to change your goals, but you don't know what goals to change and to what, then you would need to determine what goals you want to change to. But in order to change what you want, you need to change what you want to change what you want.

To be honest, I think that the only reason one would want to mess with their utility function like that would be if there was something they wanted to do that they knew they could never do, either because it is trumped by more important goals or because they simply don't have the skills or resources etc.

Then again, it would also be useful for someone to recover from an addiction. Give this ability to someone who's trying to quit smoking and they'd probably never touch a cigarette again.
:PROPERTIES:
:Author: Sailor_Vulcan
:Score: 1
:DateUnix: 1453077763.0
:DateShort: 2016-Jan-18
:END:
