#+TITLE: [D] Wednesday Worldbuilding Thread

* [D] Wednesday Worldbuilding Thread
:PROPERTIES:
:Author: AutoModerator
:Score: 12
:DateUnix: 1514992014.0
:DateShort: 2018-Jan-03
:END:
Welcome to the Wednesday thread for worldbuilding discussions!

[[/r/rational]] is focussed on rational and rationalist fiction, so we don't usually allow discussion of scenarios or worldbuilding unless there's finished chapters involved (see the sidebar). It /is/ pretty fun to cut loose with a likeminded community though, so this is our regular chance to:

- Plan out a new story
- Discuss how to escape a supervillian lair... or build a perfect prison
- Poke holes in a popular setting (without writing fanfic)
- Test your idea of how to rational-ify /Alice in Wonderland/

Or generally work through the problems of a fictional world.

^{Non-fiction should probably go in the Friday Off-topic thread, or Monday General Rationality}


** There's this science fiction setting that I've been kicking around in my head (if that doesn't imply a much greater level of development than what it's got so far).

I'm aiming for a space opera kind of thing along the lines of /Dune/ or some aspects of /Star Wars/. A major aspect of the setting is that, somewhere along the line, people had ideas about how they wanted the universe to work and they had the power to enforce those ideas. Maybe it was a superintelligent A.I. That part isn't important right now.

The important bit is what they wanted: for history to be a /human/ story, where humans are the protagonists of their own stories. To the people that built the future, this meant removing any technology whose purpose could be accomplished by humans (and therefore can be interpreted as replacing humans). Weirdly, the story that comes to mind most readily is that of the Finnish sniper Simo Häyhä, who killed up to five hundred soldiers in the Winter War: how much of this accomplishment would have been his, had he been wielding an auto-targeting rifle that even guided his hands into the proper position?

I'm wondering how far I should go with this, though. Even given the strictest interpretation, spaceships will be a thing because there are no circumstances in which a human can travel through space unassisted.

What about power generation, though? Humans can turn cranks, even if that's terribly inefficient.

Computers definitely won't be allowed for many things, but should they be totally disallowed? Part of me says "yes," but another part of me says that if, say, the calculations being made would take more than a human lifetime to complete, then it's okay. Basically, pocket calculators are out, but Future!NASA can still run climate simulations.

People can beat each other to death with their fists, so are weapons banned? That seems going kind of overboard!

Unless this is a story of hunter-gatherers who periodically board space ships, "No technology that does things that a human could do" can't be the /whole/ story, then, even if it's a good enough summation that most people describe it that way.

Even so, I think that most things are handmade, and the only stuff that isn't is what /can't/ be: very fine circuitry, spaceship parts, etc.

I've got some other random stuff that I've been spitballing, but it's tangential from this part so I'll end my post here.
:PROPERTIES:
:Author: callmesalticidae
:Score: 6
:DateUnix: 1514996606.0
:DateShort: 2018-Jan-03
:END:

*** I think that there's a very simple way to do this, and it is this: all /decisions/ must be made by humans, and no technology must be permitted to /make decisions/ on its own.

To take your example of the sniper; he is permitted his sniper rifle, because it makes no decisions. He is not permitted an auto-targeting sniper rifle, because that makes the decisions for him. Power generation? As long as a human decides how much power is generated, and where it goes to, you can generate all the power you want. Spaceships? They require human pilots, who make all the decisions. Weapons? Lightsabers, pistols, sniper rifles, nuclear explosives are all allowed; self-targetting drones are not, because they are making their own decisions.

Since humans make all the decisions, therefore, history is forced to be a human story.
:PROPERTIES:
:Author: CCC_037
:Score: 13
:DateUnix: 1515006323.0
:DateShort: 2018-Jan-03
:END:

**** In real life we're currently dealing with the problem of humans being influenced by bots and algorithms sending them information to optimize their likelihood of making decisions that make the company money.

How does a computer “just following orders” or a human otherwise using technology to effect other humans decision-making ability fall under this paradigm? What's the point where it stops being a human decision?
:PROPERTIES:
:Author: trekie140
:Score: 3
:DateUnix: 1515072935.0
:DateShort: 2018-Jan-04
:END:

***** This is where we start to get into gray areas.

On the one end of the spectrum, we have a telephone; Alice talks to the telephone, and the telephone transmits her voice to Bob, and Alice tries to influence Bob's decision. In this case, there are very clearly no non-human decisions being made, and thus this is acceptable.

On the other end of the spectrum, there is an Persuasion Machine. Alice goes to the Persuasion Machine, and tells it "Persuade Ben to choose X", and it persuades Ben to choose X. In this case, there are several decisions (especially as regards how to persuade Ben) that the machine is making, and this is obviously disallowed.

Between the two, there is a spectrum of prediction bots and algorithms influencing human decisions - some of them influencing the decisions of their own designers, quite unintentionally (e.g. a weather prediction algorithm with an unintentional bias towards predicting rain might make someone less likely to go on a picnic). Even a large, colourful sign saying "Lowest Prices" will influence human decisions to some degree.

Hmmmmm.

Clearly humans must be permitted to influence each other, or there will be no communication at all. So the telephone is permitted. And Alice calling up Bob and saying "you should shop here, our prices are cheaper than the place down the road" is, in my view, pretty clearly permissible.

The question, then, comes in two parts. The first is whether or not Alice can call up Bob on the phone and say "you should shop here, /the computer says/ our prices are cheaper than the shop down the road". And the second is whether Alice can record herself saying "you should shop here, our prices are cheaper than the shop" and play that recording down every phone in the street at once.

I'd say yes to the first and no to the second; Alice can claim that the computer says anything to Bob, but she has to handle the process one-on-one, in a sense 'piloting' the conversation and making all the decisions (even if that involves pulling information from predictive algorithms), but she can't /automate/ the process.

Does that seem like a sensible place to draw the line to you?
:PROPERTIES:
:Author: CCC_037
:Score: 3
:DateUnix: 1515077728.0
:DateShort: 2018-Jan-04
:END:

****** It does. The definition of automated can be tricky, but I like the idea of every machine requiring an operator in order to work even if it's just to regularly push a button.
:PROPERTIES:
:Author: trekie140
:Score: 5
:DateUnix: 1515082353.0
:DateShort: 2018-Jan-04
:END:


****** I don't follow.

If Alice designs a persuasion algorithm, why shouldn't she be able to let a bot following the algorithm persuade Bob? As long as the algorithm is deterministic in nature, by using a bot Alice has simply pre-committed to following that particular decision-making scheme.

If you draw the line at /automation/, then it's not decision making that's the issue, but [[/u/callmesalticidae][u/callmesalticidae]]'s original idea: removing any technology whose purpose could be accomplished by humans.
:PROPERTIES:
:Author: ben_oni
:Score: 2
:DateUnix: 1515090870.0
:DateShort: 2018-Jan-04
:END:

******* A deterministic algorithm can still be considered to be making decisions - even though the decision is completely deterministic (along the lines of "IF Bob.Income > 10000 THEN Offer Discount").

I'm not saying that this is a good idea, or even a feasible idea; I'm merely presenting it as a possible method by which to reach [[/u/callmesalticidae][u/callmesalticidae]]'s aim of ensuring that "history is a human story" (along with, of course, completely obliterating any intelligent aliens - a course of action I also do not condone).
:PROPERTIES:
:Author: CCC_037
:Score: 3
:DateUnix: 1515091499.0
:DateShort: 2018-Jan-04
:END:

******** u/ben_oni:
#+begin_quote
  A deterministic algorithm can still be considered to be making decisions - even though the decision is completely deterministic (along the lines of "IF Bob.Income > 10000 THEN Offer Discount").
#+end_quote

From a certain point of view. However, the proposed rule would take away from Alice the option to use a bot to precommit to a particular algorithm. So the most important decisions are really being made by whatever mechanism is ensuring that "history is a human story".
:PROPERTIES:
:Author: ben_oni
:Score: 1
:DateUnix: 1515101158.0
:DateShort: 2018-Jan-05
:END:

********* In the same way as having freedom now does not allow you to punch someone else in the nose (not legally, at least), in this hypothetical world humans are not allowed to decide to let a computer make decisions, even in a completely automated manner.

If Alice wants her algorithm followed, she needs to write it down and give it to a low-paid intern with instructions along the lines of "follow these rules OR ELSE"
:PROPERTIES:
:Author: CCC_037
:Score: 1
:DateUnix: 1515125860.0
:DateShort: 2018-Jan-05
:END:

********** u/ben_oni:
#+begin_quote
  In the same way as having freedom now does not allow you to punch someone else in the nose
#+end_quote

You and I seem to have very different ideas of what freedom means.
:PROPERTIES:
:Author: ben_oni
:Score: 1
:DateUnix: 1515127192.0
:DateShort: 2018-Jan-05
:END:

*********** What, are you saying that the freedom to punch me in the nose is not a type of freedom?
:PROPERTIES:
:Author: CCC_037
:Score: 1
:DateUnix: 1515133660.0
:DateShort: 2018-Jan-05
:END:


**** So, flipping a coin or rolling a die is right out.
:PROPERTIES:
:Author: ben_oni
:Score: 2
:DateUnix: 1515040098.0
:DateShort: 2018-Jan-04
:END:

***** The easiest fix for this is to so arrange the laws of physics that any coin toss or die roll has an easily predictable result.
:PROPERTIES:
:Author: CCC_037
:Score: 1
:DateUnix: 1515040477.0
:DateShort: 2018-Jan-04
:END:

****** Removing all random processes from the world is the /easy/ fix? Wow.
:PROPERTIES:
:Author: ben_oni
:Score: 2
:DateUnix: 1515089456.0
:DateShort: 2018-Jan-04
:END:

******* "Easy" as in "the first option to come to mind". Not "easy" as in "achievable".
:PROPERTIES:
:Author: CCC_037
:Score: 2
:DateUnix: 1515090654.0
:DateShort: 2018-Jan-04
:END:


**** That works pretty well. I don't know why I didn't think of that!
:PROPERTIES:
:Author: callmesalticidae
:Score: 2
:DateUnix: 1515042631.0
:DateShort: 2018-Jan-04
:END:


*** u/Peewee223:
#+begin_quote
  People can beat each other to death with their fists, so are weapons banned? That seems going kind of overboard!
#+end_quote

I agree - People can't cut things without a blade, and people can't put holes in people from a distance without guns.

#+begin_quote
  What about power generation, though? Humans can turn cranks, even if that's terribly inefficient.
#+end_quote

Same deal as the climate simulations - a healthy laborer can only realistically sustain [[https://en.wikipedia.org/wiki/Human_power][75W]] for an 8 hour shift. A thousand people working in rotating 8 hour shifts can only put out 25KW. What's the cutoff for parallel calculations done by humans, anyway? Judging by a randomly selected benchmark (bitcoin mining), my GPU on its own is approximately 1*10^{13} times faster at calculating than I am... or ~1500 times faster than every human in the world calculating things in their head simultaneously.

Another interesting idea is that reading and writing is, strictly speaking, unnecessary - people can speak, understand one another, and remember a great deal of stories after all. This also comes with a free explanation of why nobody's gone and reinvented the lost knowledge - the pseudoluddites burned all the books and technical manuals.
:PROPERTIES:
:Author: Peewee223
:Score: 2
:DateUnix: 1515007657.0
:DateShort: 2018-Jan-03
:END:


*** In this scenario, was the knowledge to create forbidden tech removed by force with some kind of enforcement agency making rediscovery difficult, or was the laws of the universe changed so the forbidden tech is impossible to make?
:PROPERTIES:
:Author: Weebcluse
:Score: 2
:DateUnix: 1515038159.0
:DateShort: 2018-Jan-04
:END:

**** The former. Right now, the enforcement agency is a superintelligent AI, but once I figure out the other stuff I'm going to see if there's something else that I can use, because "A superintelligent AI did it" may /work/ but gets kind of stale after you've used it fifty times.
:PROPERTIES:
:Author: callmesalticidae
:Score: 1
:DateUnix: 1515042519.0
:DateShort: 2018-Jan-04
:END:


*** I wonder, how do you go about inventing a computer without first inventing a way to add two small numbers together automatically?

Technology is usually a progression from simple to advanced, and you're prohibiting the simple parts... I'm not seeing how that works.

The solution I'd use would be expensive magic - there are no climate simulation computers of any kind, because there are no computers, because there are no pocket calculators. Weather/climate predicting "oracles" would be used instead. Make such "enchantments" prohibitively expensive, and while they could in theory be used for simple things like aiming a rifle, they'd only ever actually get used by state-level actors, for things that simply can't be done in cheaper ways.
:PROPERTIES:
:Author: Peewee223
:Score: 1
:DateUnix: 1515005763.0
:DateShort: 2018-Jan-03
:END:

**** u/callmesalticidae:
#+begin_quote
  this meant removing any technology whose purpose could be accomplished by humans
#+end_quote

This is in our future. Computers were already invented. Pocket calculators existed. It's just that then much of this was /removed/ at some point.

I'm not wondering how technology could have progressed after this point (it's totally plausible that it has ground to a halt because people can't understand the cutting edge of technology anymore, meaning that they can't build upon it), but wondering what technologies have been pared back.

This is why "hunter-gatherers who periodically use spaceships" is a possible (albeit undesirable) outcome.
:PROPERTIES:
:Author: callmesalticidae
:Score: 3
:DateUnix: 1515006114.0
:DateShort: 2018-Jan-03
:END:

***** Ah, I've been reading too much time travel - I thought you meant removing the existence of pocket calculators from the timeline without affecting supercomputers, not just erasing them from the historical records / public conscience.

Comments retracted.
:PROPERTIES:
:Author: Peewee223
:Score: 2
:DateUnix: 1515006331.0
:DateShort: 2018-Jan-03
:END:


*** I'm reminded of [[https://www.amazon.com/Memory-Earth-Homecoming-Orson-Scott/dp/0812532597/ref=sr_1_7][another]] sci-fi setting, where all transportation technology was forcibly removed from society. The people aren't allowed to even think of /the wheel/, but they're able to board starships and travel to other planets. I found this to be heavy-handed and obnoxious. I know what the writer was trying to do, I just don't think it worked out very well.

In order to make this setting work, you'd have to have a reason why a miller can't attach his grindstone to a waterwheel.
:PROPERTIES:
:Author: ben_oni
:Score: 1
:DateUnix: 1515090176.0
:DateShort: 2018-Jan-04
:END:


*** I've put a bit more brain-time on this. Please let me know how far astray I'm going.

--------------

If the goal is for history to be a human story, all that's needed is to tell history from a human perspective. Taking the example of the sniper, suppose we did give him a rifle with aim-assist and auto-firing capabilities. He's still choosing where to be, which battles to fight, who to shoot, and when to leave. Presumably, his opponents will have similar technology, so at some point, a certain kill count could still be considered an impressive human accomplishment.

But if it's just kill counts that are impressive, then the crew of the [[https://en.wikipedia.org/wiki/Enola_Gay][Enola Gay]] certainly racked up quite the score. I remember seeing this discussion in Heinlein's [[https://www.goodreads.com/book/show/17214.Starship_Troopers][/Starship Troopers/]], when the protagonist considers why infantry exist when a tech type can push a button and destroy whole cities.

Going back to WWII, there are more than a few stories both human and technological that have been told. Consider the codebreakers who built the first computers. The story of a computer breaking a code might not be interesting, but the story of the codebreakers building the computers is very much a fascinating human story.

--------------

When studying modern history, it seems that all stories are economic, social, and/or political in nature. Take, for instance, 2017's sex scandals: the first one was a human story about a powerful predator, but as the stories kept coming, the story morphed into a tale of a society that incentivizes such behavior; a story of social moral decay, if you will. I can only assume that you want to avoid those sorts of stories so that history turns on the actions of individuals rather than groups. If that is the actual goal, I recommend introducing a mechanism to keep population densities low, so that the actions of very few people still mean a great deal on a historical scale. This would also mean keeping AI populations low-to-nonexistent.

One could also look at modern history as the consequence of removing power from individuals. Monarchs have been largely removed from any real power, leaving elected legislatures and complex bureaucracies to do the real decision-making. In those nations that still have supreme leaders, the stories are those of suffering and grief. Even the super-rich have been powerless to change the frameworks that are already in place, or even to nudge the decision-making processes. One could argue that history is no longer a human story because it has reached its [[https://ps321.community.uaf.edu/files/2012/10/Fukuyama-End-of-history-article.pdf][culmination]]. Barring catastrophic disasters on Earth, the next phase of history to be a human story may very well be space exploration, which could explain why "Elon Musk" and "SpaceX" are household names in the same vein as "Neil Armstrong". Then again, any real space exploration will be so difficult, expensive, and most importantly time-consuming, that it probably won't be a human story either.
:PROPERTIES:
:Author: ben_oni
:Score: 1
:DateUnix: 1515101309.0
:DateShort: 2018-Jan-05
:END:


*** u/ben_oni:
#+begin_quote
  the story that comes to mind most readily is that of the Finnish sniper Simo Häyhä, who killed up to five hundred soldiers in the Winter War: how much of this accomplishment would have been his, had he been wielding an auto-targeting rifle that even guided his hands into the proper position?
#+end_quote

How much of the accomplishment is his given that he was using a sniper rifle instead of, say, a bow and arrow?

--------------

Much of technological progression happens in a two-step process: automation followed by miniaturization. Your proposed rule would prohibit the automation step while allowing the miniaturization phase. But you can't get to miniaturization if the automation doesn't happen first.
:PROPERTIES:
:Author: ben_oni
:Score: 1
:DateUnix: 1515005267.0
:DateShort: 2018-Jan-03
:END:

**** u/callmesalticidae:
#+begin_quote
  How much of the accomplishment is his given that he was using a sniper rifle instead of, say, a bow and arrow?
#+end_quote

I think that a gun isn't fundamentally different from a bow for this purpose, at least before we get beyond a certain rate of fire, but that's definitely open for debate.

#+begin_quote
  Much of technological progression happens in a two-step process: automation followed by miniaturization. Your proposed rule would prohibit the automation step while allowing the miniaturization phase. But you can't get to miniaturization if the automation doesn't happen first.
#+end_quote

Yes. This does mean that technology isn't advancing much, if at all, and most of the higher technology is maintained by non-human means.

Technology has definitely fallen back in a lot of respects, though. This would be a setting where people can travel faster than light eat cultured meat, and light their homes with electricity, but computers are rare and anything that /can/ be handmade /is/ handmade (but things that can't be, are made by self-maintaining, probably self-replicating, fabricators).
:PROPERTIES:
:Author: callmesalticidae
:Score: 3
:DateUnix: 1515005788.0
:DateShort: 2018-Jan-03
:END:


** I've been mulling over an idea of a world in which people have very limited precognition, granted through either technological or arcane means. Essentially, this would manifest as a momentary burst of alertness at a moment specified after that moment has passed.

Say, for example, a woman discovers she's forgotten her cell phone when she arrives at work. She can send a small "blip" back to herself that morning when she put it down on her desk, which could serve as a reminder to pick it back up.

Is there a reasonably consistent, non-arbitrary way to limit this power so that it's useful for simple, mundane tasks such as "Don't forget your keys!" and "That's salt, not sugar!" but not for more complicated things like predicting the next week's lottery numbers or using time-loop haxx to brute-force arbitrary mathematical problems?
:PROPERTIES:
:Author: Nulono
:Score: 3
:DateUnix: 1515222449.0
:DateShort: 2018-Jan-06
:END:

*** So basically it's a tachyonic antitelephone that boosts awareness instead of sending a message? Well, since all it does is highlighting a moment one is supposed to take an action, I don't think it requires any restrictions aside from maybe mentally exhausting user or rewinding up to certain amount of time.
:PROPERTIES:
:Author: Jakkubus
:Score: 2
:DateUnix: 1515276895.0
:DateShort: 2018-Jan-07
:END:

**** Basically. Or you could think of it as always sending the same message of "!".

Having it be exhausting could help some. Most of what I'm trying to avoid is schemes involving precommitting, like "I'm going to look at options A, B, C, and D for a moment each, and then choose the one that future me highlights after the test is graded!" or "If the stock market drops, I'll send an alert to yesterday at noon...".
:PROPERTIES:
:Author: Nulono
:Score: 2
:DateUnix: 1515277612.0
:DateShort: 2018-Jan-07
:END:

***** You could also make it so that a message "locks" a certain timespan around the targeted moment forever. So if one alerted themselves at particular point of time, they may be unable to send warnings within a time window of few minutes or hours before and after it.

For example if someone made a choice at 12:15 and then sent a ping back to that moment, the time period between 11:15 and 13:15 of that day is inviolable for their power after that.
:PROPERTIES:
:Author: Jakkubus
:Score: 1
:DateUnix: 1515278203.0
:DateShort: 2018-Jan-07
:END:
