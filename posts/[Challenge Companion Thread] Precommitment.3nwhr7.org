#+TITLE: [Challenge Companion Thread] Precommitment

* [Challenge Companion Thread] Precommitment
:PROPERTIES:
:Author: alexanderwales
:Score: 15
:DateUnix: 1444259217.0
:DateShort: 2015-Oct-08
:END:
#+begin_quote
  Precommitment is a strategy in which a party to a conflict uses a commitment device to strengthen its position by cutting off some of its options to make its threats more credible. Any party employing a Strategy of Deterrence faces the problem that retaliating against an attack may ultimately result in significant damage to their own side. If this damage is significant enough, then the opponent may take the view that such retaliation would be irrational, and therefore, that the threat lacks credibility, and hence, it ceases to be an effective deterrent. Precommitment improves the credibility of a threat, either by imposing significant penalties on the threatening party for not following through, or, by making it impossible to not respond.
#+end_quote

The most classic example of this (from either Thomas Schelling or Bertrand Russell, I'm having trouble tracking down the quote) is that in a game of chicken, you can definitively win by simply removing your steering wheel and throwing it out the window, so that it's no longer a game of flinching but of certain death for your opponent if /he/ doesn't flinch. This is easily extended into the question of nuclear brinksmanship and dead-hand systems, which I believe is what much of game theory was originally meant to analyze.


** "Hurray," said the two drivers, about to crash into each other. "This was the rational decision!"
:PROPERTIES:
:Author: TimTravel
:Score: 10
:DateUnix: 1444322132.0
:DateShort: 2015-Oct-08
:END:

*** Chicken is not a game anyone rational wants to play in the first place. The standard analysis relies heavily on symmetry, non-repetition, both players knowing the exact payoff matrix in advance, knowing the other player knows, and knowing neither of them can change the game.

The rational response is usually something like "Dude, let's just flip a coin and then go have burgers."

I always thought the "throw away the steering wheel" ploy was funny, because what would really happen is that guy would crash regardless--because he's now in a high speed car that he can no longer steer 8-)
:PROPERTIES:
:Author: DocFuture
:Score: 1
:DateUnix: 1444607776.0
:DateShort: 2015-Oct-12
:END:


** Very interesting concept. In the cryptocurrency community there is a thing called [[https://en.bitcoin.it/wiki/Proof_of_burn][Proof of Burn]] where you prove that you've spent coins to unspendable addresses. This shows a monetary commitment without actually paying anyone specifically.

More broadly, smart contracts can achieve this precommitment function extremely generally, such as "send one dollar to bob that is only spendable on bread." Scripts enforce the spendability of the token inside the network. [[https://www.ethereum.org/][Ethereum]] is an attempt at a Turing complete scripting language for smart contracts.

My favorite example of a dead man's switch precommitment in fiction is in Snow Crash where [[#s][spoiler]].
:PROPERTIES:
:Author: Polycephal_Lee
:Score: 5
:DateUnix: 1444264011.0
:DateShort: 2015-Oct-08
:END:

*** u/Transfuturist:
#+begin_quote
  Until a man is twenty-five, he still thinks, every so often, that under the right circumstances he could be the baddest motherfucker in the world.

  Hiro used to feel that way, too, but then he ran into Raven. He no longer has to worry about trying to be the baddest motherfucker in the world. The position is taken.
#+end_quote
:PROPERTIES:
:Author: Transfuturist
:Score: 5
:DateUnix: 1444270666.0
:DateShort: 2015-Oct-08
:END:


** How could this be made into horror? I'm thinking about some kind of story where making precommitments actually tweaks your utility function to prioritize that precommitment. Someone accidentally precommits recursively, and as they fulfill their precommitments, the situations and states of mind they find themselves in make them more likely to make further precommitments - until their entire life is devoted to fulfilling them.

No one notices.
:PROPERTIES:
:Score: 3
:DateUnix: 1444308471.0
:DateShort: 2015-Oct-08
:END:

*** An individual living in a world of easy cognitive modification reasons that [[http://mindingourway.com/dark-arts-of-rationality/][making your instrumental goals terminal]] is a great way to approach your original terminal goals. To celebrate, they modify their motivation system to encourage taking these opportunities.
:PROPERTIES:
:Author: Transfuturist
:Score: 2
:DateUnix: 1444350362.0
:DateShort: 2015-Oct-09
:END:

**** Hahahaha what the fuck. That is some mind-screwy stuff. It seems like a delighted and perverse way to twist basic epistemological truth-seeking concepts to goal-seeking ends.
:PROPERTIES:
:Score: 1
:DateUnix: 1444361783.0
:DateShort: 2015-Oct-09
:END:


** Precommitting is often a good strategy where privacy is involved. If you will always respond the same way regardless of how your privacy is being trespassed, nobody can infer from your protectiveness whether or not there actually is something there this time. China is thought to do this- they keep lots of places undisclosed so would-be spies have a harder time telling which ones actually hide secrets. I am not okay with people looking through my drawers, looking on any devices I own, or generally invading my privacy without my explicit consent, even if 99% of the time I have nothing to hide there.
:PROPERTIES:
:Author: Cruithne
:Score: 3
:DateUnix: 1444346966.0
:DateShort: 2015-Oct-09
:END:

*** I neither confirm nor deny that I am an alias of Eliezer Yudkowsky.
:PROPERTIES:
:Author: thecommexokid
:Score: 1
:DateUnix: 1444448343.0
:DateShort: 2015-Oct-10
:END:


** I swear by my ability to make this sort of vow that I will now and henceforth defect (as applies to the specific context) against anyone who, in knowledge of this vow, attempts to use a precommitment strategy to unfavorably limit my options.
:PROPERTIES:
:Score: 3
:DateUnix: 1444281556.0
:DateShort: 2015-Oct-08
:END:

*** I only saw the last line:

#+begin_quote
  Yay, first mover advantage!
#+end_quote

Therefore I will precommit to not read anything else in your comment.
:PROPERTIES:
:Author: xamueljones
:Score: 7
:DateUnix: 1444287493.0
:DateShort: 2015-Oct-08
:END:

**** Wait, what? I didn't say that at all. You should check again.
:PROPERTIES:
:Score: 1
:DateUnix: 1444310352.0
:DateShort: 2015-Oct-08
:END:

***** u/xamueljones:
#+begin_quote
  precommit to not read anything else in your comment.
#+end_quote

LALALALA!!!

I'm not reading anything you may or may not be saying!!!! ^ _ ^
:PROPERTIES:
:Author: xamueljones
:Score: 2
:DateUnix: 1444314438.0
:DateShort: 2015-Oct-08
:END:


*** Precommitment doesn't unfavorably limit your options, it unfavorably limits the /outcomes/ to your options.

Here's the payoff matrix for a game of chicken:

|          | Swerve | Straight |
|----------+--------+----------|
| Swerve   | 0,0    | -1,+1    |
| Straight | +1,-1  | -10,-10  |

Here's what it looks like if only one driver has removed his ability to swerve:

|          | Straight |
|----------+----------|
| Swerve   | -1,+1    |
| Straight | -10,-10  |

The player's only rational course of action is to swerve, but his /options/ have not actually been limited (and in fact those options remain exactly the same).

I should also point out that in many cases, precommitment is just about credibility. The game of chicken is all about credibility, as is nuclear brinksmanship, as is making a New Year's resolution.

If you say "I vow that I will defect if you precommit" then I don't find your vow to be particularly credible, so I'll throw my steering wheel out the window, which means that you are faced with the choice of either crashing into my car and dying, or suffering from a reputational hit from losing and suffering whatever the consequences might be from breaking your vow. Given that choice, I believe you'll break your vow, because I don't think your vow will credibly stop you in the face of certain death. Your vow doesn't seem much stronger than simply saying "I'm totes not going to swerve", which is exactly what you'd say if you were going to swerve.

What you /really/ need to do is something like hiring an assassin who will murder you and your family if you ever don't defect against someone who has used a precommitment strategy. So long as I find /that/ credible, I might believe that you would defect even in the face of changed incentives from /my/ precommitment, because the payoff for you would be:

|          | Straight |
|----------+----------|
| Swerve   | -51,+1   |
| Straight | -10,-10  |

Because if you swerve, you not only take the reputational hit and the loss of credibility for future coordination problems, but also you (and your family) still die.
:PROPERTIES:
:Author: alexanderwales
:Score: 3
:DateUnix: 1444326004.0
:DateShort: 2015-Oct-08
:END:

**** u/deleted:
#+begin_quote
  Precommitment doesn't unfavorably limit your options, it unfavorably limits the outcomes to your options.
#+end_quote

Sure. And holding a gun to your head doesn't force you to do anything, the person is just asking you to choose between doing what they ask vs taking a bullet to the skull. ;)

#+begin_quote
  Your vow doesn't seem much stronger than simply saying "I'm totes not going to swerve", which is exactly what you'd say if you were going to swerve.
#+end_quote

Ahh, but that is the magic! I have used this sort of vow many times, with 100% success rate, and to much benefit. By breaking this vow at any time, I lose the ability to use it as a precommitment device in the future, forfeiting all future utility gained by its use, which I estimate to be quite substantial.

Granted, the disutility of death is quite a bit more than that. So no, it would not work in the "throw out steering wheel" case. But it would work for many lesser forms!
:PROPERTIES:
:Score: -1
:DateUnix: 1444353020.0
:DateShort: 2015-Oct-09
:END:


** Does anyone else feel that the rational/lesswrong community use exactly the opposite meaning for precommitment?

With Parfit's Hitchiker, Schelling would precommit to payment by, say, having Ekman tie him up, in order to force him to pay when they get there.

A lesswrongian would just say "I precommit to paying you."

Alternatively a LWian might have said this just before they passed out, just in case a selfish mindreader chances on them before they die.
:PROPERTIES:
:Author: Revisional_Sin
:Score: 2
:DateUnix: 1444478418.0
:DateShort: 2015-Oct-10
:END:
