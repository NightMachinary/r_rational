#+TITLE: [D] Monday General Rationality Thread

* [D] Monday General Rationality Thread
:PROPERTIES:
:Author: AutoModerator
:Score: 9
:DateUnix: 1529939217.0
:DateShort: 2018-Jun-25
:END:
Welcome to the Monday thread on general rationality topics! Do you really want to talk about something non-fictional, related to the real world? Have you:

- Seen something interesting on [[/r/science]]?
- Found a new way to get your shit even-more together?
- Figured out how to become immortal?
- Constructed artificial general intelligence?
- Read a neat nonfiction book?
- Munchkined your way into total control of your D&D campaign?


** An oddball question - I'm a regular here, but using a throwaway for obvious reasons.

I recently wrapped up my PhD and received an extremely prestigious award -- essentially "best PhD thesis awarded this year" from a very high ranking technical institute. Obviously, there is no such thing as "best PhD", but I'll take it.

Obviously, this affords me unprecedented opportunities - simply having it on my resume will give me better job offers and salaries. However, I suspect that taking maximum advantage of this will require more creativity. The obvious answers include putting extra effort into building up my contacts, as well as making sure that website+linkedin+resume work together to streamline people becoming aware of it, but I'm sure that I'm missing something. Thoughts?
:PROPERTIES:
:Author: rationalthrowaway5
:Score: 7
:DateUnix: 1529951824.0
:DateShort: 2018-Jun-25
:END:

*** Use it as an excuse to meet and network with previous winners of the award. It's very useful to have more connections with people who are very skilled in their field (even if they won the award for something that's completely unrelated to your field).
:PROPERTIES:
:Author: xamueljones
:Score: 14
:DateUnix: 1529961251.0
:DateShort: 2018-Jun-26
:END:


** How should I talk to irrational people? In particular I have difficulty talking to someone who has power over me (eg. boss, parent), who seems to be convinced they understand me and treat me according to their models. When I try to point out their errors, they accuse me of using my arguments against others and not myself... [[https://www.lesswrong.com/posts/AdYdLP2sRqPMoe8fb/knowing-about-biases-can-hurt-people][when that appears to be what they have done]]. My belief that they are the less rational party comes from prior experiences, with one particular case where I showed them that their model of me was wrong, but they continued using it.

They do not like being questioned, contradicted, the usual stuff. But I still require their good will, and I wish them well; they are a good person in general.

How can I communicate to them effectively so they do not feel antagonised by me when I suggest something they don't like? Any general tips for how to communicate well would also be appreciated.
:PROPERTIES:
:Author: causalchain
:Score: 3
:DateUnix: 1529988359.0
:DateShort: 2018-Jun-26
:END:

*** Consider reading Dale Carnegie's /How to Win Friends and Influence People./ It has a lot of tips about optimizing your conduct to appeal to others, many of which boil down to friendliness and empathy.

The key to persuading others is to understand how they communicate and what they value, and then demonstrate their values in their own language. This can be tough, but it yields lifelong benefits.
:PROPERTIES:
:Author: 9adam4
:Score: 5
:DateUnix: 1530062004.0
:DateShort: 2018-Jun-27
:END:

**** Thank you very much, and I definitely read the book.
:PROPERTIES:
:Author: causalchain
:Score: 2
:DateUnix: 1530063032.0
:DateShort: 2018-Jun-27
:END:


*** u/CCC_037:
#+begin_quote
  When I try to point out their errors, they accuse me of using my arguments against others and not myself... when that appears to be what they have done.
#+end_quote

Hmmm. Can you give a suitably anonymised example of a typical interaction?
:PROPERTIES:
:Author: CCC_037
:Score: 3
:DateUnix: 1530006303.0
:DateShort: 2018-Jun-26
:END:

**** My memory is poor and and I should actually make notes about my interactions. I'll give you what I can.

Situation a: Instruction.They would tell me to do something which I do not want to do or cannot do. I would either explain what is wrong or offer an alternative which I think solves their intention. Sometimes this is enough, but other times they would insist on it. Attempts to ask why are rejected. If I continue to try and argue it, they will get frustrated with me.

Situation b: argument.Either when I continue to refuse an instruction that I cannot do, or if we get frustrated at each other for any other reason. Since they have power over me, I must avoid offending them, but they do not hold back so much. Their arguments are based on their model of me, which while mostly right, also has many divergences which create "wrong" arguments which I reflexively refute (habit I need to control). The arguments rarely achieve anything.

This isn't comprehensive, if there is any questions you can think of then feel free to ask. I would also love general communication tips!
:PROPERTIES:
:Author: causalchain
:Score: 2
:DateUnix: 1530062532.0
:DateShort: 2018-Jun-27
:END:

***** u/CCC_037:
#+begin_quote
  They would tell me to do something which I do not want to do or cannot do.
#+end_quote

You're talking about bosses and parents. These people do have the authority to instruct you to do things which you do not want to do (you can negotiate, which as you point out does work some of the time). Ultimately, however, unless you have a moral objection along the lines of "I'd prefer to get fired" or you're asked to do something outright illegal, you are expected to either do as your boss requires or, if it is impossible, to get as close to his request as possible - whether or not the boss explains why.

#+begin_quote
  Their arguments are based on their model of me, which while mostly right, also has many divergences which create "wrong" arguments which I reflexively refute (habit I need to control).
#+end_quote

This will be particularly frustrating - someone tries to tell you to do A, happens to mention B, and you reflexively refute B which has nothing to do with A. You've probably noticed this already.

Now, I don't really know how your arguments tend to progress, but one suggestion I can make in general - when arguing with anyone, for any reason, /do not interrupt/. Close your mouth and /wait/ for them to speak their /entire/ argument without interruption - and only once they have finished present a summary of your counter-arguments. (Exception - if there is something urgently time-sensitive, e.g. the room at the back is on fire, then interruptions are acceptable).

Finally, see if you can join a local Toastmasters or Agora Speakers club - they're all about teaching people to communicate effectively and you'll learn a lot more from them in-person than from me over a text-only interface.
:PROPERTIES:
:Author: CCC_037
:Score: 3
:DateUnix: 1530074370.0
:DateShort: 2018-Jun-27
:END:

****** Thank you for your response! I'll do my best to listen to let them talk and finish their argument. I'll see about joining a Toastmasters or Agora Speakers club, that sounds like it will be helpful.

On another note, I've noticed that my poor attempts at argument have created general counterarguments that they can use against me. Eg. "if you respond that means you haven't listened to what I said". This is probably my biggest mistake, as these communication blockers get in the way of us resolving any disputes we have.
:PROPERTIES:
:Author: causalchain
:Score: 2
:DateUnix: 1530108271.0
:DateShort: 2018-Jun-27
:END:

******* u/CCC_037:
#+begin_quote
  On another note, I've noticed that my poor attempts at argument have created general counterarguments that they can use against me. Eg. "if you respond that means you haven't listened to what I said". This is probably my biggest mistake, as these communication blockers get in the way of us resolving any disputes we have.
#+end_quote

Hmmm. The first idea that occurs to me to resolve this is a simple modification of the strategy I suggested earlier - after waiting and hearing out their entire argument, summarise it back to them. I'd recommend using a phrasing along the lines of "So, to rephrase your argument, <summary>. Is this correct?" - then, if they say 'no' you can ask for clarification, while if they say 'yes' they can no longer legitimately claim that you were not listening and you can go ahead and present your counter-argument.

I hope this works out for you.
:PROPERTIES:
:Author: CCC_037
:Score: 2
:DateUnix: 1530110714.0
:DateShort: 2018-Jun-27
:END:

******** This is good, I will use this.
:PROPERTIES:
:Author: causalchain
:Score: 2
:DateUnix: 1530111029.0
:DateShort: 2018-Jun-27
:END:


*** I was going to second the recommendation of [[https://en.wikipedia.org/wiki/How_to_Win_Friends_and_Influence_People][How to Win Friends and Influence People]], but I see that you've already read it. In that case, I would recommend reading it again :)

That said, it bears remembering that, in general terms, humans do not default to being explicitly rational in the sense of epistemic or instrumental rationality. Instead, we are adaptation-executors, with adaptations pertaining to social status (external) and self concept (internal) being extremely prominent. Based on a combination of our own feelings and the reactions we perceive from others, we form a narrative. In that story, we play a role that we find plausible and appealing in some way -- rebel, leader, hero, victim, listener, communicator, student, teacher, etc.

Stories need contrast or conflict to be interesting. So while you might in some cases appeal to a common enemy or upcoming calamity to establish the need for an alliance, this doesn't always work. Instead, people often look to distinguish themselves from whatever role you are playing so that they can play a separate role.

Thus, while you are playing the role of the truth-seeking rationalist, assuming you do it well, it can produce pressure for others to respond with a visibly contrasting role -- pragmatist, perhaps, or faithful believer. This pressure basically continues until rationalism fades into the background and becomes a common cultural assumption instead of an individualistic trait. A possible solution to this would be to break the frame of the role they are playing by assuming an aspect of the role yourself, for example if they try to play the nutty flat earther as comic relief foil to a dour Spockian rationalist role you've fallen into, you might use logic based humor as a way to make the comic role redundant and thus less appealing.

Another issue to consider is simply cognitive miserliness. We tend to go with what needs less energy to process. So models that seem simpler and easier to process, or things we are instinctively attuned to (such as stories instead of math) tend to take prominence without any effort. In this situation it may make sense to pick a time when the person has extra energy (like on a day off when they are well rested, instead of right after work when they are exhausted) or motive to spend energy (like when considering ways it might be crucial to survival or one's reputation) on considering the correct model.
:PROPERTIES:
:Author: lsparrish
:Score: 2
:DateUnix: 1530076433.0
:DateShort: 2018-Jun-27
:END:

**** Thanks for your comment, this is a really interesting way to model things. Indeed, I have considered an issue of mine which rings in a similar way. I find that in interactions with people who have an expectation of me, I have this compulsion not to break their expectations (or as it really is, what I /think/ their expectation is). The feeling is quite similar to not wanting to admit to lying.

An example would be when someone is trying to convince me of something. Often I find that I come to agree with them, but my physical response lags behind, acting like someone who is slowly being convinced. I'm not sure if this is similar or completely different from your model of roles, but if you have any insight then I would be very interested.

I (think I) get the gist of your model but I don't see it in real life. I definitely have experienced unwittingly playing the devils advocate and rudely awakening to realise that while I mostly agree with the person I'm talking to, they don't know that since we've only discussed things we disagree on. I don't yet see this role-fitting on the more general scale, so I would be intrigued if you have any examples and elaborations.

For the case of my superior: Unfortunately, I don't think I play the rationalist role very well, and probably appear insolent more than anything; I suck at applying rationality to /actually doing things/ so it looks like I'm just trying to use cheap talk to get out of work. For all I know, that is exactly what I'm doing and all my rationality is just a story I made for myself. I hope it isn't.
:PROPERTIES:
:Author: causalchain
:Score: 2
:DateUnix: 1530109601.0
:DateShort: 2018-Jun-27
:END:


*** u/ben_oni:
#+begin_quote
  My belief that they are the less rational party comes from prior experiences
#+end_quote

Your belief is in error. Self-perception bias causes us to believe we are better than we actually are; in this case, you value the virtue of /rationality/ and have developed narratives to support that belief. Whether it is true or not, that belief is inherently harmful in your relations with other people.
:PROPERTIES:
:Author: ben_oni
:Score: 2
:DateUnix: 1530103208.0
:DateShort: 2018-Jun-27
:END:

**** You're right, I shouldn't believe that I am being rational just because I value rationality. I think that I do not overestimate myself, but I may very well be in error. I consider myself an aspiring rationalist at best, a wishful thinker at worst. I think that I am aware of the risk of my biases, but I am also aware that the thought makes me even more vulnerable.\\
I agree that believing they are less rational is inherently harmful, but I can't just will away what I think to be true. Even so, I only disrespect them in this one aspect; in general they are very capable and superior to me in almost every way.
:PROPERTIES:
:Author: causalchain
:Score: 1
:DateUnix: 1530107439.0
:DateShort: 2018-Jun-27
:END:


** Are there any good EU based charities that focus on life extension research? I'm currently donating to several different charities that focus on research into specific diseases (heart/brain/cancer), but I get the impression that those kind of charities are kinda overfunded and doing research into ageing seems like it would be a more generic solution anyway.

The EU based restriction is because tax benefits make it nearly twice as effective for me to donate to EU based charities relative to non-EU based ones.
:PROPERTIES:
:Author: Silver_Swift
:Score: 6
:DateUnix: 1529949606.0
:DateShort: 2018-Jun-25
:END:


** Go you guys think No Game No Life is rational fiction? For those who don't know, NGNL is about a brother/sister duo who are /very/ good at games, and get transported into a world where all conflict is decided by games.

I believe it is rational fiction, though it is hidden sometimes by silly character motivations and fanservice (Though, at one point the main characters use fan service as a distraction in order to win a game.)
:PROPERTIES:
:Author: Iwasahipsterbefore
:Score: 1
:DateUnix: 1530009738.0
:DateShort: 2018-Jun-26
:END:

*** I think most people here would enjoy it but it's not even remotely rational, just occasionally intelligent and munchkiny.
:PROPERTIES:
:Author: Makin-
:Score: 8
:DateUnix: 1530057534.0
:DateShort: 2018-Jun-27
:END:

**** This. It's entertaining for a lot of the same reasons, having a character who wins via intelligence rather than strength or having unique magical powers. But a lot of the intelligence is "told not shown", the games usually lay out the rules ahead of time in attempt to convince the reader that it's "fair play", but they're usually vague enough that the specific interpretation the MC uses to win isn't necessarily predictable. Usually that's how he wins, by exploiting a loophole in the rules because they weren't specific enough, so I guess that's somewhat rational, but only somewhat.
:PROPERTIES:
:Author: zarraha
:Score: 2
:DateUnix: 1530122286.0
:DateShort: 2018-Jun-27
:END:


*** While it has several themes that we tend to like here (the most obvious being "smart people actually doing smart things win by being smart", I can think of several ways in which it is irrational. Silly characters aside, the most obvious is that part where the brother "disappears" and the sister magically knows how to play her game because their bond is so strong or something?

I personally quite enjoyed it though.
:PROPERTIES:
:Author: Flashbunny
:Score: 3
:DateUnix: 1530053282.0
:DateShort: 2018-Jun-27
:END:


** Just caught up on Westworld! Pretty fun stuff, though I think I liked S01 more. Some quick, snarky, spoiler-y speculation:

When trying to estimate the eleven thousand lines of parameter values of whatever for the behavioral models of each of the guests, they really shouldn't have bothered with perfect retrodiction in silico -- I think this is why James-Delos-bot bugged out so quickly in the physical world (/test set), because the fitted model was trying to make predictions out of sample (either because of the complexity of the real world, or b/c by construction model was never trained on his fancy designed-by-apple hotel suite), which when overfit af it's gonna have trouble with. I think they even confirmed this with their "human sanity occupies a narrow band, most possible consciousnesses are batshit" line. They should have tried fitting a multilevel model to all the guests, to adaptively regularize a prior distribution describing the range of plausible human personality (i.e. estimate the hyperparameters describing human behavior as a whole, or at least the cross section of rich people able to visit the park). Maybe then they could have avoided the seemingly inevitable breakdown.

Of course, if they're making basic Stats 101 mistakes like that, their model probably sucked to begin with. I guess it worked well enough for the non-inferred hosts, though? Maybe "good" parameter values were just selected by hand for those, or else they were running on an entirely different model (they did have differently shaped positronic brains, right? The white tennis-ball-sized thing vs the shiny dark marble? Although I guess the former might have just been a casing for the latter).
:PROPERTIES:
:Author: phylogenik
:Score: 1
:DateUnix: 1529985770.0
:DateShort: 2018-Jun-26
:END:

*** Haven't watched season 2 yet, so I'm ignoring the rest of your post, but:

#+begin_quote
  can't seem to get spoiler bars to work right, sorry
#+end_quote

There are two ways to spoiler text:

>!Spoilery spoilers!<

becomes:

Spoilery spoilers

and

[Mouseover for spoilers](#s "Spoilery spoilers")

becomes:

[[#s][Mouseover for spoilers]]
:PROPERTIES:
:Author: Silver_Swift
:Score: 2
:DateUnix: 1530042042.0
:DateShort: 2018-Jun-27
:END:

**** Thanks! I was trying to do the first one but only the second was in the sidebar and all other guides I found to do the first sort online didn't seem to work. I'll edit it with proper spoiler bars.
:PROPERTIES:
:Author: phylogenik
:Score: 2
:DateUnix: 1530042441.0
:DateShort: 2018-Jun-27
:END:
