#+TITLE: [Q]Why is a copy of you still you?

* [Q]Why is a copy of you still you?
:PROPERTIES:
:Author: Articanine
:Score: 23
:DateUnix: 1442978020.0
:DateShort: 2015-Sep-23
:END:
Destructive mind uploading, essentially creates a copy of you in a computer, and destroys your original mind. I mean its great and all that a copy of you still loves on, but the original you still dies. You still died, what's so great about that? I mean if I died I wouldn't care if I had a copy or not because I would be dead. So why would you guys say that a copy of you is still you?


** For the cautious, like myself, there is a different procedure to follow under the Ship of Theseus. It's called the Moravec procedure [[https://en.wikipedia.org/wiki/Mind_uploading][(Gradual Replacement on Wikipedia)]], and it's designed to effect digital upload with no discontinuity in consciousness or awareness. The brain is gradually eaten by nanotechnology, and the parts that are consumed are simulated by a computer and interact with the remainder of your organic brain while it is being consumed.

You function entirely normally throughout the procedure, and in the end you are an entirely digital mind, without ever doing so much as falling asleep or going under anesthetic. Still not something to follow if you believe that "quantum" plays some magical effect in personhood, identity, consciousness, or whatever the hell people call the soul nowadays, but it is sufficient to cover the objection you lay out in the OP.

This is borne out of a concern for some special internal reference frame. I consider copies to be the same as the original in every respect from the outside (barring actual technical differences in the behavior of the mind), but I have never left my brain (besides my dissolution under anesthetic and /maybe/ during sleep), so I am still somewhat concerned about leaving it within a discontinuity. The only times I've considered discontinuous upload for myself, I was more suicidal than less, so at the very least it is something I would have to change my intuition on, and I don't have enough evidence about discontinuities that already happen (general anesthesia, /maybe/ sleep) to convince myself on that point.
:PROPERTIES:
:Author: Transfuturist
:Score: 36
:DateUnix: 1442980682.0
:DateShort: 2015-Sep-23
:END:

*** I like this idea. My view is that "you" are a ball of electricity running in a certain pattern, bouncing around a brain. If that is extinguished, you are dead. Your description would be a way to carefully transfer the continuous ball of electricity over to a computer without interrupting its pattern or turning it off. The interesting question is what happens if you are cryopreserved. I guess according to my own definition, you would die, and a copy of you would wake up in your body. So if souls exist, your original soul would stay in the afterlife and another soul would animate your body, instead of your original soul being transferred back into your body.
:PROPERTIES:
:Author: pizzahotdoglover
:Score: 6
:DateUnix: 1442983034.0
:DateShort: 2015-Sep-23
:END:

**** Churn infinite saved souls into heaven by oscillating the pope between barely alive and barely dead?
:PROPERTIES:
:Author: Gurkenglas
:Score: 18
:DateUnix: 1442999423.0
:DateShort: 2015-Sep-23
:END:

***** There's a relevant SMBC where they discover that, since beings are ensouled at conception, arbitrarily large amounts of souls may be generated by continuously dividing and joining zygotes and egg. The society in question then sells the souls to lucifer in return for immortality.
:PROPERTIES:
:Author: GaBeRockKing
:Score: 8
:DateUnix: 1443031916.0
:DateShort: 2015-Sep-23
:END:

****** one of my favorites in fact!
:PROPERTIES:
:Author: puesyomero
:Score: 2
:DateUnix: 1443063762.0
:DateShort: 2015-Sep-24
:END:


***** Ah, [[/r/rational]]. You say the funniest things.
:PROPERTIES:
:Score: 4
:DateUnix: 1443007740.0
:DateShort: 2015-Sep-23
:END:

****** It's like the plan to activate all the slayers by making Buffy spin in/out her grave.
:PROPERTIES:
:Author: Gurkenglas
:Score: 8
:DateUnix: 1443016059.0
:DateShort: 2015-Sep-23
:END:


***** If he agreed to it then it's suicide and they're all going to hell. If he didn't agree to it then that's fucked up.
:PROPERTIES:
:Author: psychothumbs
:Score: 5
:DateUnix: 1443029501.0
:DateShort: 2015-Sep-23
:END:

****** Shut up and calculate, we need to fill this uncountable infinity somehow!
:PROPERTIES:
:Author: Transfuturist
:Score: 5
:DateUnix: 1443041366.0
:DateShort: 2015-Sep-24
:END:


**** It's complicated by the ball of electricity being shaped and maintained by the physical brain. You are able to fall asleep, fall into a coma, and even die for short periods, but barring physical/chemical damage, your brain is able to reform your pattern much as a switched-off computer can fire up and and proceed to automatically reload your preferred operating system and personal environment.

The question then becomes: does cryopreservation preserve sufficient information to allow a future reconstruction process to build a platform which would result in booting up a mindstate /sufficiently close to the original/ that it would be considered an instance of You-the-original?

From an internal perspective, the mind (assuming it was healthy and functioning) would have the original's memories and personality, and perceive the discontinuity as nothing more than a long sleep or coma.

From an external perspective, there would probably be a lot of legal issues, because current legal systems do not recognize transferral or copying of mindstates from the original substrate (admittedly, this is mostly because there has never really been a call for it yet). Identity is currently mostly based on physical markers - fingerprints, DNA matches, visual traits such as facial appearance. Your new body (assuming you had one and were not being run on software) would be considered a separate identity by default under modern systems.

You could get around this with some preparation - setting up a (probably nonprofit) corporate entity whose day-to-day maintenance is handled by lawyers, and whose corporate rules include something along the lines of "In the absence of designated source of CEO-level directives, CEO-level directives may be issued by any source which holds the passphrase." Your could then go to the lawyers, give the passphrase, and install your identity (if you had one) as the new CEO, both as your original self and after coming back from cryo. Have the corporation own all your personal resources in the first place, and you don't need to worry about them being dispersed if your original self dies.

The next major legal problem is attaining a legal identity if you are not corporeal. A little easier in countries where corporations are able to obtain citizenship status, but still difficult to be recognized globally as a human unless you are walking around in (or at least tele-operating) a meat body. The main problem is gaining identity for a body which was not 'born' in the conventional manner. Unless you have the resources to own and operate an orphanage, hospital, or other facility capable of processing paperwork for teenagers or adults who have 'lost their memory' and need new government-approved identities to operate in society, you are going to have problems.

(I presume there is at least some process for issuing new identity documents to adult civilians whose previous identities cannot be determined, but it would not surprise me if it required intervention and/or pressure from medical organizations. And gaining identity can itself be different from gaining citizenship.)
:PROPERTIES:
:Author: Geminii27
:Score: 7
:DateUnix: 1443008453.0
:DateShort: 2015-Sep-23
:END:

***** u/Transfuturist:
#+begin_quote
  your brain is able to reform your pattern
#+end_quote

Have we ever observed recovery from brain-death? I don't believe anyone's ever recovered from loss of electrical activity in the brain.
:PROPERTIES:
:Author: Transfuturist
:Score: 2
:DateUnix: 1443022430.0
:DateShort: 2015-Sep-23
:END:

****** We use induced hypothermia in open heart surgery pretty routinely nowadays. There are also instances of people recovering from extreme hypothermia where no brain activity can be detected. So, I'd have to tentatively say yes, there have been instances of recovery from loss of electrical activity in the brain before.
:PROPERTIES:
:Author: aperrien
:Score: 5
:DateUnix: 1443053594.0
:DateShort: 2015-Sep-24
:END:


****** [deleted]
:PROPERTIES:
:Score: 7
:DateUnix: 1443028950.0
:DateShort: 2015-Sep-23
:END:

******* I'd like to see the ethics review boards for /those/ experiments.
:PROPERTIES:
:Author: Transfuturist
:Score: 5
:DateUnix: 1443041286.0
:DateShort: 2015-Sep-24
:END:

******** [[http://embed.gyazo.com/ebd4b168de40662070fcaed02343ca1b.png]]
:PROPERTIES:
:Author: sole21000
:Score: 5
:DateUnix: 1443056917.0
:DateShort: 2015-Sep-24
:END:


****** Hmm. Perhaps. Wetware makes things complicated - anything capable of suppressing electrical activity to the point of dispersing the overall pattern would most likely also damage the cells.

I'd like to think that it'd be possible to construct a copy of a brain cell-by-cell, load each cell with the correct levels of assorted biochemicals and electrical potential, and then let it all kick off. Tricky to not accidentally trigger something like an epileptic fit, though, although maybe it would be robust enough to settle down into normal operation?
:PROPERTIES:
:Author: Geminii27
:Score: 0
:DateUnix: 1443023450.0
:DateShort: 2015-Sep-23
:END:


***** So, in the future, immortals would all seek citizenship in The City of London, as they recognize corporate citizens.
:PROPERTIES:
:Author: Frommerman
:Score: 1
:DateUnix: 1443206378.0
:DateShort: 2015-Sep-25
:END:


*** Î”
:PROPERTIES:
:Author: kaukamieli
:Score: 3
:DateUnix: 1443049888.0
:DateShort: 2015-Sep-24
:END:


** I think the traditional arguments on this notion that can be found elsewhere are strong, but if they have not persuaded you it might help you to think about it from this different perspective instead: I don't care about avoiding death per se so much as I 1. care about avoiding the painful and existentially unpleasant process of dying, and 2. care about getting to experience the enjoyable process of living. I can't see any sense in which death or nonexistence is bad that doesn't fall into one of those two categories. If that's so, then destructive uploading is no big deal. Do you see any third reason death is bad that I have missed here?
:PROPERTIES:
:Author: chaosmosis
:Score: 7
:DateUnix: 1442984378.0
:DateShort: 2015-Sep-23
:END:

*** Well, this may come across as a bit selfish, but honestly I really don't care what happens after my death. I mean if there's a copy of me running around after I die that's great and all but it makes no difference to me because I am still dead.
:PROPERTIES:
:Author: Articanine
:Score: 4
:DateUnix: 1443014215.0
:DateShort: 2015-Sep-23
:END:

**** You're saying that you don't think destructive uploading satisfies 2. It causes a copy of you to experience the enjoyable process of living, but not you yourself to experience that process. I didn't anticipate this as a possible response, honestly. Maybe going into more detail will help get the intuition across better.

Under normal circumstances, when a human dies, they still exist as a dead body. Do you think that you would enjoy existing as a dead body? Likely not. Likely, you believe that personal identity in a moral sense is not found in the simple physical fact that mass and energy are conserved. Instead, you believe that your identity lies within the content within your mind. This is about information.

Similarly, like you, I care about my own experiences, not someone else's. But what makes an experience "mine"? I think that an experience is mine if external circumstances interact with my thoughts and feelings and memories. That is, if they interact with a particular pattern of information.

What is an "experience" in the first place? A certain kind of information.

If identity is information, then it does not make sense to say that information can be identical without identity being identical. To deny the equivalency is to say that identity is not information. For the reasons given in the above paragraphs, it seems like your value system commits you to the view that identity is indeed found within information.

Does this make more sense? If you disagree with the idea that identity is found within information, where would you place it instead? What additional pieces would you add to metaethics, and why are they necessary?
:PROPERTIES:
:Author: chaosmosis
:Score: 4
:DateUnix: 1443027470.0
:DateShort: 2015-Sep-23
:END:


**** u/nicholaslaux:
#+begin_quote
  because I am still dead
#+end_quote

Your initial question was effectively asking people to explain what they think of as their self-identity, but this seems to be indicating that you already have an answer (your self-identity is your current physical body, rather than, say, your collection of memories, or your thought processes, or something else) and aren't especially interested in other opinions on it.

It's possible that's just how I'm reading this post and that's not what you meant, but that is how it comes across to me.
:PROPERTIES:
:Author: nicholaslaux
:Score: 2
:DateUnix: 1443037695.0
:DateShort: 2015-Sep-23
:END:


*** *3. I care about the feelings of some people who will still be there when I'm not, and might miss me.
:PROPERTIES:
:Author: Jules-LT
:Score: 1
:DateUnix: 1443001354.0
:DateShort: 2015-Sep-23
:END:

**** Okay, still seems fine unless your friends hate robots.
:PROPERTIES:
:Author: chaosmosis
:Score: 1
:DateUnix: 1443025019.0
:DateShort: 2015-Sep-23
:END:


** [deleted]
:PROPERTIES:
:Score: 9
:DateUnix: 1442991615.0
:DateShort: 2015-Sep-23
:END:

*** Are you sure about that, if you cease to exist then why do you have dreams? Additionally, I read an article somewhere that stated that even when sleeping you still have a minimal level of consciousness in order to experience dreams. So really, the only time you cease to exist is when you die, I don't think your mind can restart after a shut down,however, if you have evidence on the contrary can you please link it.
:PROPERTIES:
:Author: Articanine
:Score: 3
:DateUnix: 1443014091.0
:DateShort: 2015-Sep-23
:END:

**** We also have comas where people do not dream, which people are capable of recovering from.

I guess I don't really think of dream consciousness to be the same as waking consciousness anyway. It's more like dream consciousness is just a side effect of your brain undergoing a defrag process, while waking consciousness is a side effect of normal brain operation. There's a potential bridge between them, in the form of lucid dreaming, but ... it's tough for me to say "oh yeah, that's me" when talking about dreams, simply because the dream version of myself behaves in ways that are far different from what I would expect of even an imperfect clone of myself.
:PROPERTIES:
:Author: alexanderwales
:Score: 4
:DateUnix: 1443021143.0
:DateShort: 2015-Sep-23
:END:


**** Dreaming only usually happens during REM sleep, which is the shortest phase of sleep. You are not dreaming at all for several hours each night, and sleep studies show that your higher brain functions run radically differently during deep sleep as well, indicating a lack of consciousness.
:PROPERTIES:
:Author: Frommerman
:Score: 2
:DateUnix: 1443207022.0
:DateShort: 2015-Sep-25
:END:


**** [deleted]
:PROPERTIES:
:Score: 2
:DateUnix: 1443028335.0
:DateShort: 2015-Sep-23
:END:

***** u/Transfuturist:
#+begin_quote
  Would you want to live in a state of constant dreaming, unable to interact with the outside world, unable to realize that you're dreaming, constantly forgetting what you just dreamt?
#+end_quote

The quality of the sensory experience does not have any special consideration for its existence. You are conscious while you're dreaming. I don't think you can even say for certain that experience is interrupted even in the case of anesthetic or comas, as there is still brain activity, and you might simply not /remember/ any experience you do observe. That is massively internal, and we need further research to say anything on the subject.
:PROPERTIES:
:Author: Transfuturist
:Score: 3
:DateUnix: 1443042354.0
:DateShort: 2015-Sep-24
:END:


*** And if you take this to the conclusion every nanosecond your brain stops and starts. The universe isn't infinitely fidelity and your brain certainly doesn't operate on the lowest level anyway.
:PROPERTIES:
:Author: RMcD94
:Score: 2
:DateUnix: 1443003139.0
:DateShort: 2015-Sep-23
:END:

**** Precisely. The mind-pattern which exists after one nanosecond, or after an eight-hour sleep, is merely the /closest match/ to the previous pattern, to the point where average human senses can't tell the difference.

And even then, we can usually tell when someone's just woken up and when they're halfway through their day. We just lump it all under a group of states we consider to be sufficiently "that person".
:PROPERTIES:
:Author: Geminii27
:Score: 3
:DateUnix: 1443009183.0
:DateShort: 2015-Sep-23
:END:


** [[http://lesswrong.com/lw/qx/timeless_identity/]]
:PROPERTIES:
:Author: EliezerYudkowsky
:Score: 18
:DateUnix: 1442979339.0
:DateShort: 2015-Sep-23
:END:

*** I agree with your stance on cryonics - but with respect to deconstructive-reconstructive teleporters, would this prediction pay its rent? Would you actually enter such a teleporter? Telling me that the copy created on the other end is me does little to calm me, given that the "original" destroyed on this end is /also/ me. So, even given the fact that the copy is me - a point that you do make well - 50% of all mes die every time I enter the teleporter. It's a game of Russian Roulette, even if it doesn't look like it from the outside - and "the outside" includes previous teleporter users, because the ones you're talking to are obviously the survivors.
:PROPERTIES:
:Author: LiteralHeadCannon
:Score: 5
:DateUnix: 1443027352.0
:DateShort: 2015-Sep-23
:END:

**** Just modify yourself to only care about at least one copy of your pattern continuing to exist. It's saner in the long run.

The "just-a-copy" intuition is tempting, but it's physically unsustainable - you end up having to "tag" a particular configuration of particles as "you" and in the next breath say that another, physically identical configuration is "not you". Which is literally not possible without dualism - the tag is almost by definition superphysical (since if it was physical, we could duplicate it.)

Oh, you might say, but the tag is just an abstraction - it's just part of my model of the universe. But then I say, exactly what /physical properties/ is that abstraction based on? It can't be something you /perceive/ - all your senses are physical. So the forced conclusion is that "I" is physically arbitrary, or indexical. But if it's indexical, you're forced to admit that you "one second in the future" is a different person than "you now".

Then you get into continuity. But /the transporter clone has continuity too/.

By the way, this is why dualists-in-denial like to take refuge in quantum, since it offers some "promising" (if you're trying to cling to a single consciousness) claims about noncopyability. Unfortunately, our brains almost certainly aren't quantum computers.
:PROPERTIES:
:Author: FeepingCreature
:Score: 3
:DateUnix: 1443033750.0
:DateShort: 2015-Sep-23
:END:

***** u/deleted:
#+begin_quote
  Oh, you might say, but the tag is just an abstraction - it's just part of my model of the universe. But then I say, exactly what physical properties is that abstraction based on? It can't be something you perceive - all your senses are physical. So the forced conclusion is that "I" is physically arbitrary, or indexical. But if it's indexical, you're forced to admit that you "one second in the future" is a different person than "you now".
#+end_quote

Welllll... sorry, but I've been starting into analysis and topology, so this now bugs me.

That is, I could just say, sure, "one second into the future" /is/ different from me. But it's only a /continuous/ change. I could easily charge that there are some /discrete/ changes which may be physical continuations of "me", but don't have the same "personal identity" (for all that such is a meaningful, rigorous concept, which is not much).
:PROPERTIES:
:Score: 7
:DateUnix: 1443040422.0
:DateShort: 2015-Sep-24
:END:

****** Bringing continuity questions into physics is a bit iffy. On the one hand, /all/ physical changes are continuous, since every particle in the universe moves along differentiable, slower-than-light paths.

On the other hand, we have some unanswered questions about time and space at the smallest scales, and calculus concerns itself with /infinitely/ small scales.
:PROPERTIES:
:Author: Chronophilia
:Score: 2
:DateUnix: 1443044307.0
:DateShort: 2015-Sep-24
:END:

******* u/Sceptically:
#+begin_quote
  On the one hand, all physical changes are continuous, since every particle in the universe moves along differentiable, slower-than-light paths.
#+end_quote

Quantum tunnelling.
:PROPERTIES:
:Author: Sceptically
:Score: 3
:DateUnix: 1443046697.0
:DateShort: 2015-Sep-24
:END:


******* You could also be aware that the brain does all it's information processing in "steps" as it were. The spiking activity is pretty discrete. Now that does not rule out some sort of chemical based computation, and I do not have all the facts on those.
:PROPERTIES:
:Author: aperrien
:Score: 1
:DateUnix: 1443053882.0
:DateShort: 2015-Sep-24
:END:


******* I would be more likely to argue that everything is discrete since the universe doesn't have an infinite resolution

On the other hand there is never a difference between sleep and teleporting.
:PROPERTIES:
:Author: RMcD94
:Score: -1
:DateUnix: 1443050231.0
:DateShort: 2015-Sep-24
:END:

******** Not really, I dislike the fact that this keeps getting brought up because sleeping involves continuity of consciousness while teleportation does not
:PROPERTIES:
:Author: Articanine
:Score: 2
:DateUnix: 1443057208.0
:DateShort: 2015-Sep-24
:END:

********* How does it? You lose continuity the moment you fall asleep?
:PROPERTIES:
:Author: RMcD94
:Score: -1
:DateUnix: 1443086479.0
:DateShort: 2015-Sep-24
:END:

********** You actually maintain continuity of consciousness throughout sleep; it's memory formation that's interrupted.
:PROPERTIES:
:Author: LiteralHeadCannon
:Score: 3
:DateUnix: 1443109468.0
:DateShort: 2015-Sep-24
:END:

*********** How are you defining continuity?
:PROPERTIES:
:Author: RMcD94
:Score: -1
:DateUnix: 1443110264.0
:DateShort: 2015-Sep-24
:END:


****** The copy is discontinuous in position. But that's not the sort of thing, /by itself/, that physics allows you to /even care/ about. And if you really want to care about it, you have to say that your consciousness is sensitive to the gravity of distant stars or something, which just seems silly.
:PROPERTIES:
:Author: FeepingCreature
:Score: 1
:DateUnix: 1443091916.0
:DateShort: 2015-Sep-24
:END:

******* Sure, I totally identify with continuous past-and-future extensions of myself. Such as the me who typed that previous sentence, for instance.

However, before swallowing the arguments being made at the top-level for the proposition OP is asking about, I'd like to actually see the science. After all, it's /pretty weird/ that a group of people normally obsessed with scientific and statistical evidence are suddenly making /verbal, analytical-philosophical arguments/ about a proposition that /only run in favor with almost none against/. It stinks of rationalization in the face of an empty pool of evidence.
:PROPERTIES:
:Score: 2
:DateUnix: 1443103995.0
:DateShort: 2015-Sep-24
:END:

******** I mean, we're talking about a definitions debate here. "What does it mean to be /you/" is not something that has an objective answer. What, would you have us measure the color of the souls of the copy and the original?

I can find somebody who wrote my argument up in PDF form with cites at the bottom, if you like, but that's about as scientific as I can make it.
:PROPERTIES:
:Author: FeepingCreature
:Score: 1
:DateUnix: 1443157095.0
:DateShort: 2015-Sep-25
:END:

********* u/deleted:
#+begin_quote
  "What does it mean to be you" is not something that has an objective answer.
#+end_quote

Of course it has an objective answer. It's just dependent on your mind's internal, preverbal self-concept.
:PROPERTIES:
:Score: 2
:DateUnix: 1443163910.0
:DateShort: 2015-Sep-25
:END:

********** "Subjective" literally means "dependent on your mind". :-)

Anyway, I'm not saying "this is correct"; I'm saying "if you believe that, you're not basing it on physics."
:PROPERTIES:
:Author: FeepingCreature
:Score: 2
:DateUnix: 1443169198.0
:DateShort: 2015-Sep-25
:END:

*********** u/deleted:
#+begin_quote
  "Subjective" literally means "dependent on your mind". :-)
#+end_quote

Well no, it means "dependent on your opinion."
:PROPERTIES:
:Score: 2
:DateUnix: 1443190198.0
:DateShort: 2015-Sep-25
:END:


******** Well, it is an empty pool of evidence for now. We don't have a deconstructive teleporter or a brain uploader right now, so we cannot say whether any of our philosophical ideas work in reality for sure.
:PROPERTIES:
:Author: Frommerman
:Score: 1
:DateUnix: 1443206745.0
:DateShort: 2015-Sep-25
:END:

********* Which is precisely why we should be very, very skeptical about these things.
:PROPERTIES:
:Score: 1
:DateUnix: 1443206934.0
:DateShort: 2015-Sep-25
:END:


***** I'm not saying the version on the other end /isn't me/. I'm saying the version on this end /is me/. If I accept that the version on the other end is me, which I do, then 50% of mes die when the teleportation event occurs. It's directly equivalent to flipping a coin that kills you when it comes up heads - an activity that also "leaves at least one copy of your pattern continuing to exist".

You either accept quantum immortality (which has some really weird and interesting implications, but it's not scientifically provable and I'd prefer all things considered not to test it myself, because humans are survival-seeking mechanisms) or you accept that entering a teleporter is equivalent to the "I shoot you if the coin comes up heads" game I described.
:PROPERTIES:
:Author: LiteralHeadCannon
:Score: 4
:DateUnix: 1443035345.0
:DateShort: 2015-Sep-23
:END:

****** I really hope quantum immortality is true, or some other form of solipsistic immortality, because that gets me a way /out/ of this dying universe.

I imagine some really trippy and horrible mind-modifying effects would come about when your brain is being destroyed. Quantum immortality doesn't mean guaranteed humanity, wholeness, or mental health. It just means that you never stop observing. Ever.
:PROPERTIES:
:Author: Transfuturist
:Score: 4
:DateUnix: 1443041949.0
:DateShort: 2015-Sep-24
:END:


****** u/FeepingCreature:
#+begin_quote
  an activity that also "leaves at least one copy of your pattern continuing to exist".
#+end_quote

No it actually doesn't.

#+begin_quote
  then 50% of mes die when the teleportation event occurs
#+end_quote

Yeah but it's not a messy painful death - it's just a spontaneous ceasing to exist. And a you is still around. Our intuitions are not well suited for this situation.

Imagine I run two copies of you. I leave them running in perfect lockstep. Then I turn one off.

Try to explain to me how what just happened is /bad/.

Imagine being in the experience of that copy. You're just happily existing along - when suddenly, nothing whatsoever bad-feeling happens, and a version of you who had the /exact same experience up until that moment/ happily goes about their day. How is that a different person? It can't even /indexically/ be considered a different one, since you are literally incapable of diverging.

This is the part that I don't get. /Why on earth/ would you choose, when deciding "for both", to identify with the version that stops existing? It has no outside benefit- and the inside is identical.
:PROPERTIES:
:Author: FeepingCreature
:Score: 1
:DateUnix: 1443091640.0
:DateShort: 2015-Sep-24
:END:

******* Suppose that we replace the instantaneous deconstruction component of the teleporter with a handgun. Now, I'll concede that if I /had/ to choose between being instantaneously deconstructed or being shot to death with a handgun, I'd choose the former, because it's a less unpleasant experience. But that's obscuring the reason that you'd choose just about any non-death thing over being instantaneously deconstructed - because you don't want to experience death.

Would you enter a teleporter that copies you over here, recreates you somewhere else, and shoots the version of you at the starting location to death with a handgun? I guess their instantaneous deconstruction mechanism must be broken.
:PROPERTIES:
:Author: LiteralHeadCannon
:Score: 3
:DateUnix: 1443110093.0
:DateShort: 2015-Sep-24
:END:

******** I'd rather there wasn't a handgun, because hey, why not two copies? But sure, I'd shoot myself if I got confirmation of receipt. If there exists a copy of my pattern elsewhere, the only value to "me" is the unique local interactions and the memories that I've diverged, which would be maybe a day at most. (The longer this goes on, the less I'd shoot myself.)
:PROPERTIES:
:Author: FeepingCreature
:Score: 1
:DateUnix: 1443157592.0
:DateShort: 2015-Sep-25
:END:


*** But is continuity of consciousness maintained?
:PROPERTIES:
:Author: Articanine
:Score: 1
:DateUnix: 1442981431.0
:DateShort: 2015-Sep-23
:END:

**** Eliezer holds that continuity of consciousness is an illusion. Anything sufficiently like yourself that functions in a sufficiently similar manner will believe that they woke up after some discontinuity, and that they are still alive. To the copy, it doesn't matter. To the original, they're too busy not experiencing anything to experience nonexistence.

Picture being frozen. You may very well "die," due to a large enough discontinuity that the homunculus staring into our universe loses its place on the record track of your life. However, once you're unfrozen (in a future where we are capable of unfreezing people without killing them), there's still a functional person there, with your memories and behaviors. That person is still alive, and it has every right to think it's you. In that sense, continuity of consciousness doesn't matter in the /slightest./ I'm simply more concerned with the original, since that's what I identify closer with, or at least my intuition does.
:PROPERTIES:
:Author: Transfuturist
:Score: 23
:DateUnix: 1442981799.0
:DateShort: 2015-Sep-23
:END:

***** u/EliezerYudkowsky:
#+begin_quote
  Eliezer holds that continuity of consciousness is an illusion.
#+end_quote

No I don't.
:PROPERTIES:
:Author: EliezerYudkowsky
:Score: 3
:DateUnix: 1443377349.0
:DateShort: 2015-Sep-27
:END:

****** u/Transfuturist:
#+begin_quote
  The gold head only remembers the green heads, creating the illusion of a unique line through time, and the intuitive question, "Where does the line go next?" But it goes to both possible futures, and both possible futures will look back and see a single line through time. In many-worlds, there is no fact of the matter as to which future you personally will end up in. There is no copy; there are two originals.

  ...

  But on an ontologically fundamental level, nothing with a persistent identity moves through time.

  Even the braid itself is not ontologically fundamental; a human brain is a factor of a larger wavefunction that happens to factorize.

  Then what is preserved from one time to another? On an ontologically basic level, absolutely nothing.

  ...

  The computational pattern computes, "I think therefore I am". The narrative says, today and tomorrow, "I am Eliezer Yudkowsky, I am a rationalist, and I have something to protect." Even though, in the river that never flows, not a single drop of water is shared between one time and another.

  If there's any basis whatsoever to this notion of "continuity of consciousness"---I haven't quite given up on it yet, because I don't have anything better to cling to---then I would guess that this is how it works.
#+end_quote

Could you elaborate on how you do not, then? Otherwise, it doesn't seem like you've explained yourself very well.
:PROPERTIES:
:Author: Transfuturist
:Score: 3
:DateUnix: 1443381919.0
:DateShort: 2015-Sep-27
:END:

******* u/EliezerYudkowsky:
#+begin_quote
  If there's any basis whatsoever to this notion of "continuity of consciousness"---*I haven't quite given up on it yet, because I don't have anything better to cling to*---then I would guess that this is how it works.
#+end_quote

I don't know how I can make it any plainer; I haven't given up on continuity of consciousness because I don't yet feel like I have a full dissolution that works without it. Other people claim they do and that they're satisfied; I don't know if I'm missing something they know, or if they're just worse than me at spotting wordless dangling loose ends. Though frankly my priors are toward the latter. Real dissolutions should be both explicable and complete.

The thing I was tentatively suggesting might embed continuity of consciousness was Pearl-style causal relations, because material persistence obviously can't do it, because there is no such thing.
:PROPERTIES:
:Author: EliezerYudkowsky
:Score: 4
:DateUnix: 1443385686.0
:DateShort: 2015-Sep-27
:END:

******** I question that materialism has any grounds for continuity of consciousness, as the concept itself seems to beg a Cartesian observer. Causality may sustain the illusion of identity in a material world, as each successor mind is continuing the cognitive computations of its predecessor and maintains a configuration consistent with the mind's past in a mind-readable format, and that is enough for a successor to identify with a predecessor.

I think we're using different meanings for continuity of consciousness. When I say that you say continuity is an illusion, I mean that you mean the intuition of a Cartesian observer arising from this identification is false. I'm not sure what you mean when you say you "haven't given up on continuity of consciousness," as I doubt you are a dualist. Do you mean continuity in the sense of the paragraph above, of continuing cognitive computations, or what?
:PROPERTIES:
:Author: Transfuturist
:Score: 1
:DateUnix: 1443395114.0
:DateShort: 2015-Sep-28
:END:


******** The one thing I've never quite understood of defenses of "continuity of consciousness" is what it's even an answer to, what requires it in this world, how a counterfactual world without it would differ from this world. I regularly have clear gaps in my continuity of consciousness; is there some important sense in which I should consider myself to have died?
:PROPERTIES:
:Author: tene
:Score: 1
:DateUnix: 1443425935.0
:DateShort: 2015-Sep-28
:END:

********* Er, the disassembling "teleporter" problem, or destructive uploading, for example? I think this whole thing is a rare instance of a philosophical issue that will actually cause people to take very different views on technological possibilities in the future. Specifically, my roommate has stated that he sees no problem with uploading himself destructively once that becomes possible, while I myself think that's completely bonkers.
:PROPERTIES:
:Author: AlcherBlack
:Score: 2
:DateUnix: 1443455663.0
:DateShort: 2015-Sep-28
:END:


***** I made a long post to say there is a difference in the sleep thing, possibly not knowingly losing the continuity, and making a 100% perfect clone of yourself and killing yourself and knowing you'll stop experiencing things and that the clone will take your place.

Especially if you upload just your mind. Then when you realize you are in a computer, you'll know the original you is probably still running around there and you are a copy. Instead of continuity, it's more of a split.

If you were to just boom, disappear and in the same moment there would appear new you which is 100% perfect copy of you, in your place, that I'd call theoretical bullshit.

If someone would replace you with 100% perfect copy when you were unconcious, that might feel like continuity in theory.

Of course, it doesn't really have to be 100% perfect copy, our bodies change all the time, so minor differences are not noticeable. Probably our minds wouldn't have to be 100% perfect copies either, it could forget quite a lot of things and it would still feel like continuity, and you'd probably not even remember you forgot something. ;) If it isn't obvious, like how to walk, but you wouldn't think you were replaced if it wasn't mainstream technology. Memory problems do happen and we change opinions and stuff, we aren't static.

Aaaand this got a bit long again, in a different way...
:PROPERTIES:
:Author: kaukamieli
:Score: 1
:DateUnix: 1443053549.0
:DateShort: 2015-Sep-24
:END:

****** I'm not arguing that a copy doesn't feel identical to the original, I'm just wary that there isn't actually some strange metaphysical shit going on.

I doubt I would be nearly so reticent about copy-and-transfer once I was actually uploaded, unless I tried to keep a continuous awareness running for as long as possible.
:PROPERTIES:
:Author: Transfuturist
:Score: 1
:DateUnix: 1443057293.0
:DateShort: 2015-Sep-24
:END:

******* u/kaukamieli:
#+begin_quote
  I doubt I would be nearly so reticent about copy-and-transfer once I was actually uploaded
#+end_quote

At least the version of you in the computer might not be, probably depending whether or not it was your decision to put yourself in the computer. Then again, it might not be a untampered copy, they might just have programmed you to think you wanted that yourself. We probably have the tech at that point.

If you were an uploded mind, would you have any way to know you are a perfect copy? No. Even if you do have a consciousness, you might be missing some of your memories, but still experience things. You still probably would not mind being experiencing things. You are you even if you had less memories, just as you are you today and you will be you tomorrow, though you have different memories. You might not be the same you, though you arguably have the same consciousness and point of reference.

Might also depend a lot on what kind of system you were put into. Something in somewhere without any connection to anywhere else, so you might still die?
:PROPERTIES:
:Author: kaukamieli
:Score: 1
:DateUnix: 1443059091.0
:DateShort: 2015-Sep-24
:END:


**** If you're uploadable with 100% fidelity, then you are, or possess a 1:1 mapping to, an algorithm. In this case, the continuation of your consciousness is simply whenever that algorithm progresses a certain minimum amount. Continuity holds as long as the upload is correctly synchronized*, whether that next step is executed in 5 picoseconds, 1 hour, or 1000 years from now.

* ie. no further mental activity occurs in your physical brain past the point at which its state is captured.

If you are not (1:1 mappable to) an algorithm, then a) the question of continuity of consciousness is moot because what is uploaded cannot be the same as you, and b) you are most likely physics defying and may be about to disappear in a puff of logic ;)

I am assuming for the sake of argument that you believe human consciousness is computable, since your question implies that.
:PROPERTIES:
:Author: tilkau
:Score: 2
:DateUnix: 1443001777.0
:DateShort: 2015-Sep-23
:END:


** It's partially a language problem. "You" is used to mean your individual self, but also used to mean "The organism which exhibits all the characteristics of yourself". As these tend to refer to the same thing pretty much 100% of the time outside of very specific SF works, there's never really been a need to separate the meanings, which is why it's easy to pose identity-based questions which are ambiguous about what they're talking about.

I find that a good analogy is to expand the idea of self to encompass a group or team of individual instances. We see this today in the form of companies - a company representative can be referred to as if they are the company, in many circumstances: "Oh, we had a meeting with BigCorp the other day" (i.e. we had a meeting with a /individual representative of BigCorp/).

So imagine the corporation of Alice. There might be two individuals, there might be a hundred. All are considered sufficiently Alice-like to be considered part of Alice. Any individual Alice-instance can be considered as their own person, but also in the context of them being an Alice.

In the case you mention, there is no confusion - the original Alice-instance is destroyed in a manner where they do not experience post-destruction continuity. The new Alice-instance is not the old one, but they are still /an/ Alice - and from an external perspective they are probably sufficiently Alice-like that they inherit the Alice relationships in existence.

Think of a major corporation which changes CEOs - the original CEO could be retired, or doing something else, or dead, but the corporation they helmed is still in existence and maintains all its legal agreements, resources, debts, contracts etc. From an external perspective, it hasn't changed.
:PROPERTIES:
:Author: Geminii27
:Score: 5
:DateUnix: 1443006992.0
:DateShort: 2015-Sep-23
:END:


** [[https://www.reddit.com/r/rational/comments/39xqpi/rrationals_view_on_the_continuity_of/cs7fq15][My reply, last time this came up]]
:PROPERTIES:
:Score: 3
:DateUnix: 1442978582.0
:DateShort: 2015-Sep-23
:END:

*** Did you delete that account?
:PROPERTIES:
:Author: traverseda
:Score: 2
:DateUnix: 1442983344.0
:DateShort: 2015-Sep-23
:END:

**** His original self died; this is a copy. :)
:PROPERTIES:
:Author: Geminii27
:Score: 9
:DateUnix: 1443008501.0
:DateShort: 2015-Sep-23
:END:


**** Yes. It's a habit of mine.
:PROPERTIES:
:Score: 1
:DateUnix: 1443004941.0
:DateShort: 2015-Sep-23
:END:

***** Ah, you're that person. I was confused because your current account is 10 entire days old.
:PROPERTIES:
:Author: traverseda
:Score: 1
:DateUnix: 1443034428.0
:DateShort: 2015-Sep-23
:END:

****** I know right! I've held onto this one for a while. I really like the username
:PROPERTIES:
:Score: 2
:DateUnix: 1443042048.0
:DateShort: 2015-Sep-24
:END:


** In a certain sense, the "you" from each instant vanishes without any trace other than the "you" from subsequent instants. Call these p1 and p2. How are they related?

There are two fundamental connections we can identify here. One is the similarity: p1 and p2 have many very similar attributes including most past memories. The other is the causal connection: p2 would (with high probability) not exist unless p1 first existed.

A high fidelity copy of you meets both of these criteria. Two such copies, or 100 such copies, would meet this criteria equally well in terms of their relationship to the original. The copies would have only the similarity relationship to each other, however.
:PROPERTIES:
:Author: lsparrish
:Score: 3
:DateUnix: 1443025972.0
:DateShort: 2015-Sep-23
:END:

*** That's not true because the difference between a copy and future you, is that there is a continuity between you and future you, while there is not one between a copy.
:PROPERTIES:
:Author: Articanine
:Score: 1
:DateUnix: 1443148905.0
:DateShort: 2015-Sep-25
:END:

**** What do you mean by "continuity", exactly?
:PROPERTIES:
:Author: lsparrish
:Score: 0
:DateUnix: 1443305726.0
:DateShort: 2015-Sep-27
:END:


** A second copy of me is still me for all the reasons the first copy ever was.

I'm sad that a first copy was destructively uploaded, because it means there's not two of me, which I would vastly prefer. But once I'm uploaded I can't imagine there being much of a barrier to making more copies. Even if I do keep them in stasis as backups.
:PROPERTIES:
:Score: 2
:DateUnix: 1443026941.0
:DateShort: 2015-Sep-23
:END:

*** u/Transfuturist:
#+begin_quote
  there's not two of me, which I would vastly prefer
#+end_quote

You're on the list of reproductive hazards now.
:PROPERTIES:
:Author: Transfuturist
:Score: 2
:DateUnix: 1443042647.0
:DateShort: 2015-Sep-24
:END:

**** Just for that? I vastly prefer there to be a second copy of you as well.
:PROPERTIES:
:Score: 3
:DateUnix: 1443042941.0
:DateShort: 2015-Sep-24
:END:


** Nobody actually knows, it's just a guess.

These things get reasonably complicated once you have multiple copies of a person and have to decide whether the death of one of them matters as much as the death of someone else.

There are just a few standard "solutions" (guesses) as to the answer -

- just this copy (but how do you distinguish "this" copy in certain edge cases?)

- as long as one copy survives (but would you really be OK with dying just because a copy somewhere else lives?)

- as long as one copy "descended" from this one survives (implies odd shifts over as your fellow copies are merely "descended" from past!you, no current!you)

- radical rejection of "identity" (almost impossible for humans, leads to people rejecting death-is-bad because it's "illogical")

Stuff like that.
:PROPERTIES:
:Author: MugaSofer
:Score: 2
:DateUnix: 1443035487.0
:DateShort: 2015-Sep-23
:END:


** [[https://www.youtube.com/watch?v=pdxucpPq6Lc][A YouTube video]] outlining the problem. It doesn't actually answer it, but is worth watching nonetheless.
:PROPERTIES:
:Author: 2-4601
:Score: 1
:DateUnix: 1443000853.0
:DateShort: 2015-Sep-23
:END:


** It depends on how you define "you".

I define "me" as my current mind state and all descendants of that mind state.
:PROPERTIES:
:Author: ArgentStonecutter
:Score: 1
:DateUnix: 1443015121.0
:DateShort: 2015-Sep-23
:END:


** My experiences are me. If I keep my experiences, I am still me. I've personally lost a bit of my body in real life, and I'm not any less 'me' than I was when I had all my pieces and parts.

If it were forced on me when my body was healthy and I wasn't done with it yet, I might be very angry, but I would still be me.
:PROPERTIES:
:Author: Farmerbob1
:Score: 1
:DateUnix: 1443094146.0
:DateShort: 2015-Sep-24
:END:


** Well it depends on your definition of "you", "self" or "I" (short words are the most complicated especially tricky pronouns which are just aliases for proper nouns that describe a complicated concept)

But for me, myself, and I: I am a vector state of thoughts and experiences. The native hardware I was developed on is fallible and has to date a 100% chance of eventual catastrophic failure. I like it and will want to emulate it after I escape, and I may have to grown and learn some different tools, but when I find a good safe way out (pls note short adjectives) I'm taking them.

Also this: [[https://xkcd.com/505/][XKCD:Bunch of rocks]]
:PROPERTIES:
:Author: Empiricist_or_not
:Score: 1
:DateUnix: 1443203466.0
:DateShort: 2015-Sep-25
:END:


** Would you agree that you now and you at age seven are both still you? And yet a copy of you now has far more in common with you now than you now and you at seven have with each other. So why wouldn't the other you be you?
:PROPERTIES:
:Author: abhassl
:Score: 1
:DateUnix: 1443304187.0
:DateShort: 2015-Sep-27
:END:


** we have no reason to believe it either would or would not be. we have absolutely no prior information on the topic.
:PROPERTIES:
:Author: lahwran_
:Score: 1
:DateUnix: 1444269668.0
:DateShort: 2015-Oct-08
:END:


** You are already a constantly changing copy of yourself. The original you constantly vanishes as time progresses and your body changes.

The idea of an 'original' is an absurdity produced by our extremely limited brains, not a real thing.
:PROPERTIES:
:Author: Detsuahxe
:Score: 1
:DateUnix: 1443000015.0
:DateShort: 2015-Sep-23
:END:


** Which of you all commenting here is a published neuroscientist or cognitive psychologist specializing in the human self-concept?

And which of you all commenting here have actually invented and experimented with "destructive mind-uploading"?

That's right, NOBODY AT ALL.

This question probably doesn't make enough scientific sense to have an answer.
:PROPERTIES:
:Score: 1
:DateUnix: 1443039822.0
:DateShort: 2015-Sep-23
:END:


** If you make perfect copies, each copy would awaken as if they were you, from a deep sleep.

If you vitrify your brain and then later it's thawed out perfectly, you'd awaken as if from a deep sleep.

Each version of you thinks it's you and with 100% fidelity in the thought experiment, many here would argue that it's "good enough" or "what's the difference?"

The argument is actually about the procedure though... people who disagree do do because they worry that something is lost. Intuitively, they know who they are, but not at a level that they can intuitively believe they can be copied or cryopreserved or mind-uploaded with 100% accuracy, since they don't know what the cutoff is where you lose key attributes about yourself that are capable of answering these questions.

What is my consciousness?

What is my identity?

Edit: well, I guess we can't answer these questions NOW, but we hope neuroscience will improve. And develop to the point that we can understand the physical reality of the brain at such a level that simulating it would be indistinguishable from the psychological inner-thinking reality that's capable of pondering such questions.
:PROPERTIES:
:Author: notmy2ndopinion
:Score: 1
:DateUnix: 1443006383.0
:DateShort: 2015-Sep-23
:END:

*** The question is not about the copy, it is about the death of the original. If you do a scan-and-transfer upload, and the meat body wakes up, it (generally) won't want to die.
:PROPERTIES:
:Author: Transfuturist
:Score: 2
:DateUnix: 1443042567.0
:DateShort: 2015-Sep-24
:END:

**** True -- I totally agree. You (v1.0) generally don't want to die.

#+begin_quote
  Destructive mind uploading, essentially creates a copy of you (v2.0) in a computer, and destroys your original mind. I mean its great and all that a copy of you (v2.0) still loves on, but the original you still dies. You(v1.0) still died, what's so great about that? I mean if I died I wouldn't care if I had a copy or not because I would be dead. So why would you guys say that a copy of you is still you?
#+end_quote

v1.0 = v2.0. They are equivalent from an identity standpoint, until they diverge, based on experiences... or death on arrival.
:PROPERTIES:
:Author: notmy2ndopinion
:Score: 1
:DateUnix: 1443056430.0
:DateShort: 2015-Sep-24
:END:
