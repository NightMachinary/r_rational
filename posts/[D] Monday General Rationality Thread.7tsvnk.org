#+TITLE: [D] Monday General Rationality Thread

* [D] Monday General Rationality Thread
:PROPERTIES:
:Author: AutoModerator
:Score: 17
:DateUnix: 1517238405.0
:DateShort: 2018-Jan-29
:END:
Welcome to the Monday thread on general rationality topics! Do you really want to talk about something non-fictional, related to the real world? Have you:

- Seen something interesting on [[/r/science]]?
- Found a new way to get your shit even-more together?
- Figured out how to become immortal?
- Constructed artificial general intelligence?
- Read a neat nonfiction book?
- Munchkined your way into total control of your D&D campaign?


** I've recently become somewhat obsessed with [[http://www.koryheath.com/zendo/][Zendo]], a tabletop game of inductive logic.

I think many people here would get a kick out of it, because the point of the game is to figure out a secret rule through experimentation.

Incidentally, I learned about its existence from a story posted here, [[https://archiveofourown.org/works/6178036/chapters/14154868][Cordyceps]].
:PROPERTIES:
:Author: awesomeideas
:Score: 11
:DateUnix: 1517260958.0
:DateShort: 2018-Jan-30
:END:

*** [deleted]
:PROPERTIES:
:Score: 6
:DateUnix: 1517424375.0
:DateShort: 2018-Jan-31
:END:

**** The 2-4-6 task was exactly how I explained it to my only friend who's read HPMOR, actually!

It's incredibly easy to make new rules, and new variations on old rules. With people who've played a lot, you can keep tacking logical operators on stuff, and as long as everyone is playing on a similar level, it just gets more fun.

That's actually an important point. The people you play with have to have the ability to hold multiple properties in their heads and use abstract thought. If you try to play with someone who doesn't have those abilities, it is just sad.

That said, I'd suggest playing with a diverse group. I've played with biology people, literature people, and engineering people in one group, and the difference in modes of thought make for clear variations in strategy which are cool to see.

When you do end up playing, please let me (and the community) know how it goes!
:PROPERTIES:
:Author: awesomeideas
:Score: 3
:DateUnix: 1517426461.0
:DateShort: 2018-Jan-31
:END:


** I think it's rational and ethical to not want to contribute to the war effort in a country that one lives in, because contributing means that one has a chance to contribute to unjust murder and I think it's rational and ethical to want to minimize this chance. This should also be balanced with one's self-interest, though, since gaining capital would let one donate money and otherwise influence the world in a positive way, thereby possibly saving lives and offsetting the chance of murder that they contribute to.

My dilemma lies with trying to figure out how much contribution is OK. Paying taxes is pretty vital to doing anything else and is otherwise a fairly minimal and general war effort contribution so I think that's OK even if it contributes to war. I think involving oneself with/working for a company that makes weapons puts one's efforts too close to the war effort to be ethical; working for a company that doesn't have any divisions that sell to the army is probably the most ethical way one can contribute to their self-interest while also minimizing war involvement.

What about companies that make a lot of things for the civilian sector but also have a division that sells stuff to the army? Is it unethical to work for them, is it rational to want to avoid those companies, even work that's outside of those divisions in those companies, if one wants to minimize the number of deaths they are involved in? Are those companies far enough away from the war effort that working for them makes a similar minimal impact as paying taxes does?

Or is my entire framework here irrational and one should just ignore the possible unjust death count one would be contributing to if they help design stuff for a company and just work anywhere?
:PROPERTIES:
:Author: DifficultReplacement
:Score: 8
:DateUnix: 1517241315.0
:DateShort: 2018-Jan-29
:END:

*** It's tougher because you don't necessarily know if the war is unjust. We can say today with great certainty participating in WW2 for the allies was just. But at the time, average citizens didn't know about concentration camps, it just appeared to be another general European war, so would in 1941 an American wanting to join the war be immoral if it made the war last longer?

Similar situation with the Iraq war. Now we know there wasn't much evidence of weapons of mass destruction. But if there was say a 1% chance of Iraq having WMDs America could stop by sending in soldiers, which an average citizen like you may think is true, then it may very well be a just war.

Even if you still think it ended up of the negative end of the moral scale, is it far enough on the negative end after weighing the positives to significantly change your life?
:PROPERTIES:
:Score: 4
:DateUnix: 1517258684.0
:DateShort: 2018-Jan-30
:END:

**** u/CCC_037:
#+begin_quote
  Similar situation with the Iraq war. Now we know there wasn't much evidence of weapons of mass destruction.
#+end_quote

This was known during most of the actual war itself. Mind you, I'm not sure if it was known /by/ the average American...

Nonetheless, if your country is in a war, then you can assume that the media you are exposed to is largely propaganda, unless you make deliberate and significant effort to ensure it is not. Does this consideration change your analysis?
:PROPERTIES:
:Author: CCC_037
:Score: 2
:DateUnix: 1517300435.0
:DateShort: 2018-Jan-30
:END:


*** What about a defensive war? Can it ever be "unjust"?
:PROPERTIES:
:Author: eternal-potato
:Score: 2
:DateUnix: 1517260800.0
:DateShort: 2018-Jan-30
:END:


*** I'm not sure what your trying to discuss. It sounds like a question about ethics and morality. Allow me to rephrase your arguments, and then let me know if I have it right, okay?

1. Unjustly killing a person is morally wrong.

2. Innocent bystanders die in war, which killings are morally wrong.

3. War, therefore, is morally wrong.

4. Actions that support a war effort are morally wrong.

5a. War-profiteering is morally wrong.

5b. War is financed by taxes, which are paid by citizens. Therefore, paying taxes in wartime is morally wrong.

--------------

First, can we agree to remove rationality from this discussion? There's nothing inherently irrational about supporting an unjust war. Rationality doesn't take sides in moral debates. Which is why the sidebar says (of rational fiction) that "factions are ... driven into conflict by their beliefs and values."

Second, is it ethical to participate in an unjust and immoral society? Is it preferable to try to change that society from within, or to leave and join a different, more just, society? If the latter, what if you decide that on the balance your society is moral and just, but that a different society is more moral and just, is it preferable to leave and join the other society?
:PROPERTIES:
:Author: ben_oni
:Score: 2
:DateUnix: 1517263557.0
:DateShort: 2018-Jan-30
:END:


*** u/CCC_037:
#+begin_quote
  What about companies that make a lot of things for the civilian sector but also have a division that sells stuff to the army?
#+end_quote

I think it depends to some degree on /what/ the company is selling to the army. Guns are one thing, bandages are a completely different thing.

I don't think it really matters how much the company sells, or who else they sell to - that is, I think it is ethical to work for a company that sells bandages, /even if/ they sell those bandages exclusively to the army.
:PROPERTIES:
:Author: CCC_037
:Score: 1
:DateUnix: 1517300598.0
:DateShort: 2018-Jan-30
:END:

**** What about electronic equipment that could potentially be used for missile guidance? Or power/conversion/managing equipment like power transformers that can be used to power military equipment, e.g. boats?
:PROPERTIES:
:Author: DifficultReplacement
:Score: 3
:DateUnix: 1517350059.0
:DateShort: 2018-Jan-31
:END:

***** You have a point. For certain electronics and some other equipment, it /does/ matter who it is sold to.
:PROPERTIES:
:Author: CCC_037
:Score: 1
:DateUnix: 1517367076.0
:DateShort: 2018-Jan-31
:END:


*** /I think you underrate the importance of taxes:/

My own personal sense of the situation is that the important thing isn't the absolute contribution of an act, but the marginal contribution of one course of action relative to another.

This is of course not the case - we must also watch out for the contribution of one's actions and precommitments on the existence/selection/stability of Nash equillibria - but for social movements that are not even remotely popular yet, ignoring these second-order features and using pure marginal analysis can probably be justified in the same way as the small angle approximation in physics.

...So, using this marginal view, we can do a economic supply/demand calculation and find the market-clearing amount of evil. The result, in the long run, for most people, I suspect, is that the supply/demand curves are such that the supplied number of bombs falls far more when they stop contributing taxes than when they decide not to work somewhere and the next highest bidder takes the job instead.

This may not be the case if the person in question is underpaid - that is, substantially more competent than the average person in their pay range.
:PROPERTIES:
:Author: BoilingLeadBath
:Score: 1
:DateUnix: 1517353206.0
:DateShort: 2018-Jan-31
:END:


** Do we have any numbers on how many people have been frozen down/have subscribed for cryonics? Also, why isn't there any cryonics services in europe? Any rules that particularly are problematic?
:PROPERTIES:
:Author: Sonderjye
:Score: 4
:DateUnix: 1517350702.0
:DateShort: 2018-Jan-31
:END:


** I have a question regarding rationality. What actions would you recommend for someone who is attempting to become a rationalist. Points I wish to clarify:

I do not mean suggestions like read the less wrong sequences. In this case the reason for that is thus. If you wished to learn mathematics, you could read a maths textbook. However if you actually wanted to get anywhere you have to practice. So this is what I am requesting. Suggestions that can be given for the practice of the important skills of rationality. In fact in your opinion what are the most important skills of rationality.

The ideas that I have had so far are

Tracking down intelligent sounding people with both sides of a viewpoint seems like a reasonable idea. You can then try asking them why they believe what they believe. Do this with both sides of a debate, including your own side. Fact check everything, check for logical flaws, and make sure you don't accidently or subconsciously strawman someone by requesting clarification if a position seems utterly stupid beyond what you have seen elsewhere and checking multiple sites for information. If a site fails this check stop using it.

Second, pick a argument on which you have a side. This shouldn't be a strong opinion or one tied up in your sense of self. Try writing down your most persuasive case for the position. All facts must be backed up and all arguments must be free from logical fallacy. If it helps you pretend that you are going to be using this to try to persuade people and every time you feel tempted to relax your standards think to yourself "The truth will stand up to scrutiny. If this is true it will stand up to the fires of judgement without aid" Also write down any arguments you think of that will argue for the other side.

Thirdly start a journal. In this journal, write down each of your actions for a few days. Once they are written down, write down your reason for doing them. Look over this a consider. Consider long term goals, reasons for achieving them and whether you are taking action towards them. (As an aside what motivated you to become a rationalist and does it affect what skills you are good at?)

After that I'm not sure. For instance how does one use bayes probability theory in the real world? Where does one get priors from and where does one get adjustment factors? How does one tell you are right? Are there any other skills of a rationalist that I am leaving out, or do my plans have some flaw or improvement that I need to check.

I am writing this comment for a couple of reasons. Firstly I wish to be more rational. I do not like the idea of biases and emotions controlling my every action. Secondly I am planning, once I improve my writing skills, to write a story with a rationalist protagonist and I wish to better understand the character. This character will be rational because the world involves a large amount of mind control and moral dilemmas and the more the character thinks things through the better for the story. Them mustering good arguments for both sides and being forced to choose is sort of the point of the story. Thirdly, I think this seems interesting. Fourthly, one of the things I always wished for myself was for me to be less ignorant and understand more of reality. This is why I am going to study maths at university. Fifthly, if I do get some friends who are interested I can give them suggestions.

Tldr What are the most important skills of a rationalist and how do you practice them to begin with
:PROPERTIES:
:Author: genericaccounter
:Score: 6
:DateUnix: 1517262809.0
:DateShort: 2018-Jan-30
:END:

*** Read the Luminosity sequence, which is a series of “how-to” posts. I ultimately didn't maintain everything that the sequence talked about, but /trying/ still had a good impact on my life and I'd very much recommend doing the same.
:PROPERTIES:
:Author: callmesalticidae
:Score: 6
:DateUnix: 1517267509.0
:DateShort: 2018-Jan-30
:END:


*** You could do that thing that SSC does and make lots of specific predictions with confidence intervals until your predicted certainty matched how often you were actually correct. Make these predictions public or something like that to ensure you are forced to admit when you're wrong and adjust accordingly.

The other thing I often hear recommended for developing instrumental rationality is if you're confident about a prediction make a bet to keep yourself honest (so you have to admit if you're wrong) and to test performance. This is similar to the previous technique and overlaps (if you're well calibrated and think something is probably going to happen you should try to make bets) with it, but has the advantage of having a higher psychological cost than just being wrong (even for say $50) so it will force you to adjust more greatly.

As for finding conflicting viewpoints being civilly discussed to look at I might recommend the SSC subreddit particularly the culture war threads. If you want to find viewpoints you're likely to never otherwise encounter personally being debated civilly, then I don't know of anywhere else that's better for that.
:PROPERTIES:
:Author: vakusdrake
:Score: 2
:DateUnix: 1517268334.0
:DateShort: 2018-Jan-30
:END:


*** u/CCC_037:
#+begin_quote
  After that I'm not sure. For instance how does one use bayes probability theory in the real world? Where does one get priors from and where does one get adjustment factors?
#+end_quote

Guesswork.

No, seriously. That or looking up statistics, but in the moment it's often guesswork and gut feel.

What explicitly using Bayes does is that it makes your guesses more /consistent/. That, and it allows you to improve your intuitions about probabilities with respect to each other. So you can make guesses about things that you are pretty confident about, and transform them into information about things that you are less confident about; or you can deliberately bias your all guesses to one or another side, in order to be fairly certain about which side your final result is biased towards.
:PROPERTIES:
:Author: CCC_037
:Score: 1
:DateUnix: 1517300953.0
:DateShort: 2018-Jan-30
:END:


*** Well, that's not really quite fair to "reading math textbooks". I've gotten quite a bit better at math over the last three or four years from, almost exclusively, doing just that. (I've never really learned to do work at home, so I have not yet successfully set up a practice-session program. But I /can/ get myself to carefully read a text. So I do that.)

Similarly, I've heard it said (but not checked the literature myself) that the usual fiction reading that people do is pretty well known to improve their mental models of people's emotions... and I'm reasonably confident that reading repeated fictionalizations of rational though processes has made me more likely to use them - and use them correctly.

On the other hand... towards the end of the first batch of writing on LW, EY wrote a couple posts that basically said "yeah, I've written an infodump of bits pointing in the right direction, now we have to figure out (1) what matters the most and (2) how to actually teach it. And figure out the meta-level problems of figuring out (3) /when we've taught it/ and (4) /how to know that someone has figured out 1, 2, and 3/."

I've been somewhat underwhelmed by our progress on questions 1-4 in the last decade. (But then I'm not in a good location or group to notice any such progress, so that doesn't signify much.)
:PROPERTIES:
:Author: BoilingLeadBath
:Score: 1
:DateUnix: 1517354561.0
:DateShort: 2018-Jan-31
:END:


** So as it turns out, Andrej Karpathy hates everything I do about the tech sector. Yay.

EDIT: LOL, now he's telling everyone about paperclip maximizers to explain why AIXI won't work.
:PROPERTIES:
:Score: 2
:DateUnix: 1517251538.0
:DateShort: 2018-Jan-29
:END:

*** What does he hate?
:PROPERTIES:
:Score: 1
:DateUnix: 1517258784.0
:DateShort: 2018-Jan-30
:END:

**** He spent a whole slide of his presentation deliberately quoting and presenting the evidence for, "We wanted flying cars, and we got 140 characters." He was talking about his work on AI at OpenAI and now Tesla.
:PROPERTIES:
:Score: 1
:DateUnix: 1517264790.0
:DateShort: 2018-Jan-30
:END:

***** I much prefer 140 characters over metal death machines raining from the sky, though.
:PROPERTIES:
:Author: callmesalticidae
:Score: 12
:DateUnix: 1517267591.0
:DateShort: 2018-Jan-30
:END:

****** You and I are very different kinds of people, then. "Metal death machines raining from the sky" really speaks to the seven-year old in me.
:PROPERTIES:
:Score: 1
:DateUnix: 1517413666.0
:DateShort: 2018-Jan-31
:END:

******* Nod. I don't even like driving. I simply can't get past “metal death machine hurtling at sixty miles per hour, and even if I do everything right, I also have to trust that everyone else is going to properly operate their own metal death machines.”

(This is a big reason I moved to SF, where the public transportation is good enough that I don't need a car)

Self driving cars cannot come quickly enough.
:PROPERTIES:
:Author: callmesalticidae
:Score: 1
:DateUnix: 1517413769.0
:DateShort: 2018-Jan-31
:END:

******** Actually, I really prefer public transit too, but every transit option around here sucks. It took me 70 minutes to walk-bus-train-train-walk for a commute I could make by car in 20-30 minutes, if you could only park a car in a pocket dimension.
:PROPERTIES:
:Score: 1
:DateUnix: 1517415727.0
:DateShort: 2018-Jan-31
:END:


*** Links?
:PROPERTIES:
:Author: vakusdrake
:Score: 1
:DateUnix: 1517267603.0
:DateShort: 2018-Jan-30
:END:

**** Unfortunately it looks like he's not sharing his slides immediately, so we'll have to wait two weeks for the lecture recording to go up on YouTube.
:PROPERTIES:
:Score: 1
:DateUnix: 1517267826.0
:DateShort: 2018-Jan-30
:END:

***** Oh you're at a talk, because I had next to no idea what you were talking about.
:PROPERTIES:
:Author: vakusdrake
:Score: 3
:DateUnix: 1517268471.0
:DateShort: 2018-Jan-30
:END:

****** I've been busy all day.
:PROPERTIES:
:Score: 1
:DateUnix: 1517274135.0
:DateShort: 2018-Jan-30
:END:


** I've been enjoying 'Thinking, Fast and Slow' however it mentions an experiment in which people became happier when holding a pen in their mouth. Does anyone know if this experiment were reproduced successfully? I remember hearing that power-poses(i.e. standing in a powerful position to gain confidence) were debunked.
:PROPERTIES:
:Author: Sonderjye
:Score: 1
:DateUnix: 1517740486.0
:DateShort: 2018-Feb-04
:END:
