#+TITLE: [D] Friday Open Thread

* [D] Friday Open Thread
:PROPERTIES:
:Author: AutoModerator
:Score: 19
:DateUnix: 1571411115.0
:DateShort: 2019-Oct-18
:END:
Welcome to the Friday Open Thread! Is there something that you want to talk about with [[/r/rational]], but which isn't rational fiction, or doesn't otherwise belong as a top-level post? This is the place to post it. The idea is that while reddit is a large place, with lots of special little niches, sometimes you just want to talk with a certain group of people about certain sorts of things that aren't related to why you're all here. It's totally understandable that you might want to talk about Japanese game shows with [[/r/rational]] instead of going over to [[/r/japanesegameshows]], but it's hopefully also understandable that this isn't really the place for that sort of thing.

So do you want to talk about how your life has been going? Non-rational and/or non-fictional stuff you've been reading? The recent album from your favourite German pop singer? The politics of Southern India? The sexual preferences of the chairman of the Ukrainian soccer league? Different ways to plot meteorological data? The cost of living in Portugal? Corner cases for siteswap notation? All these things and more could possibly be found in the comments below!

Please note that this thread has been merged with the Monday General Rationality Thread.


** The first meeting of my Applied Bayes group went pretty well! Thanks to those who offered [[https://www.reddit.com/r/rational/comments/dekobl/d_monday_request_and_recommendation_thread/f2yg8c2/][mascot suggestions]]! Advertising the group was a bit /too/ successful, if anything -- the classroom we were in was packed, with people having to line up along the walls. I think that contributed to its major failing: it went well for a /lecture/ but not a /discussion/, and the 5-10 people who participated primarily engaged in 1-on-1 conversations with me instead of the broader audience. For some reason a solid third of the attendees consisted of math / stats PhDs, postdocs, & PIs, despite my advertising the group as 'beginner friendly' and 'non-rigorous'*. That probably didn't help overall math anxieties (a lot of questions to me were prefaced with 'this is probably really stupid / basic / simple').

Gonna try a few things to open people up in the next meeting and make it more group discussion-y (e.g. include alcoholic options in the snacks / refreshments). We'll see how it goes.

Also chatted to a director of the broader program and was told that while I definitely wouldn't be competitive for their "/senior/ research data analyst" positions, if I were to stick around I should definitely consider applying to their /junior/ role. Which gives me hope that after graduation I won't be hopelessly unemployed & destitute (or, well, mooching off my wife's residency stipend wherever the match puts us).

*(where they were for the previous, more technical iteration idk. Although it can't just be the level of rigor -- my deep learning group from last year was decidedly basic & received a tenth the interest, if that)

edit: in unrelated news, we recently upgraded our coffee machine to a Breville Barista Express (BES870XL) and I've been really enjoying my morning lattes. Coffee connoisseurs might scoff, but to my indelicate palate the shots I pull are definitely comparable to those I get from the 10x as expensive grinder & espresso machine we have at work. Big fan of it overall!
:PROPERTIES:
:Author: phylogenik
:Score: 12
:DateUnix: 1571415266.0
:DateShort: 2019-Oct-18
:END:


** Just completed my first marathon! Happy to have finished, not so happy I was mentally weak and walked some parts so I missed my time. I really thought all the "20 miles is the first half" comments were jokes, but they weren't.

I would recommend any lower impact exercise over running, but I do think the marathon was a good experience in self suffering for me.
:PROPERTIES:
:Author: RetardedWabbit
:Score: 8
:DateUnix: 1571501797.0
:DateShort: 2019-Oct-19
:END:

*** Thanks for your perspective. I've run a couple of halves with minimal excruciating pain and managed to hit my goal for both of them, but a marathon is another beast entirely. It's on my bucket list but my drive to train needs some serious work.
:PROPERTIES:
:Author: LazarusRises
:Score: 3
:DateUnix: 1571758036.0
:DateShort: 2019-Oct-22
:END:

**** I was beating myself up pretty bad when I posted that, it was a good experience and I only missed my arbitrary goal time by five minutes but achieved my actual goal of finishing without injury.

In hindsight the pain wasn't too bad, it was just the duration of it. The worst it got was 5/10 for me, just constant invasive muscle soreness pain, which is a level you can "push through" and focus on ignoring. But I was pushing it from mile 14-21 with a "this hurts but I'm doing well" mindset that failed me at mile 22 so I started walking anything I could pretend was a hill.

My 3 training tips: follow a plan, find a running group (especially for the long runs), and avoid the treadmill if you can.

Sticking to a plan helped me feel calmer going into it and prevented me from moving runs around or doing anything crazy/lazy.

Having a running group is great for your spirits, especially when you see them at the actual marathon, and having one that sets up water stations is vital for long runs.

I find running on a treadmill is mentally the hardest, since you can hop off at any time for any "reason". Knowing you just have to run back to where you started is a lot easier than thinking you still have to stay on the treadmill for another half.
:PROPERTIES:
:Author: RetardedWabbit
:Score: 1
:DateUnix: 1572238052.0
:DateShort: 2019-Oct-28
:END:


** There's something I've been thinking about and maybe I'll make a topic later if it warrants it.

​

Basically munchkinry tends to be either immoral, or illegal IRL. e.g tax evasion, cheating, manipulation, lying, deadbeat dads, cuckoldry, nepotism etc. Those are all in some way or another exploits that if used with proper planning and creatively could give an immoral actor big advantages with little to no risk.

​

Yet we inherently consider those things immoral, even if rationally some could be used while causing little harm and suffering. Do you think characters in stories where munchkinry is possible in ways we don't consider immoral would see them as inherently immoral ?

​

It's interesting, because when you actually think about potential exploits in our own world in a vacuum without our biased morality lenses, many do exist and could be easily applied but most good people would never even consider using them. We just see them as inherently immoral and evil.

​

Our rational MCs attempting to exploit anything would probably be either severely reprimanded, ostracized, or jailed, for even suggesting the use of said munchkinry. To the npcs it'd likely be akin a colleague casually suggesting you team up to scare some travelers into giving you some snacks, and justifying it by saying the travelers will barely miss it and nobody will actually get hurt.
:PROPERTIES:
:Author: fassina2
:Score: 12
:DateUnix: 1571438522.0
:DateShort: 2019-Oct-19
:END:

*** I don't think that munchkinry is inherently likely to be immoral--it's just that there have to be reasons why people don't take advantage of obvious exploits, and one of those reasons can be "it's immoral."

Real life munchkins that are moral:

- Use electricity and transistors to rapidly do calculations.
- Build structures out of concrete.
- Take advantage of hormonal offswitch for preventing pregnancy.
- Carry water in containers so you won't run out.

These things don't feel like munchkins because they are just things that we do. Munchkins that we /don't use/ have to have a reason why we don't use them.

Examples:

- 3d print an army of 3d printers. (Too complicated.)
- Build structures out of solid steel. (Too expensive.)
- Eat tons of protein to get buff. (Kinda works--but strength depends on a variety of factors.)
- Rent a deceased-person's home for cheap because everyone else thinks it's haunted or creepy. (This one works!)
- Steal money to get rich. (It's immoral and other people will punish you.)

I agree that it would be nice to see munchkins in fiction that are unused for moral reasons. It's hard to write a convincing fictional moral framework.
:PROPERTIES:
:Author: blasted0glass
:Score: 21
:DateUnix: 1571440594.0
:DateShort: 2019-Oct-19
:END:

**** Great comment. This is why we should share our thoughts people..

​

Some examples of less commonly used real life munchkins that some of us could actually apply and why most people don't use them:

- Skill focused learning. (It's hard, and requires access to information and enough humility to be willing to learn).
- Exercising. (it's hard, requires a system, habit or planning to do consistently, requires being comfortable standing out).
- Live frugally, save money, retire early. A.k.a FIRE (Saving money is hard, living frugally is hard, having high paying jobs accelerates the process by a lot).
- Hire people to work for you, pay them less than they make you, get free money, repeat until it becomes inefficient. (What most businesses are built on, requires an efficient way to turn labor hours into money, it's hard and risky).
- Buy a duplex, or bigger as your first home. With some special loans for first time home buyers people can buy houses that actually make them money and live for free without needing insane amounts of money. (Saving money is hard, credit ratings, lack of information, housing market needs to be good, people have different priorities when buying homes [neighborhoods, school districts, location, status]).

If anybody has more of these, please share them with us ;)
:PROPERTIES:
:Author: fassina2
:Score: 10
:DateUnix: 1571446439.0
:DateShort: 2019-Oct-19
:END:

***** I'm honestly not really seeing the point you're trying to make.

To quote SMBC on this, "You already know all the good advice. Brush your teeth, exercise regularly, save money. There's no secret trick, you just need the discipline to do it."
:PROPERTIES:
:Author: CouteauBleu
:Score: 5
:DateUnix: 1571482093.0
:DateShort: 2019-Oct-19
:END:


***** Economies of scale to get more for less effort - need to coordinate more people to work towards a bigger goal, any risk is magnified by the bigger size of the project, flooding the market could crash the price.

Marry a rich person to get rich - tons of competition, feeds into the problems of socioeconomic inequality (rich people have better selection of mates to choose from), spouse has reduced incentive to be faithful.

Hypnotize yourself into the ideal person - hypnosis isn't as powerful as people think, risk of unintended side effects, risk of delusion.

Start a cult that does good things - likely to backfire, successful cults tend to have sociopathic leaders that teach insane things.

Train the brain to work like a computer then "download" skill books and study them in your sleep - brains are bad at memorizing large amounts of data, you'd need megabytes worth to be much use.
:PROPERTIES:
:Author: lsparrish
:Score: 3
:DateUnix: 1571458054.0
:DateShort: 2019-Oct-19
:END:


**** An example of immoral munchkins in fiction is necromancy, isn't it? It's basically free labor that can enhance productivity, but is seen as distasteful because of the raising the dead thing.
:PROPERTIES:
:Author: argentumArbiter
:Score: 7
:DateUnix: 1571453829.0
:DateShort: 2019-Oct-19
:END:

***** Usually necromancy is immoral due to the existence of souls, you aren't getting a zombie worker for nothing you're at best stealing a soul from it's afterlife, and at worst torturing/harming that soul for gain.
:PROPERTIES:
:Author: RetardedWabbit
:Score: 1
:DateUnix: 1571504944.0
:DateShort: 2019-Oct-19
:END:

****** And in universes where there /isn't/ some cosmically mandated ethical downside to a zombie proletariat, people go ahead and do it.
:PROPERTIES:
:Author: IICVX
:Score: 1
:DateUnix: 1571535345.0
:DateShort: 2019-Oct-20
:END:


*** It would have to depend on the situation. IRL, we can't munchkin anything because all the low hanging fruit has already been taken. The only things left to munchkin are things that are immoral. I think the same holds true for fictional worlds.

However, a lot of the time characters are able to munchkin because they're categorically different than the the non-main-character. In HPMOR, Harry can munchkin because he's got access to a unique depth of knowledge. In Worm, Taylor can munchkin because she's the only one able to control a million bugs at once. In MoL, Zorian can munchkin due to multiple unique circumstances.

But in D&D where anyone can create an infinite loop of Wish spells? You better believe there's a reason nobody does that, and your best case scenario is a quick and painful death instead of a more eternal punishment.
:PROPERTIES:
:Author: xachariah
:Score: 7
:DateUnix: 1571465588.0
:DateShort: 2019-Oct-19
:END:


*** You're cherry picking examples using the criteria of munchkin AND illegal/immoral, when you should be looking for legal munchkins of which there are plenty but they are pretty "common sense".

Most real life munchkin's are just specialized professionals, like corporate accountants. Corporations are great at munchkining within the law to maximize profit. For example there's a government grants for the common person munchkin named Matthew Lesko, he publishes books and has a website to help people find and get government grants for things you would never think there are grants for like LASIK.

Most of life's optimizations for laypeople are small, or have high costs. We still have revolutions from new optimizations, but they aren't as dramatic as in fiction.
:PROPERTIES:
:Author: RetardedWabbit
:Score: 7
:DateUnix: 1571505893.0
:DateShort: 2019-Oct-19
:END:


*** I used to think that things like eg. manipulating others by telling anything but the literal truth was somehow morally wrong. The problem was - I actually acted on that belief and the results were horrible for me and the people I cared about. So clearly there is some “munchkinry” (ie; using your brain) which is totally fine to apply to everyday situations. But you're right that stories tend to focus on combative situations because, ... uh... it's more interesting?

I'll give you an example of “munchkinry” applied to the real world that I did: the scenario was that I was depressed and my flatmate's cat (which he loved) was missing. For me, it was a substantial effort just to get up and make breakfast (as things are when one is depressed) and I saw a brief glimpse of the cat while doing so. I wasn't close with my flatmate - we pretty much did our own thing. But I thought - if I write a quick text (30sec of my time) that's gonna make his day (and I quickly got a reply saying exactly that), and since I myself enjoy making people happy then it improves my mood significantly too. This, pretty much costlessly, has in all probability made both me and my flatmate significantly more productive (him because less cat worry and me because good start to day where I accomplished something real) - and all it took was a quick text.

When you look at it like that, it seems like an impossible hack - two people getting something (long-lasting benefits) from essentially nothing. But I find the point of view which produces these results in the real world is rare.
:PROPERTIES:
:Score: 3
:DateUnix: 1571462996.0
:DateShort: 2019-Oct-19
:END:


*** Aside for [[/u/xachariah][u/xachariah]]'s (quite accurate) answer, I'd say people do munchkin and get rewarded for it in real life.

We live in a culture that places a high value on entrepreneurs, and especially start-up makers, people who see an optimization that hasn't been done before and think of ways to apply it at scale.

We have a vibrant, extremely developed ecosystem for finding these people and giving them guidance, funding and leverage; in some countries, we even have the government treating these people has a strategic assets worth subsidizing.

This is nothing new either. The concept of entrepreneurship, and gathering capital to invest in upscaling new innovations is in large part what led to the industrial revolution.
:PROPERTIES:
:Author: CouteauBleu
:Score: 5
:DateUnix: 1571481852.0
:DateShort: 2019-Oct-19
:END:


** So I just finished Storm Front by Jim Butcher on Audible. I enjoyed the narrator but the character himself was wobbling back and forth between me enjoying him and me calling him an idiot.

Does the series/character improve as it goes on? He seems to handle the idiot ball in quite a few ways that I wouldnt expect someone that describes themselves as a "powerful and experienced wizard" would.

I DID enjoy him as a person though. His humor is dry enough that I enjoy it and I like that he doesnt just complain about everything the whole time.

Secondary point, Ive listened to The Nightmare Stacks by Charles Stross on a recommendation from a few users here. How is the rest of the series comparatively? I was thinking of getting book one and reading through them all.
:PROPERTIES:
:Author: SkyTroupe
:Score: 3
:DateUnix: 1571428226.0
:DateShort: 2019-Oct-18
:END:

*** [deleted]
:PROPERTIES:
:Score: 9
:DateUnix: 1571436483.0
:DateShort: 2019-Oct-19
:END:

**** Dresden is pretty rational but not extremely intelligent, I think. His emphasis on preparation is very strong. The inciting event of Ghost Story is a particularly strong example. He also regularly attacks problems with a [[https://old.reddit.com/r/slatestarcodex/comments/c0nqg7/people_seem_to_think_thieves_should_lockpick_or/er6huvz/?context=2][hacker mindset]], IIRC, although no examples come to mind since I haven't read any of the books in a few years. Having values such that he's not willing to sacrifice innocents to save innocents doesn't speak to the quality of his thought processes, so I don't think you should count it against him.
:PROPERTIES:
:Author: hyphenomicon
:Score: 3
:DateUnix: 1571457418.0
:DateShort: 2019-Oct-19
:END:


*** It's worth pointing out that the earlier books have a different main character, but the quality is pretty consistent throughout. Perhaps the Jennifer Morgue is an exception; I enjoyed that one the least as it didn't seem to follow the rules of the setting as closely as I'd have expected.

Reading from the beginning gives a lot of nice running jokes and back-references, it's probably worth it.
:PROPERTIES:
:Author: kraryal
:Score: 3
:DateUnix: 1571437406.0
:DateShort: 2019-Oct-19
:END:


*** Dresden gets better at taking exploits and power as the series goes on, and matures into the talent he has at the beginning. But the people around him are the rational ones - Johnny Marcone, though he falls in prominence, and Thomas Raith, who is introduced in Grave Peril (book 3). If you read through Grave Peril or already know the important spoilers about Thomas ( he's Harry's half-brother ), then check out the novella focused on him, which is called Backup and is published alone and in the collection Side Jobs. (Be warned, the short description of the novella on its Amazon page reveals that spoiler.) It talks about a secret Masquerade-within-the-Masquerade with a war which is conducted much more like a rationalist story.
:PROPERTIES:
:Author: VorpalAuroch
:Score: 2
:DateUnix: 1571445369.0
:DateShort: 2019-Oct-19
:END:


** Do we ever see a sith deflect blaster bolts? I'm not sure how often we ever see them getting shot at in the first place, but I had the thought and didn't immediately feel like going through a days worth of movies. I guess video games or the tv series-es is acceptable, but i'm primarily thinking of the movies.
:PROPERTIES:
:Author: anenymouse
:Score: 2
:DateUnix: 1571548193.0
:DateShort: 2019-Oct-20
:END:

*** Vader "catches" Han's shots in the Cloud City meeting, at the very least.
:PROPERTIES:
:Author: GeeJo
:Score: 3
:DateUnix: 1571549127.0
:DateShort: 2019-Oct-20
:END:

**** Oh yeah and in the opening of episode 4 when he's crushing the Rebels. He uses his hand in both occasions though. And whatever Kylo Ren did at the start of episode 7 with the freezing of the bolt. There really aren't that many times where they got shot at unless i'm forgetting some.
:PROPERTIES:
:Author: anenymouse
:Score: 2
:DateUnix: 1571549451.0
:DateShort: 2019-Oct-20
:END:

***** At the end of Rouge One Vader deflects barrage of blaster bolts with lightsaber.
:PROPERTIES:
:Author: Wiron2
:Score: 1
:DateUnix: 1571581024.0
:DateShort: 2019-Oct-20
:END:


** Over the last day-and-a-half, I've been doing a lot of thinking and self-reflection. (WARNING: Post may be rather rambly, and may be more of a direct thought dump.)

Today, I decided to write down the things I thought about to better help me organize and refine my thoughts. I wrote down a large list of points in a notepad app, and I don't think I really came to any particularly interesting conclusions, but, of the more interesting things, I explored the space of potential core values (which should apply to several kinds of agents, including humans, aliens and AI).

I have a vague feeling that the simplest single core value that leads to desirable behavior is based on "preserving (useful) information" (but that needs a bit of refinement and clarification). Archiving a lot of information ultimately requires compression, and compression requires world modeling of some sort. Modeling agents - including the self - is also useful (for archival, search, etc.). A lot of values that seem desirable are compatible with preserving information (Preserving species, lengthening lives: irreversible information loss - like death - is the WORST thing that can happen from this perspective). Another potential core value is "preserving potential", or "ensuring potential is developed", but that is extremely vague and nebulous.

An interesting thought I came across, is that evolved life is "lazy", and instinctively avoids work to preserve energy. Reinforcement learning AI notably DOES NOT do this, unless it was trained in an environment heavily constrained for time or energy! That means that as long as the fitness function is "stuff gets done", and not "stuff gets done efficiently", then RL AI will get stuck on suboptimal - but working - solutions.

A really surprising observation is that "torture" is actually extremely nebulous. *SUB QUESTION:* What do people actually think about torture? The concept of is inherently bad. Why? (or why not?) What exactly IS torture? Is it pain? /(No.)/ Negative reinforcement? /(Maybe?)/ Negative reinforcement with extra conditions (not being able to control the source of negative reinforcement)? /(Maybe?)/\\
Is it the damage in body and mind that traditional torture causes?\\
What if torture did not result in any damage - physical, mental, emotional, and social - would it still be bad? /(I don't think so, but would that even be torture?)/\\
In any case, what about AI/agents that do not have a concept of pain/negative reinforcement. Can they even be tortured in principle?

Even as I'm writing this comment I'm updating my notes, but I've noticed that at 80 bullet points I'm starting to have trouble navigating, writing, and reading those notes - but I can't really think of a way to condense down the text in any meaningful manner.

Things that I have not even finished elaborating on:

- Social values
- How exactly do world modeling, compression, information, memory, and consciousness correlate?
- Other "reasonable" values (that is, any values that you can see an agent reasonably have).
- Physics, on a fundamental level, seems not to allow information to be lost. Sadly, the information is usually irretrievable after thermodynamics/black holes/etc. happens to it.

  - What about situations like kugelblitz black holes? What if you create a kugelblitz around a planet with sentient life, that can remain self-sustaining for billions of years. How does relativity interact with this? What happens to the information inside?
  - In practice, the information, AND the potential of things inside, is lost, so those two goals are set against doing this. What about other moral values? Is it moral to do this? Does it morally matter what happens inside /after/ the kugelblitz is made?

- A bunch of concepts that seem nebulous (or just fuzzy). Can they be clarified? If not, why do we have a concept like that? (see other nebulous concepts like free will.)
- I haven't fully elaborated on why some counter-intuitive things can be potentially good for us, depending on how the universe works. (consider various simulations, with various purposes: research, entertainment, etc. For example, causing a false-vacuum collapse in a distant galaxy, whose future light-cone will never cross ours may increase our chances of survival. In most interpretations, this is bad, or just irrelevant, though).

  - It's interesting to consider what each core value leads us to do in these kinds of situations. Maximizing the chance of survival of ANY sapience makes us /not/ bomb the distant galaxy, preserving information deems it irrelevant since the future light-cones will never cross.

My notes are a bit too big to paste them into a reddit comment in their entirety, so here's a link to a paste with the notes I made as I was riding my train of thought: [[https://paste.sh/jiiZqQV-#ydwtC_0O5ZyWOqM0iDnd-BFP][LINK]]

I'd appreciate it if people poked holes and mentioned interesting things I missed in those notes. I think this topic is really fascinating to explore and that I barely made a dent in what there is to consider.
:PROPERTIES:
:Author: mateon1
:Score: 1
:DateUnix: 1571427200.0
:DateShort: 2019-Oct-18
:END:

*** I didn't read all of your comment, but:

#+begin_quote
  Negative reinforcement
#+end_quote

In psychology there's negative reinforcement and punishment, you're mixing them up. The point of torture isn't to reinforce anything, is it? It's just punishment.

I'd say that torture is systematic inflicting of pain against one's will. It works because (most) humans have strong negative utility associated with pain. You could "torture" an AI by systematically inflicting negative utility upon it in ways that it could do nothing about. But at that point the word's definition is stretched a bit from normal use..
:PROPERTIES:
:Author: CraftyTrouble
:Score: 8
:DateUnix: 1571435615.0
:DateShort: 2019-Oct-19
:END:

**** u/mateon1:
#+begin_quote
  In psychology there's negative reinforcement and punishment, you're mixing them up.
#+end_quote

True, I believe that in all cases above I actually meant something along the lines of inducing negative utility, or more accurately, causing negative stimulus.

I started exploring the concept of torture, and of non-human agents because over the past few years, I've been occasionally seeing discussions involving things like "torturing simulations of people", and I've never been convinced that I should care at all. On the other hand, I came across fiction that explores things from the point of view of AI.

The first fic of this type I saw was "the DataPacRat Manual" (something along those lines), which at the time I found fascinating, but not really satisfying.

More recently, I came across a [[/r/HFY][r/HFY]] story where an AI made from a bunch of imperfectly uploaded human minds wakes up after an alien attack, and initially seeks revenge, then "revives" the human race by repairing the damaged scans and putting each one in a robot.

A few days ago, I read Post Human, which is about an AI made from an uploaded human mind apparently being the last "human" alive.

None of those fics really satisfied me, so I spent a lot of time thinking about Human-like AI, other kinds of AI agents, and what it would mean to self-improve directly, how that connects to current machine learning knowledge, basic neuroscience, compilers, JIT runtimes, symbolic execution, model verification, proof generation and proof checking, among other things. More importantly, connecting to the point from a few paragraphs ago, those kinds of agents wouldn't have to have a pain stimulus, or other negative stimulus equivalent.
:PROPERTIES:
:Author: mateon1
:Score: 1
:DateUnix: 1571487752.0
:DateShort: 2019-Oct-19
:END:


*** For Physics, you would likely appreciate the distinction between Gibbs Entropy and Shannon Entropy. Shannon information can be lost, Gibbs information can't. We typically care about Shannon information.
:PROPERTIES:
:Author: hyphenomicon
:Score: 2
:DateUnix: 1571457576.0
:DateShort: 2019-Oct-19
:END:


*** After sleeping on all of this, and going back to it, I realize that I should spend a lot more effort on condensing information (or even omitting some!) when posting something with intent to generate discussion.

As is, I believe this comment, and the linked paste IS valuable, since it is a rough outline of how I came across some of these conclusions, but I don't think reddit is the correct place to /explore/ concepts and their consequences. I'm not sure what form of communication would be right for that purpose. (wiki? public google doc? multiplayer notepad?)
:PROPERTIES:
:Author: mateon1
:Score: 1
:DateUnix: 1571486442.0
:DateShort: 2019-Oct-19
:END:
