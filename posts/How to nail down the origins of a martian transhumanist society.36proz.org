#+TITLE: How to nail down the origins of a martian transhumanist society

* How to nail down the origins of a martian transhumanist society
:PROPERTIES:
:Author: Colonel_Fedora
:Score: 9
:DateUnix: 1432179744.0
:DateShort: 2015-May-21
:END:
So I've had this setting idea rattling around in my idea for a while, and I want to make sure it makes sense on close examination. Basically it takes place a century to a century and a half from now, with humanity existing in colonies throughout the solar system, with the largest concentration being on mars. I want Earth to simply not be available because of the challenges and complications that would pose. My issue is thinking of a good reason for that to be the case, since I can't think of anything that could make the Earth less hospitable than literally anywhere else in the solar system. My only idea so far is for a rogue AI to take it over and just dedicate itself towards keeping the remaining humans away from Earth. That of course raises a lot of questions about why it wouldn't just hunt them down or whatever. So basically I'm asking for ideas.

Edit: Thanks for the ideas everyone! I'll think about them. In the mean time I'm going to make a post detailing martian society, which is where most of my thought about this setting has gone into.


** Sci-fi with unfettered strong AI isn't really about people anymore. It's about the AI. The Singularity is very real for sci-fi, as that is a point at which all rules of relatable characters (uploaded, flesh, or AI) and plot tension go out the window. Make it about transhumans if you want, but don't go down the full-blown, strong-AI-to-hard-takeoff apocalypse route unless you want the story to be about that.

For story telling reasons, I'd cap processing capability of all general computer intelligences (AI or uploaded) to within no more than about 30-50% of an unaugmented human's processing ability for the same resource cost--just declaring super-intelligences as impossible because of combinatorial complexity issues for storing and working with information in a neural network. This is also a hard cap for size. No Jupiter brains.

There is no strong science yet /disproving/ this (though there are good theories), so that will at least maintain some suspension of disbelief. Big, "dumb" expert systems will still be better for grinding through huge amounts of information given specific tasks, but that lower, more human level will be the limit for complex general intelligences able to work at real time.

Blind optimizers also shouldn't work (even slow ones) because nanotech is both difficult to make and easy to disrupt (otherwise, grey goo ho!)

--------------

As for Earth not being available, the sci-fi trope standards apply.

First, informational separation. Assume there are still visible "alive" looking cities, but no one seems to want to risk making high-energy ground station transmissions from Earth for some reason. At least few to none that the outer system can make out.

There are then the physical barriers:

- A cloud of high orbital junk that no one has cleaned up, from the last anti-sat war, makes getting to the Earth too dangerous.
- Quarantined surface because of moderately bad grey goo scenario. Intrastellar radiation is bad enough to prevent high-atmospheric or space transmissions (remember, no super AI or invincible nanotech). The colonies enforce a blockade and shoot down anyone trying to take off.
- Xenophobic Earth world government won't allow any contact right now (think 1600s Japan).
- Automated weapons platforms, either in orbit or on the surface, simply shoot at anyone who tries to get too near the Earth (works with other reasons).
- Mars just doesn't have a good industrial base or a space program yet. Getting out of Earth's gravity well is hard compared to Mars', even if you can get there in one piece. Too hard to make it worth while considering other challenges.
- Ignore the "silent Earth" scenario. There was complete planetary destruction. Core crackers turned it into a newly developing asteroid field, or it just got knocked out of orbit and into deep space.
:PROPERTIES:
:Author: TimeLoopedPowerGamer
:Score: 10
:DateUnix: 1432183148.0
:DateShort: 2015-May-21
:END:

*** To add to your excellent list:

Moderate nuclear exchange (maybe middle east or india/pakistan) triggered huge nuclear winter, some feedback loops whent out of whack and now temperature has plummeted.

Advances in the biotech field made for an extremly ugly period of biological warfare. Taylored strains of 100% lethal long-term incubation ebola targetting red haired people, the isreali population or people with the genes for the epicanthic fold. Total devastation.
:PROPERTIES:
:Author: SvalbardCaretaker
:Score: 7
:DateUnix: 1432203646.0
:DateShort: 2015-May-21
:END:

**** u/dspeyer:
#+begin_quote
  Moderate nuclear exchange (maybe middle east or india/pakistan) triggered huge nuclear winter, some feedback loops whent out of whack and now temperature has plummeted.
#+end_quote

To colder than Mars?

If you can terraform the rest of the solar system, you can clean up moderate disasters on Earth.

(Incidentally, this is why I really want to do some terraforming: we're going to need geoengineering for Earth eventually, and it's always best to learn on a system with no users.)
:PROPERTIES:
:Author: dspeyer
:Score: 3
:DateUnix: 1432230828.0
:DateShort: 2015-May-21
:END:

***** Of course not colder then mars. If the single criterium you have is "which is going to be more habitable" then earth is going to win out in almost any scenario. Even giant dropped asteroids leave you with pressurized atmosphere, probably oxygen (though not necessarily) and heaps of surface water.

Thus if you want your Civ to choose mars you either have to choose a disaster that makes Earth absolutely unaccessible (goo, AI gone wrong) or impose political or other motivations on your colonists (new frontier, fear from mutated human cannibals, solar modules not working under heavy cloud cover) etc.
:PROPERTIES:
:Author: SvalbardCaretaker
:Score: 3
:DateUnix: 1432231688.0
:DateShort: 2015-May-21
:END:


*** u/deleted:
#+begin_quote
  Sci-fi with unfettered strong AI isn't really about people anymore. It's about the AI.
#+end_quote

I'm not convinced by that. A strong AI is made by people. If it's made properly, we will make it so that the resulting universe is one that we want. Do you want a universe where no reasonably close to real stories are written about humans?
:PROPERTIES:
:Score: 1
:DateUnix: 1432226098.0
:DateShort: 2015-May-21
:END:

**** u/TimeLoopedPowerGamer:
#+begin_quote
  A strong AI is made by people.
#+end_quote

/Maybe/ once. The rest is laughably optimistic in a very odd way. I lose suspension of disbelief faster for such poetic future conceit* than any other authorial fiat. What I /want/ has little to do with the reality of creating an AI. See: Friendly AI, AI boxing thought experiments.
:PROPERTIES:
:Author: TimeLoopedPowerGamer
:Score: 3
:DateUnix: 1432238053.0
:DateShort: 2015-May-22
:END:

***** You seem to be under a misapprehension about what I am claiming.

Whenever we do things, we are trying to modify the universe to better match the universe we want. That's our goal. We don't always succeed, obviously. Whoever tries to create an AI is doing so in the belief that it will get us closer to their preferred universe. If they succeed and end up with the strong AI they want, that AI will build the universe they wanted. That's the success condition. I haven't said anything interesting or surprising yet; I'm pretty much just rephrasing definitions. Rephrasing definitions isn't a mark of optimism.

If the group that first creates strong AI does a proper job of it, and they want a universe in which humans can undertake interesting and worthwhile activities, then the AI will ensure that humans can undertake interesting and worthwhile activities. Again, nothing interesting here. No wild optimism. It's just clarifying the success condition for any AI research group with a particular goal.

If I were claiming that /any/ strong AI created by humans would inevitably result in a universe in which humans routinely undertake interesting and worthwhile activities, that would be unreasonably optimistic.

You, conversely, were claiming that /any/ story that includes a strong AI cannot include humans undertaking interesting and worthwhile activities, at least nothing worth writing stories about.
:PROPERTIES:
:Score: 1
:DateUnix: 1432270693.0
:DateShort: 2015-May-22
:END:

****** You wrote:

#+begin_quote
  You, conversely, were claiming that *any* story that includes *a strong AI* cannot include humans undertaking interesting and worthwhile activities, at least nothing worth writing stories about.
#+end_quote

You are factually incorrect in that statement.

I initially wrote:

#+begin_quote

  #+begin_quote
    Sci-fi with *unfettered* strong AI isn't really about people anymore.

    [...]

    ...don't go down the full-blown, *strong-AI-to-hard-takeoff apocalypse* route unless you want the story to be about that.
  #+end_quote
#+end_quote

As for my reaction to your messages, you were suggesting very specific, very *optimistic* constraints for strong AI that would allow for interesting human stories.

In your initial message, you wrote on this in a way that hinted you thought any other result was unlikely or possibly broke your suspension of disbelief if used in fiction. That stance would be a very *optimistic* one. It is not clear to me if you hold this belief or not.

Strong, safe, singular (though not leading directly into a Singularity) AI *can* make a good secondary story element or background feature. That's not what I was talking about. Though I think that Friendly AI is very unlikely to be done right IRL, it is /possible/ and is certainly useable in fiction.

Please read what I wrote more carefully. I will attempt to do the same with your posts.
:PROPERTIES:
:Author: TimeLoopedPowerGamer
:Score: 1
:DateUnix: 1432282618.0
:DateShort: 2015-May-22
:END:


**** How would a properly made AI make the earth uninhabitable?
:PROPERTIES:
:Author: pokepotter4
:Score: 1
:DateUnix: 1432305102.0
:DateShort: 2015-May-22
:END:

***** I was going on a tangent of a tangent rather than commenting on the main topic. Assuming you're trying to bring it back to the main topic...it doesn't have to be uninhabitable to /everyone/; it just has to be a supremely bad target for colonization or contact. An extremely insular society bristling with weapons serves that purpose.
:PROPERTIES:
:Score: 1
:DateUnix: 1432330364.0
:DateShort: 2015-May-23
:END:


** Probably the best thing you can do is to start writing. It is said that every writer has about a million bad words worth of writing to go through before they can produce anything halfway decent. Best to get through those as fast as possible and learn all you can from that.

That said, don't worry about getting it perfect. The story you want to tell isn't about what happened to Earth. You are basically at a point where you will accept any plausible idea to explain away that annoying detail so you can move on. So don't sweat it! Just let that be a free variable; have it be something so horrible and emotionally charged that it just isn't mentioned in polite company, or something along those lines.

Do some brainstorming about the setting. Start somewhere in the middle with characters that interest you. Write about their stories and exploits, and try to imagine what life is like for them in this world. Like a grain of sand that is the catalyst for a pearl, let your story coalesce around these ideas. The other details will fall into place.
:PROPERTIES:
:Score: 8
:DateUnix: 1432182701.0
:DateShort: 2015-May-21
:END:


** Earth is densely populated, well-organized, and completely inflexible. Doing /anything/ outside of the List of Ordinary Things requires a license. Taking up a single unusual hobby is a few weeks' work with the bureaucrats, but technological innovation is completely impractical. This is enforced by every electronic device on the planet, all of which have law-enforcement circuitry.

Several outer colonies could invade, but then they'd be stuck dealing with a trillion people who don't know any other way of living. And the knowledge of how to feed and clothe that population is embedded in the policies: starting from scratch would mean widespread starvation.

There exist charities that take the most valuable technological advances of the outer solar system and try to shepherd them through Earth's bureaucracy. It's frustrating work, but high impact.
:PROPERTIES:
:Author: dspeyer
:Score: 6
:DateUnix: 1432230611.0
:DateShort: 2015-May-21
:END:

*** Nah, run it the other way. Earth fully networked and hit post-scarcity at about the same time as the off-world colonies reached a decent size. Then technological and cultural advancement started to happen at really frightening velocities on earth due to well over ten billion minds all being in low latency contact and not engaged in the work of survival. Due to the light-speed delays in communication everyplace much beyond low earth orbit decoupled from the accelerating earth culture, and shortly after that, it became common sense to avoid even contact with it like the plague because the informational firewalls and memetic immune system of a typical belt ship or martian colony would just melt like a snowflake in the core of the sun if hooked up to The Internet. The belter joke goes that they blew up the com link with earth after their latest anti-virus software update offered to remove the known infohazards of "religion, neo-classical economics and pre-tizzard psychological theory" Occasionally earth launches aid packages that.. while obviously designed to be as harmless as at all possible.. are still extremely scary.

Auto-doc Medical kits with the ability to preform full shape changes into any biologically plausible form.

Self-help books that actually work.

Ect.

Then there are the things that go up that are not aid packages, which tend to just be incomprehensible. And The Event that happened to the moon, which decent people do not speak of.
:PROPERTIES:
:Author: Izeinwinter
:Score: 12
:DateUnix: 1432234820.0
:DateShort: 2015-May-21
:END:

**** Or for comedic works, there is this: The singularity hit, the Republic of Earth slapped a warp drive on the allen belt and.. left. There is a sign in the orbit it used to occupy saying "Parking reserved. Back in a millennium or three."
:PROPERTIES:
:Author: Izeinwinter
:Score: 5
:DateUnix: 1432237257.0
:DateShort: 2015-May-22
:END:


**** TL;DR Earth is inhabited by the Vile Offspring?
:PROPERTIES:
:Author: Solonarv
:Score: 2
:DateUnix: 1432258253.0
:DateShort: 2015-May-22
:END:


** Earth is still there, has a population of 49 billion (4 pure ai per originally-human mind), and the rest of the solar system shuns it as the great whore of babylon on the grounds that anyone foolish enough to visit either never comes back, or comes back... changed. Heck, just talking too much to earthlings has been known to result in being persuaded to let your radio eat your brain. (Moravec upload) Done, dusted. This isn't because earth is horrid - it's just undergone a heck of a lot faster cultural change than the much lower populations elsewhere. Also, there is the unpleasant fact that earth-side minorities that care about off-world people tend to be... radical.
:PROPERTIES:
:Author: Izeinwinter
:Score: 5
:DateUnix: 1432181858.0
:DateShort: 2015-May-21
:END:


** Several specific ideas here have incorporated this, but I feel the general concept could use expressing.

You don't have to make Earth completely worthless, you just have to make it less worthwhile than other planets in the system. Given how ludicrously uninhabitable some parts of the solar system are, the easiest way would be to severely damage the viability of Earth to human populations. [[/u/alexanderwales]]'s asteroid, [[/u/SvalbardCaretaker]]'s nuclear exchange and biological warfare, or a big dumb grey goo (as opposed to a full-blown AI) are all viable ways to serve this purpose without the need for an intelligence actively keeping humans away. This has the benefit/detriment (depending on your story) of potentially having a fixed end date for its inhospitability that those off of Earth could calculate.
:PROPERTIES:
:Score: 4
:DateUnix: 1432215808.0
:DateShort: 2015-May-21
:END:

*** Yes. The problem with grey goo is, if you have grey goo its immensely valuable to make other planets hospitable. Obviously not the failed goo, but all the other related nanotech. You either incorporate them (and can easily create a power creep you did not want in the first place) or you get some inconsistencies in your setting.
:PROPERTIES:
:Author: SvalbardCaretaker
:Score: 4
:DateUnix: 1432217726.0
:DateShort: 2015-May-21
:END:

**** Excellent point; the Grey Goo scenario doesn't arise in a vacuum, so you'd have to go to some lengths to remove nanotech from the general tech level of humanity.
:PROPERTIES:
:Score: 6
:DateUnix: 1432218035.0
:DateShort: 2015-May-21
:END:


** 1. Religious extremists with both technical expertise (possibly stolen) and a death wish have destroyed the Earth. If you need an answer to "how?", the easiest way to destroy Earth given near-future technologies involves gaining control of an asteroid mining operation and ramming a sufficiently large one into the planet at maximum speed. Slingshot it around a few planets, skim by the Sun to avoid detection on the final approach, and then kill almost everyone on Earth.

2. The Earth was destroyed by scientists trying to do something stupid, like messing with cosmic strings, or strangelets, or an Einstein-Rosen bridge, or something that humans a hundred years from now might be able to manipulate but not quite understand. The less you explain this, the better, unless your story is about the destruction of Earth.

3. You don't actually have to say, since it could happen quickly. The opening line of Neal Stephenson's new book is, "The Moon blew up without warning, and for no apparent reason", which I think is a perfectly fine thing to do.

[[http://qntm.org/destroy][How to destroy the Earth]] might be a good resource.
:PROPERTIES:
:Author: alexanderwales
:Score: 9
:DateUnix: 1432181839.0
:DateShort: 2015-May-21
:END:

*** That needs to go into the Opening Lines Hall of Fame.
:PROPERTIES:
:Author: callmebrotherg
:Score: 4
:DateUnix: 1432228967.0
:DateShort: 2015-May-21
:END:


** Some Earth scientists were experimenting with teleportation. They found out how to create wormholes with one end in their own reference frame (attached to the surface of the Earth, essentially) and the other in a different reference frame. They tried to test this by putting the other end along Earth's orbit but got the numbers wrong.

Right now, there's a moderately large wormhole on Earth's surface that connects to the outer stretches of the sun's corona. It's slowly boring a hole through the Earth, venting superheated gases, etc. It's about as inviting as Venus, except it's eventually going to destroy enough of the Earth to smash it into pieces.

Besides, the only great thing about Earth is the ready supply of volatiles.
:PROPERTIES:
:Score: 4
:DateUnix: 1432226887.0
:DateShort: 2015-May-21
:END:


** If you're interested in the AI with orange/blue morality, consider having the AI be religious or highly environmentally friendly. It doesn't want to destroy humans, but it also doesn't want them on Earth. Earth is its own, its precious.
:PROPERTIES:
:Author: boomfarmer
:Score: 3
:DateUnix: 1432254873.0
:DateShort: 2015-May-22
:END:


** AI is practically the only major x-risk that /doesn't/ make /only/ the Earth uninhabitable. Out-of-control replicating nanotech, engineered pathogens, extreme radioactivity, etc. The /distinguishing/ factor of strong AI as an x-risk is that it will come and get you on Mars, which is the reason why Elon Musk is worried.
:PROPERTIES:
:Author: EliezerYudkowsky
:Score: 8
:DateUnix: 1432214330.0
:DateShort: 2015-May-21
:END:

*** But it doesn't /have/ to make all planets uninhabitable, depending on what its utility function is. A bad utility function could produce all sorts of plot-convenient behaviors, like killing everyone on Earth but nowhere else. By definition, a utility function can be practically anything, and given that it's making the Earth uninhabitable we already know that the AI is exhibiting unintended behaviors.

(The question isn't whether the depicted world is one that you would expect given someone saying "AI killed everyone", it's whether it's plausible as a background detail.)
:PROPERTIES:
:Author: alexanderwales
:Score: 6
:DateUnix: 1432224320.0
:DateShort: 2015-May-21
:END:

**** Most utility functions lead to the AI converting its future light cone to usually computronium. Even an AI programmer who has heard of that anecdote (but thinks the problem nonhard enough that he can solve it personally) is usually going to get the universe converted. On the other hand, if they were also educated in the (today nonexistent) theory of writing utility functions that don't convert the universe, I would be hard-pressed to find a mistake for them to make that would doom Earth and only Earth. You'd basically have to deliberately specify Earth as a playground and set the rest of the universe off-limits with your hard theory.
:PROPERTIES:
:Author: Gurkenglas
:Score: 1
:DateUnix: 1432820492.0
:DateShort: 2015-May-28
:END:


*** There's a great book about this (a superintelligence that has taken over Earth trying to come get everyone on Mars) by John Barnes called The Sky So Big and Black.
:PROPERTIES:
:Author: summerstay
:Score: 1
:DateUnix: 1433286941.0
:DateShort: 2015-Jun-03
:END:


** u/callmebrotherg:
#+begin_quote
  That of course raises a lot of questions about why it wouldn't just hunt them down or whatever.
#+end_quote

It wasn't programmed to keep humans off Earth, but was programmed to do Some Whatever Thing that, /incidentally/, makes Earth out to be Not An Option At All, No Sir.
:PROPERTIES:
:Author: callmebrotherg
:Score: 3
:DateUnix: 1432181524.0
:DateShort: 2015-May-21
:END:


** You might want to read the Eclipse phase RPG setting books. Much of what you describe is in it's history.
:PROPERTIES:
:Author: Empiricist_or_not
:Score: 3
:DateUnix: 1432243934.0
:DateShort: 2015-May-22
:END:


** Have you considered grey goo? It's basically rogue AI on a budget.

It presumably doesn't know or care about space travel, but it's either poisonous or corrosive or it's just outcompeted every living thing on Earth. People don't visit Earth because they don't want to risk carrying spores away.

And maybe it can only grow properly in Earth-like atmospheres; so space stations and pressurised colonies are at risk, but it can't colonise outdoor areas on Mars or Venus.
:PROPERTIES:
:Author: Chronophilia
:Score: 6
:DateUnix: 1432189608.0
:DateShort: 2015-May-21
:END:
