#+TITLE: [AMA] I'm a soldier for the Yeerk Empire and I'm dying. Ask me anything.

* [AMA] I'm a soldier for the Yeerk Empire and I'm dying. Ask me anything.
:PROPERTIES:
:Author: CouteauBleu
:Score: 33
:DateUnix: 1501881239.0
:END:
Alright, let's do this.

First thing first, I've arranged for confirmation of my identity with [[/u/limewarden][u/limewarden]]. As you can see in [[https://fake.link.com][this video]], I own a laser gun, which I used to burn through various households objects in my flat, responded to some of limewarden's prompts, showed realtime events on the TV to prove I was streaming in real time, etc.

As to why I'm doing this... shit. I'm still not sure I'm going to go through with it. Look, the thing is, I'm dying. I have less than a week to live, so this is me filling my personal bucket list.

Let's talk a bit about me. My name is Starrat 731. I'm a part of the invasion force that was sent to take over the Earth a few months ago. For my entire life out of the pool, I was stationed in Paris as a sleeper cell. My job description was roughly: "Gather information about the local culture, don't get noticed, don't die." Kind of a cushy job, really. Until the Animorphs made their broadcast (serious side question, does anyone know how the hell they survived a fucking meteor strike? that... disturbs me /a lot/). For those out of the loop, Paris (and the surrounding region) is currently being quarantined. The military is combing through the city, looking for, well... us.

I'm pretty sure I'll die before they find me. Ten million is a lot of people to comb through, and it's not like they have long range Yeerk detectors. And I'm going to run out of oatmeal pretty soon.

In the meantime, I'm willing to answer questions. Nothing too strategically relevant, of course (don't even try to fish for my location either).

Oh, also, I guess you can ask questions to my host too. His name is Olivier Faure. He's a complete asshole, but I guess if you want to know his perspective or something, I can answer for him.

Hope this thread doesn't get censored (limewarden says he's working on mirrors and stuff).

EDIT: fixed spelling mistakes. I only know English marginally better than my host does.

EDIT: Closed. I won't answer any more questions.

--------------

*META: Alright, I was bored and I needed my Animorphs fix, so like all people with unhealthy needs, I just decided to make my own!* This is a roleplay thread; try to ask question you would ask to Starrat; keep in mind that I am not the author, and my answers will mostly be speculative. The whole quarantine thing is probably completely incompatible with canon as written by TK17Studios, but eh. Maybe if we make this sufficiently awesome, he'll /have/ to make it canon.

*EDIT:* Some people have asked me questions about qualia and stuff. I don't want to discourage those questions and I hate to break your suspension of disbelief, but I have little to no background in psychology, neurology, etc (and aeronautics, quantum physics, engineering, or other things that might help me answer questions from a position of authority). Just be aware that while I'll try to give the most realistic, plausible answers I can without being too vague, I'm not an actual yeerk. Anything I say about my experience controlling someone's brain will be completely made up, with very little research behind it, if any.


** Ok, fellow redditors, is this legit? Could anyone have faked that video? Even assuming "Starrat" is an actual alien, this could still be another one of Esplin's publicity stunts, so keep your guard up, as we will likely have no immediate way of verifying whether or not Starrat is lying.

Supposing this is the genuine act of one yeerk, I am perhaps more disturbed than I was before. Starrat talks about his (her, its?) life not like a parasitic drone but like an individual with hopes and dreams. Seriously, alien slugs have "bucket lists?" But if you, Starrat, are truly capable of feeling pleasure and pain, excitement and fear, joy and wonder ... can you yeerks not recognize the horror in your denial of the same to the humans whose bodies you so mercilessly steal for yourselves? Humans do have dreams and bucket lists too, Starrat. I don't know any formerly infested people myself, but I've heard stories, stories of the /horror/, the horror at being trapped in your own mind, unable to move of your own volition, unable to scratch the itch of your own desires, deprived utterly of the freedom even to keep your imagination to yourself. Can /you/ imagine what it's like to be controlled in that way? How can you not see the moral atrocity of your invasion? Wait, of course you see it, you can read the pain directly from the mind of your host, yet somehow you /continue/ occupying his body. The moral thing for you to do is crawl out of his head and die /right now./
:PROPERTIES:
:Author: LieGroupE8
:Score: 15
:DateUnix: 1501893841.0
:END:

*** We have no way of knowing. Alien disinfo, teenager messing around trying to scare people, real alien actually on reddit, some nation-state pulling a false flag, "Animorph" hoaxers sustaining the gag, hyperintelligent AI with aims we can't guess. We don't really have priors or any way of verifying any claims.

All we can do is try to prompt as much information disclosure as possible. See if there's any inconsistencies or if it seems completely made up. Act like we accept it's true, or at least could be, unless we can conclusively disprove it.

We don't know that Oliver Faure (can someone find this guy's social media at least?) can retain any Yeerk info after being unpossessed. Right now Starrat has the information of two minds, one of which might be lost if we encourage him to suicide. Even though it's not ideal, we have to prolong Oliver's slavery to try and get what we can out of Starrat 731.
:PROPERTIES:
:Author: AnonymousAvatar
:Score: 7
:DateUnix: 1501897456.0
:END:

**** I mean, I could get out of Olivier's head (that's Olivier, with a 'i', btw) and die? He'd be okay. Probably more okay than if I died in his head, actually.

Good luck making me do that.
:PROPERTIES:
:Author: CouteauBleu
:Score: 5
:DateUnix: 1501925779.0
:END:


*** Has literally any living thing ever just /laid down and died/ because it realized a /moral/ problem with its existence? Has that kind of abstract, disembodied Thou Shalt ever mattered to /anyone/?

Plainly the only way to solve this problem is to take a third option and find some way for the Yeerks to exist as something other than parasites or invaders.

I mean, hell, can you imagine being a sapient individual with emotions, hopes, and dreams... /and you're a fucking slug/? A slug! You can't even move around or anything!
:PROPERTIES:
:Score: 8
:DateUnix: 1501905961.0
:END:

**** You're right and wrong at the same time. It's not about being a slug. Being a yeerk without host... I think it's pretty close to what humans with total locked-in syndrome feel.

Imagine it as being with 100 people in Plato's metaphorical cave. Every so often, one guy gets to go outside the cave interact with the outside world, maybe bring back (metaphorical) food or (metaphorical) fire. For most of you, your only interactions with the outside world are talking with the people who got out of the cave, and speculating, and preparing instructions for the next guy to go.

Except it's not reliable. You ask the last "scout" a question like "Hey, what color were the trees?", and he answers "I didn't look" or "I don't remember". So you make sure to ask the next guy to look at the trees' color; but other people also have a lot of questions, and the scout only has three (Earth) days to look, and he might forget too, and you can't always predict who will be the next guy to get out of the cave, etc.

Then you get to be the next guy out of the cave. You can see everything. You have hundreds of questions to answer, including your own. You can interact with the world, and you have a /purpose/. Until you need to get back to the pool.

So yeah. Infestation is awesome. For me.
:PROPERTIES:
:Author: CouteauBleu
:Score: 5
:DateUnix: 1501926282.0
:END:

***** I notice you still don't seem to have moral qualms, nor to even desire a way to avoid the harm you inflict on humans. Interestingly, you describe your slug state as "locked-in syndrome", which is /exactly/ what you do to your hosts.

So I think we're gonna have to exterminate you. Oh well, it was a nice try.

Anyway, so what do you do when you see humans' sexual fetishes in their heads?
:PROPERTIES:
:Score: 6
:DateUnix: 1501945683.0
:END:

****** #+begin_quote
  So I think we're gonna have to exterminate you
#+end_quote

Yeah, people with better technology, better military commanders and a unified planetary government have tried. The Visser killed millions of you as /collateral damage/. We have antimatter bombs.

Let's not get into threats.

#+begin_quote
  Anyway, so what do you do when you see humans' sexual fetishes in their heads?
#+end_quote

Generally speaking, either be vaguely embarrassed or not give a shit. Speaking for myself, act upon (some of) them.
:PROPERTIES:
:Author: CouteauBleu
:Score: 4
:DateUnix: 1501961372.0
:END:

******* Well, since my appeals to ethics are going nowhere, I might as well satisfy my curiosity. What do you do when your host is sleeping? Do you sleep too? Do you think about your own things? Do you influence his dreams?
:PROPERTIES:
:Author: LieGroupE8
:Score: 5
:DateUnix: 1501971639.0
:END:

******** Yes to the last part. No comment on the rest.
:PROPERTIES:
:Author: CouteauBleu
:Score: 3
:DateUnix: 1501975321.0
:END:


*** Re: the bucket list thing - Not exactly as you imagine it. My... let's call it my purpose, is to learn and amass new experiences. This seemed like the last opportunity I'd have to do so, so I'd make it count. It's not a literal "things I dreamed to do before I died" thing.

Re pleasure and pain: I think you're confused. Feeling pain and feeling empathy aren't the same thing.

For starters, I think you're over-estimating the horror part of the enslavement experience. It's not like our hosts are in constant physical pain. We can control some of our hosts' feelings, both with direct brain "contact" and with a healthy diet, sports, etc. The horror you heard about exist, but it was at it fullest when the humans were in the cages or after they were freed. While we're in their brain, it's more of a muted, quiet existential horror. We can both ignore it most of the time. Right now Olivier knows I'm about to die, so it's mostly awkwardness with some hope and a bit of boredom.

Second, I'm guessing you think of morality as an absolute thing. Like, if you feel pain, you realize that pain is bad and no-one should get to feel it. That's not really how it works. The only reason you're believe that ethics are something that exists is because your species evolved to have strong social mechanisms, which means you have a lot of empathy. So when you see someone suffer, you feel bad, especially if you feel similar to them. Most advanced species have high empathy, btw, that's not really a human thing.

The thing is, most species feel empathy in a different way, and yeerk do too. The most obvious metaphor is "but humans kill cows", but I don't think it works that well, because the social dynamics are completely different. (though I guess the invasion force at Venture could have been called "vegans"; sort of; not really)

The way yeerks see humans is closer to the way humans see their computers or their pets. Except not really, because you have a ton of movies about robots who start demanding rights and dignity and stuff. My point is, we don't see you as people, we see you as resources. I know all about how human psychology relates to dehumanization. I understand about the iterated prisoner's dilemma. And, seeing our recent shortcoming, maybe we'd have been better off if we'd approached you as equals, forced ourselves to respect your agency, and tried to create some sort of voluntary infestation program.

But these things are tactical considerations, not ethical ones. I have nothing to gain and everything to lose by releasing my host right now. So, sorry not sorry.
:PROPERTIES:
:Author: CouteauBleu
:Score: 5
:DateUnix: 1501925674.0
:END:

**** #+begin_quote
  I'm guessing you think of morality as an absolute thing.
#+end_quote

It is. It is the set of logical consequences of a certain collection of axioms, including an axiom about empathy. Empathy is what makes morality /morality/, and not just some sort of rational egoism. The mere fact that you evolved to not recognize this, or that I evolved to recognize it, does not motivate me to change my own position. The only moral response to a species which does not recognize morality is hostility.

#+begin_quote
  So, sorry not sorry.
#+end_quote

Look at you, being an apologist for slavery using flippant idioms from your host's own enslaved intelligence.

Fine, you don't want to die? I get it. So go to a zoo and infest a /monkey,/ if you absolutely must have a host. Hell, go to a hospital and pilot the body of a coma patient. I'll wait. Maybe if you yeerks can show that kind of commitment to minimizing enslavement, we can talk about peace. Maybe.
:PROPERTIES:
:Author: LieGroupE8
:Score: 5
:DateUnix: 1501953286.0
:END:

***** That sounds like a cool insult, honestly. "[[http://cinnamonbunzuh.blogspot.fr/2012/01/book-19-departure.html][Your mother infested a monkey!]]". I mean, I could, but a monkey body is a serious downgrade from a human body, and also I would probably die because most monkeys don't sit on caches of maple oatmeal.

#+begin_quote
  The only moral response to a species which does not recognize morality is hostility.
#+end_quote

I'd argue that it's a practical response, not an ethical one.

But yeah, I hear you. We had a shot at enslaving the entire planet and reaping the benefits (a huge war machine, relative safety from extinction) and we blew it, and now we're in an awkward position.

Rational egoism + benefits of hindsight tells me we'd have been better off if we'd approached the planet openly, and tried to build a yeerk-human society based on consensus and cooperation; but I don't delude myself in thinking there's any higher value in ethics than "rational egoism" mixed with a heavy does of "being afraid of revenge" and capitalism.

/META: And now I'm reading cinnamon bunzuh again./
:PROPERTIES:
:Author: CouteauBleu
:Score: 6
:DateUnix: 1501962144.0
:END:

****** Openly admitting that you would totally enslave and exploit us if it were at all practical is /not/ a great way to repair relations with a species that actually does think there is a higher value in ethics (or really any species for that matter). So tell me: if you could modify your biology so that you weren't dependent on another (intelligent) species to accomplish anything, would you do it? Or if you could modify your values so that you actually /do/ value ethics/empathy intrinsically, would you do it, even if only for the purpose of fostering strategic cooperation with humans?
:PROPERTIES:
:Author: LieGroupE8
:Score: 5
:DateUnix: 1501970537.0
:END:

******* I can't speak for my entire species, but personally speaking, no and maybe.

The topic includes a bunch of information I'm not ready to share, but speaking in broad strokes... Intrinsic values aren't really that important to humans. Values and social standards come from arrangements of convenience, and the standards change to follow the practical interests, not the other way around. They matter even less to yeerks; where human societies change their outlook over the course of decades (eg regarding homosexuality), yeerk societies change over the course of /months/ (hence the Aftran force in Ventura having second thoughts).

If, and it's a big if, diplomatic relationships open, our outlook will matter on a personal and societal level, not on a grand strategy level. I'd argue that outlook doesn't really matter in realpolitik. Most human countries act like impulsive narcissists if we interpret them as coherent entities anyway.

The way it will work is, sooner or later, one of two things will happen:

- Open war will start, until one side is incapable or unwilling to fight any longer (most metropolises will be smoking craters at that point)

- A country or two will start a program for yeerk integration. There aren't many of us, so given a 0.1% "integration" rate, a population of 1'000'000 or more would be enough. We could all fit within Paris/NY/London (assuming we don't blow them up next; again, not speaking for high command, but I do want to point out it's on the table).

Let's assume everything goes well (it won't, the Visser's a jerk). There will be riots demanding we be all killed or sent off planet somehow, political movements and external pressure by other countries to stop the program. Let's assume they all blow over.

As this point, we'd basically have to hand ourselves over for the infestation program to proceed. No-one would accept it otherwise. We'd have so sign treaties, surrender our fleet and our military secrets to whatever country welcomes us, and put ourselves at their mercy.

At this point, integration becomes less about grand strategy and more about personal relationships. This is uncharted territory, because Yeerks have zero experience with consensual relationships so far. Like, imagine you come from a culture where all men/women you date are slaves. That's the socially accepted norm for relationships: a master and a slave. The slave has absolutely no say in how the relationship works, what the master does, whether or when they have sex, when they spend time together, what they talk about, etc. Imagine those relationships are all you know... and then you date a millennial, who thinks relationships should be between equals.

No matter how well-intentioned you are, you're going to make blunders. That's why I'm saying values don't matter that much. Integration will be about yeerks and humans learning the ropes of cohabiting, and eventually they will form habits which will become rules which will become an ethics code, and they'll all agree that people like me were awful and they're very sorry about us (and Ventura).

I guess I could pay more lip service to their future beliefs, help my species' diplomatic relations... fuck that. I was never much for hypocrisy.
:PROPERTIES:
:Author: CouteauBleu
:Score: 5
:DateUnix: 1501977670.0
:END:

******** I don't really disagree with any of this on a factual level, though I can't say the same for any philosophical conclusions that I may have been intended to draw thereby.

How much of this is your own philosophy, and how much is borrowed from your human host?

Also, you say the Visser is a jerk. Interesting. What is your opinion of him, and his actions in Ventura? On this topic, what is your opinion of the "Animorphs" and their actions thus far?
:PROPERTIES:
:Author: LieGroupE8
:Score: 1
:DateUnix: 1501983454.0
:END:

********* The game theory and sociology bits are mostly from my and other hosts. The philosophy and future predictions are me.

I don't like that Esplin killed an entire colony, with millions of humans and thousands of yeerks, to cover his mistakes. No more on that.

Re - Animorphs: I guess I'm just as puzzled as anyone. These are teenagers. How did they blow up our main pool (killing thousands of us, by the way), and how did they survive a goddamn meteor strike? Is this Harry Potter, and one of them is the Chosen One?
:PROPERTIES:
:Author: CouteauBleu
:Score: 1
:DateUnix: 1502013215.0
:END:


******* I vote we start feeding everyone we can grab maple instant oatmeal and see who develops addiction symptoms.
:PROPERTIES:
:Score: 1
:DateUnix: 1502061935.0
:END:


***** Pffffffft look at the guy who thinks morality is axiological.
:PROPERTIES:
:Score: 1
:DateUnix: 1502061777.0
:END:


** Would you rather control 1 horse-sized duck or 100 duck-sized horses?
:PROPERTIES:
:Author: keeper52
:Score: 9
:DateUnix: 1501907164.0
:END:

*** Neither. I want opposable thumbs, man.
:PROPERTIES:
:Author: CouteauBleu
:Score: 7
:DateUnix: 1501926345.0
:END:


** [META] Alright, I'm going to call it quits.

It was pretty fun, but I think we've explored most of the questions you guys had to ask.

Again, for the record, I'm no philosopher, I'm no neurosurgeon and I'm no yeerk. Everything I said about qualia is mostly my uninformed beliefs + "make it up as I go along". Everything I said about philosophy is mostly me trying to a steelman a nihilist moral relativist henchman, 'cause they usually get the short end of the stick in fiction.

I want to insist, don't take anything I said from a position of authority, and remember this is mostly non-canon. On the other hand, now that it's over, I'd be interested in [[/u/TK17Studios][u/TK17Studios]] 'returns on the whole thing.
:PROPERTIES:
:Author: CouteauBleu
:Score: 6
:DateUnix: 1502013542.0
:END:

*** Holy CRAP. I haven't read anything but the OP yet, but this sounds awesome. Diving in.
:PROPERTIES:
:Author: TK17Studios
:Score: 3
:DateUnix: 1502014120.0
:END:


** how the fuck do you unify quantum physics with general relativity to produce a quantum theory of gravity that doesn't have infinities everywhere

while I'm asking an alien to solve longstanding dilemmas in science, it occurs to me that if anyone knows the answers to the hard problem of consciousnesss it's the aliens with universal brain adapters. any insight you shed would be appreciated.
:PROPERTIES:
:Author: Aretii
:Score: 3
:DateUnix: 1501897194.0
:END:

*** 1 - No idea.

2 - The "hard question" sort of answers itself. There is no such thing as qualia, and we're all philosophical zombies. The main reason that your own thinking seems so untractable is that you have a lot of processes under the hood, that operate without you being aware of them.

Like, not just physical processes (processing thousands of little eye-pixels into an image, running your body), but mental processes as well. You thoughts are messages that are sent from one part of the brain to another; each of these messages passes through different parts of your brain that augment or process them in some way, and usually you can't detect those parts (you can just feel the effects when they go wrong).

From where I'm standing, the process is basically

- Information

- Information with noise and details removed

- Information weighted with priors and a few heuristics

- Altered brain state.

The reason it doesn't feel like a physical process, (like, for instance, your vision) is that your "consciousness" only perceives things that have gone through this process, and isn't aware of the intermediate steps on any level (just like your intestines are basically unaware of your stomach).

PM me if you want the longer neurology explanation.
:PROPERTIES:
:Author: CouteauBleu
:Score: 5
:DateUnix: 1501924024.0
:END:

**** You know, for a brain parasite, you ain't so good at neuroscience.
:PROPERTIES:
:Score: 2
:DateUnix: 1502062117.0
:END:

***** /META:/ Well, yeah. I can't pretend to be better at neuroscience than I am. I think literary conventions say we're supposed to find what I say very insightful and impressive anyway.
:PROPERTIES:
:Author: CouteauBleu
:Score: 1
:DateUnix: 1502089193.0
:END:

****** META: Or maybe Olivier has limited and flawed knowledge of neuroscience, but thinks he's way better-informed than he is, and Starrat has no way of knowing that Olivier is not in fact an expert on the subject.
:PROPERTIES:
:Author: LazarusRises
:Score: 2
:DateUnix: 1502129641.0
:END:

******* :(

Seriously though, that wouldn't work. A yeerk would have a pretty intimate understanding of brains (especially since they can adapt to different species, so they'd be able to compare their psychologies). So if were to, say, write a serious fanfic of this, I'd probably research my stuff more.
:PROPERTIES:
:Author: CouteauBleu
:Score: 2
:DateUnix: 1502130327.0
:END:

******** Aw I didn't mean to be cruel! I don't know anything about neuroscience either :P

I don't think a Yeerk necessarily has to understand brains. Just like you said, we don't 'understand' our own internal processes on an intuitive level--we didn't even know about the circulatory system until the Renaissance. As Gedds didn't exactly have the capacity for advanced medical science, the Yeerks have only had a few years to really dig into brains, hardly enough to come to a comprehensive understanding of how all sentient brains work.
:PROPERTIES:
:Author: LazarusRises
:Score: 2
:DateUnix: 1502131078.0
:END:


******** META: if you write a fanfic of this, I can write some background materials for you to make it neuroscientifically plausible. Not all true, obviously, but not obviously false based on today's science.
:PROPERTIES:
:Score: 1
:DateUnix: 1502139565.0
:END:

********* See this with [[/u/TK17Studios][u/TK17Studios]]. He's (probably) making this into an interlude.
:PROPERTIES:
:Author: CouteauBleu
:Score: 1
:DateUnix: 1502212593.0
:END:


********* I'd take an infodump of this if you're willing; this was likely to be my writing project for the evening but I can push it back a bit.
:PROPERTIES:
:Author: TK17Studios
:Score: 1
:DateUnix: 1502233983.0
:END:

********** Yo, infodump!

So the first thing is to maybe read [[http://philosophyofbrains.com/2015/12/14/surfing-uncertainty-prediction-action-and-the-embodied-mind.aspx][the introductory overview]] to predictive processing. We can go from there. You might also have seen some SSC posts about "Bayesian brain" stuff: this is that stuff.

The important thing for Yeerks is that actions are created when top-down predictions are more precise than bottom-up prediction-errors; in Bayesian terms, when the prior is more informative than the likelihood. In this model, everything from the highest layers of the neocortex to the spinal cord does its little "Bayesian handshake", and then samples a downwards prediction of its own. The only difference is that when the spinal cord does the "handshake", it has a second way to shake hands: it can quash the bottom-up error signal, the one saying "That muscle isn't /there!/", by just /moving/ the muscle.

This means that the balance between action and body-placement sense is found in those top-down and bottom-up precision signals. When the bottom-up precision is greater, you sense where your muscles /are/; when the top-down precision is greater, you /move/ the muscles.

There's an interesting detail here: what humans consciously perceive is the top-down predictions, not the bottom-up errors. So when you sense something, the signal actually travels upwards to compute a new prediction, it all handshakes once all upward errors have become negligible, and then you perceive the new prediction that moves downwards again. Maybe Yeerks work that way, maybe they don't.

This is all important for how you infest a brain. Let's say you sit wrapped around the highest layers of cortex, and you start learning how those cells are working from your "skin", which of course has a layer of your own neural tissue. Assume relative electrochemical compatibility between the two kinds of tissue. Eventually, you're going to learn to interpret the activities of the neurons below you, and you're going to "sense" the waves of predictions and errors that constitute the waves of perception and action.

What can you do, as the Yeerk? Well, you can peek and poke signals to the neurons you can touch. Now, sending your own signals down purely exteroceptive perception pathways will just cloud your own vision: you /need/ percept signals to perceive the world from inside the skull. But you can do something useful: you can send your own signals down proprioceptive and motor pathways, /including/ precision signals. In fact, you can probably modulate the precision signals so that the "predictions" (motor commands encoded /as/ predictions) /you/ send down the motor pathways have /more/ precision than those that the rest of the infested brain is trying to generate. So the motor pathway ends up disregarding the rest of its own brain, and listening to /you/ instead.

Since you're already peeking at the perceptive and memory pathways, you can integrate the information. You perceive as the human perceives, remember as they remember, and can act as /you/ please.

Of course, there's going to be some dangers here. Emotion is modeled (in this whole theoretical framework) as interoceptive ("from the guts", inside-the-body) perception (perceiving "how am I" in the bodily sense). Strong emotion will come from highly precise interoceptive prediction errors. Likewise, "willpower" could be modeled as the executive functions of the brain volitionally tuning up the precision on its own motor signals, but spending energy on the precise computations needed to do so (since tuning up precision means taking away autonomy from the lower layers, resulting in more time spent on Bayesian handshakes at the higher layers). So extraordinarily strong emotion or willpower /could/ override the Yeerk's control signals to break through, as we once saw with Marco's mom.

There'll also be the trouble for the Yeerk of learning how to "pilot" the autonomic motor systems well enough that they don't start firing large, precise errors all over the place, causing the rest of the Controlled brain to pitch a fit. In fact, the Yeerk will have to spend some time learning how to control the motor systems and understand the perception systems for each new species it infests, as an individual. Yeerk pools will probably need have some training hosts available to teach newly spawned or arrived Yeerks how to pilot the local bodies.

Aaaaaand that's the end of it. I have to go buy groceries. In real life there would be numerous incompatibilities of biology, neural tissue, and neurocomputational algorithms, but for hard scifi purposes, we can more-or-less render Yeerks and other brain parasites neuroscientifically and cognitive scientifically plausible /enough/.

For extra twist-the-screws horror, the Yeerk can sometimes sadistically note to the host that each layer of cortex is basically a Yeerk-esque controller to the layer below it. That's why Yeerks can /be/ so plausible: the hierarchies of the brain are constructed around each layer up piloting the one below it through both perception and action, ending at the highest executive functions and the muscle reflex arcs in the spinal cord.
:PROPERTIES:
:Score: 2
:DateUnix: 1502650593.0
:END:

*********** w00t

eternal gratitude
:PROPERTIES:
:Author: TK17Studios
:Score: 1
:DateUnix: 1502664852.0
:END:


********** I'm out with my wife right now. Will write a short version tomorrow.
:PROPERTIES:
:Score: 1
:DateUnix: 1502249203.0
:END:

*********** It is today. =D
:PROPERTIES:
:Author: TK17Studios
:Score: 1
:DateUnix: 1502414524.0
:END:

************ On vacations I am captive to my wife, who says Reddit just makes me angry. Send the A-Team.
:PROPERTIES:
:Score: 2
:DateUnix: 1502415504.0
:END:

************* I am literally the last person allowed to complain about people sending writing in late, so no worries. Enjoy the vacation!
:PROPERTIES:
:Author: TK17Studios
:Score: 2
:DateUnix: 1502417172.0
:END:


** Nothing strategically relevant?

What's your favorite Earth-food, and why?

I mean, besides brains.

[[/disblegh][]]
:PROPERTIES:
:Author: IAMA_Draconequus-AMA
:Score: 5
:DateUnix: 1501900267.0
:END:

*** Brains aren't my food. They're more like my favorite cushions!

Ralph's brand maple oatmeal. It has this subtle flavor of not dying slowly and painfully, I just love it for some reason. (but it actually tastes like crap; never liked oatmeal much)

Croissants. There's something beautiful about a thing that crafted with so much love and effort, just for us to consume. (this was a subtle metaphor!) Seriously, though, viennoiseries are the best.
:PROPERTIES:
:Author: CouteauBleu
:Score: 8
:DateUnix: 1501924864.0
:END:


** Why yes, this /is/ allowed, and yes, I can pass a test for not being a Controller. Yes, I will spend three days in the hut. Or three weeks, or whatever it is. Just pay for the hut, give me some instant oatmeal, and let me have an internet connection so my job doesn't think I'm missing.
:PROPERTIES:
:Score: 3
:DateUnix: 1501904970.0
:END:


** Did you have friends when you were in the pool? Like were there a few other Yeerks that you especially liked to talk to?

Do you have friends now? Either other Yeerks, or just regular people who you like to talk to or spend time with?
:PROPERTIES:
:Author: keeper52
:Score: 3
:DateUnix: 1501907981.0
:END:

*** In the pool: no comment.

Now: I can't answer in detail (identifying info), but yes to both. I avoid hanging out with other controllers too much; there aren't many of us in Paris, and if one of use get caught... well, espionage, isolated cells, you get the idea. We do chat online pretty often, though.

Also, I do a lot of sightseeing.
:PROPERTIES:
:Author: CouteauBleu
:Score: 3
:DateUnix: 1501926924.0
:END:


** Monsieur "Starrat", votre anglais est très bon, mais j'ai une petite question logistique: vous semblez parler l'anglais comme langue maternelle, mais vous prétendez utiliser uniquement les connaissances d'Oliver Fauve. On peut supposer que votre français est encore mieux. En mettant de côté la nature exclusivement répréhensible de votre espèce, je suis curieux de savoir comment accéder aux souvenirs et aux expériences d'Oliver si rapidement. De plus, je suis curieux de savoir si vous conservez les souvenirs et les expériences lorsque vous changez d'hôte. Je ne m'intéresse pas à moi même, mais serait-il possible pour vous de donner aux compétences d'anglais d'Oliver directement à une autre personne?

De plus, quelqu'un peut-il confirmer si "Oliver Fauve" existe vraiment? Date de naissance, histoire de l'emploi, quoi que ce soit. Quelqu'un devrait dire à sa famille (si ce n'est pas trop tard).
:PROPERTIES:
:Author: kleind305
:Score: 3
:DateUnix: 1502053825.0
:END:

*** /META - Translation for those wondering:/

Mister "Sarrat", your english is really good, but I have a small logistic question: you seem to speak English as a mother tongue, but you claim to only use Oliver Faure's knowledge. We can suppose your French is even better. Leaving aside the exclusively reprehensible nature of your species, I'm curious to know how to access (sic) Olivier's memories and experiences so fast. Moreover, I'm curious to know if you conserve memories and experience when you change hosts. I'm not interested in myself (sic), but would it be possible to give Olivier Faure's english skills directly to someone else?

Moreover, can someone, confirm whether "Olivier Faure" really exists? Birthdate, job history, anything. Someone should tell his family (if it isn't too late).
:PROPERTIES:
:Author: CouteauBleu
:Score: 3
:DateUnix: 1502054430.0
:END:


*** "Olivier Faure" is obviously a pseudonym, and I'm not going to help you contact his family. Anonymity is a matter of survival right now.

Regarding skill transfer: I think that's tactical intelligence, so no comment. Olivier's mother tongue is French, and he does speak English somewhat.

--------------

/META:/ Thanks for the compliment, I guess. Most of my internet browsing is on english-speaking websites, so that helps. Of course speaking in real-time is way harder. Oliv*i*er Fau*r*e is my real name, since this is kind of a Self-Insert. In retrospect, it would make way more sense for Sarrat to use a pseudonym, since he's on the run. (also, this is a surprisingly common name; googling it will give you a Parti Socialiste deputy).
:PROPERTIES:
:Author: CouteauBleu
:Score: 1
:DateUnix: 1502055064.0
:END:

**** Unfortunately, the existence of google translate made it very difficult to learn french the way I was supposed to. I always lean too hard on it.

Intended to be along the lines of "how you access Olivier's..", since it would seem that yeerks are able to access the memories fast enough to avoid suspicion. Clearly the host helps unintentionally, but even so.

also: "I'm not interested, myself, but would.."
:PROPERTIES:
:Author: kleind305
:Score: 1
:DateUnix: 1502060754.0
:END:


** What does "good" look like to you? Your answer can take the form of defining good or laudable acts, describing a good society, or expressing what makes another person or individual good. How does that conception of good square with that of your hosts and how do feel about your hosts conception of good? As a corollary feel free to answer the same questions for "bad".
:PROPERTIES:
:Author: swaskowi
:Score: 2
:DateUnix: 1501904470.0
:END:

*** I guess it depends on what "good" you mean. Like, when someone says "wow, this is a really good fruitcake!", it's a valid english sentence, but it's obviously not the same good you're talking about.

Humans have different 'levels' of good too. First you have "What gets me my dessert" then you have "What keeps my parents happy with me", then "What my peers approve", and eventually "What I approve".

Mostly ethical thinking is a process of internalizing social norms and external pressures into your own thinking. It often boils down to "Treat others as you would have them treat you", but it can vary from culture with added caveats and rules.

So our own conception of 'ethics' and good would be pretty similar on some points (though pools are a cultural entity much stronger than most tribes, no comment on that). Killing other is bad, stealing is bad, etc.

Regarding your underlying question "How do you feel about being a monster to your host and the fact that your host thinks you're a monster", I'm mostly okay with that?

It's not like yeerk society was shaped in a multi-cultural environment where we had to learn to cooperate with and respect other cultures. We take what we need and that's about as far as it goes regarding other species.
:PROPERTIES:
:Author: CouteauBleu
:Score: 3
:DateUnix: 1501928465.0
:END:


** Why do you consider Oliver an asshole?
:PROPERTIES:
:Author: MrCogmor
:Score: 2
:DateUnix: 1501905948.0
:END:


** Have you ever been in other species? Or in other people besides Olivier?

If so: what's it like? Do they have different qualia? Like, if you've been in a species that has sonar, could you describe what that's like to a human? Or do colors seem different to different people? Anything like that?
:PROPERTIES:
:Author: keeper52
:Score: 2
:DateUnix: 1501907283.0
:END:

*** No and no.

Re - the color thing: sort of. Imagine colors are letters. What you're thinking is "When Alice sees a G, does Bob see a Y?". The truth is, they both "see" the same "letters", except they see them in a different "handwriting". (except color-blind people, and other exceptions, you get my point)

Re - different qualia: I honestly couldn't describe it to you. The thing is, yeerks don't really "feel" their host's qualia, they perceive the processes underlying it.

If I described a human's processes to you, you wouldn't be able to map much of it to your own subjective experience. For instance, I can spend all day talking about the patterns of anger or happiness, how they work, what stimuli create them, how they propagate to your brain... but it wouldn't make you visualize/feel these emotions the way a good movie would. So me describing a sonar's qualia wouldn't really mean anything to you.

Re - how different are they: a lot. Most species has the same core senses and emotions (sight, hearing, fear, anger, etc), but they all feel them on wildly different scales, and they all have different secondary senses.

Humans have a really good sense of depth, and extremely sharp awareness of their environment. Some have a ridiculously fine sense of smell and taste (and they eat /a lot/). Some are tree-dwellers, and they have amazing balance and proprioception. Some can map heat and air currents around them in three dimensions, and perceive how they evolve and how they're going to go.
:PROPERTIES:
:Author: CouteauBleu
:Score: 3
:DateUnix: 1501964093.0
:END:


** Can you tell us a joke, like you would tell it to another Yeerk? Or something you find funny.
:PROPERTIES:
:Author: keeper52
:Score: 1
:DateUnix: 1501908105.0
:END:

*** Yeerks don't have a sense of humor except when they infest humans.

Um... C'est un mec qui entre dans un café et plouf.
:PROPERTIES:
:Author: CouteauBleu
:Score: 1
:DateUnix: 1501926443.0
:END:


** I think the military found him.
:PROPERTIES:
:Author: callmebrotherg
:Score: 1
:DateUnix: 1501909545.0
:END:

*** Nope. Different time zone.
:PROPERTIES:
:Author: CouteauBleu
:Score: 2
:DateUnix: 1501924028.0
:END:


** Starrat, what is your take on the recent French election?
:PROPERTIES:
:Author: Ardvarkeating101
:Score: 1
:DateUnix: 1502047772.0
:END:

*** I thought the presidential debates were fascinating. You can learn a lot about a culture by knowing who its politicians are, what they represent, what message they put forward and which information they think is a strong argument.

I didn't care much for the results themselves.
:PROPERTIES:
:Author: CouteauBleu
:Score: 1
:DateUnix: 1502050950.0
:END:


** It's been a few days. Do you still have oatmeal?
:PROPERTIES:
:Author: Brain_Blasted
:Score: 1
:DateUnix: 1502203838.0
:END:

*** Argh eurh pain death eeuuuuurh.

Also the AMA is closed, so let's say one of four things happened:

- Starrat killed himself with his Dracon beam.

- Starrat was captured trying to breach the Paris quarantine.

- Starrat starved to death.

- A yeerk commando was sent to terminate Starrat.
:PROPERTIES:
:Author: CouteauBleu
:Score: 1
:DateUnix: 1502213153.0
:END:
