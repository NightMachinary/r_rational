#+TITLE: [Q] Examples of realistic rational fiction

* [Q] Examples of realistic rational fiction
:PROPERTIES:
:Author: bribedzapp
:Score: 15
:DateUnix: 1449417063.0
:DateShort: 2015-Dec-06
:END:
I've been searching for alternatives to the glorification of irrationality that I seem to notice in mainstream fiction and movies.

I was introduced to the idea of rationality in fiction by Ayn Rand's Fountainhead, although I'm aware she isn't a shining example of rational fiction.

To be honest, in reading your "Characteristics of Rational Fiction" sidebar, I identified entirely with the proposals therein, but I have never felt compelled to delve into either the sci fi or fantasy genres. As a rule, I tend to drift toward satire from many sources.

That being said, I don't want you all to think that I'm lambasting the genres. I am only asking humble questions.

My question is two-fold: Is rational fiction necessarily sci fi or fantasy related? I imagine the answer is no, but I'll let you guys confirm my suspicion or not.

Lastly, what are some examples of realistic rational fiction?

Thank you.


** The problem with realistic rational fiction set in the now is that the people who are able to write it are much better suited using that ability elsewhere.

Reality is complicated. It's hard and costly to figure out what information you're missing that you need. Experiments are not nice and neat, [[/u/eaturbrainz]] made a point about how SF&F is much more /accessible/ to the experimenter. I've complained quite a bit, either internally or externally, about the assumptions that characters in stories are able to make about the results of their experiments, simply because the author didn't think of all the other hypotheses that could explain the character's observations. But basically, fiction is simplified, because it was created by a human brain, and human brains cannot GM for reality.

SF&F has simple rules on the level of toy models, like a spherical cow in a vacuum. Rational stories are able to deal with those. But look at some of these guidelines on the sidebar:

#+begin_quote
  Any factions are defined and driven into conflict by their beliefs and values, not just by being "good" or "evil".

  The characters solve problems through the intelligent application of their knowledge and resources.
#+end_quote

The social aspect is a nightmare. There are over seven billion people on Earth, and all sorts of groups, government agencies, companies, interest groups, that are trying to affect us in some way. The cash flows are ludicrously complex. We don't even know whether the economy is over- or undervaluing certain classes of stocks, because markets are social and depend on assumptions en masse.

So, reality is complicated. The reason rational fiction does not try to deal with reality is because of this. A rational protagonist that is not given some special systems to study and abilities to exploit, be they fantastic or science fictional, then has to deal with application of rationality to the mundane, which is what the author is supposed to be doing in the first place. Without a special system, they aren't able to accurately describe the effects the character would have on the world around them. Without special abilities, the character is powerless compared to any other of their peers. The rational thing to do in reality happens, to /some/ extent, all around us. When people gain a special cause, like maximizing Islam, or maximizing global QALYs, then interesting behavior occurs, but without a comparative advantage in something to the rest of the world, interesting things do not happen. Real life happens.

So, the reasons are one, but it has two expressions. First, the system that is available for study is the same as in reality, and thus hard to realistically experiment on and fairly boring (why not magic!), and the abilities provided are limited to those in reality, which is not much of an obstacle but then limits interesting stories to people with lots of money and/or very little governmental oversight.
:PROPERTIES:
:Author: Transfuturist
:Score: 55
:DateUnix: 1449431781.0
:DateShort: 2015-Dec-06
:END:

*** I feel like either i am missing something or what you are saying comes with extra assumptions about the nature of rational and\or realistic fiction.

I mean, sure the things you write will make it kind of impossible to write realistic rational fiction where the MC conquers the world without understanding the full power structure of the world. But how would that really prevent writing good rational detective stories for example? or a drama? horror? thriller? all of those are possible without breaking the list on the right of this sub..

having said all of that, even if you did attempt to write a rational realistic story where the MC unites earth under some actual central government, neither the "realistic" nor the "rational" aspects demand that every single thing you say will be scientifically proven. if you believe the world works some way and you wrote a story that way, even if you miss interpreted the political power balance in some country, or the cause for economic issues in another, it still will be fine. the point of rational fiction is that you won't make things conveniently happen for your story to progress. meaning less literary shortcuts. and realistic fiction is about stories that could happen in real life, meaning no invented world mechanics.
:PROPERTIES:
:Author: IomKg
:Score: 9
:DateUnix: 1449487427.0
:DateShort: 2015-Dec-07
:END:

**** u/Transfuturist:
#+begin_quote
  But how would that really prevent writing good rational detective stories for example? or a drama? horror? thriller?
#+end_quote

Small scale is certainly possible, that is true. I'm not sure what drama is exactly as a genre, but it sounds a lot like it depends on miscommunication.

#+begin_quote
  if you believe the world works some way and you wrote a story that way, even if you miss interpreted the political power balance in some country
#+end_quote

The problem there is not even getting everything correct, it's simply the complexity that would arise when the entire world is the scope of your story. Significant Digits manages to do well to make the world-optimization subplot satisfactory, but it's using gross simplifications, because the politics and machinations themselves are not what the story is about. Neither is realism the case in Death Note; the only efforts of the UN are to create a very tiny detective force in Japan with a memorable cast of characters and direct relation to the protagonist's father, big surprise. Making a realistic story /about/ world optimization would be incredibly difficult.
:PROPERTIES:
:Author: Transfuturist
:Score: 2
:DateUnix: 1451505793.0
:DateShort: 2015-Dec-30
:END:

***** A drama could be about many things i think, could be about a family handling a child being diagnosed with cancer for example. I don't see any issue with making that setting rational.

It will definitely be difficult to write a realistic world unification rational fic where a single character based on it's abilities optimize the world entirely. but you could write about someone trying to do that by for example running for presidency or somesuch.
:PROPERTIES:
:Author: IomKg
:Score: 2
:DateUnix: 1451581779.0
:DateShort: 2015-Dec-31
:END:

****** u/Transfuturist:
#+begin_quote
  could be about a family handling a child being diagnosed with cancer for example
#+end_quote

...NO

DAS IST VERBOTEN
:PROPERTIES:
:Author: Transfuturist
:Score: 1
:DateUnix: 1451591863.0
:DateShort: 2015-Dec-31
:END:


*** u/deleted:
#+begin_quote
  The rational thing to do in reality happens, to some extent, all around us. When people gain a special cause, like maximizing Islam, or maximizing global QALYs, then interesting behavior occurs, but without a comparative advantage in something to the rest of the world, interesting things do not happen. Real life happens.
#+end_quote

Of course, this does mean that /having a concrete goal around which plans and strategies can be inferred/ is a minor superpower in real life.

/coughcough/getyourselfintoUofA/coughcough/
:PROPERTIES:
:Score: 8
:DateUnix: 1449442349.0
:DateShort: 2015-Dec-07
:END:

**** I'm working on it, geez.
:PROPERTIES:
:Author: Transfuturist
:Score: 4
:DateUnix: 1449443035.0
:DateShort: 2015-Dec-07
:END:


**** What's U of A? University of Alberta?
:PROPERTIES:
:Author: GlueBoy
:Score: 1
:DateUnix: 1449514910.0
:DateShort: 2015-Dec-07
:END:

***** Well, she'd have to tell you where she lives herself.
:PROPERTIES:
:Score: 1
:DateUnix: 1449515662.0
:DateShort: 2015-Dec-07
:END:

****** Ah I thought it was a reference to something.
:PROPERTIES:
:Author: GlueBoy
:Score: 1
:DateUnix: 1449518673.0
:DateShort: 2015-Dec-07
:END:


*** Well said.
:PROPERTIES:
:Author: EliezerYudkowsky
:Score: 10
:DateUnix: 1449436333.0
:DateShort: 2015-Dec-07
:END:

**** [[http://suptg.thisisnotatrueending.com/archive/23588264/images/1362966247406.jpg][Aw, shucks.]]
:PROPERTIES:
:Author: Transfuturist
:Score: 1
:DateUnix: 1449437227.0
:DateShort: 2015-Dec-07
:END:

***** Why is there a firing squad?
:PROPERTIES:
:Score: 1
:DateUnix: 1449441980.0
:DateShort: 2015-Dec-07
:END:

****** It's a marching platoon, not a firing squad. The important part is the exclamation marks, anyway.
:PROPERTIES:
:Author: Transfuturist
:Score: 3
:DateUnix: 1449443531.0
:DateShort: 2015-Dec-07
:END:


*** You said that much more eloquently than the vague thought that was lingering at the back of my mind.
:PROPERTIES:
:Author: FuguofAnotherWorld
:Score: 2
:DateUnix: 1449432321.0
:DateShort: 2015-Dec-06
:END:

**** [[/u/LiteralHeadCannon]] said it much more concisely, so I think he wins instead.
:PROPERTIES:
:Author: Transfuturist
:Score: 3
:DateUnix: 1449432588.0
:DateShort: 2015-Dec-06
:END:


*** I'm a bot, /bleep/, /bloop/. Someone has linked to this thread from another place on reddit:

- [[[/r/bestof]]] [[https://np.reddit.com/r/bestof/comments/3yt576/utransfuturist_explains_why_exploring_smart/][/u/Transfuturist explains why exploring smart, goal-focused characters is easier in science fiction and fantasy than in real life settings.]]

[[#footer][]]/^{If you follow any of the above links, please respect the rules of reddit and don't vote in the other threads.} ^{([[/r/TotesMessenger][Info]]} ^{/} ^{[[/message/compose?to=/r/TotesMessenger][Contact]])}/

[[#bot][]]
:PROPERTIES:
:Author: TotesMessenger
:Score: 1
:DateUnix: 1451498940.0
:DateShort: 2015-Dec-30
:END:


*** u/Tonkarz:
#+begin_quote
  But basically, fiction is simplified, because it was created by a human brain, and human brains cannot GM for reality.
#+end_quote

No, fiction is simplified because "human brains" (by which you mean "authors") have an extremely limited space (either in time, or pages) in which to tell a compelling storyline, and things like hard-line realism interfere with that.

Plus, audiences often don't accept hard-line realism as realistic.
:PROPERTIES:
:Author: Tonkarz
:Score: 1
:DateUnix: 1451549092.0
:DateShort: 2015-Dec-31
:END:

**** Are you seriously saying that human brains (by which I mean "human brains") /can/ GM for reality? I'd like to see you try.

But basically all you're adding here is that the readers are human brains as well. Yes, the medium is inherently limited, but that doesn't keep a /subjective experience/ from being told in rather fine detail. You're not writing up the workings of setting mechanics in third-person omniscient, you're depicting events that characters sense and how they interpret and react to them. The mechanics of the setting are intrinsic to the plot, they're not what's being detailed save through the observable effects. No, hard-line realism does not interfere with the space in which a story is told (No more than the complexity of the real world interferes with the narrative you can make of your own life).

As for what the readers accept, that has every problem inherent with deciding what reality is in the first place, and is yet another reason why those who can write contemporary rational fiction should be implementing instead of just writing about it.
:PROPERTIES:
:Author: Transfuturist
:Score: 1
:DateUnix: 1451549817.0
:DateShort: 2015-Dec-31
:END:


** Are you saying you want to write [[http://alicorn.elcenia.com/stories/earthfic.shtml][earthfic]]?
:PROPERTIES:
:Author: IWantUsToMerge
:Score: 7
:DateUnix: 1449426833.0
:DateShort: 2015-Dec-06
:END:

*** It took me an embarrassingly long time to figure out that this was about fanfiction and not just a reversal of the current treatment of specfic (which is obviously treated much better than fanfic, or earthfic in this story).
:PROPERTIES:
:Author: LiteralHeadCannon
:Score: 2
:DateUnix: 1449429818.0
:DateShort: 2015-Dec-06
:END:

**** Yes, but the opposite of earthfic /is/ specfic, just so we're clear. Specfic is treated like earthfic, fanfic is treated like specfic, and earthfic is treated like fanfic.
:PROPERTIES:
:Author: Transfuturist
:Score: 1
:DateUnix: 1449429997.0
:DateShort: 2015-Dec-06
:END:

***** Yes (although I didn't realize it quite that explicitly because my mind doesn't really file authorized "fanfiction" in the same drawer as the common unauthorized stuff).

People pretend they're not synonymous for ass-covering reasons, but in real life, doesn't "lit fic" essentially mean "earth fic"?
:PROPERTIES:
:Author: LiteralHeadCannon
:Score: 1
:DateUnix: 1449430670.0
:DateShort: 2015-Dec-06
:END:

****** Not all earthfic is literary, actually. But specfic is considered genre fiction and thus can never be literary, although that prejudice is going away with growing acceptance of things like Dune and Tolkien. Once people who grew up reading genre fiction take their place at the top of the ivory tower, specfic will be introduced into literary canon +once more.+
:PROPERTIES:
:Author: Transfuturist
:Score: 1
:DateUnix: 1449432310.0
:DateShort: 2015-Dec-06
:END:


** The trouble is that, unless it requires social power you can't obtain, if you come up with a clever idea for a realistic exploit, it's generally more rational to implement it than write about it. Relatedly, I've had a lot of ideas about how evil forces on the Earth today could optimize for their utility functions, and I've kept quiet about them for fear that the ideas might reach them.
:PROPERTIES:
:Author: LiteralHeadCannon
:Score: 9
:DateUnix: 1449430131.0
:DateShort: 2015-Dec-06
:END:

*** [deleted]
:PROPERTIES:
:Score: 2
:DateUnix: 1449430247.0
:DateShort: 2015-Dec-06
:END:

**** Yes, but they're harder to come up with, vaguer, and/or worse, for entropic reasons.
:PROPERTIES:
:Author: LiteralHeadCannon
:Score: 4
:DateUnix: 1449430428.0
:DateShort: 2015-Dec-06
:END:

***** As EY doesn't put it, it's much easier to fuck +everything+ something up than to get +something+ everything right.
:PROPERTIES:
:Author: Transfuturist
:Score: 7
:DateUnix: 1449432396.0
:DateShort: 2015-Dec-06
:END:

****** No, fucking /everything/ up /all at the same time/ is pretty difficult. Problem is, fucking up one substantial thing still has quite a lot of personal cost.

Like, the primary reason we /don't/ have a society that can easily be destroyed from the inside by one fuck-up is because those kinds of social structures die in embryo /because they suck/. /But/, our societies and structures haven't been optimized /in particular/ for robustness to individual mistakes.

Or actually, I can think of a few that /are/, but they have their other-side-of-the-coin, too: if you engineer the US government to be extremely robust against the personal ideologies of ambitious legislators, then it's extremely robust against the personal ideologies of /good/ ambitious legislators.

Reality doesn't have a built-in alignment system, so it's hard to build human structures that measure alignment well-enough to make themselves /more/ useful to Good than to Evil (and for purposes of this post, assume Good and Evil hold their usual D&D definitions, because why not).
:PROPERTIES:
:Score: 4
:DateUnix: 1449441192.0
:DateShort: 2015-Dec-07
:END:

******* Well, it's more like, there are more groups that are against your utility function than are for it, so it's easier to find utility functions against yours that have low-hanging fruit in their implementations.

Although those in charge of that group may not be implementing those things because their own goals are different from the professed goals of the group, which would be why you have many different ideological revolutions that just happen to benefit one charismatic leader's lifestyle.
:PROPERTIES:
:Author: Transfuturist
:Score: 1
:DateUnix: 1449443428.0
:DateShort: 2015-Dec-07
:END:

******** u/deleted:
#+begin_quote
  there are more groups that are against your utility function than are for it, so it's easier to find utility functions against yours that have low-hanging fruit in their implementations.
#+end_quote

Really? I mean, I guess I don't understand precisely what you mean by "your utility function" (yours? Mine? LW as a group?), but considering you were mentioning "humanity's survival", I would figure that almost all people very likely prefer that there are some people in existence as opposed to none. They would usually even prefer that they, personally, be alive rather than dead.

"Let's kill everyone" doesn't seem to be anyone's "utility function", just the effect of certain actions some people are intent on taking (like global warming and all that).

#+begin_quote
  Although those in charge of that group may not be implementing those things because their own goals are different from the professed goals of the group, which would be why you have many different ideological revolutions that just happen to benefit one charismatic leader's lifestyle.
#+end_quote

This is seriously way vague.
:PROPERTIES:
:Score: 1
:DateUnix: 1449444105.0
:DateShort: 2015-Dec-07
:END:

********* u/Transfuturist:
#+begin_quote
  what you mean by "your utility function"
#+end_quote

The observer. The general 'you.'

#+begin_quote
  but considering you were mentioning "humanity's survival"
#+end_quote

You're mixing up threads. :P
:PROPERTIES:
:Author: Transfuturist
:Score: 2
:DateUnix: 1449445694.0
:DateShort: 2015-Dec-07
:END:


** I like to think that a good example of a realistic rational fiction would be the television series The Wire. There are many actors in the system, all of them with realistic values and all of them proceed to fulfill their values in a reasonably rational manner, given the constraints of their ability / resources and the conflicting values of other actors. And of course everything goes to shit and it's impossible to really blame anyone for it because that's the complexity of real life.
:PROPERTIES:
:Author: deccan2008
:Score: 4
:DateUnix: 1449459865.0
:DateShort: 2015-Dec-07
:END:


** I don't know what the general [[/r/rational][r/rational]]'s stance on it is, but I think [[http://www.imdb.com/title/tt1856010/][House of Cards]] isn't far removed from a realistic rational fiction. The characters are motivated by (more or less) realistic ambitions and I don't think the way in which they go about achieving those is in any shape or form orthogonal to the Characteristics of RF.
:PROPERTIES:
:Author: RoggBiv
:Score: 2
:DateUnix: 1449517998.0
:DateShort: 2015-Dec-07
:END:


** Yeah, the main difficulty is coming up with ideas that will work in the real world. It's very difficult but possible. The Sherlock Holmes stories are rationalist fiction, and predicted much of modern forensics.
:PROPERTIES:
:Author: want_to_want
:Score: 2
:DateUnix: 1449578163.0
:DateShort: 2015-Dec-08
:END:


** One reason ratfic is rarely set in the present: Modern rationalism is essentially equivalent to futurism, not just because most modern rationalists happen to be interested in futurism, but because predicting the future is basically what reason is for. A theory is only as good as the predictions it makes. No matter what, if it cannot predict the future, it is not useful. It's natural, then, that rationalists would have minds full of arresting visions of strange futures.
:PROPERTIES:
:Author: IWantUsToMerge
:Score: -2
:DateUnix: 1449427146.0
:DateShort: 2015-Dec-06
:END:

*** u/Transfuturist:
#+begin_quote
  Modern rationalism is essentially equivalent to futurism
#+end_quote

No.

#+begin_quote
  but because predicting the future is basically what reason is for
#+end_quote

That is what /intelligence/ is for, and long-term predictions are not something we're able to do, even with rationality. All we know is that there are some properties that the future is likely to have, and that there are some possibilities that contravene what most people take for granted, like humanity's continued survival.

#+begin_quote
  A theory is only as good as the predictions it makes. No matter what, if it cannot predict the future, it is not useful.
#+end_quote

Non sequitur.

#+begin_quote
  It's natural, then, that rationalists would have minds full of arresting visions of strange futures.
#+end_quote

No, it's natural because the extant culture is tied to futurist and transhumanist culture, where people are brought to rationality through SF&F and SF&F lovers like EY.
:PROPERTIES:
:Author: Transfuturist
:Score: 4
:DateUnix: 1449430541.0
:DateShort: 2015-Dec-06
:END:

**** (contrarianism engaged)

#+begin_quote
  All we know is that there are some properties that the future is likely to have, and that there are some possibilities that contravene what most people take for granted, like humanity's continued survival.
#+end_quote

Is this /really/ true? I've heard at least some people (including some SF&F authors and "futurists") argue, with somewhat good evidence, that predictions of the End Times are /extremely/ frequent throughout human history, and that the prior probability we should allocate to any /particular/ such prediction is thus correspondingly low.
:PROPERTIES:
:Score: 1
:DateUnix: 1449442177.0
:DateShort: 2015-Dec-07
:END:

***** First, I said some possibility, merely pointing out its existence. Second, I'm not talking about any predictions in particular, which are indeed extremely unlikely due to conjunction. I'm talking about the marginal probability of humanity's extinction, across all conditions.

Indeed, not only am I talking about the marginal probability, I am talking about the perceived marginal probability. A majority of people do not go about with a likelihood judged greater than zero that society as they know it might be destroyed, let alone the extinction of humanity. They take everyday life for granted.

...Not that I find it particularly worth considering at the moment. But people don't acknowledge the possibility, because that sort of thing is reserved for science fiction, religious nuts, and conspiracy theorists.
:PROPERTIES:
:Author: Transfuturist
:Score: 2
:DateUnix: 1449444021.0
:DateShort: 2015-Dec-07
:END:

****** u/deleted:
#+begin_quote
  Indeed, not only am I talking about the marginal probability, I am talking about the perceived marginal probability. A majority of people do not go about with a likelihood judged greater than zero that society as they know it might be destroyed, let alone the extinction of humanity. They take everyday life for granted.
#+end_quote

Ok, and now I'm /not/ being /all that/ contrarian anymore, but what about, for instance, Fox News viewers, or Daily Mail readers? It seems that the /real/ problem with talking about extinction risks is /precisely/ that manipulative douchebag organizations make /every/ effort to convince common people on the streets that WE'RE ALL GONNA DIE ANY DAY NOW basically all the time, thus rendering scientists or technologists talking about extinction risks nigh-unbelievable until you actually /teach people/ the difference between "journalists" and professional scientists.

#+begin_quote
  ...Not that I find it particularly worth considering at the moment.
#+end_quote

WAHOO!

(I don't consider myself educated enough about extinction risks to have an opinion besides, "OH FUCK GLOBAL WARMING but at least goal-oriented AI may be more difficult than previously supposed for good or ill BUT GLOBAL WARMING IS ALREADY HAPPENING BECAUSE WE DIDN'T TAKE PREVENTATIVE MEASURES DECADES AGO.")

#+begin_quote
  But people don't acknowledge the possibility, because that sort of thing is reserved for science fiction, religious nuts, and conspiracy theorists.
#+end_quote

True though.
:PROPERTIES:
:Score: 1
:DateUnix: 1449444613.0
:DateShort: 2015-Dec-07
:END:

******* ...I managed to forget about GW for a few months. Thanks for that.
:PROPERTIES:
:Author: Transfuturist
:Score: 1
:DateUnix: 1449445758.0
:DateShort: 2015-Dec-07
:END:

******** Sorry. I keep noticing it because it's unnaturally warm for this time of year, but only during the daytime, so I can't clothe myself appropriately and keep ending up uncomfortable.
:PROPERTIES:
:Score: 1
:DateUnix: 1449449306.0
:DateShort: 2015-Dec-07
:END:


**** u/IWantUsToMerge:
#+begin_quote
  That is what intelligence is for
#+end_quote

You seem very particular about the distinction between reason and intelligence.

#+begin_quote
  long-term predictions are not something we're able to do, even with rationality
#+end_quote

I think you may be misunderstanding me, just as when I say "evidence", I do not mean "proof", likewise when I say "prediction", I do not mean "prophesy". It is very strange that you admit the definition of intelligence as a predictive aparatus, but you do not admit that that then makes long-term forecasts a function of intelligence.
:PROPERTIES:
:Author: IWantUsToMerge
:Score: 1
:DateUnix: 1449448689.0
:DateShort: 2015-Dec-07
:END:

***** Long-term predictions at the level of detail of a story are many-zeroes impossible, intelligence or not. Long-term plans require maintenance, because otherwise chaotic divergence occurs. The space of possibilities in the future is combinatorially curved. Conjoining many probable conditions results in an infinitesimally probable outcome.

We can only speak in terms of marginal probabilities.
:PROPERTIES:
:Author: Transfuturist
:Score: 1
:DateUnix: 1449449059.0
:DateShort: 2015-Dec-07
:END:

****** I /know/. Sci-fi is still a semi-reasonable way of getting a few of the likeliest possibilities into the public consciousness, or examining a few specific aspects likely to be shared by many of them.
:PROPERTIES:
:Author: IWantUsToMerge
:Score: 1
:DateUnix: 1449449756.0
:DateShort: 2015-Dec-07
:END:

******* But... how does that relate RT/RST stories to SF&F?

And keep in mind that most RT/RST stories so far have been SF&F themed hard fantasy, not hard speculative sci-fi.
:PROPERTIES:
:Author: Transfuturist
:Score: 2
:DateUnix: 1449449848.0
:DateShort: 2015-Dec-07
:END:
