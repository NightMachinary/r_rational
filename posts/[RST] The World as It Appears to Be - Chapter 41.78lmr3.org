#+TITLE: [RST] The World as It Appears to Be - Chapter 41

* [[http://archiveofourown.org/works/9402014/chapters/28425584][[RST] The World as It Appears to Be - Chapter 41]]
:PROPERTIES:
:Score: 18
:DateUnix: 1508908801.0
:DateShort: 2017-Oct-25
:END:
[deleted]


** That... That's a damn good argument.
:PROPERTIES:
:Author: GrecklePrime
:Score: 11
:DateUnix: 1508911904.0
:DateShort: 2017-Oct-25
:END:

*** I don't get why they can't just give her a few leading bits and use the rest of their universe to themselves.
:PROPERTIES:
:Author: DCarrier
:Score: 6
:DateUnix: 1508912268.0
:DateShort: 2017-Oct-25
:END:


** I... call bullshit.

If the "outside world" were so perfect and suffering-free and well balanced and well governed, no imperfect history box would have been created in the first place; especially since I'd expect those to be heavily regulated and monitored.

I suspect that Vishkar is lying to trick the other witnesses into believing she ought to win. If they believe that even for a second, she wins.

--------------

Also, I know I shouldn't complain about realism when reading an Overwatch fanfic, but /this is not how transhumanism will work, dammit/!

In Vishkar's testimony, humanity invented the history-boxes, used them wrong, then added a bunch of universal rules on how to use them. This isn't how science and engineering work outside of science fiction.

Inventions aren't discrete things. It's not "at time t there is no car, at time t+1 cars are invented and people have cars". Technological advances are gradual, they're based on previous advances and discoveries. And they're not implemented uniformly: distributing technology is easier in some cases and harder in others, depending on supply chains, existing infrastructures, how hard it is for people to learn to drive, etc.

My point is, by the time Mercy was able to simulate the universe well enough to save everyone from death, other people would already have built their own variations of history boxes; they would have bigger, slower boxes with rougher heuristics, but they'd be able to use them to do time travel, pretend to be Iron Man and stuff like that. The whole "is it okay to simulate suffering?" question would have been asked way before God!Mercy had completed her project.

I don't know exactly why this upsets me. I think people who imagine transhumanist futures don't realize how hard to imagine these things are, how simplistic most predictions are, or just how logistics work. It's like if someone in 1700 wrote a story about a guy inventing a car, then three months later everyone is already using cars all the time, then 3 years later the first road accident happens and people start worrying that maybe they should regulate the whole "car" thing. It makes for a simpler, more straightforward story, but it's completely absurd if you think about it too hard.
:PROPERTIES:
:Author: CouteauBleu
:Score: 7
:DateUnix: 1508918424.0
:DateShort: 2017-Oct-25
:END:

*** Possible counter point: Angela may have been the only person with access to the resources and vision necessary to create something like Athena, and Athena's gestalt mind may have been a significant force multiplier in creating the historybox.
:PROPERTIES:
:Author: Detsuahxe
:Score: 8
:DateUnix: 1508927726.0
:DateShort: 2017-Oct-25
:END:

**** Yeah, I think that's the intended interpretation. Still kind of weird and question-raising.
:PROPERTIES:
:Author: CouteauBleu
:Score: 7
:DateUnix: 1508942870.0
:DateShort: 2017-Oct-25
:END:


**** yeah I don't see any reason why universe simulation MUST be a diffuse technology, especially if it were enabled by Athena's super-human intelligence, and Athena was the only such being.
:PROPERTIES:
:Author: wren42
:Score: 1
:DateUnix: 1509247460.0
:DateShort: 2017-Oct-29
:END:


*** That's not how I read it. It seems more like there were many history boxes, at some point they were good enough to be considered accurate to the point that people can be cleanly copied out of them, then there was a large (political) debate about the suffering caused within them (something that some people probably didn't understand, let alone care about) but the suffering was deemed acceptable due to the benefits and explained away as being merely a copy. Once the history boxes became widely commercialized for use in entertainment the old explanation as to why the suffering "isn't real" couldn't be applied anymore and the people on the other side of the debate won out this time.

Nothing in Lakshmi's speculation (because that's what it is) demands that the rules were implemented immediately after the first 'accidents' happened, just that everything happened in roughly the order she proposes.
:PROPERTIES:
:Author: Bowbreaker
:Score: 7
:DateUnix: 1508940478.0
:DateShort: 2017-Oct-25
:END:


*** u/serge_cell:
#+begin_quote
  It's like if someone in 1700 wrote a story about a guy inventing a car, then three months later everyone is already using cars all the time, then 3 years later the first road accident happens and people start worrying that maybe they should regulate the whole "car" thing.
#+end_quote

LOL

1543 Guns are introduced to Japan

1560 Everyone using guns

1603 Guns are heavily regulated by Tokugawa shogunate
:PROPERTIES:
:Author: serge_cell
:Score: 7
:DateUnix: 1508995174.0
:DateShort: 2017-Oct-26
:END:


*** Agreed about the suspiciousness of the setup--I also should go back and check a certain part related to the despairing amateur's motivation. Winston was immediately extremely alarmed about divergent terminations, albeit mollified a bit by them being self-terminations; it shouldn't take a 200-year alternate history for people to crack down on all divergence-causing interference ('chatting with celebrities'), or at least ensuring heavy regulation to ensure minimum divergence, similar to the lag compensation. That said, would the Iris stand by while Lakshmi lies about the Iris telling her things? Recall that any plan she can make to subvert what the Iris wants her to do, or any predictions she has about the outside, can be seen by the Iris beforehand. Hmm, I also remember a mention of 'pawn 1', so perhaps she has at least one other created individual to leave and try to maximise shareholder value in the outside reality too..?

That said, after all the ominous foreboding leading up to this chapter--particularly including the very last part of the previous chapter--this was a wonderfully refreshing subversion of expectations!

Let's see, anything else to consider while I'm writing... if deterministically feasible, I should definitely adopt the historybox pulling-out as a thing to do, and a thing to hope someone else does if I fail. In practice, probably requiring an assumption of infinite resources, in order to (potentially) make all dead inhabitants of all already-existed universes into equal god-like entities. Ah, there's the regulation matter again, the issue that a god-like entity must have oversight to prevent creating otherwise-impossible entities that then die without being turned into gods in turn... otherwise, in the short-term, might not be possible to even recreate the path of one's own branch. There's also the question of whether to have the 'first one' be equal to all others, though possible if all can have infinite resources, though an unchangeable oversight which isn't oneself is also scary in its own way.

I keep being interrupted while writing--ah, yes. Historybox revival: not (I think?) demonstrably equivalently desirable continued existence without dying even once, but one of the next-best things.
:PROPERTIES:
:Author: MultipartiteMind
:Score: 1
:DateUnix: 1509076813.0
:DateShort: 2017-Oct-27
:END:


** Bravo and well played.
:PROPERTIES:
:Author: gryfft
:Score: 6
:DateUnix: 1508910888.0
:DateShort: 2017-Oct-25
:END:


** By the way, Lakshmi isn't maximizing the expected shareholder value, or winning soon enough to launch space conquest early enough to capture one more terabyte of harddrive space would be worth a 99.999% chance of annihilation.
:PROPERTIES:
:Author: Gurkenglas
:Score: 3
:DateUnix: 1508997240.0
:DateShort: 2017-Oct-26
:END:


** This was great.
:PROPERTIES:
:Author: entropizer
:Score: 2
:DateUnix: 1509502258.0
:DateShort: 2017-Nov-01
:END:
