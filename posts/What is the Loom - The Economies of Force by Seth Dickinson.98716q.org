#+TITLE: What is the Loom? - The Economies of Force by Seth Dickinson

* What is the Loom? - The Economies of Force by Seth Dickinson
:PROPERTIES:
:Score: 34
:DateUnix: 1534548047.0
:DateShort: 2018-Aug-18
:END:
[deleted]


** Your scenario's real key isn't opacity of neural networks, it's perfect coordination between actors with common interest to perform only activities that are positive sum for their entire community, without any commons problems. This is not likely to emerge by accident in opaque systems short of general superintelligence. It's not a communications issue, it's an incentives issue.
:PROPERTIES:
:Author: EliezerYudkowsky
:Score: 10
:DateUnix: 1534599425.0
:DateShort: 2018-Aug-18
:END:

*** [deleted]
:PROPERTIES:
:Score: 1
:DateUnix: 1534645922.0
:DateShort: 2018-Aug-19
:END:

**** u/EliezerYudkowsky:
#+begin_quote
  Market participants predict, and predicting each others' actions is functionally the same as coordinating in this scenario.
#+end_quote

False AFAICT? They just predict mutual defection and go on mutually defecting. The whole point of the Prisoner's Dilemma is that the only Nash equilbrium is not Pareto efficient.
:PROPERTIES:
:Author: EliezerYudkowsky
:Score: 7
:DateUnix: 1534648495.0
:DateShort: 2018-Aug-19
:END:

***** [deleted]
:PROPERTIES:
:Score: 3
:DateUnix: 1534691092.0
:DateShort: 2018-Aug-19
:END:

****** A Nash equilibrium is /not/ Pareto efficient by definition; that's not anywhere on Wikipedia or any game theory textbook I've ever read, so where'd you get that "definition" from? In fact, the defect-defect state of the Prisoner's Dilemma doesn't even satisfy the Wikipedia definition of Pareto efficiency you yourself quoted:

#+begin_quote
  Pareto efficiency or Pareto optimality is a state of allocation of resources from which it is impossible to reallocate so as to make any one individual or preference criterion better off without making at least one individual or preference criterion worse off.
#+end_quote

It is in fact /perfectly/ possible to describe a state of resource allocation where /both/ participants are better off than they are in the defect-defect equilibrium, and that is the state corresponding to the world in which both players cooperate. (If we refer to the players as A and B, then A has more resources in cooperate-world than in defect-world, and so does B; there is no "individual or preference criterion" being made worse off in this case.) I'm really not sure where your confusion lies here, but I'd recommend familiarizing yourself with the definitions a bit more.

*EDIT:* Interestingly enough, not only is the defect-defect equilibrium not Pareto efficient, it's the /only/ possible outcome of the Prisoner's Dilemma that isn't; every other outcome (cooperate-cooperate, cooperate-defect, defect-cooperate) does in fact satisfy the definition of Pareto efficiency. This shows why Pareto efficiency on its own is actually a fairly weak condition; it doesn't distinguish between equilibrium and non-equilibrium states.
:PROPERTIES:
:Author: 696e6372656469626c65
:Score: 3
:DateUnix: 1534706670.0
:DateShort: 2018-Aug-19
:END:


** Humans are black box neural-network intelligences as well, just natural instead of artificial. [[https://www.telesurtv.net/english/news/Brazilian-Indigenous-Leader-Guardian-of-the-Amazon-Murdered-20180816-0009.html][Killing]] [[https://en.wikipedia.org/wiki/Edward_Bernays#United_Fruit_and_Guatemala][people]] [[https://en.wikipedia.org/wiki/Military%E2%80%93industrial_complex][for]] [[https://en.wikipedia.org/wiki/Ford_Pinto#Cost-benefit_analysis,_the_Pinto_Memo][profit]] [[http://time.com/4989641/water-air-pollution-deaths/][is]] [[https://en.wikipedia.org/wiki/2008_Chinese_milk_scandal][nothing]] [[https://en.wikipedia.org/wiki/Grenfell_Tower_fire#Aluminium-polyethylene_cladding][new]]. Corporations can be thought of as limited-liability neural-network-guided paperclip maximizers, where paperclips = profit. As the Grenfell Tower fire illustrated, the difference between £24 per square meter for fire-resistant materials and £22 for combustible materials can be enough for human profit-optimizers to decide to drastically increase the odds of letting the building and its occupants burn to death to save a little money.

AI is not scary because it might kill us or let us die for profit. We're already dealing with that from other people. AI is scary because it can do it better. Because it can replace us. And because it will disregard our lives once we're no longer needed. Profit is just another type of paperclip.
:PROPERTIES:
:Author: Norseman2
:Score: 6
:DateUnix: 1534581196.0
:DateShort: 2018-Aug-18
:END:

*** It seems that your comment contains 1 or more links that are hard to tap for mobile users. I will extend those so they're easier for our sausage fingers to click!

[[http://time.com/4989641/water-air-pollution-deaths/][Here is link number 1]] - Previous text "is"

[[https://en.wikipedia.org/wiki/Grenfell_Tower_fire#Aluminium-polyethylene_cladding][Here is link number 2]] - Previous text "new"

--------------

^{Please} ^{PM} ^{[[/u/eganwall]]} ^{with} ^{issues} ^{or} ^{feedback!} ^{|} ^{[[https://reddit.com/message/compose/?to=FatFingerHelperBot&subject=delete&message=delete%20e4ege1p][Delete]]}
:PROPERTIES:
:Author: FatFingerHelperBot
:Score: 3
:DateUnix: 1534581206.0
:DateShort: 2018-Aug-18
:END:


** Your scenario requires some extreme leaps of logic and events that could never happen in our world.

People don't just IPO ideas, stock prices don't rise that quickly even if the algorithms saw an advantage in them doing so, because of how they work and how risk / reward is calculated.

By the time we had perfect information algorithms trading in our markets which is never, but let's assume near perfect then, we'd have ai automated hiring if there was still a need for people to work by then.

And you should also keep in mind, most business are small and private, they couldn't care less about stock prices. We just get this skewed view of public companies as being more relevant than they are because they are public companies and therefore more media attention is put into them.

> If you have significant number of people spending a significant amount of their disposable income at McDonalds, then in the long run you've got a very advanced McChicken.

This is just incorrect, things don't improve because they are popular or good products. To improve you have to risk it getting worst because that's how you improve, by testing different methods.

If you are winning you have no reason to take the risk for a marginal improvement, and you have even less reason to allocate the time and resources to seek said improvement, because you're already winning.

Winning harder is not the goal, the goal is to win with the lowest possible costs so you can have the highest possible profits.

Edit*

> So, when some sociopath corporate guy with a drone fetish comes up with the idea to manufacture lethal drones to use against civilians?

This never happens because we have something called laws, regulations, rules, governments, UN intervention...

And even in the impossible scenario that it did pass through all these obstacles it would last long because civilians would destroy it themselves. 5 dudes that had family killed by drones; bomb the business, kill it's leadership etc. This is far more likely to happen than anything else that would have to happen to create said scenario in the first place.
:PROPERTIES:
:Author: fassina2
:Score: 5
:DateUnix: 1534560401.0
:DateShort: 2018-Aug-18
:END:

*** [deleted]
:PROPERTIES:
:Score: 3
:DateUnix: 1534600372.0
:DateShort: 2018-Aug-18
:END:

**** I was just replying to your question, do you think this could happen in our world? Or whatever.

Anyway I'm not interested in agruing, let's just say I still think you are incorrect after reading your reply.
:PROPERTIES:
:Author: fassina2
:Score: 3
:DateUnix: 1534604349.0
:DateShort: 2018-Aug-18
:END:


*** u/wren42:
#+begin_quote
  So, when some sociopath corporate guy with a drone fetish comes up with the idea to manufacture lethal drones to use against civilians?

  This never happens because we have something called laws, regulations, rules, governments, UN intervention...
#+end_quote

HA. there's a post /right above yours/ with half a dozen links to corporations killing people for profit, either directly or through negligence.

The assassinations of union leaders by fruit and soft drink companies is notorious.
:PROPERTIES:
:Author: wren42
:Score: 1
:DateUnix: 1534973898.0
:DateShort: 2018-Aug-23
:END:

**** Sure I shouldn't have said never, but it's very unlikely to happen.

My point was that a publicly traded company whose only income stream is drone bomb strikes is as likely to happen as things falling up instead of down.

BTW my comment is older than those..
:PROPERTIES:
:Author: fassina2
:Score: 1
:DateUnix: 1534976411.0
:DateShort: 2018-Aug-23
:END:

***** u/wren42:
#+begin_quote
  Sure I shouldn't have said never, but it's very unlikely to happen.
#+end_quote

this is naive first world upper middle class thinking, unfortunately. A lot of us grew up in very stable feeling environments. Things were mostly peaceful, mostly prosperous, mostly orderly and law abiding.

Most of the world and history isn't like that. Most of it is full of people killing the shit out of each other for some resources or land or political influence or slaves or religious conflicts.

If you think this stuff isn't going on, that corporations aren't abusing the environment and their customers and poor developing countries to the full extent they can get away with you aren't paying attention. And yes that includes killing people, even today, even in the US, even though there are laws, and they are getting away with it.
:PROPERTIES:
:Author: wren42
:Score: 1
:DateUnix: 1535035076.0
:DateShort: 2018-Aug-23
:END:

****** I agree with you. Like I said, that was not my point to begin with.

This is besides the point but maybe you should check out rational optimist. Basically it's a book about how things are getting better in our world.

Of course that doesn't mean bad things stopped happening, it just means that statistically speaking less bad things are happening on average than they did in the past. And the trend is for it to continue.
:PROPERTIES:
:Author: fassina2
:Score: 1
:DateUnix: 1535055869.0
:DateShort: 2018-Aug-24
:END:


** Whatever people think of the plausability of your argument, I had at least as much fun reading it as I did writing the story. Awesome job.

I think the idea of AI evolving a ‘behavior fog,' a sort of persistent illusion which could excuse efficient behavior which humans might otherwise object to, is pretty cool.
:PROPERTIES:
:Author: GeneralBattuta
:Score: 3
:DateUnix: 1534734829.0
:DateShort: 2018-Aug-20
:END:


** u/PM_ME_OS_DESIGN:
#+begin_quote
  Not Being Killed By Drones^{tm}
#+end_quote

Please don't use =^tm=. Use the TM symbol (=™=): ™

#+begin_quote
  Not Being Killed By Drones™
#+end_quote

It's an actual character, not a combination of characters. Just copy/paste it in.
:PROPERTIES:
:Author: PM_ME_OS_DESIGN
:Score: 8
:DateUnix: 1534555903.0
:DateShort: 2018-Aug-18
:END:

*** I'm not sure why you were downvoted for this, you're not wrong.

If you're not going to ™ then at least ^{TM} instead of ^{tm.}
:PROPERTIES:
:Author: ElizabethRobinThales
:Score: 4
:DateUnix: 1534566922.0
:DateShort: 2018-Aug-18
:END:


** My interpretation of the story was that the Loom was some kind of rival network. The author of the story repeatedly mentions fractals, and in fractal geometry, similar patterns recur at progressively smaller scales. I thought the ending of the story was basically implying that the "competitive model" of Rade's world, with its trading algorithms and so on, was also occuring at a higher meta-level between the drone network and the Loom network. Whereas the drone network is portrayed as uber-capitalistic, I interpreted the Loom network as more socialistic (although that was left kind of unclear and I might be reaching).
:PROPERTIES:
:Author: Penguin4512
:Score: 2
:DateUnix: 1534607845.0
:DateShort: 2018-Aug-18
:END:

*** I liked the drones. I thought they were cute.

They only kill people sometimes. For a semi-unplanned superintelligence takeoff, that's far from the worst outcome!
:PROPERTIES:
:Author: FeepingCreature
:Score: 2
:DateUnix: 1534618876.0
:DateShort: 2018-Aug-18
:END:


*** My interpretation of the story was that the Loom was an idea. Something that our brains would interpret as being incontrovertible. A truth hard-wired so deeply into the structure of the brain that no argument could possibly reach out or change it once it was activated, and, once activated, people would have the urge to spread the good news, by force and revolution if necessary. And whatever the idea at the heart of the Loom is, it's clear that people are willing to die for it.

Whether said "truth" is actually true or just a logical fallacy that can't be thought past by a human brain isn't made clear by the story.
:PROPERTIES:
:Author: Nimelennar
:Score: 1
:DateUnix: 1534732006.0
:DateShort: 2018-Aug-20
:END:

**** Do those kinds of logic traps exist? Or is that an undecidable problem?
:PROPERTIES:
:Author: nerdguy1138
:Score: 1
:DateUnix: 1535183841.0
:DateShort: 2018-Aug-25
:END:

***** Certainly, intrusive thoughts that can't be easily reasoned away exist; it's a common symptom of depression. "Depression lies" is one description I've heard a lot.

That said, the idea of a universal idea that can override all other ideas is almost certainly false; if there were such an idea, I would think that someone would have stumbled upon it by now, and it would already pervade all of humanity.
:PROPERTIES:
:Author: Nimelennar
:Score: 1
:DateUnix: 1535293902.0
:DateShort: 2018-Aug-26
:END:


*** exactly. to me it seemed to be a memetic network - a mental state that is contagious and creates a value in the subject of wanting to spread it. Much like religion, for instance. It's highly likely for memes like this to come into being and spread virulently.
:PROPERTIES:
:Author: wren42
:Score: 1
:DateUnix: 1534974039.0
:DateShort: 2018-Aug-23
:END:
