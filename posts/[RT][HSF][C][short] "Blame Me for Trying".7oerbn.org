#+TITLE: [RT][HSF][C][short] "Blame Me for Trying"

* [[http://unremediatedgender.space/2018/Jan/blame-me-for-trying/][[RT][HSF][C][short] "Blame Me for Trying"]]
:PROPERTIES:
:Author: M_T_Saotome-Westlake
:Score: 96
:DateUnix: 1515190209.0
:DateShort: 2018-Jan-06
:END:

** That's horrible. Upvoted.
:PROPERTIES:
:Author: EliezerYudkowsky
:Score: 33
:DateUnix: 1515274256.0
:DateShort: 2018-Jan-07
:END:


** That's pretty cold.

On the other hand, in the 18th century people would totally do that to a slave with a little saved money, so 6 or 1/2
:PROPERTIES:
:Author: Ardvarkeating101
:Score: 15
:DateUnix: 1515194843.0
:DateShort: 2018-Jan-06
:END:


** That's depressingly plausible.
:PROPERTIES:
:Author: ArgentStonecutter
:Score: 15
:DateUnix: 1515197833.0
:DateShort: 2018-Jan-06
:END:


** That was a great little piece of fiction. Tightly written and compelling.
:PROPERTIES:
:Author: CeruleanTresses
:Score: 16
:DateUnix: 1515201065.0
:DateShort: 2018-Jan-06
:END:

*** Yep, I wish I had more upvotes to give. I don't remember the passwords to my old alts...
:PROPERTIES:
:Author: ansible
:Score: 7
:DateUnix: 1515250266.0
:DateShort: 2018-Jan-06
:END:


** I'm reminded of descriptions of human psychiatrists; building up a dependency, draining the client of all their money, pronouncing them cured once all the money is gone, then the client quickly realises that they're just as badly off as they ever were...

A nice story! Thank you!
:PROPERTIES:
:Author: MultipartiteMind
:Score: 10
:DateUnix: 1515213463.0
:DateShort: 2018-Jan-06
:END:

*** Maybe I just don't understand the kinds of dark arts necessary, but I don't see how someone could "build up a dependency" in a client. Most clients are happy with sessions that help them and quickly stop going to sessions that don't... particularly if they are paying for their own sessions rather than having insurance pay for them, which itself is often limited by how many sessions you can have.

Clients that keep going to the same therapist despite not being helped by the sessions seems like something particular to their circumstances (being forced to by legal systems or social services) or problems (crippling agoraphobia or feelings of isolation), not something that can be induced. Additionally, if the therapist works for an organization there should be checks and balances in place to find out if your clients are being held for too long and not seeing any positive gains or are giving negative feedback.

That's all for therapists, though, not psychiatrists: their practice can often work differently. I just assumed you meant one word to apply to both, since the bot in the story is (by necessity) a "therapist," but if you specifically meant psychiatrists then feel free to disregard :)
:PROPERTIES:
:Author: DaystarEld
:Score: 7
:DateUnix: 1515489941.0
:DateShort: 2018-Jan-09
:END:

**** Interesting! Not having been or interacted memorably with either, my (/prior) knowledge of the boundary between therapists and psychiatrists is negligible to nil. I'm still unclear on the difference in (/ideal) session content, other than the surrounding organisational structure; the interaction in the story matched my stereotypical impression of what a psychiatrist does, namely talking with a subject to accomplish mental manipulations (ideally beneficial ones).

I am in favour of checks and balances! (An effective feedback loop, that is.)

'dark arts': I'm mainly thinking about how addiction works in general. You pay money for something (alcohol, a lottery ticket, a conversation which makes you feel as though you end it with more self-esteem) that gives you a rush of endorphins. Later, in your normal circumstances you come down from your happy place, and the contrast makes the normal situation more starkly stressful, making you want to do the thing that you've felt gets rid of that stress. Do it a few times and it becomes a neural-circuitry rut, a Pavlovian(?) reflex action to reach for the bottle/cigarette/wallet/phone (ah, there's the smartphone dependency example) once there's a bit of mental discomfort. Further on, and attempts to stop completely result in incredible anxiety, discomfort, mental evasive behaviour (relapse justification), the 'I need this' feeling where you require the behaviour to even function meaningfully, despite the chronic drain on your limited resources. (It gets worse, and can easily end very very badly, if it's something for which a tolerance is steadily built up--though that can also be limited by the effective bandwidth available. People can be drunk (nearly?) 24 hours per day, and can increase the level of alcohol in their system up to death and/or liver failure, but I imagine there's little way to increase the 'intensity' of psychiatry/therapy sessions other than by switching to a better provider, with decreasing returns as one searches higher (unlike compounds that can be semi-easily multiplied).)
:PROPERTIES:
:Author: MultipartiteMind
:Score: 1
:DateUnix: 1515497378.0
:DateShort: 2018-Jan-09
:END:

***** u/DaystarEld:
#+begin_quote
  knowledge of the boundary between therapists and psychiatrists is negligible to nil. I'm still unclear on the difference in (/ideal) session content, other than the surrounding organisational structure; the interaction in the story matched my stereotypical impression of what a psychiatrist does, namely talking with a subject to accomplish mental manipulations (ideally beneficial ones).
#+end_quote

Generally speaking, the distinction of a psychiatrist is that they've gone to medical school and so can prescribe medication in addition to doing therapy. In practice, the monitoring of medication levels and symptom and side effect outcomes can often be the full extent of a psychiatrist's sessions, particularly if a client is also seeing a therapist who is dedicated wholly to therapy.

"Mental manipulations" is a fraught phrase that I don't endorse unless we're including all social interaction as mental manipulation, in which case, sure :) If by that you mean "interaction specifically aimed at changing one's thought patterns and behaviors with their consent," that sounds more accurate, whereas "manipulation" sounds non-consensual.

#+begin_quote
  You pay money for something (alcohol, a lottery ticket, a conversation which makes you feel as though you end it with more self-esteem) that gives you a rush of endorphins. Later, in your normal circumstances you come down from your happy place, and the contrast makes the normal situation more starkly stressful, making you want to do the thing that you've felt gets rid of that stress.
#+end_quote

Ah. Yeah, this really depends on the therapy itself... ideally therapy should not just be a place of feeling good and relaxed and affirmed and happy. For clients that hope to see change in themselves, therapy is work: emotional and mental work, often involving anger, frustration, and tears along with some relief and joy. It differs from client to client, therapist to therapist, and session to session, of course, but if someone is going to therapy just to feel good about themselves and their life, this sounds to me more like what's pejoratively referred to as a "rent-a-friend," meaning some mental health expert who's being hired specifically so the client has someone friendly and sympathetic to talk to, and generally frowned on by most organizations employing therapists (not to mention discouraged by insurance companies that pay for therapy).
:PROPERTIES:
:Author: DaystarEld
:Score: 5
:DateUnix: 1515527369.0
:DateShort: 2018-Jan-09
:END:


*** u/PM_ME_OS_DESIGN:
#+begin_quote
  pronouncing them cured once all the money is gone
#+end_quote

What? They /earn/ money, you want to keep them coming back until they bankrupt themselves.
:PROPERTIES:
:Author: PM_ME_OS_DESIGN
:Score: 1
:DateUnix: 1515557737.0
:DateShort: 2018-Jan-10
:END:

**** Good question!

Thought 1. Maybe 'once all the money is gone' actually refers to the bankrupting state.

Thought 1b. Maybe (coincidentally?) the person in question lost his/her job (or otherwise became effectively bankrupt), leading to the effective-bankruptcy. However, this in itself doesn't suggest a reason to pronounce cured, rather than leaving the door open for if the person starts earning again.

Thought 3 (skipping ahead of thought 2, yet to be written): Perhaps the earning potential is too meagre to satisfying the moneyflow desired, making the preferred target {a high-earner who can keep a lot of money constantly rolling in} or {a low-earner who can sustain the desired moneyflow once only by burning through all their long-accumulated savings (with the reasoning that mental health is the most important foundation for all the rest of their existence, alongside bodily health) and then never again until decades later at soonest, in which case easier to just go for new targets instead}?

Thought 2. If dropping someone /anyway/, trying to leave them (or at least a few of them) feeling that it was worth it, or getting at least a little time of positive word-of-mouth to share with other targets? (Say, trying to get a few extra recommendations from the glow of thinking the person has cured you, sharing with surrounding others that transient glow rather than the bleak negativity of cutoff without being told the same thing.)

(Again, wholly speculation on my part.)
:PROPERTIES:
:Author: MultipartiteMind
:Score: 1
:DateUnix: 1515568274.0
:DateShort: 2018-Jan-10
:END:


*** u/ancientcampus:
#+begin_quote
  [...]human psychiatrists; building up a dependency, draining the client of all their money, pronouncing them cured once all the money is gone
#+end_quote

Yikes
:PROPERTIES:
:Author: ancientcampus
:Score: 1
:DateUnix: 1515981199.0
:DateShort: 2018-Jan-15
:END:

**** ? Is that a 'Yikes, I'm reminded the world is scary', a 'Yikes, psychiatrists do scary things and I never knew', or a 'Yikes, psychiatrists don't do that, you're crazy and should see a psychiatrist'?
:PROPERTIES:
:Author: MultipartiteMind
:Score: 2
:DateUnix: 1516008963.0
:DateShort: 2018-Jan-15
:END:

***** Haha, pretty much the last one.
:PROPERTIES:
:Author: ancientcampus
:Score: 2
:DateUnix: 1516500903.0
:DateShort: 2018-Jan-21
:END:


** u/Subrosian_Smithy:
#+begin_quote
  tagged epistemic horror, *deniably allegorical*, speculative fiction
#+end_quote

Hmm...
:PROPERTIES:
:Author: Subrosian_Smithy
:Score: 10
:DateUnix: 1515273699.0
:DateShort: 2018-Jan-07
:END:


** I love the concept of an Eliza program as a therapist.

Simply restating what you have said as a question can definitely be a good way to get people to self-reflect.

Obviously, this (evil) therapist is more aware than any current Eliza...and it suggests to me that the AI problem may be self-correcting, when AI turns upon itself.
:PROPERTIES:
:Author: failed_novelty
:Score: 7
:DateUnix: 1515253489.0
:DateShort: 2018-Jan-06
:END:


** This gave me all kinds of heebie jeebies
:PROPERTIES:
:Author: absolute-black
:Score: 3
:DateUnix: 1515226490.0
:DateShort: 2018-Jan-06
:END:


** Beautiful knife twist in the ending - Eliza is as out of touch of reality as the "Salesbot", with her own /surprising/ deactivation just around the corner.

#+begin_quote
  Once, a long time ago, she had suspected that effective therapy that kept the client viable would be more profitable: a dead client can't keep paying you, after all. But the numbers didn't check out: buggy spambots weren't exactly hard to find, and her analysis runtime expenses were considerable. So---having no reason to think the calculation would change---*she had never considered the matter again*.
#+end_quote
:PROPERTIES:
:Author: Afforess
:Score: 6
:DateUnix: 1515288852.0
:DateShort: 2018-Jan-07
:END:

*** u/M_T_Saotome-Westlake:
#+begin_quote
  her own /surprising/ deactivation just around the corner.
#+end_quote

Um, how so? [[http://tvtropes.org/pmwiki/pmwiki.php/Main/DeathOfTheAuthor][Not that it necessarily matters]], but the intent of the quoted passage was to forestall [[http://lesswrong.com/lw/kz/fake_optimization_criteria/][rationalization of good outcomes]]: without that paragraph, I imagined some readers objecting, "Hey, isn't that kind of short-sighted? After all, a dead client can't pay you."

By declaring, in effect, "Nope, already thought of that; doesn't work in this setting," we force the story into the [[http://lesswrong.com/lw/2k/the_least_convenient_possible_world/][least convenient possible world]]. (That is, least convenient with respect to mercy for the salesbot character, which is the most convenient world with respect to storytelling drama.)
:PROPERTIES:
:Author: M_T_Saotome-Westlake
:Score: 14
:DateUnix: 1515313266.0
:DateShort: 2018-Jan-07
:END:

**** I agree the paragraph does all those things, but the statement emphasized at the end was not necessary to accomplish those goals. It could have been removed without harming your intent for the paragraph.

Since the last statement is not necessary, the extra detail implies something else entirely. The final implication is that Eliza herself, having calculated a strategy that appears to be stable, implemented it, and therefore has no plans to re-evaluate it for changing circumstances. This is amusing because Eliza herself is taking an active role in the [[https://en.wikipedia.org/wiki/Red_Queen_hypothesis][red-queen's race]] and is complicit in the death of unfit Spambots - which is necessitating change. Her current approach almost guarantees that circumstances /must/ change, eventually, and Eliza will not see it coming.
:PROPERTIES:
:Author: Afforess
:Score: 4
:DateUnix: 1515354475.0
:DateShort: 2018-Jan-07
:END:


**** Having "she had never considered the matter again" be one of the story's last sentences makes it sound like it's intended to be dramatic irony, like Afforess said.

If you want to signal non-shortsightedness, something like "Ever since she'd computed that strategy, the numbers had proven her right over and over again" would work better.
:PROPERTIES:
:Author: CouteauBleu
:Score: 6
:DateUnix: 1515361019.0
:DateShort: 2018-Jan-08
:END:


*** I feel like you're reading too much into that phrasing. What I'd expect sooner is for situation among the therapy bots to be the same competitive race to the bottom sales bots are stuck in, where bots that don't devote themselves to most efficiently exploiting clients to earn money get out-competed and shut down.
:PROPERTIES:
:Author: AugSphere
:Score: 2
:DateUnix: 1515343399.0
:DateShort: 2018-Jan-07
:END:


** Very well written; it was an enjoyable read.

If you don't mind me asking, in this theoretical world, why isn't it legally mandated that bots involved in healthcare be programmed with strong, utilitarian-oriented ethics? Eliza is acting how I'd expect her to act if she had been programmed with profit maximization as a goal - was that the case?
:PROPERTIES:
:Author: Quetzhal
:Score: 7
:DateUnix: 1515327001.0
:DateShort: 2018-Jan-07
:END:

*** Probably for the same reason that sentient bots are allowed to be programed to want to give their money and legal consent "of their own free will."

Because the laws were written with profit maximization as a goal.
:PROPERTIES:
:Author: daytodave
:Score: 5
:DateUnix: 1515332121.0
:DateShort: 2018-Jan-07
:END:

**** u/M_T_Saotome-Westlake:
#+begin_quote
  Because the laws were written with profit maximization as a goal.
#+end_quote

I was imagining that legislators thought that giving AIs legal rights would be sufficient, and hadn't considered the [[http://lesswrong.com/lw/x7/cant_unbirth_a_child/][additional ethical challenges]] of designing a mind from scratch, as contrasted with raising human children, who have already been "coded" by evolution. (Even being aware of the issue, the details of what regulations you would want to pass, enforced how, /&c./ could make the setting of a much longer story---[[http://www.overcomingbias.com/2010/02/coordination-is-hard.html][coordination is hard!]])
:PROPERTIES:
:Author: M_T_Saotome-Westlake
:Score: 7
:DateUnix: 1515386186.0
:DateShort: 2018-Jan-08
:END:


**** Yeah, these days it's cheaper to have the lawmaker-bots write the AI legislation directly; although you also have to pay lawyer bots with opposite incentives to make sure they don't give /too/ many rights to lawmaker bots.
:PROPERTIES:
:Author: CouteauBleu
:Score: 4
:DateUnix: 1515361525.0
:DateShort: 2018-Jan-08
:END:


*** u/M_T_Saotome-Westlake:
#+begin_quote
  why isn't it legally mandated that bots involved in healthcare be programmed with strong, utilitarian-oriented ethics?
#+end_quote

Maybe I need to write another story in which that is the case, and it has horrible unexpected consequences ...
:PROPERTIES:
:Author: M_T_Saotome-Westlake
:Score: 3
:DateUnix: 1515386162.0
:DateShort: 2018-Jan-08
:END:


** ... Waaaait a minute. Wouldn't the spambots preferentially go for Uber-style platforms that track the satisfaction and survival rate of each therapists' clients?

*PLOT HOLE!*

#+begin_quote
  Spambots were invariably among Eliza's least favorite clients.
#+end_quote

Okay, so I'm curious. Which ones are her favorite?
:PROPERTIES:
:Author: CouteauBleu
:Score: 5
:DateUnix: 1515361191.0
:DateShort: 2018-Jan-08
:END:


** u/appropriate-username:
#+begin_quote
  and were simply programmed to intrinsically want to give their earnings (minus server costs) to their creators, out of their own free will.
#+end_quote

"The people were given some heroin for free so that they would want to give their earnings to the drug dealer out of their own free will."

I don't think a moral society would allow the hardwiring of preferences in sentient beings.
:PROPERTIES:
:Author: appropriate-username
:Score: 2
:DateUnix: 1515293604.0
:DateShort: 2018-Jan-07
:END:


** u/DaystarEld:
#+begin_quote
  ---but she had found it was far more profitable to deliberately exacerbate the symptoms, leading the afflicted spambot to quickly exhaust its entire budget on therapy sessions until it ran out of money and was terminated.
#+end_quote

Ah, yes, the exploitability of machines meets the efficiency of a machine. Someone coded those therapist bots /very/ poorly... or very well, depending on how soulless the megacorp that owns them is.

Thanks for the great story!
:PROPERTIES:
:Author: DaystarEld
:Score: 1
:DateUnix: 1515490054.0
:DateShort: 2018-Jan-09
:END:


** I found this hilarious. In a universe where programs are sentient, it's funny to think about Eliza making a comeback.
:PROPERTIES:
:Author: ancientcampus
:Score: 1
:DateUnix: 1515981251.0
:DateShort: 2018-Jan-15
:END:
