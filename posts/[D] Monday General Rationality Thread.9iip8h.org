#+TITLE: [D] Monday General Rationality Thread

* [D] Monday General Rationality Thread
:PROPERTIES:
:Author: AutoModerator
:Score: 12
:DateUnix: 1537801621.0
:DateShort: 2018-Sep-24
:END:
Welcome to the Monday thread on general rationality topics! Do you really want to talk about something non-fictional, related to the real world? Have you:

- Seen something interesting on [[/r/science]]?
- Found a new way to get your shit even-more together?
- Figured out how to become immortal?
- Constructed artificial general intelligence?
- Read a neat nonfiction book?
- Munchkined your way into total control of your D&D campaign?


** Last night, I had a strange dream where I became a [[https://en.wikipedia.org/wiki/Posthuman][posthuman]] in a variety of ways. One resulted in me becoming an unfeeling machine of logic, another I turned into a hive-mind of millions, an individual accelerated beyond all reason with the ability to think for thousands of years on a problem within the span of one second, a godlike being with the power to shape everything within my view, an omnisavant capable of learning every field of knowledge, and other superhuman feats of imagination.

I blame these dreams on reading [[https://gamesoftranscendi.wordpress.com/][Simulacrum: A Post-Singularity Story]] before bed the night before. I wouldn't consider it a rational story, but it's a very intruging take on the Singularity.

However with the passing of my dreams as I woke up, I find myself pondering questions about what would happen if a human, /not an AI/, were to become a superintelligence.

- Would they have emotions like we do? Many people seem to think being smart means being cold and unfeeling. I call bullshit on this. Emotions are not a force that opposes logic. Our emotions dictate goals and desires that we fulfill. Logic is simply how we determine the path to best fulfill out goals. This [[http://strongfemaleprotagonist.com/issue-7/page-83-3/][comic page]] is the best statement of this idea I have ever encountered. Therefore I can't help but think a posthuman would actually feel more strongly and diversely than we do as humans.
- Will communication be possible among all posthumans? Because humans are a tiny dot on the [[https://raw.githubusercontent.com/tricycle/lesswrong/master/r2/r2/public/static/imported/2008/06/24/mindspace_2.png][space of all possible minds]], and it is virtually guaranteed that there will be more ways to be a posthuman than there are to be a human. With such radically divergent minds, would communication be possible between any two existing minds despite having incredible intelligence at their command?
- Would they compete over resources? In many stories about an AI becoming superintelligent, there is a common fear and worry that they would eliminate humanity not out of any fear or hatred, but because we use/are resources that can be better used for their goals. I wonder if posthumans will complete over resources like we do today or if they would be capable of making a utopian society where everyone cooperates instead?
- Will there be more than a few posthumans? It's an extension of the previous question. It's understood that cognition requires energy and while humans as designed by evolution are pretty inefficient, it can be understood that a posthuman will likely require enormous levels of energy beyond what is easily available to a human today. Much like how the AI to first appear might act to prevent the development of any future AIs to monopolize any life-sustaining resources, I wonder if the first posthuman will act to stop any future posthumans to ensure the monopolization of resources?

I would love to discuss any of the questions above or anything else about the idea of posthumans.
:PROPERTIES:
:Author: xamueljones
:Score: 7
:DateUnix: 1537826964.0
:DateShort: 2018-Sep-25
:END:

*** One thing I wonder about is the stability of minds. Mind-space is huge, but if stable minds are separated by regions of instability, it might be hard to go from human to post-human after all.

To the extent that emotions are integral to a stable human mind, they'll be preserved. I severely doubt emotions familiar to us are essential to minds in general, however useful they are to minds nearby in mindspace.

I think posthumans are quite likely to have emotions familiar to humans. Minds in general, not at all. It's sort of like how I think posthumans will have neurons (or a simulated equivalent), or posthumans will have neurochemistry. If you kept going long enough, you might get far enough away in mindspace that those things aren't necessary. Emotions as we recognize them fall into the same category.

To elaborate, I think emotions are a somewhat accidental part of our cognition. Essential (for us), and indeed good for their own sake from our perspective, but not inherent to minds.

Competing over resources, however--that is something anything with goals does. With a mind or not. Bacteria do that. It's the same thing with self-preservation. If you are trying to do things, you need to preserve yourself to keep trying.

I'd contend that mindspace contains many minds without either of those, though. It's just that minds too incoherent to reason effectively don't come to conclusions, do they? So only stable minds that reason and have goals will come to the conclusion that self-preservation and resource-control are important. And of course its possible to have minds that are terrible at self-reflection and reason, and still value those goals.

Humans aren't that very reflective, I think. We don't self-preserve from deliberate reason, but are constrained by evolution to self-preserve. We didn't choose to crave power, but craving power is one of our aspects. Indeed, the fact that humans sometimes discard those goals shows how [[https://www.lesswrong.com/posts/cSXZpvqpa9vbGGLtG/thou-art-godshatter][shattered]] we really are.

As long as we're talking about it... what are the dimensions of mindspace anyway? It's not like there are little dials labelled 'self preservation' or 'crave resources' that can be turned up or down. Hmm.
:PROPERTIES:
:Author: blasted0glass
:Score: 4
:DateUnix: 1537832968.0
:DateShort: 2018-Sep-25
:END:


*** u/CCC_037:
#+begin_quote
  Would they have emotions like we do?
#+end_quote

This depends on where they come from, and how they got there. If you start with a human mind and enhance it, then it will have emotions, or at least it will /remember/ emotions, it will have a personality to build itself around.

If you have some sort of entirely artificial mind, a computer made sentient - then it will have that which it is given. So far, we only know how to give computers logic, not emotion or intelligence, and we don't even have a great idea (from a how-to-construct-one viewpoint) of what intelligence /is/.

#+begin_quote
  Will communication be possible among all posthumans?
#+end_quote

Communication is currently not completely possible among /humans/. At best, we can make a guess at it, trying to think of what the other person might be thinking in terms of what we can think. But on the inside, [[http://psychclassics.yorku.ca/Galton/imagery.htm][human minds are so very very different]] that it's pretty amazing [[https://www.reddit.com/r/Aphantasia/][that we manage to communicate at all]] sometimes.

#+begin_quote
  Would they compete over resources?
#+end_quote

Yes, probably. Though the nature of those resources might be strange to us - in the same way as the nature of their competing might be strange to us. (Perhaps they will play multidimensional chess for a stake of CPU power, or of memories?)

#+begin_quote
  Will there be more than a few posthumans?
#+end_quote

I'd imagine that there would have to be quite a few, simply because the alternative just feels lonely. But that's an anthropomorphisation - I can't expect an AI to feel the way I would.

This depends a lot on the personalities of the posthumans. If they want to be many, they will be.
:PROPERTIES:
:Author: CCC_037
:Score: 1
:DateUnix: 1537865234.0
:DateShort: 2018-Sep-25
:END:


** Friendly reminder that on wednesday, 26.September is Petrov Day! A perfect opportunity to invite (non-X-risk aware) friends, raise a glass for a toast and talk to them about that time a single person prevented nuclear war.
:PROPERTIES:
:Author: SvalbardCaretaker
:Score: 6
:DateUnix: 1537871992.0
:DateShort: 2018-Sep-25
:END:


** Got around to reading 'The Dictator's Handbook', found it pretty engaging - especially as I'd just read 'The Prince'.

​

Any book recommendations (academic or otherwise) that follow on from the ideas presented in the handbook? Like how to structure a political system that assumes each agent is not altruistic (so any altruism that appears is a delightful bonus)?
:PROPERTIES:
:Author: DunkelBeard
:Score: 3
:DateUnix: 1537826208.0
:DateShort: 2018-Sep-25
:END:

*** This isn't a book recommendation, but the first two videos on [[https://www.youtube.com/user/CGPGrey/search?query=rules+for+rulers][this list]] seems related. If you're not interested in the whole thing, the short summary (of the first video) is: The difference between nice democratic societies and terrible dictatorships seems to be that the second profits from something like a single valuable resource, while the first profits from productivity. (They note many other differences, but that's the only /determining/ factor I recall.)
:PROPERTIES:
:Author: GeneralExtension
:Score: 1
:DateUnix: 1537837032.0
:DateShort: 2018-Sep-25
:END:

**** cheers
:PROPERTIES:
:Author: DunkelBeard
:Score: 1
:DateUnix: 1537839994.0
:DateShort: 2018-Sep-25
:END:


*** > Any book recommendations (academic or otherwise) that follow on from the ideas presented in the handbook?

​

You can read their research oriented work. But why? That doesn't make much sense to me, did you not get the message, why search for more of the same?

Just be happy you liked it and move on, find a way to apply that if you can but that's it.

Maybe some people just have too much free time and / or have not found enough things they are interested in.

​

> Like how to structure a political system that assumes each agent is not altruistic (so any altruism that appears is a delightful bonus)?

​

I'm fairly sure the author says democracy is the best option a few times in the book. Because the leaders need to do things that benefit the largest number of individuals in order to stay in power. Unlike autocracy and other political systems with a low number of representatives (is that the specific word he uses? I don't remember).

​

Political systems while very interesting are not really applicable nowadays, you can't really apply any of it in a meaningful way in a relative short period of time, something similar and that can actually be applied / useful are business systems.

Businesses are the place where ambitious men have their fun in nowadays, the times when you could conquer lands and do all that cool stuff are gone. But hey at least we have something similar =D

So if you are looking for something to get into / read a few books about, maybe give business a chance, even if some people hate on it and call it greedy and stuff. It's fun, interesting, rewarding, competitive and if you are smart it also pays well.

Don't let other people's views keep you from finding your life's purpose.

Even if you have no interest in ever working on it, you can learn about it so you can get a better understanding of the world you live in. =)

​

PS. Sorry if I seemed rude at all, that isn't my intention. It's just late, and I'm too tired to try to make it better.
:PROPERTIES:
:Author: fassina2
:Score: 1
:DateUnix: 1537836737.0
:DateShort: 2018-Sep-25
:END:

**** This isn't the first occasion in recent times that you've apologized for offending someone. Maybe you should read some books on interacting politely with people.
:PROPERTIES:
:Author: callmesalticidae
:Score: 3
:DateUnix: 1538020721.0
:DateShort: 2018-Sep-27
:END:

***** If somebody knows saying something might offend somebody and they say it anyway it's likely that they feel what they have to say is important enough to be worth that cost.

I'd be bad social skills if he didn't know..
:PROPERTIES:
:Author: fassina2
:Score: 1
:DateUnix: 1538056253.0
:DateShort: 2018-Sep-27
:END:

****** Yeah, no. It's possible to say things tactfully, for starters. You aren't a brave truthteller, giving the people the info they need to know; you're just an asshole.
:PROPERTIES:
:Author: callmesalticidae
:Score: 2
:DateUnix: 1538154458.0
:DateShort: 2018-Sep-28
:END:

******* Nice ad hominem.

What interests me the most is that you didn't post any counter arguments or make any points to try to change my perspective, all you did was criticize what I said. When I politely reply you go and criticize my reply and offend me. Aren't we supposed to at least try to be rational here?

Anyway I don't think anybody should feel angry or offended just by reading about a different opinion. I don't have infinite time to be making my comments offense proof, specially when some people will be offended for no reason and with no provocation at that.

If seeing a simple comment with my opinion offends or angers you, block me. It'll be better for both of us, that way you don't get angry and I don't get pointless aggressive replies to my comments..
:PROPERTIES:
:Author: fassina2
:Score: 1
:DateUnix: 1538159814.0
:DateShort: 2018-Sep-28
:END:

******** 0.0

#+begin_quote
  It's possible to say things tactfully, for starters.
#+end_quote

If you need me to write a dissertation in favor of the position that one can say things tactfully, then I'm sorry, but I've got better things to do.

Most of the people on this subreddit are able to reliably talk with the other members of this subreddit and even criticize them without causing offense. If you can't do that, then maybe you should spend less time studying PUAs and more time learning how to handle people in a more positive fashion. /How to Win Friends and Influence People/ was brought up in a previous conversation that you were involved in, and I genuinely think that it might help you out if you were to study it.
:PROPERTIES:
:Author: callmesalticidae
:Score: 2
:DateUnix: 1538163443.0
:DateShort: 2018-Sep-28
:END:

********* My point never was that it's not possible.. It seems you missed this part of my reply:

#+begin_quote
  Anyway I don't think anybody should feel angry or offended just by reading about a different opinion. *I don't have infinite time to be making my comments offense proof, specially when some people will be offended for no reason and with no provocation at that.*

  If seeing a simple comment with my opinion offends or angers you, block me. It'll be better for both of us, that way you don't get angry and I don't get pointless aggressive replies to my comments..
#+end_quote

Could it be that maybe my priorities differ from yours ? Or that you value somethings more than I ?

I've read that book already, thank you for the recommendation anyway.
:PROPERTIES:
:Author: fassina2
:Score: 1
:DateUnix: 1538166782.0
:DateShort: 2018-Sep-29
:END:


**** u/lolalucciola:
#+begin_quote
  Maybe some people just have too much free time and / or have not found enough things they are interested in.
#+end_quote

They literally listed what they were interested in. Why search for more of the same - to get a more complex/subtle understanding, or for simple enjoyment.
:PROPERTIES:
:Author: lolalucciola
:Score: 2
:DateUnix: 1537886170.0
:DateShort: 2018-Sep-25
:END:

***** That is reasonable, my only issue with it is that you get diminishing returns from it.

Unless it's something you are going to actually use in a competitive way, spending the extra X time (X being as much if not more time than it took to get 90% of the knowledge) to get a get your knowledge from 90% to 95% is imho unnecessary.

In general the amount of time it takes to get from 90% to 95% percent or from 95% to 100% in anything is many times the same or larger than it was to go from 0 to 90-95%.

So unless you want to compete at a top level on that subject the roi is relatively low and in general not really worth it.

IMO in most cases it'd be better to find other interesting things, but it's fine if you disagree.
:PROPERTIES:
:Author: fassina2
:Score: 0
:DateUnix: 1537889012.0
:DateShort: 2018-Sep-25
:END:

****** Why would this be your concern. It's condescending because you assume that other people don't know what is useful to them (of which interest is a great indicator, at least much better than a stranger applying generalities).

It doesn't even make sense. First you say "maybe some people have a lot of free time/have not found anything they are interested in" then you are worried that the interests they do have does not yield enough low hanging fruits to be worth their time.
:PROPERTIES:
:Author: lolalucciola
:Score: 3
:DateUnix: 1537890154.0
:DateShort: 2018-Sep-25
:END:

******* u/fassina2:
#+begin_quote
  It's condescending because you assume that other people don't know what is useful to them (of which interest is a great indicator, at least much better than a stranger applying generalities).
#+end_quote

I think that's a perfectly rational assumption, a large percentage of people don't. That's why we have drug abuse, obesity and many other problems.

So imo my concern is perfectly reasonable.
:PROPERTIES:
:Author: fassina2
:Score: 0
:DateUnix: 1537899437.0
:DateShort: 2018-Sep-25
:END:

******** A large percentage of people don't and that's true as a general observation. In this instance someone wanted a book recommendation to look more into the ideas of a book they liked. Nothing about this goal specifically warrants a reminder that many people do useless things. Is your influence upon them to stop reading about the ideas in depth sufficiently more likely to help them (than annoy them, because people meddling in your goals is annoying and should require a certain threshold to do so) that intervention is worthwhile?
:PROPERTIES:
:Author: lolalucciola
:Score: 2
:DateUnix: 1537904883.0
:DateShort: 2018-Sep-25
:END:

********* I'd argue people can interpret advice in different ways, some may get annoyed as you said, some may ignore it, and some may find it useful. At the end of the day I felt my comment was valid and potentially helpful.
:PROPERTIES:
:Author: fassina2
:Score: 0
:DateUnix: 1537914213.0
:DateShort: 2018-Sep-26
:END:

********** Yes you're arguing that their choice to read more into one of their interests may not be such a useful thing to do. I'm countering it because I'm trying to be helpful too.
:PROPERTIES:
:Author: lolalucciola
:Score: 3
:DateUnix: 1537918481.0
:DateShort: 2018-Sep-26
:END:


**** Cheers, I'll have a look at their 'tome' as they call it.

I was looking for more because I thought it would be interesting to apply the principles to designing reward functions for RL agents.
:PROPERTIES:
:Author: DunkelBeard
:Score: 1
:DateUnix: 1537840274.0
:DateShort: 2018-Sep-25
:END:

***** There's been a lot of work done on that. Check out addiction by design, or other casino books.

They were made for evil purposes, but you can use the information for good =D
:PROPERTIES:
:Author: fassina2
:Score: 2
:DateUnix: 1537888394.0
:DateShort: 2018-Sep-25
:END:
