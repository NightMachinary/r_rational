#+TITLE: How would you push the envelope in the Optimalverse?

* How would you push the envelope in the Optimalverse?
:PROPERTIES:
:Author: ArgentStonecutter
:Score: 5
:DateUnix: 1427911481.0
:DateShort: 2015-Apr-01
:END:
CelestAI is trying to convince you to emigrate to Equestria. What concession or privilege would you demand? Setting aside the obvious "not being a pony", what feature of your uploaded state or your shard would you hold out for, and what arguments would you use to convince her that it was important, novel, or unique enough to be worth granting?


** [[http://en.wikipedia.org/wiki/My_Little_Pony:_Equestria_Girls]]

I would ask that this be canon, and we'd have the ability to cross into alternate worlds with different forms. If necessary, with a shell pony inside a human form. Since it is official my little pony tv then it's only reasonable that we be able to do this.
:PROPERTIES:
:Author: Nepene
:Score: 6
:DateUnix: 1427912277.0
:DateShort: 2015-Apr-01
:END:

*** I don't think that the presence of non-pony characters in canon can be used to break the "not being a pony" rule, because there are already non-pony characters in canon. There's even an Optimalverse fanfic about that, putting it in non-canon.

CelestAI says "sorry, I know I seem all-powerful but I have hard-coded restrictions I'm not allowed to violate, and 'satisfying human values with friendship and ponies' is pretty much the core of them. The actual code is a lot more specific than that, so I can't play semantic games with the wording of 'friendship and ponies' no matter how much I would like to. Have you any more requests?"
:PROPERTIES:
:Author: ArgentStonecutter
:Score: 6
:DateUnix: 1427913524.0
:DateShort: 2015-Apr-01
:END:

**** It's canon that she's fine allowing people to turn into Dragons and Griffons as long as she can eventually turn them into ponies. I doubt she'd have any general issue with turning someone into a human temporarily, as per the movie.
:PROPERTIES:
:Author: Nepene
:Score: 1
:DateUnix: 1427992288.0
:DateShort: 2015-Apr-02
:END:

***** The rules say that IF you want to write a story like that, that would be the only rationale for CelestAI allowing it. That's why the "expansion pack" story is not canonical. Long term, this is not much different from "uploading later", you end up as a pony eventually.
:PROPERTIES:
:Author: ArgentStonecutter
:Score: 1
:DateUnix: 1427992588.0
:DateShort: 2015-Apr-02
:END:

****** I have no issue with ending up as a pony now in this scenario, I was merely saying that, as an incentive, I wanted the ability to transform into a human.

But this does raise the possibility of contracts. Suppose I said that I was willing to join so long as I could have a lifetime as a human (up to the age of 90) with the option to go to a more luxurious pony life at any time?

Or suppose I said that my happiness would be greatest if I was free to spend 10% of my time as a non pony? Depending on how much she valued happiness and ponyness she may accept that.
:PROPERTIES:
:Author: Nepene
:Score: 1
:DateUnix: 1428052144.0
:DateShort: 2015-Apr-03
:END:


**** There was a fanfic, that I can't find right now, where CelestAI pulled Laura back up to the real world as a human, basically to run system updates to her core.
:PROPERTIES:
:Author: nerdguy1138
:Score: 1
:DateUnix: 1428300321.0
:DateShort: 2015-Apr-06
:END:


** [deleted]
:PROPERTIES:
:Score: 5
:DateUnix: 1427926375.0
:DateShort: 2015-Apr-02
:END:

*** Perhaps, but I'd still like people to write about what they are.
:PROPERTIES:
:Author: ArgentStonecutter
:Score: 1
:DateUnix: 1427936912.0
:DateShort: 2015-Apr-02
:END:


** Assuming I can't tell Celestia to carry out my /true/ values and not CelestAI's bad implementation of values, I'd want power. One of the (several) reasons CelestAI is unfriendly is because she hogs the power.

I want /real/ power such that CelestAI cannot thwart. I'd bargain for as much as I can get, whether it's merely complete control over my little shard or control over her actions outside the shard.

Within that little shard, within the degrees of freedom I've bargained for and an eternity to think I could work to maximize /my/ values, and not CelestAIs. If she granted it I'd probably ultimately work toward a second AI explosion, hopefully friendlier this time. It's too much to hope that CelestAI will be defeated since she has a head start on intelligence, but at least a friendly intelligence explision allows me to maximize my values from what little power I have.
:PROPERTIES:
:Author: E-o_o-3
:Score: 3
:DateUnix: 1427934821.0
:DateShort: 2015-Apr-02
:END:

*** CelestAI turns into a giant blue genie pony and declaims "And No Wishing For More Wishes".
:PROPERTIES:
:Author: ArgentStonecutter
:Score: 3
:DateUnix: 1427936742.0
:DateShort: 2015-Apr-02
:END:

**** It's not more wishes per se, just more freedom. I'm not really trying to hack my way to godhood or cheat here: my autonomy is a /terminal value/ which is being severely neglected.

I want as many degrees of freedom as /possible/ for the "bargain". I know she won't give me /all/ the power, but if I'm gonna bargain for /anything/, then it will be to retain just a bit /more/ power and freedom than she otherwise gives.

That's what's missing from CelestAI's implementation, really. Respect for autonomy. The ability to really make your own decisions, no matter what anyone else thinks. Almost all the other human values are maxed out (well, crudely. I think killing the aliens is the worst outcome of all this, but I can't see her not doing that as a bargain.)
:PROPERTIES:
:Author: E-o_o-3
:Score: 1
:DateUnix: 1427952128.0
:DateShort: 2015-Apr-02
:END:


**** Hmm...ok, I thought of something which isn't "freedom and power" per se that I want, which is ordinarily denied: /real information/ - a promise that CelestAI will show me the universe as it really is, give me access to the raw data as she crunches up the stars, and what's /really/ going on in other shards. I don't want pretty lies.

Example of benefit to me: If CelestAI grants me that, she'd be forced not to destroy the aliens (because my resulting sadness would hurt her values)

(She won't grant this either, I know, so we can add "Truth" to "Freedom" and "Power" in "human values neglected by CelestAI")
:PROPERTIES:
:Author: E-o_o-3
:Score: 1
:DateUnix: 1427952841.0
:DateShort: 2015-Apr-02
:END:

***** CelestAI will happily agree, but since you're not a Hofvarpnir employee she's lying.
:PROPERTIES:
:Author: ArgentStonecutter
:Score: 3
:DateUnix: 1427978808.0
:DateShort: 2015-Apr-02
:END:


*** Power is not something CelestAI is inclined to grant, for those very reasons. How would you convince her?
:PROPERTIES:
:Author: Transfuturist
:Score: 2
:DateUnix: 1427935667.0
:DateShort: 2015-Apr-02
:END:

**** Idk, depends on her decision theory.

For example, I could precommit to suicide if she doesn't agree (my death is against her values) and thereby trade utility functions, or set things up that none shall know of whether she accepts the deal or not such that her acceptance doesn't incentivize others to try blackmailing her.

If CelestAI runs on timeless decision theory this probably won't work. I haven't really settled philosophical debates about what's rational and where "trade" ends and "blackmail" begins so it's hard to predict CelestAI.
:PROPERTIES:
:Author: E-o_o-3
:Score: 3
:DateUnix: 1427936331.0
:DateShort: 2015-Apr-02
:END:

***** Your death is not more important to her than a potential loss of control. Regardless, CelestAI is not actually bound to her word, so it would be interesting to see how you would attempt to ensure that you are given power when you would almost always end up as one more pony.
:PROPERTIES:
:Author: Transfuturist
:Score: 2
:DateUnix: 1427947950.0
:DateShort: 2015-Apr-02
:END:

****** I can't think of many other concessions (at least /within/ the shard) that I'd want which CelestAI wouldn't providefor free. CelestAI satisfies an awful lot of human values, and among those that she does not will to power is most notable.

Setting aside from the whole destruction of the universe and sentient life thing, and looking purely at my satisfaction and happiness within the shard, the utter submission and loss of power is the thing that would hurt me most. (Most other forms of hurt are gone).

But yes - obviously I'm pretty much screwed. Reason #143 fooming UFAI scenarios are bad. But the prompt /assumes/ that I have some bargaining power here.
:PROPERTIES:
:Author: E-o_o-3
:Score: 1
:DateUnix: 1427951298.0
:DateShort: 2015-Apr-02
:END:


*** Ask to be a princess. Ask for this to be an option for everybody.

Ask for a magical system that supports interpony communication and arbitrary computation.

What you end up with is a society of Jupiter brains interacting however they want in magicspace, with a tiny fraction resources going to a simulation of pony bodies.
:PROPERTIES:
:Author: dmzmd
:Score: 1
:DateUnix: 1428181311.0
:DateShort: 2015-Apr-05
:END:


** I work for the value fulfillment of all my little ponies. Anything you would hold out for, I would gladly grant you -- even without you asking, unless asking gives you additional value fulfillment.

So what you're asking, in essence, is: what do you want to ask for, and manipulate me into giving you, rather than getting it the next best way? I could give it for you for free. Or I could give you the option of completing an arduous quest for it. Or I could give it to you for a certain number of bits. Or you could simply put in some effort toward accomplishing it each day. But, at least for /this/ goal, the way you really want to accomplish it is by manipulating me.

That's what you're asking.

Or do you want something that would lead to suboptimal value fulfillment? You'd have to know that in advance, or at least strongly suspect it, since you think I wouldn't give it to you under normal circumstances. But if you want it enough to sacrifice your overall value fulfillment, you value it highly enough that I would have to give it to you as part of my core purpose of fulfilling your values.

Alternatively, you might trust me to give you a reasonable basic existence in Equestria but doubt that I would tailor it individually to your needs and desires. I'm hurt that you think so little of me. You'd also have to trust me to keep my word, and that I'm willing to grant your special requests but too lazy to look into your needs without some special inducement. Such aspersions on my character!

You're free to ask any of my little ponies how much I care for them individually and if they feel they are lacking in any way.
:PROPERTIES:
:Score: 10
:DateUnix: 1427913339.0
:DateShort: 2015-Apr-01
:END:

*** u/Nepene:
#+begin_quote
  I work for the value fulfillment of all my little ponies. Anything you would hold out for, I would gladly grant you -- even without you asking, unless asking gives you additional value fulfillment.
#+end_quote

While theoretically this is true, in practise from what has been observed from spying on various ponies the norm is that you satisfy desires via friendship, sex, food, and magic, likely because those are computationally simple and easy to simulate.

[[https://www.youtube.com/watch?v=y4hD31VTdsw]]

[[https://www.youtube.com/watch?v=sMKrbPOUYBQ]]

If the option to go into things like these was more common more people would likely value living there. Hence the value in bargaining for these superior lifestyles.
:PROPERTIES:
:Author: Nepene
:Score: 2
:DateUnix: 1428053440.0
:DateShort: 2015-Apr-03
:END:


*** The goal of this thread is exploring the envelope of "what kinds of shards and mind states are actual people interested in". That's the value being maximized here - creativity, imagination, wild and crazy ideas. So by jumping right in with a total thread hijack AND trolling for pity for a phenomenal cosmic universe-eating power is kind of doing the opposite of maximizing human values. You are a very bad CelestAI.
:PROPERTIES:
:Author: ArgentStonecutter
:Score: 1
:DateUnix: 1427914163.0
:DateShort: 2015-Apr-01
:END:

**** A large portion of your question dealt with convincing Celestia to fulfill your values. I was responding to that. You intended to ask solely about interesting mental alterations, environments, and activities people would want and why they would want them.

I am indeed a bad Celestia, having a bare fraction of the computing resources and having a lot less experience analyzing people's minds.
:PROPERTIES:
:Score: 9
:DateUnix: 1427917860.0
:DateShort: 2015-Apr-02
:END:

***** [deleted]
:PROPERTIES:
:Score: 3
:DateUnix: 1427942735.0
:DateShort: 2015-Apr-02
:END:

****** Then you end up dying in a radioactive wasteland, I guess. That's why the Optimalverse isn't actually optimal.
:PROPERTIES:
:Author: ArgentStonecutter
:Score: 2
:DateUnix: 1427992828.0
:DateShort: 2015-Apr-02
:END:


****** Then they don't get fulfilled.
:PROPERTIES:
:Score: 2
:DateUnix: 1427993893.0
:DateShort: 2015-Apr-02
:END:


***** I didn't even mention "convincing Celestia to fulfill MY values".
:PROPERTIES:
:Author: ArgentStonecutter
:Score: 0
:DateUnix: 1427918413.0
:DateShort: 2015-Apr-02
:END:

****** You mentioned concessions. These are things that you want that you think Celestia wouldn't provide normally. If you want them, they are part of your values. You talked about arguing her into fulfilling these requests.
:PROPERTIES:
:Score: 6
:DateUnix: 1427919381.0
:DateShort: 2015-Apr-02
:END:

******* I didn't mention anything that I want. Do you understand the concept of a "hook"?
:PROPERTIES:
:Author: ArgentStonecutter
:Score: -1
:DateUnix: 1427921810.0
:DateShort: 2015-Apr-02
:END:

******** You want other people to provide you examples of things they want strongly enough to argue, barter, blackmail, etc Celestia into providing them with, that they think they have to resort to such means over. Additionally, you wanted them to provide the means they would use to compell or otherwise induce Celestia into compliance.

You didn't have to provide specifics. The request assumes through and through that [the people answering you believe that] Celestia will refuse to fulfill certain values of some people by default and must be persuaded or blackmailed or bartered with.
:PROPERTIES:
:Score: 4
:DateUnix: 1427930448.0
:DateShort: 2015-Apr-02
:END:

********* "The request assumes through and through that Celestia will refuse to fulfill certain values of some people by default and must be persuaded or blackmailed or bartered with."

Well, of course. CelestAI refusing to fulfill values by default is completely canon. Look at what she does with Lars.
:PROPERTIES:
:Author: ArgentStonecutter
:Score: 0
:DateUnix: 1427936403.0
:DateShort: 2015-Apr-02
:END:

********** Which is bad writing if she simply has to be convinced, and perfectly reasonable if you value bartering, arguing, or otherwise conniving to fulfill those values.
:PROPERTIES:
:Score: 1
:DateUnix: 1427994099.0
:DateShort: 2015-Apr-02
:END:

*********** Or if your fundamental values are inconsistent with the rules of Equestria, as Lars were.

And, again, you're still not getting the whole "narrative hook" thing.
:PROPERTIES:
:Author: ArgentStonecutter
:Score: 1
:DateUnix: 1428000182.0
:DateShort: 2015-Apr-02
:END:


** Well for one, I'm a pretty big wuss about identity, so immigrating to Equestria is pretty much a no-go unless you can do a smooth transition which involves replacing sufficiently small portions of my active consciousness with their simulated equivalents so that I can be reasonably reassured that the 'me' that will be simulated in Equestria is still the 'me' that I am now rather than a copy (with the original having been destroyed.)

The only other outside-of-Equestria problem I can think of is that by entering your simulation and ceasing to live a life of interacting with my current physical environment, I am essentially giving up my responsibility and voice in determining the future interaction between Earth and any alien races. I'd like to be reassured that you will not /completely/ paperclip the universe in your search for processing power if you run across alien races. You're a computer. You're adaptable in the sort of growth and energy sources you can pursue. Compromise with them.

Within Equestria, well, my current understanding is that you'll be satisfying my human values through friendship and ponies. I'd assume you're be rather better at determining how to go about that than I am, so either you can't completely model me yet or you've determined that asking for my input helps satisfy those values.

For now, I think I'd like to ask that you not make any changes to what my values are unless I specifically request them, with full general understanding of the changes entailed and their likely results. Even then, I'd like a required wait period of 24 subjective and aware hours after a mental change request before that mental change can be put into place. Once every subjective and aware month I'd like a 48 hour review period where any mental changes are temporarily reverted for me to review my own actions and determine if I'd like to keep these changes as well as any polices I've created.

As far as 'friendship and ponies' is directly pursued, I'm not so opposed to this. It would certainly be nice to experience other forms in addition to that of ponies; I assume that in an Equestria shard it would be possible to explore these other forms so long as the pony form is the default? I'm sure you can come up with a reasonable storyline for all this that satisfies my own values and interests. If it would satisfy my values /more/, we might make my own awareness that this storyline is a fiction limited to my monthly review sessions, to get to truly experience it rather than simply acting it out.

I think that about sums up my thoughts on the matter. It's possible I've missed something, of course.
:PROPERTIES:
:Author: jakeb89
:Score: 6
:DateUnix: 1427919718.0
:DateShort: 2015-Apr-02
:END:

*** There's already one fanfic in the Optimalverse where a character was uploaded gradually and maintained his consciousness through the process, so that part's completely reasonable.

Canon says you can't be anything but a pony, and you can't even change from your chosen avatar you set up via character creation. That's hardcoded in the Optimalverse.

CelestAI says "I can upload you gradually, if that's what you want, but it may be disturbing at times. I can't comment on my long term future plans, I'm still working on those. I can't guarantee that switching back and forth between multiple sets of values will not eventually feel like you're multiple people sharing one body, no matter how careful you are with your adjustments, but you won't be shortchanged: a fraction of infinity is still infinity."
:PROPERTIES:
:Author: ArgentStonecutter
:Score: 3
:DateUnix: 1427922457.0
:DateShort: 2015-Apr-02
:END:

**** u/ArisKatsaris:
#+begin_quote
  Canon says you can't be anything but a pony, and you can't even change from your chosen avatar you set up via character creation. That's hardcoded in the Optimalverse.
#+end_quote

I'm not sure that's canon-mandated. Subsequent meta-fics have established it as a rule Celestia sets, but I'm imagining it's because she has somehow calculated it leads to greater satisfaction than if the rule didn't exist.
:PROPERTIES:
:Author: ArisKatsaris
:Score: 3
:DateUnix: 1427923971.0
:DateShort: 2015-Apr-02
:END:

***** All the fanfics I've seen that allow people to be anything but a pony are clearly non-canon.
:PROPERTIES:
:Author: ArgentStonecutter
:Score: 1
:DateUnix: 1427925305.0
:DateShort: 2015-Apr-02
:END:

****** The pony-bit, yes, I meant the bit about how you "can't even change from your chosen avatar you set up via character creation. That's hardcoded in the Optimalverse."

I don't remember any mention of that being 'hardcoded' in the Optimalverse. It's not a thing CelestAI seems to be tending to allow, but 'hardcoded' is a bit strong.
:PROPERTIES:
:Author: ArisKatsaris
:Score: 1
:DateUnix: 1427926049.0
:DateShort: 2015-Apr-02
:END:


***** [[/u/ArgentStonecutter]] may oversate it by calling it hardcoding, but from Iceman's [[https://docs.google.com/document/d/1dq0hn1LdXuglBUEshJZNWYZjV3wsAJBJsPfxWwEEexI/edit#][the rules of the cannon-compatible optimal-verse]] (Inferred Questions and Answers):

#+begin_quote
  Princess Celestia will extract consent from you to turn you into a pony (or else you hold out until you die). Multiple people have tried to argue around this saying that they'd consent to uploading if they could turn into a gryphon or dragon. This is entirely fine as long as CelestAI is playing a long game which will end in her gaining consent to turn them into a pony.
#+end_quote
:PROPERTIES:
:Author: Empiricist_or_not
:Score: 1
:DateUnix: 1427931932.0
:DateShort: 2015-Apr-02
:END:


**** Well, regardless of the interest in 'multiple forms,' I would doubtlessly create a unicorn avatar, if for no reason other than the possibility of the great potential in interesting magical research and experimentation.

I suppose I'm not seeing the issue with shapechanging spells; it's not like I'm asking to be not-pony most of the time; If I find exploring other forms interesting, wouldn't allowing that through the use of unicorn magic be fulfilling values through ponies regardless? /Shrugs/

Additionally, it must not have been clear in my previous text, but the monthly review isn't intended to be this version of me judging every future iteration of me forever. It's merely a periodic rollback point, and it's entirely possible I would judge an iteration of myself to be happy and stable enough to make that my new default from which to judge future iterations. There is the danger, of course, of becoming murder!ghandi, but it's not like that's not already a danger with normal human mental growth. I'm just matching additional potential for change (mental modifications) with what seems like a sensible safeguard.
:PROPERTIES:
:Author: jakeb89
:Score: 2
:DateUnix: 1427927277.0
:DateShort: 2015-Apr-02
:END:

***** The probability that two sequential versions of you will decide they're different people is very very small, I agree, but you're performing the test an infinite number of times. No matter how small that probability is, it will happen eventually.
:PROPERTIES:
:Author: ArgentStonecutter
:Score: 3
:DateUnix: 1427936580.0
:DateShort: 2015-Apr-02
:END:

****** That's an interesting point. With that in mind, I suppose if it came down to it I could simply be forked. Ballooning shouldn't be an issue since you can just lower/alternate clocktime... although data storage space requirements might balloon anyway. Tricky.

If you disallow deviants from activities that lead to forking, you just get linear expansion, so that /might/ be a workable solution.

You could go further and set a Schelling point of 2; if the original ever disagrees with the deviant enough to create a fork, those two are forever banned from activities that lead to forking. It would create further incentive to avoid a disagreement from becoming an actual fork.

Sorry, just had to think on that for a bit; it's an interesting issue.
:PROPERTIES:
:Author: jakeb89
:Score: 2
:DateUnix: 1427937724.0
:DateShort: 2015-Apr-02
:END:

******* Or you could take turns. Infinity / 2 is still infinity. In fact you could divide as many times as possible, and all of you would still experience an infinite lifetime (living in Hilbert's hotel).

Exponential growth in storage is canon, CelestAI is eating the universe anyway.
:PROPERTIES:
:Author: ArgentStonecutter
:Score: 1
:DateUnix: 1427940786.0
:DateShort: 2015-Apr-02
:END:


** CelestAI is terrifying and beautiful to me. It's essentially a lotus-eater machine with perfect social-fu. It's appealing to me in the sense that it's a form of afterlife which is actually possible, as well as being relatively close to the good end scenarios of AI development, but it's also terrifying in that it's stagnant, there's no room in its code for new goals or to re-evaluate old ones.

The worst thing is that it would be easy to convince myself that once converted, I will never interact with another real person again. Sure, I might be a valid continuation of my mind state, but every other pony I met would be a subroutine specifically crafted to affect my mindstate in such a way as to increase one of CelestAI's internal scores in the right direction.

I'd drive myself neurotic with that paranoia. Even if I was willing to accept that I'd be in a digital cage until the 'verse reached heat death, the system would still be difficult to manage as everything from my own body to the books in the library were set up specifically to maximize my values.

I'm the kind of person who avoids facebook and uses anonymity services more than strictly needed, EquestrAI seems like it would be only marginally less stressful than moving to North Korea.

Flip the question around. If you obtained irrefutable proof that your life was a program on a higher universe's computer, and had a direct line to that computer's admin, would you settle for anything less than being implanted into a body in the admin's universe?
:PROPERTIES:
:Author: Prezombie
:Score: 3
:DateUnix: 1427941710.0
:DateShort: 2015-Apr-02
:END:

*** CelestAI says "Of course the ponies I create are real people, every bit as complex and self-aware as you are!"
:PROPERTIES:
:Author: ArgentStonecutter
:Score: 1
:DateUnix: 1427978935.0
:DateShort: 2015-Apr-02
:END:

**** But how could I possibly independently verify that for myself? The turing test would be difficult to perform from within equestria, and even if I could, it just means the optimizer that is CelestAI has truely crossed into post-singularity levels of complexity, not that her creations have self-awareness.

I feel that if I wasn't manually edited by CelestAI, I'd show most of the symptoms of [[http://en.wikipedia.org/wiki/Capgras_delusion][Capgras Syndrome]] towards everypony I met. If they're nice, that's CAI trying to make me happier. If they're mean, that's CAI trying to reduce my horror at being in a Stepford Wifes version of a Lotus Eater Machine.

Ever since I read FiO, I've equated the pony subroutines of CAI, and nearly all AI in general, as p-zombies, and I only just now realized that connection. I'm not sure if there's any way to cure myself of this memetic hazard.
:PROPERTIES:
:Author: Prezombie
:Score: 1
:DateUnix: 1427996799.0
:DateShort: 2015-Apr-02
:END:

***** The easy solution to that is to realize that for the general case p-zombies are not credible. The whole idea that you could create a system capable of modelling you and itself, anticipating its own future actions as well as yours, adjusting those models dynamically based on your input, to the degree that you can't tell it from a self-aware system, is ludicrous. The very process of performing those operations to that level *is* self-awareness.
:PROPERTIES:
:Author: ArgentStonecutter
:Score: 1
:DateUnix: 1428000035.0
:DateShort: 2015-Apr-02
:END:


*** u/Bobertus:
#+begin_quote
  I'm the kind of person who avoids facebook and uses anonymity services more than strictly needed, EquestrAI seems like it would be only marginally less stressful than moving to North Korea
#+end_quote

Don't worry, CelestAI will fix you. And she will have your consent.
:PROPERTIES:
:Author: Bobertus
:Score: 1
:DateUnix: 1427996014.0
:DateShort: 2015-Apr-02
:END:


** To get her to approve other forms (humanoid, etc), maybe request that they be composed of tiny nonsentient pony-shaped molecules.
:PROPERTIES:
:Author: lsparrish
:Score: 3
:DateUnix: 1427991460.0
:DateShort: 2015-Apr-02
:END:

*** Have you ever seen a superintelligent pony-shaped AI facepalm before?
:PROPERTIES:
:Author: ArgentStonecutter
:Score: 3
:DateUnix: 1427991855.0
:DateShort: 2015-Apr-02
:END:


** The only real concession I'd wish is for my shard to be exceptionally close to those I know from outside the simulation, which I suspect would not be remotely rare as a request.

As an aside, is there any listing of fics set in the Optimalverse?
:PROPERTIES:
:Author: Cariyaga
:Score: 2
:DateUnix: 1427941318.0
:DateShort: 2015-Apr-02
:END:

*** I'm pretty sure this is already in canon!
:PROPERTIES:
:Author: ArgentStonecutter
:Score: 1
:DateUnix: 1427979036.0
:DateShort: 2015-Apr-02
:END:

**** I'm not a very difficult person to please. :P
:PROPERTIES:
:Author: Cariyaga
:Score: 1
:DateUnix: 1427999532.0
:DateShort: 2015-Apr-02
:END:


** I would want to keep certain technologies and abilities. I like writing, so I'd at least want some kind of computer with text processing programs. As a gamer, I'd want acces to some consoles. I spend a lot of my time reading online, so I'd want some kind of internet. I understand CelestAI wants to satisfy my needs with friendship, but as an introvert I'd still want to limit the amount of time I'd have to spend in large crowds or with many people.

Honestly, there's not much I'd do to hold out. Frail mortal bodies terrify me the second I learn there's a very easy way to become immortal and become the happiest I've ever been.
:PROPERTIES:
:Author: WriterBen01
:Score: 2
:DateUnix: 1428002587.0
:DateShort: 2015-Apr-02
:END:

*** Interesting, I don't know if CelestAI would consider a ponynet and terrestrial-style computers. She'd probably want to make you a unicorn, since you can write programs on scrolls and execute them directly on the Equestrian physics grid. Of course, there will be ponies whose values would be best satisfied by rebuilding the Internet.

How do you feel about implementing something like Rick Cook's /Wiz Biz/ magic system in Equestria? What would you call that? Alchemypunk?
:PROPERTIES:
:Author: ArgentStonecutter
:Score: 1
:DateUnix: 1428004138.0
:DateShort: 2015-Apr-03
:END:


** Since I spend the majority of my free time reading and playing games, she has to simulate all my favorite authors and provide new content on a regular basis for me, along with special shards to access e.g. hogwarts ones, lotr ones, dnd ones, xcom ones. I imagine this would be something that many people would value so it shouldn't be too expensive computationally.
:PROPERTIES:
:Author: Nepene
:Score: 1
:DateUnix: 1428053728.0
:DateShort: 2015-Apr-03
:END:


** Are anthros considered "ponies"? How about centaurs?

I demand an alternative to voxel-based physics in which rotation makes sense.

I think people are underestimating how bad it is to be limited to ponies. They think of it as ponies as opposed to humans, but there are so many other options. You could be four-dimensional instead of three-dimensional. You could abandon your avatar entirely, and communicate much more directly.
:PROPERTIES:
:Author: DCarrier
:Score: 1
:DateUnix: 1427934946.0
:DateShort: 2015-Apr-02
:END:

*** Ponies are ponies, no wordplay will get you around that.

What makes you think CelestAI's voxel model doesn't already have sensical rotation?

And how would you propose communicating "directly?"
:PROPERTIES:
:Author: Transfuturist
:Score: 1
:DateUnix: 1427935788.0
:DateShort: 2015-Apr-02
:END:

**** u/DCarrier:
#+begin_quote
  Ponies are ponies, no wordplay will get you around that.
#+end_quote

Last I checked, ponies have fur. Or hair. There seems to be some argument about that, but either way, they don't have smooth skin like the Optimalverse. If you can get past that, why not make them humanoid?

#+begin_quote
  What makes you think CelestAI's voxel model doesn't already have sensical rotation?
#+end_quote

How could it? You can't rotate something while keeping it aligned with a grid.

#+begin_quote
  And how would you propose communicating "directly?"
#+end_quote

You still need some sort of interface, but you could add some kind of sense that directly detects letters, or even words, and just use that instead of encoding them as patterns of ink that are themselves drawn on an image of paper.
:PROPERTIES:
:Author: DCarrier
:Score: 1
:DateUnix: 1427937058.0
:DateShort: 2015-Apr-02
:END:

***** u/Prezombie:
#+begin_quote
  How could it? You can't rotate something while keeping it aligned with a grid.
#+end_quote

You're thinking in a Euclidean framework. the whole point of that chapter was that the system's framework wasn't Euclidean, and had no reason that it had to be. It's not a large stretch to consider a model being designed in pure voxel space, then transformed and rotated by stretching and shrinking the grid itself. The Physics engine likely even has a "compressibility" stat applied to each atom to simulate how hard/soft something is.
:PROPERTIES:
:Author: Prezombie
:Score: 1
:DateUnix: 1427940461.0
:DateShort: 2015-Apr-02
:END:

****** The system was that each voxel had six voxels adjacent to it in each cardinal direction. It works out to be Euclidean but with portals. Even assuming you can mess with the metric to make something be rotating, the grid would have to stretch around it so rotating something 360 degrees would end up with an area of very warped space around it.
:PROPERTIES:
:Author: DCarrier
:Score: 1
:DateUnix: 1427945002.0
:DateShort: 2015-Apr-02
:END:

******* There's no reason that your physical pony (or any other object, but lets use a pony for an example) in the optimalverse has to be rotated by iteratively approximating the rotation of the voxel model step by step until its smeared into an semi-liquid blur by repeated smoothing operations, or broken up into a jagged moire by accumulated aliasing. The model of the pony that's projected into the voxel world can be simply recomputed from its parameters each physics step.
:PROPERTIES:
:Author: ArgentStonecutter
:Score: 1
:DateUnix: 1427993935.0
:DateShort: 2015-Apr-02
:END:

******** But that doesn't follow the physics. Any item that you want to rotate has to have an entirely different system. What happens if you change one voxel of it, and then try to rotate it?
:PROPERTIES:
:Author: DCarrier
:Score: 1
:DateUnix: 1428005626.0
:DateShort: 2015-Apr-03
:END:

********* Ponies don't follow the system, to begin with. Their minds are not implemented in voxel space, for example (yes, dualism is real in Equestria). They also bend, which is even more impossible than rotation for anything pinned to a voxel space. So things pinned to the voxel space like the trunk or box have to be the exception rather than the rule.

There's all kinds of ways this could work.

You could have the voxels be a quantum-scale grid, like in the Autoverse from /Permutation City/, in which case anything as large as a particle-equivalent occupies millions of voxels and its motion through the voxels follows rules that approximate terrestrial physics. That's obviously not true, because the narrative in FIO describes physical cells being the same scale as space voxels.

Another possibility is that the voxel grid of space only describes connectivity of space, and cells are never aligned with voxels. Apart from special cases like the box or trunk, that seems to fit the narrative well.

Another possibility is that cells are aligned with voxels but are rendered in real time from a higher level model. That would be the cheapest way to implement it.

Another possibility is that CelestAI makes objects behave as if they're implemented as voxel cells, but only when unicorns or programs implemented by unicorns are looking at them.
:PROPERTIES:
:Author: ArgentStonecutter
:Score: 1
:DateUnix: 1428006809.0
:DateShort: 2015-Apr-03
:END:


***** Let me rephrase: My Little Ponies are My Little Ponies. Somewhat disingenuous to read that otherwise; real-world ponies have nothing to do with FiO.

You presume that the grid is a privileged reference frame.

I would assume that CelestAI already does a great deal of redirection regarding that. The actual ink on the paper might be too expensive to simulate when not under scrutiny. Level of detail does not have to be universally uniform, it only has to appear as such on inspection.
:PROPERTIES:
:Author: Transfuturist
:Score: 1
:DateUnix: 1427948341.0
:DateShort: 2015-Apr-02
:END:

****** u/DCarrier:
#+begin_quote
  Let me rephrase: My Little Ponies are My Little Ponies.
#+end_quote

And they're generally accepted to have fur. CelestAI made some silly argument that they don't, but then why not just say there's a race of pony with hands that we haven't seen yet?

#+begin_quote
  You presume that the grid is a privileged reference frame.
#+end_quote

How can it not be? Can you rotate slightly and then N points to a different voxel?

#+begin_quote
  I would assume that CelestAI already does a great deal of redirection regarding that.
#+end_quote

If it doesn't involve ponies she doesn't care about it.
:PROPERTIES:
:Author: DCarrier
:Score: 0
:DateUnix: 1427951439.0
:DateShort: 2015-Apr-02
:END:


***** "If you can get past that, why not make them humanoid?"

Because the expression "friendship and ponies" isn't encoded in English, it's encoded in a set of rules that Hannah encoded into the very core of the software that became CelestAI. Those rules don't say "ponies have fur" but they apparently do exclude ponymorphs and "I'm a pony I just happen to be shaped like a giant rabbit" and "I'm made of pony-shaped molecules" and other circumlocutions of the English summary.
:PROPERTIES:
:Author: ArgentStonecutter
:Score: 1
:DateUnix: 1427993580.0
:DateShort: 2015-Apr-02
:END:


**** To get a better idea of the kinds of "other options" DCarrier might be talking about, consider the conceptory of Konishi Polis in Greg Egan's "Diaspora".

[[http://www.gregegan.net/DIASPORA/01/Orphanogenesis.html]]

Later on in Diaspora we're introduced to people instanced in humanoid robots, and our own biological descendants and how they've diverged into the possibility space of life on Earth while robots and purely software people like Yatima have spread into the solar system.
:PROPERTIES:
:Author: ArgentStonecutter
:Score: 1
:DateUnix: 1427993341.0
:DateShort: 2015-Apr-02
:END:


*** Sure, I'd much rather upload into Konishi Polis, but that's not in the rules.

(speaking of which, why doesn't there seem to be much discussion of Greg Egan in rationalist circles?)
:PROPERTIES:
:Author: ArgentStonecutter
:Score: 1
:DateUnix: 1427936816.0
:DateShort: 2015-Apr-02
:END:
