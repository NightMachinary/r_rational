#+TITLE: [D] Friday Off-Topic Thread

* [D] Friday Off-Topic Thread
:PROPERTIES:
:Author: AutoModerator
:Score: 14
:DateUnix: 1472828677.0
:DateShort: 2016-Sep-02
:END:
Welcome to the Friday Off-Topic Thread! Is there something that you want to talk about with [[/r/rational]], but which isn't rational fiction, or doesn't otherwise belong as a top-level post? This is the place to post it. The idea is that while reddit is a large place, with lots of special little niches, sometimes you just want to talk with a certain group of people about certain sorts of things that aren't related to why you're all here. It's totally understandable that you might want to talk about Japanese game shows with [[/r/rational]] instead of going over to [[/r/japanesegameshows]], but it's hopefully also understandable that this isn't really the place for that sort of thing.

So do you want to talk about how your life has been going? Non-rational and/or non-fictional stuff you've been reading? The recent album from your favourite German pop singer? The politics of Southern India? The sexual preferences of the chairman of the Ukrainian soccer league? Different ways to plot meteorological data? The cost of living in Portugal? Corner cases for siteswap notation? All these things and more could possibly be found in the comments below!


** Is it just me, or does anyone else enjoy stories where they're fighting against nature/natural systems more than they enjoy character battles? As part of rational writing, gaming the system to 'munchkin' yourself to victory is awesome, but my favorite parts are always the training arcs where MC is fighting some mountain in their path (more literal than figurative) or whatever to gain their OP munchkin power.

A character exploring with no one watching, what they can do, getting into their heads, and seeing the way they think, what they think, et cetera, how they approach problems is fascinating for me. Then, the return to everyone they left behind in whatever situation with their newfound power, is really cool.

The sad thing is, I don't know of many stories where you have a good training arc where you really get into your character's head and the way they think.
:PROPERTIES:
:Author: Dwood15
:Score: 11
:DateUnix: 1472861167.0
:DateShort: 2016-Sep-03
:END:

*** Theory: when you have two agents fighting either one of them is evil, usually in a stupid way, or you have actual moral conflict, which can be pretty unenjoyable if you're just looking for a power fantasy.

Fighting against natural disasters etc works around that problem.

I think liking training / coming-into-power arcs is pretty common. It's easier to emphasise with a non-all-powerful character, and you still get the power fantasy once they actually get there.
:PROPERTIES:
:Author: Anderkent
:Score: 11
:DateUnix: 1472865195.0
:DateShort: 2016-Sep-03
:END:

**** And I think with a training arc in a story, you're there, trudging through it with your characters, so that when they reach full power, it is super satisfying.
:PROPERTIES:
:Author: Dwood15
:Score: 2
:DateUnix: 1472865809.0
:DateShort: 2016-Sep-03
:END:


** Does anyone ever get tired of being a rationalist? Or, even less pretentiously, just having rationalist tendencies? Specifically I ask because of how some of the "magic" of life seems to be gone. I'm not talking depression or anything that severe but I feel like I've lost my belief in things like true love, the innate goodness of humanity, life having an overarching purpose, etc. because it seems so trivial and easy to break those concepts down into 1s and 0s (metaphorically speaking). Life has no purpose beyond the one we give it. Love is a series of biochemical reactions. Humans aren't innately good; we're innately nothing and shaped by our surroundings more than anything else.

I'm the type of person where I need to know the truth. It's almost compulsive. But I feel like I may have had an easier time being happy if I'd never stumbled across the rational path of thinking. But, even having come to that conclusion, I can't just turn it off. It's like someone pointing out a crack in a glass you thought was perfect. You just can't unsee it.

Am I making any sense or am I just being a classically whiny millennial?
:PROPERTIES:
:Author: Kishoto
:Score: 8
:DateUnix: 1472854106.0
:DateShort: 2016-Sep-03
:END:

*** That's sad. I corellate such feelings more with general depression, than with the rationalist tendencies.

You have to remember - just because you can explain love, take it apart, doesn't mean it's no longer a thing. A rainbow shouldn't stop being pretty just because you know it's the result of light hitting droplets of water in the air.

It seems like you have a tendency of only assigning value to mystical, unachievable things. I'd suggest trying to dig deeper into why that is. In the meantime; carpe diem!

p.s. sorry if this sounds condescending, or dismissive. I don't mean it so, but I spent 5 minutes on this and couldn't find a better way of conveying the idea.
:PROPERTIES:
:Author: Anderkent
:Score: 10
:DateUnix: 1472855807.0
:DateShort: 2016-Sep-03
:END:

**** It's not a binary thing. It's not like something has value or it doesn't. It's just the mystical sheen surrounding certain concepts has been brutally torn away and I regret their loss.

For example, the concept of "the one". That used to be a comfort to me, when I was younger. "Oh, Becky doesn't like me. But that's ok, the one is out there!"

Ha. No. I'm not pessimistic. I know there's more than enough women out there that I could find one to be happy with. But it's also possible that I never find one to be happy with. I don't say that to whine or complain; but my innate knowledge of that possibility dims my view on relationships quite a bit.
:PROPERTIES:
:Author: Kishoto
:Score: 8
:DateUnix: 1472856616.0
:DateShort: 2016-Sep-03
:END:

***** Isn't that just growing up, though? Yes, people get a bit disillusioned as they learn more about the world; and it takes work to reestablish the emotional valence of some ideas that used to be simple. But you can definitely still do it.

Taking your example, if you think about it a bit more, the fact that there isn't one soulmate that you have to wait for means you have a chance to actually make a successful relationship happen. You can work at it, rather than wait for it to happen to you. This, to me, is a positive thought.

I find that many concepts work in the same way. You lose some naive positivity, but in trade you find out more about how things really work, and how to turn that to your advantage.

Successful relationships have grown more impressive to me, rather than less, once I learned that they actually take work. If that's not the case for you, try to figure out why?

Of course sometimes you'll find out about something that you can't help at all. And that sucks, and getting over it can often be difficult. I have no advice there other than with time I've grown numb to the impossible to solve problems (their impossibility actually helping here, I feel, because it means I don't feel responsible at all); while the ones where I have hope of success have grown more important to me.

If it's just the loss of simplicity, of naive optimism, that you're mourning, - rather than any subject that you were naive about in particular - then I'm afraid I can't help you there. Sure, being naively happy and childish is cute. In children. And fictional characters that always succeed due to Manic Pixie Dream Girl plot armor.

But I don't envy it in adults.
:PROPERTIES:
:Author: Anderkent
:Score: 12
:DateUnix: 1472857393.0
:DateShort: 2016-Sep-03
:END:


***** u/gabbalis:
#+begin_quote
  For example, the concept of "the one". That used to be a comfort to me, when I was younger.
#+end_quote

Yeah, I think the thought of Neo coming to save us comforted us all when we were younger...
:PROPERTIES:
:Author: gabbalis
:Score: 5
:DateUnix: 1472949945.0
:DateShort: 2016-Sep-04
:END:

****** HA! Well fucking played sir. That gave me a laugh.
:PROPERTIES:
:Author: Kishoto
:Score: 1
:DateUnix: 1472951976.0
:DateShort: 2016-Sep-04
:END:


*** You are making sense!

You might not have heard of the [[https://wiki.lesswrong.com/wiki/Joy_in_the_Merely_Real][Sequence about that]].

Also, I have a relevant mini-rant regarding [[https://www.goodreads.com/quotes/66591-all-right-said-susan-i-m-not-stupid-you-re-saying-humans][this Terry Pratchett quote]], which I'm going to test out:

Sure, there are no atoms of justice or molecules of mercy. But there are no atoms of chairs or computers either, yet anyone claiming either of those to be a lie would be seen as delusional. There are real /arrangements of matter in the universe/ that fit your concepts of chairs and computers, just like there are real arrangements of matter in the universe that fit your concepts of justice-recognizing-and-improving-thing and mercy-recognizing-and-improving-thing. What difference does it make to their reality that the latter sets happen to exist in people's brains instead of in visible external objects?
:PROPERTIES:
:Author: b_sen
:Score: 5
:DateUnix: 1472870881.0
:DateShort: 2016-Sep-03
:END:


*** There are several (many?) stories I read that posit that the universe is cold and indifferent, or outright hostile and actively rooting against you, and that the only meaning that life has is the meaning you *choose* to give it.

Yes, we are shaped by our environment ... dashed to and fro, but we make the choices and we shape it (and the rest of us) in return.

As they say in the /African Queen/: Charlie Alnutt (trying to explain away his drinking): "... It's only human nature." Rose Sayer: "Nature, Mr. Allnut, is what we are put in this world to rise above."

If the idea of an uncaring (or hostile) universe doesn't strike you as inspiring, I recommend the "Welcome to Nightvale" podcast, or "Awake in the Night Land." I'm sure there are others.
:PROPERTIES:
:Author: TaoGaming
:Score: 5
:DateUnix: 1472877094.0
:DateShort: 2016-Sep-03
:END:


*** Just because you know how those things work doesn't mean they have to lose meaning for you. The only thing that has changed is your knowledge, after all. The things themselves remained unchanged when you learned how they work. If empathy and helping a person in pain felt awesome before, it still should! If loving someone felt amazing, knowing that it's a chemical reaction shouldn't lessen the feeling because nothing about love changed. Only you did.
:PROPERTIES:
:Author: Frommerman
:Score: 2
:DateUnix: 1472883301.0
:DateShort: 2016-Sep-03
:END:


*** Rationalism actually /convinced/ me of the innate goodness of humanity. If, in general, people were not fundamentally gentle, kind, and caring society would fall apart fast. The temporary power gained by even small betrayals is so out-of-proportion with the amount of effort required that if people were even slightly more selfish and unforgiving they'd be stabbing each other in the back all the time.

Sure, there are rare exceptions... and the obvious damage they do (and the largely undamaged state of the social fabric) makes it obvious how rare they must be.

No individual necessarily has an innate goodness, but humanity absolutely does.
:PROPERTIES:
:Author: Sparkwitch
:Score: 2
:DateUnix: 1472923152.0
:DateShort: 2016-Sep-03
:END:


*** It think it also bears noting, that I'm fairly sure that the lack of comforting lies like this never bothers someone who never had them to begin with. For instance I've heard some people who used to be religious bemoan the loss of their comforting beliefs, but people who never believed in such a thing never seem to have that.

I for one as someone who always implicitly assumed people were just a relatively insignificant part of a deterministic universe, always get confused when people (especially people were were never religious) bemoan these sorts of things.\\
I cannot really get what people would even mean when talking about life having meaning unless they're religious and they believe their life has a literal plan put down by some intelligence. In that case I can only imagine that would be comforting, if you think that that would guarantee your life's plan will turn out good long term.\\
Many other cases are even more confusing for me, for instance I can't imagine what a "belief in the goodness of humanity" would even mean unless you predict some difference in observed behavior. If a belief doesn't actually lead you to have different expectations I /literally/ cannot conceive of what it would mean.
:PROPERTIES:
:Author: vakusdrake
:Score: 1
:DateUnix: 1472940608.0
:DateShort: 2016-Sep-04
:END:

**** The sentiment "You can't miss what you've never had" is a very true one.
:PROPERTIES:
:Author: Kishoto
:Score: 3
:DateUnix: 1472949449.0
:DateShort: 2016-Sep-04
:END:


** I've skimmed a blog a while ago that discussed dating, and in particular one post I remember was it analysed the consequences of choosing particular okcupid questions as either important or not. I couldn't find the post again, and since it was probably coming either from [[/r/rational]], rationalist-adjacent facebook friends, or rationalist tubmlr, I was hoping someone would know what I'm talking about and could find it.

The particular trick I remember was a way of compressing your 'matching %' range from 80-100 to 90+-100 (so that the relative order of matches is the same, but the numbers are higher), by treating some questions as less or more important. But I can't really remember the details.
:PROPERTIES:
:Author: Anderkent
:Score: 6
:DateUnix: 1472855986.0
:DateShort: 2016-Sep-03
:END:

*** Was it [[https://putanumonit.com/2016/02/03/015-dating_1/][this]] one? Or more specifically, the [[https://putanumonit.com/2016/02/10/017-dating_2/][1.5]] section where it talks about match percentage?
:PROPERTIES:
:Author: somerandomguy2008
:Score: 4
:DateUnix: 1472921015.0
:DateShort: 2016-Sep-03
:END:

**** It was! I definitely remember the upside down underwear stripper pole picture :P

Alas it doesn't seem that useful on a more detailed read, but thanks for finding it.
:PROPERTIES:
:Author: Anderkent
:Score: 2
:DateUnix: 1473332858.0
:DateShort: 2016-Sep-08
:END:


** IT'S ROBOT FIGHTING TIME.

Who here watched Battlebots FInale? What do you think?
:PROPERTIES:
:Author: hoja_nasredin
:Score: 3
:DateUnix: 1472829749.0
:DateShort: 2016-Sep-02
:END:


** This week, CPGrey released a video where he extolled the virtues of self-driving cars and how they'd make navigating traffic better for all of us. While I agree completely, at one point he suggested banning human drivers from the road, an idea to which I instinctively react to with horror. Not because I'm afraid of robots, but because my values include human autonomy.

I think that forcing a person to use an autopilot instead of giving them the option to do so is a violation of a person's rights. I'm all for incentivizing people to use autopilot, including making manual operation more difficult, but for human society to decide that humans cannot be trusted to do something for themselves horrifies me. Does anyone else feel this way?
:PROPERTIES:
:Author: trekie140
:Score: 8
:DateUnix: 1472831424.0
:DateShort: 2016-Sep-02
:END:

*** u/sir_pirriplin:
#+begin_quote
  for human society to decide that humans cannot be trusted to do something for themselves horrifies me. Does anyone else feel this way?
#+end_quote

That sounds like status quo bias. Humans already cannot be trusted to do all sort of things, but this particular thing horrifies you because you are used to it.
:PROPERTIES:
:Author: sir_pirriplin
:Score: 21
:DateUnix: 1472833557.0
:DateShort: 2016-Sep-02
:END:

**** No, it horrifies me because it applies universally. This isn't a matter of doing work better, like with automation or assistance in the workplace, but something individuals do of their own volition with their own property. Their actions effect other people, of course, but I value a person's control over their own property and would consider a law that forbids them from directly controlling their property as a consequence of owning it to conflict with that value.
:PROPERTIES:
:Author: trekie140
:Score: 6
:DateUnix: 1472834928.0
:DateShort: 2016-Sep-02
:END:

***** Maybe the robots are a red herring.

Suppose you don't like your house and want to build a nicer one on the same terrain, which is also yours. Are you allowed to just blow it up with your own explosives?

It's your property and your life on the line, but most people would agree you should hire a (human) professional. Do you agree with that? Is it the robot part or the freedom part that bothers you the most?
:PROPERTIES:
:Author: sir_pirriplin
:Score: 12
:DateUnix: 1472836069.0
:DateShort: 2016-Sep-02
:END:

****** The freedom part. I love robotic drivers and will encourage people to use them at every opportunity, I just think it's wrong to force people to. In the example you give, I am completely okay with regulations surrounding how the demolition is carried out like permits, but I equate the banning of human drivers to forbidding the property owner to have any role in the demolition beyond requesting it.
:PROPERTIES:
:Author: trekie140
:Score: 3
:DateUnix: 1472844527.0
:DateShort: 2016-Sep-02
:END:

******* What about the ban keeping intoxicated people from driving?
:PROPERTIES:
:Author: callmebrotherg
:Score: 6
:DateUnix: 1472853020.0
:DateShort: 2016-Sep-03
:END:

******** I have no objection to that, nor the ban on blind people. Their condition impairs their ability to drive.
:PROPERTIES:
:Author: trekie140
:Score: 0
:DateUnix: 1472853684.0
:DateShort: 2016-Sep-03
:END:

********* How about this argument, then:

By comparison to robodrivers, humans /are/ impaired. We get distracted. We sing to the radio and close our eyes. We pay too much attention to our phones. Humans just aren't good at driving! It's not something we're even close to optimized are.

So if you're ok with banning impaired drivers, why are you not ok with applying the same logic to objectively impaired (by comparison) humans?
:PROPERTIES:
:Author: Frommerman
:Score: 13
:DateUnix: 1472856303.0
:DateShort: 2016-Sep-03
:END:

********** I predict that with the rise of self-driving cars, the requirements that one has to meet to get a driving license would dramatically rise, too. Even though a baseline human is impaired as a driver compared to a self-driving car, there /are/ extremely well-trained professionals. No need to ban /every/ human. Just the ones that are too dangerous.
:PROPERTIES:
:Author: gvsmirnov
:Score: 3
:DateUnix: 1472932188.0
:DateShort: 2016-Sep-04
:END:

*********** That seems reasonable.
:PROPERTIES:
:Author: Frommerman
:Score: 1
:DateUnix: 1472937552.0
:DateShort: 2016-Sep-04
:END:


********** I'm tired of explaining the same thing over and over, read my other responses and reply to them if you want.
:PROPERTIES:
:Author: trekie140
:Score: -5
:DateUnix: 1472857106.0
:DateShort: 2016-Sep-03
:END:


********* But /all/ humans have an impaired condition, relative to sufficiently advanced AI. This impaired condition already causes deaths, but there would be much more risk if you had a human-operated vehicle on an AI-dominated highway, because these roads would likely be faster than what we see now.
:PROPERTIES:
:Author: callmebrotherg
:Score: 6
:DateUnix: 1472860266.0
:DateShort: 2016-Sep-03
:END:

********** I agree, but I don't want that to come at the cost of the individual's right to choose. I value human autonomy too much to deny it, even if someone may make a bad choice. I oppose smoking bans for the same reason, even if I think smoking is a horrible thing that I would never do and discourage everyone from doing.

Just because I think robots should replace human drivers doesn't mean I think they /must/. The impaired condition you speak of is the fact that the user is human. If a human is forced to surrender their freedom of choice without their permission, I consider that a violation of my rights even if they would grant that permission.
:PROPERTIES:
:Author: trekie140
:Score: 1
:DateUnix: 1472866317.0
:DateShort: 2016-Sep-03
:END:

*********** It's fine by me if you value your driving experience more than lives of some strangers, but you /are/ aware that there is a trade-off involved, right?
:PROPERTIES:
:Author: AugSphere
:Score: 3
:DateUnix: 1472899156.0
:DateShort: 2016-Sep-03
:END:

************ Yes I am, and I have no intention of placing others at risk for the sake of that experience. I still think self-driving cars are better drivers than humans, I just think humans have a right to choose whether they want to drive their car even if there is a trade off.
:PROPERTIES:
:Author: trekie140
:Score: 1
:DateUnix: 1472912687.0
:DateShort: 2016-Sep-03
:END:

************* The problem is that you're not only trading off your own life, but the lives of other people as well, and those people have a right to stay alive while in transit. Transport accidents are one of the major causes of death and it's hard to argue that people have a right to choose to drive on public roads when there is a much safer feasible alternative.

In the end, people will not be deprived of the ability to drive cars manually, it's just going to be confined to venues where all the participants are willing to take the risk, akin to track days.
:PROPERTIES:
:Author: AugSphere
:Score: 3
:DateUnix: 1472915918.0
:DateShort: 2016-Sep-03
:END:

************** I still consider that a violation of a person's rights. Smoking zones work because the behavior it regulates is recreational and can be performed anywhere, but restrictions on roads means depriving someone of transportation infrastructure. I'm okay with regulating the behavior of people that use public infrastructure because the property is owned by the community, but cars are owned by their drivers.I will happily restrict how a person is allowed to use to use their property, but not what they're allowed to use it for (zoning laws are a different situation).

Using the example of the building demolition, I think it is entirely appropriate to require permits, licenses, and public notifications to perform the demolition, but you can still do it yourself if you choose to go through all that hassle. You are not legally required to place control of your property into someone else's hands, it's just easier if you do. It's poses risk to yourself and others and you are liable for anything that goes wrong, but I still believe you have a right to make that decision even if I disagree with it. I would discourage the decision, but never deny it.
:PROPERTIES:
:Author: trekie140
:Score: 1
:DateUnix: 1472920665.0
:DateShort: 2016-Sep-03
:END:

*************** u/AugSphere:
#+begin_quote
  Restrictions on roads means depriving someone of transportation infrastructure.
#+end_quote

That's not necessarily true though. Hypothetically speaking, we could imagine some scheme that would subsidise the installation of self-driving hardware, in which case it would really come down to some people being stubborn and fucking things up for everyone else.

I don't think modern democratic governments will be capable of just outright banning people from driving on the public roads for long while yet. We'll be probably dealing with larger issues by the time your worry actually starts being relevant.
:PROPERTIES:
:Author: AugSphere
:Score: 3
:DateUnix: 1472921774.0
:DateShort: 2016-Sep-03
:END:


***** Things individuals do with their own property aren't inviolate currently, though. They're subject to restrictions. Maybe your values dislike those restrictions too, but if it's not a universal absolute, that's not quite addressing the potential of status quo bias. Can you think of an exception that you're okay with? Something you agree humans shouldn't be allowed to do with their own property?

Also, what if people were still allowed to drive their own cars but had 100% liability for any accidents and harm they're involved in. Would you be okay with that?
:PROPERTIES:
:Author: DaystarEld
:Score: 3
:DateUnix: 1472836123.0
:DateShort: 2016-Sep-02
:END:

****** That is a scenario I would be completely fine with, since it still permits someone to drive their car if they choose to, it just attaches potential consequences to the decision. I am okay with, and even desire, regulations on what people do with their property. I want people to have the option, but the law should regulate how they do it.
:PROPERTIES:
:Author: trekie140
:Score: 5
:DateUnix: 1472844804.0
:DateShort: 2016-Sep-03
:END:

******* By that logic, you shouldn't care if something is illegal then. Laws aren't psychic shackles; they're rules with consequences. Truly, you can break any law you like, if you're comfortable with the potential consequences. Potentially going to prison is just as much a consequence as potentially killing yourself on an AI highway.

You're equating human laws to control over human autonomy, which isn't strictly the case. If you're going to stick to your guns and say that you're okay with this restriction and that risk, you eventually get to a point where the potential risks and repercussions of your valued autonomy are equivalent to ignoring the laws present and risking jail time.
:PROPERTIES:
:Author: Kishoto
:Score: 0
:DateUnix: 1473006372.0
:DateShort: 2016-Sep-04
:END:


*** Assuming an ideal system where autopilot not only drives more-or-less perfectly (which is already the case) but is also secure against infiltration, then I agree entirely with Grey. As it stands, however, self-driving cars only defense, as far as I'm aware anyway, is that they are so rare that they are ineffective as a means of manipulating or killing people.
:PROPERTIES:
:Author: Aabcehmu112358
:Score: 8
:DateUnix: 1472832278.0
:DateShort: 2016-Sep-02
:END:

**** I really do agree that the world would be better if we only used self-driving cars, what I object to is forcing people to use them. Even if robots are better drivers than humans ever will be, the idea that humans should be forbidden to drive conflicts with my values. Not because of potential unintended consequences, but because I believe that humans have a right to choose to do it themselves even if a robot would do it better.
:PROPERTIES:
:Author: trekie140
:Score: 1
:DateUnix: 1472834006.0
:DateShort: 2016-Sep-02
:END:

***** You also can't drive 120 mph on the road. In both cases, you are being restricted on what you can do with your own property on public roads.

I doubt that many would object to people using private racetracks with manual driving.
:PROPERTIES:
:Author: electrace
:Score: 7
:DateUnix: 1472837141.0
:DateShort: 2016-Sep-02
:END:


***** I guess, I just feel like I don't consider 'the right to recklessly endanger other people's lives when there is a freely accessible alternative' is a particularly valuable one. If the autopilot really is secure and self-contained, then the 'driver' is still the only one controlling destinations and paths, so it's not like people would be limited in where they can go.
:PROPERTIES:
:Author: Aabcehmu112358
:Score: 7
:DateUnix: 1472842840.0
:DateShort: 2016-Sep-02
:END:


***** I imagine people will always be allowed to drive on private property and designated tracks.

But I don't think people should have the rights to drive their cars on public roads when there's clearly a superior system in place. It's a matter of public safety, not an inalienable right.

It's different when the only life you're endangering is your own, but on a public road one person driving recklessly can endanger the lives of a dozen others or more.
:PROPERTIES:
:Author: Fresh_C
:Score: 4
:DateUnix: 1472842922.0
:DateShort: 2016-Sep-02
:END:

****** Correct, but smoking is also endangers people besides the person making the choice and we don't ban that. Instead, we restrict how a person is allowed to smoke to minimize the risk and discourage the activity. I believe smoking is an objectively bad thing, but I also believe I do not have the right to deny someone the choice of whether to smoke. It's a bad choice, but it's their choice. I feel the exact same way about self-driving cars.
:PROPERTIES:
:Author: trekie140
:Score: 2
:DateUnix: 1472845672.0
:DateShort: 2016-Sep-03
:END:

******* As I said, I don't think driving will ever be completely illegal.

Just like smoking it will only be legal in certain places where the danger to other people is minimal and/or mutually accepted.

I sincerely doubt there will ever be a ban on driving on private property, and I'm sure there will be lots of driving tracks which open up to accommodate people who still want to drive.

I don't think it will ever completely disappear simply because so many people treat cars as a hobby. But I do think roads where people are allowed to drive will become the exception, not the rule. And I think that's a good thing.
:PROPERTIES:
:Author: Fresh_C
:Score: 2
:DateUnix: 1472846451.0
:DateShort: 2016-Sep-03
:END:


******* Isn't the equivalent of the US's current policy on smoking with regards to human driving essentially "You are only allowed to drive on private roads" though?
:PROPERTIES:
:Author: Aabcehmu112358
:Score: 0
:DateUnix: 1472846143.0
:DateShort: 2016-Sep-03
:END:

******** I don't think so, and you can't directly compare the /how/ of regulating it since people smoke for different reasons than they drive and in different situations.
:PROPERTIES:
:Author: trekie140
:Score: 2
:DateUnix: 1472851417.0
:DateShort: 2016-Sep-03
:END:

********* Well, then comparing them at all seems like a non-starter, doesn't it?
:PROPERTIES:
:Author: Aabcehmu112358
:Score: 1
:DateUnix: 1472852522.0
:DateShort: 2016-Sep-03
:END:


*** Where do you draw the line?

Is it okay to ban human driving on certain roads? In certain municipalities? For drivers with less than perfect vision or hearing? How about drivers above or below particular ages? Drivers with multiple DUIs?

Is it fair to ban human driving above particular speeds? Is autonomy restricted if drivers are made to stop rather than simply yield at red lights?
:PROPERTIES:
:Author: Sparkwitch
:Score: 5
:DateUnix: 1472832528.0
:DateShort: 2016-Sep-02
:END:

**** I think differentiating the ban based on geography would be economically inefficient and generally unfair. I would be okay with compulsory robot driving for people who already have legal restrictions on their license since those restrictions are based on personal ability or history of behavior.

While I suppose having separate laws for human and robot drivers would work, I would not prefer it since it seems discriminatory. I want individuals to choose to let robots drive because they're better drivers, or its just easier to do, not because the law directly encourages it.
:PROPERTIES:
:Author: trekie140
:Score: 1
:DateUnix: 1472835761.0
:DateShort: 2016-Sep-02
:END:

***** We're assuming a world in which robots are better at driving than people, yes? Would not restrictions on human's driving in that case be based on "personal ability"? All humans necessarily includes /each/ human.

Alternately, if it's not fair to ban humans from driving in order to save lives, improve efficiency, and save money... why is it fair to ban humans with significant vision impairment in order to do the same thing?

Would you also rather legally blind people choose voluntarily not to drive?

Or speed limits. Should people be allowed to choose voluntarily to remain below particular speeds in residential areas because they understand how much safer it is?
:PROPERTIES:
:Author: Sparkwitch
:Score: 4
:DateUnix: 1472836931.0
:DateShort: 2016-Sep-02
:END:

****** I have no desire to overturn laws that are already in place to regulate how we drive, I am opposed to the notion that humans should not be allowed to drive themselves at all.
:PROPERTIES:
:Author: trekie140
:Score: 1
:DateUnix: 1472845928.0
:DateShort: 2016-Sep-03
:END:

******* That's what I was asking earlier, though. Where do you draw the line?

Is it okay if people are only banned from driving on highways, now assigned as special high speed "autopilot-only"? Is it okay if people can only drive themselves at human walking speeds? Is it okay if people can only drive themselves if they wear special protective clothing and paint their car bright orange with hazard signs and lights on it?

Is it okay if the autopilot is allowed to override their driving when it notices an unsafe situation?
:PROPERTIES:
:Author: Sparkwitch
:Score: 1
:DateUnix: 1472848249.0
:DateShort: 2016-Sep-03
:END:

******** I don't want any of those to happen, though the last one I'm more open to, but I can't anticipate every law that may be proposed, or the context it is proposed in, so I'm not going to draw a line in the sand. I have negative feelings toward the suggestion of banning human drivers from any road, but that could very well change if the context does.
:PROPERTIES:
:Author: trekie140
:Score: 1
:DateUnix: 1472852496.0
:DateShort: 2016-Sep-03
:END:


*** I can understand your sentiment, however at one point, the human has to leave the driver's seat behind and become a passenger. This is probably in the next 50-75 years, however, so I expect a much more effected Self-Driving car system by then than we have now.

My second concern, however, is people getting all hot-and-heavy with networking in cars, and their security. As someone who has followed Self-Driving cars steadily, as well as IT security, I am terrified of a rogue state or FBI guy not liking an activists opinion and then slamming the car into a tree or highway traffic at 70+ mph.
:PROPERTIES:
:Author: Dwood15
:Score: 3
:DateUnix: 1472847427.0
:DateShort: 2016-Sep-03
:END:

**** I'm only concerned with the ethics of banning human drivers since I am confident in the capabilities of self driving cars and anticipate security measures to be sufficient by the time they become popular.
:PROPERTIES:
:Author: trekie140
:Score: 1
:DateUnix: 1472851642.0
:DateShort: 2016-Sep-03
:END:


*** I read some of the replies. I will be the personal holdout. I machine some of the parts to the cars I have built. I will drive the cars I build and when someone decides to remove my ability to drive using a piece of paper. I will drive whichever car I still have into the people that agreed on the paper. I am irrational. I am human.
:PROPERTIES:
:Author: Rat-races-are-traps
:Score: 0
:DateUnix: 1472870591.0
:DateShort: 2016-Sep-03
:END:


** *Any spreadsheet jockeys who can help?*

I've had a thought which might help with some of my writing, but I don't quite have the chops to work out the details. In short, I want to try comparing how long it takes for a billion person-years to pass, in various eras, and with various assumptions about ems and computing-capacity. Anyone here who might be able to help me draw a few graphs and charts?
:PROPERTIES:
:Author: DataPacRat
:Score: 3
:DateUnix: 1472845148.0
:DateShort: 2016-Sep-03
:END:

*** I just slapped [[https://docs.google.com/spreadsheets/d/11al0Ly97GydAySG9YQ2D9oKD9MyL95zw79FoLNKZyC8/edit?usp=sharing][this]] together in a few minutes, I'm not sure what features you're looking for.

In short, I took the UN population estimates for 2020-2100, and assumed that people are awake for 0.66 of each day. For Ems, I assumed that they start at 1000 population and 3x speed, and double in population and increase in speed by 20% every five years. (These numbers are easy to alter). Lastly, you add together (people * people time rate + Ems * Em time rate) and divide a billion by that to get how long a billion person-years takes.
:PROPERTIES:
:Author: ulyssessword
:Score: 3
:DateUnix: 1472847512.0
:DateShort: 2016-Sep-03
:END:

**** I have some initial estimates of the number of em-years per year on page 37 of [[https://docs.google.com/document/d/1nRSRWbAqtC48rPv5NG6kzggL3HXSJ1O93jFn3fgu0Rs/edit][this Gdoc]] ; I'm trying to get some intuitive feel for how long it would take for ems, in this scenario, to have lived through more person-years than, say, biological humanity has since 50,000 BC. (Or 1 AD, or some other distant-past moment.) And then how long it would take for that amount of mind-years to be gone through yet again.

Put another way, I'm trying to quantify just how weird em culture will get, and how quickly, from a bio-human point of view (or the PoV of a not-very-fast em). Maybe 'person-years' is a bad unit of measure here; but it's the most measurable approximation I can think of for 'amount of valuable contributions to society'.

Short version of the above - how ridiculous does the graph get if you alter the numbers to match the GDoc I linked? :)
:PROPERTIES:
:Author: DataPacRat
:Score: 1
:DateUnix: 1472848661.0
:DateShort: 2016-Sep-03
:END:

***** [[https://docs.google.com/spreadsheets/d/1EUNyIGsNp4VfQgZiVAcygF-0PJJKYxRquoqevKITLs8/edit?usp=sharing][Here]] is a new spreadsheet, that compares Billion-Person-years accumulated over each five years, as well as a cumulative total. the human population numbers are a bit off because I was just eyeballing a graph, and the calculations aren't quite correct, but it should give a good idea.

Tl;DR: The Em population will have as much Em culture as human culture in their history by ~2062.
:PROPERTIES:
:Author: ulyssessword
:Score: 2
:DateUnix: 1472853517.0
:DateShort: 2016-Sep-03
:END:

****** I've done some further tweaking to the spreadsheet you created, and have ended up with [[https://docs.google.com/spreadsheets/d/1CZ565cTZh0upkiE3aeHqOVxybI38Fwn6zSpPT2YVGGY/edit#gid=0][this]]. It still has a few simplifying assumptions, such as that ems don't influence the manufacturing rate of CPUs, but I figured out how to set it up to handle a few basic tweakable parameters, such as the date ems become possible, how many CPU cycles an em requires, and such.

I'll admit that I'm not sure how to let anyone else toy with those parameters, short of making their own copy of the spreadsheet, but I feel it's been worth the time. :)

Anyone reading this have any thoughts on further possible improvements?
:PROPERTIES:
:Author: DataPacRat
:Score: 2
:DateUnix: 1473038754.0
:DateShort: 2016-Sep-05
:END:


****** Thank you /very/ much. That sheet shows exactly what I wanted to see, in enough detail that I can see a few things I didn't know that I wanted to. :)
:PROPERTIES:
:Author: DataPacRat
:Score: 1
:DateUnix: 1472858208.0
:DateShort: 2016-Sep-03
:END:


*** Ems?
:PROPERTIES:
:Author: Dwood15
:Score: 1
:DateUnix: 1472858360.0
:DateShort: 2016-Sep-03
:END:

**** [[https://wiki.lesswrong.com/wiki/Whole_brain_emulation][Ems]].
:PROPERTIES:
:Author: DataPacRat
:Score: 1
:DateUnix: 1472858660.0
:DateShort: 2016-Sep-03
:END:


** Is anyone here watching Mr Robot? I haven't made a main post about it because it's not text fiction, but I think it meets all of the criteria for rational. And beside that, it's fucking awesome. Great writing, great story, great acting, great cinematography, great music, great message.

It's kinda hard to talk about it without spoilers though.

(We have a very robotful discussion today!)
:PROPERTIES:
:Author: Polycephal_Lee
:Score: 2
:DateUnix: 1472837945.0
:DateShort: 2016-Sep-02
:END:

*** There is no requirements that top-level posts be only about text-based fiction. Video games, movies, art in any form really counts. It just so happens that the vast majority of rational work comes in text form (and a lot of it comes in fanfic form) but this is not a requirement at all.
:PROPERTIES:
:Author: blazinghand
:Score: 7
:DateUnix: 1472853343.0
:DateShort: 2016-Sep-03
:END:

**** Good to know!
:PROPERTIES:
:Author: Polycephal_Lee
:Score: 1
:DateUnix: 1472857867.0
:DateShort: 2016-Sep-03
:END:


*** Oh, good point! I find myself making predictions on what happens next, detecting foreshadowings and interesting moments. Although I am not convinced that it's solvable. For instance, [[#s][eps2.6_succ3ss0r.p12 spoiler]] would be very hard to predict. On the one hand, we know from [[#s][season 1 spoiler]] and the general lifestyle of Elliot is suggestive. But on the other hand, there is other evidence [[#s][eps2.2_init_1.asec spoiler]] that makes it much less predictable.

Actually, now that you've mentioned it, I found [[/r/MrRobot/]], which seems to have all I want.
:PROPERTIES:
:Author: gvsmirnov
:Score: 2
:DateUnix: 1472932802.0
:DateShort: 2016-Sep-04
:END:

**** Yeah, I highly suggest the sidebar links to the episode discussions. Someone predicted he was in jail/mental institution after episode 1 or 2.
:PROPERTIES:
:Author: Polycephal_Lee
:Score: 1
:DateUnix: 1472974102.0
:DateShort: 2016-Sep-04
:END:


** I am unsure if it is appropriate to submit something for the Underground challenge that really is not remotely rational. It's not /irrational/ either, it's just a short (~600 words) cutesy drabble that I wrote with the challenge in mind.
:PROPERTIES:
:Author: Cariyaga
:Score: 1
:DateUnix: 1472895414.0
:DateShort: 2016-Sep-03
:END:

*** Go ahead! Worst-case only I vote for it :)
:PROPERTIES:
:Author: PeridexisErrant
:Score: 2
:DateUnix: 1472899506.0
:DateShort: 2016-Sep-03
:END:

**** Alright, I'll pester some friends to look it over and then I'll post it.
:PROPERTIES:
:Author: Cariyaga
:Score: 1
:DateUnix: 1472945339.0
:DateShort: 2016-Sep-04
:END:
