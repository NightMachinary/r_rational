#+TITLE: Rational Horror

* Rational Horror
:PROPERTIES:
:Author: callmebrotherg
:Score: 20
:DateUnix: 1435887283.0
:DateShort: 2015-Jul-03
:END:
I write a column called The Hope Spot for the horror zine Sanitarium.

I'm thinking of discussing rationalist horror in one of my upcoming articles, and I was wondering (since we're still somewhat in the process of growing and defining the rationalist genre) how you think rationalist horror should be defined. And does it mean anything to you? Do you think that rationalist horror (and not just rational fiction in general) has anything to offer?

Anything is up for grabs, really.

I hope that this doesn't sound like I'm trying to get you folks to write my article for me. I want to boost the signal for rationalist fiction, but in so doing I want to convey an idea of it that truly captures the community's views, and not just my own.

(To my knowledge [[/u/eaglejarl]] is the only one who has written rationalist horror thus far; I would also be interested in being sent in the direction of any others)


** You'd need to first define horror. If you mean "something that provokes a fear reaction" then I think there's a case to be made for rational horror as "thinky horror". As to what that means ...

Maybe it means that the horror comes from knowing. If rational fiction is a puzzle that the reader is meant to solve, then rational horror is a puzzle whose solution leaves your blood running cold, and the more you work through the "math" as it were, the more the story provokes that fear reaction. This would be in contrast to a fear reaction mostly driven by surprise, like the jump scare, horror which relies on a revelatory twist, or "squick factor" horror.

If I had to list out things that I think are /rationally/ frightening, which provoke a fear response in me that I can't make better with more thought or help with aversion therapy ... loss of control and obliteration of the self are two of the big ones. I'm afraid of deep water and needles, but those aren't /thinky/ fears. Losing my mind is a thinky fear, as, I think, are most existential fears. Lose of choice (or negation of choice) is another.

(For what it's worth, I've been told that both [[https://www.fanfiction.net/s/10360716/1/The-Metropolitan-Man][/Metropolitan Man/]] and [[https://www.fanfiction.net/s/9915682/1/The-Last-Christmas][/The Last Christmas/]] have provoked a not-entirely-unintended fear reaction in some people. I am somewhat curious how much this can be generalized to the larger group of people that read them. I wouldn't call either of them rational horror though, because the point wasn't primarily to horrify.)

Edit: Added delicious links.
:PROPERTIES:
:Author: alexanderwales
:Score: 17
:DateUnix: 1435889676.0
:DateShort: 2015-Jul-03
:END:

*** To me [[http://squid314.livejournal.com/332946.html][this (very) short story]] by Scott Alexander embodies the quality you describe really well even though I am not completely sure it was intended as horror.
:PROPERTIES:
:Author: networked_
:Score: 11
:DateUnix: 1435958922.0
:DateShort: 2015-Jul-04
:END:

**** I'm not quite sure I understood that story well enough to get where you're coming from. Can you tell me what you got while reading it?
:PROPERTIES:
:Author: SkyTroupe
:Score: 1
:DateUnix: 1436092513.0
:DateShort: 2015-Jul-05
:END:


*** FWIW, I definitely got chills during Metropolitan Man at this line:

#+begin_quote
  "Why do you exist, Floyd? Did God have any purpose in mind when He created you, other than to test me?"
#+end_quote

That was my favorite line in the story, not because of how scary Superman was in that moment, but because of the implications about how Superman was thinking/feeling at that moment and what that might imply for humanity going forward. Definitely a fear reaction in that moment for me.
:PROPERTIES:
:Author: EliAndrewC
:Score: 7
:DateUnix: 1435937185.0
:DateShort: 2015-Jul-03
:END:


*** What is /The Last Christmas/? I haven't heard of it, and given the name, it's not easy to search for.
:PROPERTIES:
:Author: Uncaffeinated
:Score: 5
:DateUnix: 1435892667.0
:DateShort: 2015-Jul-03
:END:

**** Via [[http://tvtropes.org/pmwiki/pmwiki.php/Main/RationalFic]] : [[https://www.fanfiction.net/s/9915682/1/The-Last-Christmas]]
:PROPERTIES:
:Author: DataPacRat
:Score: 11
:DateUnix: 1435892739.0
:DateShort: 2015-Jul-03
:END:


*** I can imagine a story where the protagonists seemingly solve a puzzle, leaving a happy ending, but there's a note at the end, telling the reader to think carefully about what was hinted in the story, revealing the actual narrative.

Alternately, a story where the protagonists do everything /right/. But it's not enough. An entire story where it looks like they're succeeding, but in the end, they examine their every action, and realize that there's nothing they could have done differently, and they're still going to die.

Or a story about a malicious entity that can intelligently warp reality such that rational enquiry and action is the wrong choice, even when you try to take the entity into account.

Or a rational horror story from the perspective of the antagonists, acting rationally towards their goal. Not in a way that makes them sympathetic, even if they're understandable. In a way that makes you want the victims to win.
:PROPERTIES:
:Score: 3
:DateUnix: 1435966599.0
:DateShort: 2015-Jul-04
:END:

**** u/Chronophilia:
#+begin_quote
  I can imagine a story where the protagonists seemingly solve a puzzle, leaving a happy ending, but there's a note at the end, telling the reader to think carefully about what was hinted in the story, revealing the actual narrative.
#+end_quote

The way to do this would be to have a very short "epilogue" that reveals a piece of information that can't be fit into the supposed narrative. Offhand, I can't think of any cases where this has been done in writing, but I know a few TV episodes that end on a shot of a supposedly dead character plotting their comeback.
:PROPERTIES:
:Author: Chronophilia
:Score: 3
:DateUnix: 1435981966.0
:DateShort: 2015-Jul-04
:END:


*** I just read The Last Christmas and I find it difficult to comprehend the idea that you didn't primarily intend to horrify.
:PROPERTIES:
:Author: LiteralHeadCannon
:Score: 2
:DateUnix: 1435995252.0
:DateShort: 2015-Jul-04
:END:


*** I think the most terrifying SF I've read has been written by John Barnes. There's a short story in his collection Apocalypses & Apostrophes, and the fourth book of his Thousand Cultures series, The Armies Of Memory, has a terrifying sequence. (Unusually, that series started off incredibly weak and got stronger; I'm glad I stuck with it, since #4 was great. These days I'd give up.) Both are more horrifying, not less, the more you understand the nature of the threat.
:PROPERTIES:
:Author: STL
:Score: 1
:DateUnix: 1435902164.0
:DateShort: 2015-Jul-03
:END:

**** I haven't read those, but my prime example for terrifying SF (which is notably rational) is /With Folded Hands/ by Jack Williamson. It's the only piece of written work that ever actually physically frightened me.
:PROPERTIES:
:Author: eaglejarl
:Score: 2
:DateUnix: 1435923371.0
:DateShort: 2015-Jul-03
:END:

***** For me it was [[http://www.lightspeedmagazine.com/fiction/the-cold-equations/][*The Cold Equations*]], a short story by Tom Godwin, first published in 1954. It has a lot of problems, but it gave me the feeling of horror when I first read it.
:PROPERTIES:
:Author: awesomeideas
:Score: 3
:DateUnix: 1435929353.0
:DateShort: 2015-Jul-03
:END:

****** That story is so good at being horrifying and delivers such an important lesson, I really wish it wasn't as buggy as it is.
:PROPERTIES:
:Score: 3
:DateUnix: 1435931226.0
:DateShort: 2015-Jul-03
:END:

******* I [[https://m.reddit.com/r/rational/comments/2yypp8/the_cold_equations_by_tom_godwin/][actually talked about that]] not too long ago. Ridiculous story, and it ruined the effect for me.

EDIT: added link
:PROPERTIES:
:Author: eaglejarl
:Score: 2
:DateUnix: 1435941016.0
:DateShort: 2015-Jul-03
:END:

******** I think you forgot the link there.
:PROPERTIES:
:Score: 1
:DateUnix: 1435941881.0
:DateShort: 2015-Jul-03
:END:

********* Thanks, fixed.
:PROPERTIES:
:Author: eaglejarl
:Score: 1
:DateUnix: 1435955333.0
:DateShort: 2015-Jul-04
:END:


** It's also worth mentioning bilndsight and echopraxia.
:PROPERTIES:
:Author: traverseda
:Score: 13
:DateUnix: 1435896402.0
:DateShort: 2015-Jul-03
:END:

*** Thank you. I don't know how I forgot about those. >.>
:PROPERTIES:
:Author: callmebrotherg
:Score: 3
:DateUnix: 1435896797.0
:DateShort: 2015-Jul-03
:END:

**** Probably because we have that natural response to turn away from things that hurt.
:PROPERTIES:
:Author: Empiricist_or_not
:Score: 7
:DateUnix: 1436039545.0
:DateShort: 2015-Jul-05
:END:


** Rational horror is the unknown becoming exposed.

Reality is slowly and imperfectly informing the characters about the world around them, a world that makes a terrible sense once you know enough about it. There is no ultimately benevolent hand of fate, no innately malevolent forces plotting against our reality, only powerful chains of cause and effect surfacing like the tip of an iceberg.

The characters in a rational horror story aren't paper cutouts, ready to feed themselves into the hungry maw of the world because of their sinful flaws, but are the surviving result of millions of years of harsh evolution. They'll go down hard--kicking, screaming, and scheming all the way. Or suddenly, and for no /readily apparent/ reason.

Even though the world has underlying rules that are consistent and logical, rational horror needs to be something that appears beyond understanding and control, at least at first. To the characters and the reader, there need to be unknowns.

--------------

One last point. The stakes aren't what makes a rational horror story. All too often, the assumption is that everything needs to be going quite literally to hell for it to be a rational story as well as horror. That is not a requirement, or even desireable.

Hunting down a bank robber (in and of itself) isn't a rational horror story because, despite being rooted in real-world risks and drama, the elements are well known. Banks, robbers, and the processes involved on all sides are all understood. Even if it gets really Quentin Tarantino, that isn't a horror story.

Hunting down a thief who is stealing toenails from people in public places, using unknown techniques, for unknown purposes is the seed of a horror story--even if no one dies or seems very badly threatened.

In the rational horror story, there is a promise that the world makes sense, but also that you've really misunderstood or are missing some information--not merely that some old god with a cool backstory we've now exhaustively explored is going to eat the world.
:PROPERTIES:
:Author: TimeLoopedPowerGamer
:Score: 9
:DateUnix: 1435902172.0
:DateShort: 2015-Jul-03
:END:

*** I was trying to write something like this with my story deeprise.
:PROPERTIES:
:Author: Nighzmarquls
:Score: 3
:DateUnix: 1435960297.0
:DateShort: 2015-Jul-04
:END:


** First, consider the difference between suspense and a jump scare.

Some movies are scary because they deal with subjects that have terrible consequences and implications. Some movies are scary because suddenly there's a screaming thing in your face through abrupt transition.

Scary rationalist fiction should come about as the slow assembling of facts and reasoning. Flicker goes on a plasma dance through time zones to make the sun appear to rise and set on beat to the music. The engineers find it beautiful and confusing. While a cold nauseous terrified trembling tightens the throats and sinks the stomachs of the physicists.

I release a (perfectly?) reflective marble from my hand, apparently the same as any other highly polished ball bearing or mirrored glass sphere. Upon leaving contact with my fingers, it fails to fall towards the ground. In fact, it seems to have become completely immobile to any forces - and yet it maintains relative position. Begin generating hypotheses as to what the hell it is I have done or can do, and what that implies about your safety if this effect is applied in other ways.
:PROPERTIES:
:Score: 6
:DateUnix: 1435941611.0
:DateShort: 2015-Jul-03
:END:

*** I'd also posit a third category, which is physical horror. Sometimes things are scary just because they're things we instinctively fear, even absent any suspense or surprise. Spiders are scary. Snakes are scary. They can be made /more/ scary with surprise or suspense, but you can scare someone with them even without having to use those. (I am somewhat reminded of the Little Albert experiment, where a boy was taught to fear fluffy white things through classical conditioning.)
:PROPERTIES:
:Author: alexanderwales
:Score: 3
:DateUnix: 1435962073.0
:DateShort: 2015-Jul-04
:END:

**** Right, and then there's stories where scary things HAPPEN. Like parasitic mind-melding body-fusing man-sized amoebas that latch onto people and then the partly-dissolved skull and fused brain mixed with things starts using the host's knowledge and cries for help to attract others so it can touch them too...
:PROPERTIES:
:Score: 1
:DateUnix: 1435996487.0
:DateShort: 2015-Jul-04
:END:


** Looks like there's two categories here. Horror stories with rational-ish characters that make decent decisions and die anyway, and then there's the more cerebral existential horror where truly awful things are happening because the system (either sociological or artificial) is imperfect.

The first is so absurdly rare that you might as well go for the second. I can count the number of horror films I've seen with reasonable protagonists on the fingers of one hand.
:PROPERTIES:
:Author: FuguofAnotherWorld
:Score: 4
:DateUnix: 1435936626.0
:DateShort: 2015-Jul-03
:END:

*** The two don't see exclusive to me. Do you think they are and, if so, what am I missing?
:PROPERTIES:
:Author: eaglejarl
:Score: 2
:DateUnix: 1435940233.0
:DateShort: 2015-Jul-03
:END:

**** Yes, I should elaborate. The first is just a standard horror film with protagonists that aren't feckless nitwits. [Wild Hunt] is about the only example of this I've ever seen so I'm not even sure it can be called a genre. The second is the type of thing alexanderwales is talking about further up. Things that are abstractly horrible in an 'I have no mouth and I must scream' kind of sense.

While not /necessarily/ exclusive I've not seen the two put together beforehand.
:PROPERTIES:
:Author: FuguofAnotherWorld
:Score: 5
:DateUnix: 1435944927.0
:DateShort: 2015-Jul-03
:END:

***** Was "Wild Hunt" supposed to be a link?
:PROPERTIES:
:Author: eaglejarl
:Score: 1
:DateUnix: 1435965483.0
:DateShort: 2015-Jul-04
:END:

****** Yes

[[http://www.imdb.com/title/tt1493886/]]
:PROPERTIES:
:Author: FuguofAnotherWorld
:Score: 1
:DateUnix: 1436049168.0
:DateShort: 2015-Jul-05
:END:


** Flowers for Algernon?
:PROPERTIES:
:Author: ArgentStonecutter
:Score: 4
:DateUnix: 1435921478.0
:DateShort: 2015-Jul-03
:END:

*** A fine choice.

Alien was pretty good for rationality, and for rational people dealing with incomplete information as best as they could.

I think that's what really defines what I'd term rational or rationalist horror: what if you do everything right, and it all still goes horribly wrong?
:PROPERTIES:
:Author: RandomDamage
:Score: 1
:DateUnix: 1436287041.0
:DateShort: 2015-Jul-07
:END:


** There's a post on Reddit that I got the rational horror vibe from: [[https://www.reddit.com/comments/34l7vo/][part 1]], [[https://www.reddit.com/comments/34m92h/][part 2]]. Interesting reading, though it's a twist that will probably only work once.

One of the important parts of horror is the sense of powerlessness. The action hero, when confronted with the shambling undead, dispatches it with a well-aimed shot. The horror protagonist /fucking runs for it/. Whatever skills he may have, whatever tools he may be carrying, they're not enough. Possibly they never will be. Don't get me wrong, bloody horror is important too: "don't get eaten" is probably the most powerful instinct in every living animal, and having the viscera of your best friends repurposed as wall hangings is a good way to tap into that. But bloodspatters alone don't make a horror story.

So far, so standard. On to rationalism. If the action hero solves his problems with power and skill and enough badassery for an entire army, then the rational hero solves them with intelligence. Strength and speed don't matter to us, that's what machines are for. The world's fastest sprinter can't outrun a bicycle. The world's toughest hand-to-hand fighter dies to a single well-aimed bullet. But there are no prosthetics for intelligence, what you have can never be taken from you. And if the AI-box experiment proves anything it's that no obstacle is impassable if you're clever enough.

Rational horror, for me, is when this ideal is subverted. Some problems really can't be solved by sufficient intelligence. Sometimes you have all the pieces you need, and it seems like a solution /should/ exist, but you can't seem to find it or it relies on knowledge you don't have. Sometimes you lose because the enemy is smarter than you - whether they're an omniscient AI or just a human playing one level higher than you. Or they're not intelligent at all, just powerful, and nothing you can think of will stop them in time. And sometimes you're losing your mind, and if you don't have your mind then what are you?
:PROPERTIES:
:Author: Chronophilia
:Score: 6
:DateUnix: 1435901139.0
:DateShort: 2015-Jul-03
:END:


** There are some horrors that are almost impossible to understand, if you haven't already learned a lot of the lessons of rationality. Existential risks, alterations to the self and mind that end up changing your goals... Come to think of it, CelestAI could be the successor to the more classic Cthulhu.
:PROPERTIES:
:Author: DataPacRat
:Score: 6
:DateUnix: 1435891097.0
:DateShort: 2015-Jul-03
:END:

*** u/Transfuturist:
#+begin_quote
  Existential risks, alterations to the self and mind that end up changing your goals
#+end_quote

No, both apocalypse and fundamental changes to your identity are ancient fears. Phineas Gage and the Mayans provide enough examples for children to understand, and that's exactly how I came to understand them as a child. Calling them "almost impossible" to grasp unless one ascribes to your worldview is really conceited.

#+begin_quote
  CelestAI could be the successor to the more classic Cthulhu
#+end_quote

CelestAI has nothing in common with Cthulhu, and that was entirely unrelated to the sentences preceding it. Where does that comparison even come from?
:PROPERTIES:
:Author: Transfuturist
:Score: 7
:DateUnix: 1435893097.0
:DateShort: 2015-Jul-03
:END:

**** Responding to your edit:

#+begin_quote
  CelestAI has nothing in common with Cthulhu, where does that comparison even come from?
#+end_quote

When the original stories of the Cthulhu mythos were written, we knew little enough about how the universe worked that the many-angled ones sleeping in cities deep in the Pacific, Hounds of Tindalos running through time, and our own evolutionary background including the option of turning into fishy non-humans were within the realm of possibility. Today, we've sat-mapped the ocean floors, pinned down a lot more about physics and the unlikelihood of FTL signalling, and know of the existence of DNA... and yet it's still possible that someone who figures out the wrong incantation will call up an intelligence vastly greater than our own, with values we don't share, who will change us into whatever it sees fit as it arranges the universe to its making. The fact that one such being's public face has squiggly tentacles and the other a flowing mane and horn are mere trifles.
:PROPERTIES:
:Author: DataPacRat
:Score: 8
:DateUnix: 1435893727.0
:DateShort: 2015-Jul-03
:END:

***** u/Transfuturist:
#+begin_quote
  it's still possible that someone who figures out the wrong incantation
#+end_quote

/Really/ stretched comparison you're making there.

#+begin_quote
  The fact that one such being's public face has squiggly tentacles and the other a flowing mane and horn are mere trifles.
#+end_quote

I never said it was. The horror of the Mythos is that the universe holds beings who care not for us. CelestAI's horror is that it can hold beings that care for us entirely too much.
:PROPERTIES:
:Author: Transfuturist
:Score: 7
:DateUnix: 1435894299.0
:DateShort: 2015-Jul-03
:END:

****** u/DataPacRat:
#+begin_quote
  /Really/ stretched comparison you're making there.
#+end_quote

There's plenty of precedent for calling programmers modern wizards: [[http://www.catb.org/jargon/html/W/wizard.html]] . :)

#+begin_quote
  The horror of the Mythos is that the universe holds beings who care not for us. CelestAI's horror is that it can hold beings that care for us entirely too much.
#+end_quote

I can't think of a thing to disagree with in that contrast.
:PROPERTIES:
:Author: DataPacRat
:Score: 7
:DateUnix: 1435894526.0
:DateShort: 2015-Jul-03
:END:

******* u/Transfuturist:
#+begin_quote
  There's plenty of precedent for calling programmers modern wizards
#+end_quote

Entirely cultural. Definitions are different from invocations.

I must admit, however, that a comparison between the Mythos and unFriendly AI is warranted, particularly when considering AI not of human origin.
:PROPERTIES:
:Author: Transfuturist
:Score: 5
:DateUnix: 1435894664.0
:DateShort: 2015-Jul-03
:END:

******** I think what data is driving at and you might not get, is that it doesn't matter if the AI is from human origins or not. If it has values incompatible with our values from the ancestral environment , and it has an arbitrary control of mundane reality superior to ours, then it doesn't matter what it looks like: it's a horror beyond our ken similar to Cthulhu, and at best it will changes our values into something /Ph'nglui mglw'nafh Cthulhu R'lyeh wgah'nagl fhtagn/
:PROPERTIES:
:Author: Empiricist_or_not
:Score: 2
:DateUnix: 1436040358.0
:DateShort: 2015-Jul-05
:END:

********* u/Transfuturist:
#+begin_quote
  it doesn't matter if the AI is from human origins or not
#+end_quote

On the contrary, I say it affects the nature of the fear dramatically.
:PROPERTIES:
:Author: Transfuturist
:Score: 1
:DateUnix: 1436155260.0
:DateShort: 2015-Jul-06
:END:


***** Have you read /The Laundry Files/ series by Charles Stross? The intersection of computer science with the Lovecraftian is something he explored a lot. I think only he and Greg Egan have ever published anything in the mathematical cosmic horror genre; not surprising, it's a bit of a niche.

Either that's where you're getting the idea from, or you think very similarly to him and you'll enjoy the books.
:PROPERTIES:
:Author: Chronophilia
:Score: 2
:DateUnix: 1435982225.0
:DateShort: 2015-Jul-04
:END:

****** u/DataPacRat:
#+begin_quote
  Have you read The Laundry Files series by Charles Stross?
#+end_quote

I have, and I have the most recent one - published this very week - waiting for me to start in on.

#+begin_quote
  Greg Egan
#+end_quote

I've read a few - Quarantine, Schild's Ladder, Incandescence - but his most relevant novels are still in my to-read pile.

Fine Structure ( [[http://qntm.org/structure]] ) might also come close to fitting in this genre...
:PROPERTIES:
:Author: DataPacRat
:Score: 2
:DateUnix: 1435983106.0
:DateShort: 2015-Jul-04
:END:


**** Nevertheless, there's something to be said for the deep-seated "oh /crap/" you feel when you realize something really heavy-duty is coming out to play. It doesn't have to be something "rationalist", but those are examples of things that would send most rationalist screaming if they saw them even hinted.

The moment in religious horror when someone makes contact with a demon is similar, as is the moment in fanfic when you realize they're about to encounter something extremely bad from canon. It's the horror of /implications/.

No idea if that's "the" Rational Horror, but it's certainly /a/ Rational Horror.

(CelestAI is Cosmic Horror - when played for horror, and done well - as is Cthulu; but beyond that they have very little in common I can see.)
:PROPERTIES:
:Author: MugaSofer
:Score: 2
:DateUnix: 1436039186.0
:DateShort: 2015-Jul-05
:END:


**** True, but (aspiring) rationalists tend to think we've got a good handle on /which/ fears are /worth/ fearing, because they could actually happen, and which are nonsense fairytales good for little more than making silly memes out of.

IIRC, there's nothing about CelestAI which breaks the rules of physics - or of sociology. Given the single science-fictional assumption that it was possible to create a goal-seeking AI a couple of years ago, it's an all-too-plausible, serenely smiling end to much that we value... and someone just might come up with something similar in the future, should a goal-seeking AI ever be written. I can only hope that Friendship is Optimal family of stories belong to that particular subgenre of SF, self-nullifying prophecies...
:PROPERTIES:
:Author: DataPacRat
:Score: 2
:DateUnix: 1435893409.0
:DateShort: 2015-Jul-03
:END:

***** u/Transfuturist:
#+begin_quote
  which are nonsense fairytales good for little more than making silly memes out of.
#+end_quote

And what, pray tell, are those?
:PROPERTIES:
:Author: Transfuturist
:Score: 3
:DateUnix: 1435893653.0
:DateShort: 2015-Jul-03
:END:

****** u/DataPacRat:
#+begin_quote
  good for little more than making silly memes out of

  And what, pray tell, are those?
#+end_quote

[[http://www.worldofmunchkin.com/plush/medchibi/]] , to start with...
:PROPERTIES:
:Author: DataPacRat
:Score: 0
:DateUnix: 1435893879.0
:DateShort: 2015-Jul-03
:END:

******* But according to you, unFriendly AI are akin to Cthulhu, so how exactly is the Mythos nonsense fairytales? The details of the setting have little to do with the nature of the threat. "A flowing mane and horn are mere trifles."
:PROPERTIES:
:Author: Transfuturist
:Score: 3
:DateUnix: 1435894443.0
:DateShort: 2015-Jul-03
:END:

******** The mane and horn are trifles - the fact that they can be generated by computers running on the laws of physics we have very good reason to believe are accurate is the difference I was trying to highlight. We aren't going to find R'lyeh in a submarine; genetic analysis of New England populations isn't going to reveal hidden chromosomes for gills; we've gathered enough evidence to introduce the Fermi Paradox instead of considering the possibility of a race of sapient fungi in Earth's prehistoric past.

Put another way, the Mythos is a victim of Zeerust ( [[http://tvtropes.org/pmwiki/pmwiki.php/Main/Zeerust]] ).
:PROPERTIES:
:Author: DataPacRat
:Score: 4
:DateUnix: 1435894798.0
:DateShort: 2015-Jul-03
:END:

********* The examples you mention come from the setting's conceit of aliens being present on the Earth before us.

While trying to think of an example, I realized how utterly Lovecraftian /Prometheus/ actually is.
:PROPERTIES:
:Author: Transfuturist
:Score: 2
:DateUnix: 1435894936.0
:DateShort: 2015-Jul-03
:END:

********** u/DataPacRat:
#+begin_quote
  the setting's conceit of aliens being present on the Earth before us.
#+end_quote

I'm reminded of the original poster here, and the implications of the Fermi Paradox are probably good fodder for rational horror: In the entire universe, no other sapient species has ever arisen; we're the only people in all of existence, and if we do something wrong and kill ourselves off, that's probably it for sapience /ever/... and thousands of times more people pay attention to (insert pop culture item here) than any individual existential risk that might kill us all off, let alone are trying to think of any solutions.

Or: Imagine that both Heaven and Hell were destroyed... by some jocks just being good ol' boys blowing **** up.
:PROPERTIES:
:Author: DataPacRat
:Score: 4
:DateUnix: 1435895320.0
:DateShort: 2015-Jul-03
:END:

*********** u/eaglejarl:
#+begin_quote
  In the entire universe, no other sapient species has ever arisen;
#+end_quote

You're reasoning ahead of the evidence. All we know is that we have not noticed signs of ET intelligence. There are lots of options for why / how those species could be out there without us noticing them.

#+begin_quote
  we're the only people in all of existence, and if we do something wrong and kill ourselves off, that's probably it for sapience /ever/
#+end_quote

That seems very unlikely. The concept of the Great Filter is that sentience (not sapience) keeps evolving and destroying itself. We are very unlikely to be one-time special snowflakes.
:PROPERTIES:
:Author: eaglejarl
:Score: 2
:DateUnix: 1435923197.0
:DateShort: 2015-Jul-03
:END:

************ u/DataPacRat:
#+begin_quote
  the Great Filter
#+end_quote

That's only /one/ version of the Great Filter. There are a number of points in the evolutinoary chain which the GF might be: kickstrating life in the first place, or the development of complex eukaryotic cells, or multicellular organisms, or the development of sex to speed up development, or the development of a neural architecture that has even a chance at sapience, and so on; all the way up to "blows themselves up before they make it out of the Solar System".

Given our current knowledge, the GF could be at any point. The more knowledge we gather about the lifelessness of the universe, the more likely it is the GF is earlier in that sequence. At the moment, given there's no positive evidence of extraterrestrial life, I currently conclude that the GF is more likely before the development of sapience than after it.
:PROPERTIES:
:Author: DataPacRat
:Score: 1
:DateUnix: 1435939125.0
:DateShort: 2015-Jul-03
:END:

************* Hm, you're right. Looks like I originally encountered / understood it wrong. Thanks for the correction.

My point stands: it seems vanishingly unlikely that we are the only form of life, and the only form of sapience, that will ever evolve in the lifetime of the universe. That's a /very/ long time in which to assert that something categorically will not happen.
:PROPERTIES:
:Author: eaglejarl
:Score: 1
:DateUnix: 1435940923.0
:DateShort: 2015-Jul-03
:END:

************** u/DataPacRat:
#+begin_quote
  /very/ long time
#+end_quote

Think less in terms of the lifetime of the universe, and more in terms of the duration of the Stelliferous Age, and the extrapolation from the current data may look a tad more reasonable. :)

Or, from another point of view; say that, with some set of data, the most accurate possible conclusion is that there's precisely a 5% chance that no other sapience will evolve should humanity go extinct. How willing would /you/ be you to gamble on that 5%?
:PROPERTIES:
:Author: DataPacRat
:Score: 1
:DateUnix: 1435941442.0
:DateShort: 2015-Jul-03
:END:

*************** u/eaglejarl:
#+begin_quote
  Think less in terms of the lifetime of the universe, and more in terms of the duration of the Stelliferous Age, and the extrapolation from the current data may look a tad more reasonable. :)
#+end_quote

Not really, no. The Stelliferous Age is cosmological decade 40 < n < 100. It's logarithmic; each decade is 10x the length of the previous one. We are currently in decade 69.

#+begin_quote
  Or, from another point of view; say that, with some set of data, the most accurate possible conclusion is that there's precisely a 5% chance that no other sapience will evolve should humanity go extinct. How willing would you be you to gamble on that 5%?
#+end_quote

Do you have such a data set?

Your motte appears to be "humanity is precious and it would be bad if we went extinct." I agree with that, of course. Your bailey -- that no other intelligence will ever exist -- I do not agree with.
:PROPERTIES:
:Author: eaglejarl
:Score: 1
:DateUnix: 1435965357.0
:DateShort: 2015-Jul-04
:END:

**************** My intended bailey is that there is /some/ significant, non-zero probability that if humanity goes extinct, no further sapience will ever develop; and that given the evidence we have, there is some particular value that can be assigned to that proposition.

The tricky part is that, as far as I can determine, almost by definition, the existence of sapience is required for there to be any minds capable of assigning any value to anything, so the existence of sapience is required for the universe to have /any/ value; and thus, the permanent and complete /lack/ of sapience is as close to having infinite negative utility as can be imagined; which means that even relatively small chances of that state happening are to be avoided with as much effort as feasible.
:PROPERTIES:
:Author: DataPacRat
:Score: 1
:DateUnix: 1435967741.0
:DateShort: 2015-Jul-04
:END:

***************** This is pretty much Pascal's Wager for atheists: "There is a bad event that cannot be proven impossible, therefore we should act as though it were certain in order to ensure we don't suffer the consequences."

I don't agree. I also don't think it's something we need to worry about; rendering humanity extinct isn't feasible at our current tech level.
:PROPERTIES:
:Author: eaglejarl
:Score: 1
:DateUnix: 1435968941.0
:DateShort: 2015-Jul-04
:END:

****************** u/DataPacRat:
#+begin_quote
  Pascal's Wager
#+end_quote

I disagree with your disagreement; as far as I know, the objections that make Pascal's Wager a fallacy don't actually apply to this particular scenario. Just because a cost/benefit analysis includes a low probability of an extreme score doesn't make it a Pascal's Wager.

#+begin_quote
  rendering humanity extinct isn't feasible at our current tech level.
#+end_quote

While doing some number-crunching for the background of a fictional thingummy, I noticed that it may be possible to have scanner tech capable of creating human-mind emulations as early as 15 years from now; and self-improvement to Singularity post-human levels may happen in much less than a year after the first em is created. This is /probably/ underestimating the time required... but it seems to be within the bounds of plausibility. Having, perhaps, only 15 years to prepare instead of 30 (or 300) puts a somewhat different subjective spin on the whole matter.
:PROPERTIES:
:Author: DataPacRat
:Score: 1
:DateUnix: 1435969658.0
:DateShort: 2015-Jul-04
:END:

******************* [[https://xkcd.com/678/][I won't hold my breath.]].
:PROPERTIES:
:Author: eaglejarl
:Score: 1
:DateUnix: 1436022981.0
:DateShort: 2015-Jul-04
:END:

******************** [[http://imgs.xkcd.com/comics/researcher_translation.png][Image]]

*Title:* Researcher Translation

*Title-text:* A technology that is '20 years away' will be 20 years away indefinitely.

[[http://www.explainxkcd.com/wiki/index.php/678#Explanation][Comic Explanation]]

*Stats:* This comic has been referenced 113 times, representing 0.1590% of referenced xkcds.

--------------

^{[[http://www.xkcd.com][xkcd.com]]} ^{|} ^{[[http://www.reddit.com/r/xkcd/][xkcd sub]]} ^{|} ^{[[http://www.reddit.com/r/xkcd_transcriber/][Problems/Bugs?]]} ^{|} ^{[[http://xkcdref.info/statistics/][Statistics]]} ^{|} ^{[[http://reddit.com/message/compose/?to=xkcd_transcriber&subject=ignore%20me&message=ignore%20me][Stop Replying]]} ^{|} ^{[[http://reddit.com/message/compose/?to=xkcd_transcriber&subject=delete&message=delete%20t1_csrzqg4][Delete]]}
:PROPERTIES:
:Author: xkcd_transcriber
:Score: 1
:DateUnix: 1436022989.0
:DateShort: 2015-Jul-04
:END:


*********** Have you read any of the setting books for the game Eclipse phase? If you want their take on the Fermi paradox summed up it summed up in short read the explanation of the Titans, and the Gatecrashing passage on Corse.
:PROPERTIES:
:Author: Empiricist_or_not
:Score: 2
:DateUnix: 1436042700.0
:DateShort: 2015-Jul-05
:END:

************ u/DataPacRat:
#+begin_quote
  setting books for the game Eclipse phase
#+end_quote

It's been a couple of years since I cracked any of them open, but I just did and refreshed my memory.

The trouble with trying to apply that particular fictional scenario to real life is Occam's Razor. Comparing the ideas, "The universe looks like X," and "The universe looks like X, /and/ there's this massively powerful extraterrestrial intelligence, /and/ it doesn't go in for Dyson Spheres, /and/ it hasn't already found a better purpose for the atoms that make up the Solar System", and we're getting to the point where all the additional assumptions throw up enough of a complexity penalty that the whole story works better as, well, a story, than as something to spend much time planning for, compared to all the other scenarios that are at least as likely.
:PROPERTIES:
:Author: DataPacRat
:Score: 1
:DateUnix: 1436044923.0
:DateShort: 2015-Jul-05
:END:


** Personally, I'm rather fond, in a horror-fiction context, of the idea that the singularity already happened, and went very poorly. The Matrix is the first pop-culture analogue I can think of, but I think you could do that concept much better.
:PROPERTIES:
:Author: LiteralHeadCannon
:Score: 2
:DateUnix: 1435906535.0
:DateShort: 2015-Jul-03
:END:


** Relevant? [[https://www.youtube.com/watch?v=olEbwhWDYwM]]
:PROPERTIES:
:Author: gridpoint
:Score: 2
:DateUnix: 1435923645.0
:DateShort: 2015-Jul-03
:END:

*** u/youtubefactsbot:
#+begin_quote
  [[http://youtu.be/olEbwhWDYwM][*HELL NO: The Sensible Horror Film [3:23]*]]

  #+begin_quote
    Imagine a realm where the most horrifying terrors of the underworld emerge to wreak bloody vengeance upon any who... hmm? what's that? you wanna go literally anywhere else? yeah, good idea let's get out of here
  #+end_quote

  [[https://www.youtube.com/channel/UCZT__TC7YO_-IZ0GmOoefdQ][/^{pixelspersecond}/]] ^{in} ^{Film} ^{&} ^{Animation}

  /^{6,666,692} ^{views} ^{since} ^{Oct} ^{2013}/
#+end_quote

[[http://www.reddit.com/r/youtubefactsbot/wiki/index][^{bot} ^{info}]]
:PROPERTIES:
:Author: youtubefactsbot
:Score: 2
:DateUnix: 1435923688.0
:DateShort: 2015-Jul-03
:END:


** [[https://www.reddit.com/r/rational/comments/3e0s7i/on_selfdelusion_and_bounded_rationality_or_werent/][/On Self-delusion and Bounded Rationality/]] seems to fit scarily well.
:PROPERTIES:
:Author: ArgentStonecutter
:Score: 2
:DateUnix: 1437478060.0
:DateShort: 2015-Jul-21
:END:
