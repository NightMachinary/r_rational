#+TITLE: [Q] What can a rationalist do with a time-looping scenario (such as Groundhog Day) besides simply educating themselves to incredible levels?

* [Q] What can a rationalist do with a time-looping scenario (such as Groundhog Day) besides simply educating themselves to incredible levels?
:PROPERTIES:
:Author: AmeteurOpinions
:Score: 20
:DateUnix: 1400719312.0
:DateShort: 2014-May-22
:END:
I'm having trouble thinking of ways to exploit something like that if the only thing you bring with you per reset is the contents of your skull.


** Sounds like it's time to start experimenting.

I'd start by inserting a small harmless object, say a coin, into my ear. I'd also give myself a small cut. If, like in Groundhog day, all exterior damage is repaired, then it would allow me to experiment further. Where is the boundary for what gets carried over? The state of my neural net is a physical state, so there must be a physical boundary between what is brought over and what is not. I should be able to find it and use it.

If I can bring over objects by performing minor surgery on my person, then small computers could allow me to perform an Oracle test, for starters.

EDITs for clarity.
:PROPERTIES:
:Score: 16
:DateUnix: 1400719921.0
:DateShort: 2014-May-22
:END:

*** On the one hand, I would say it's a complete reset. Whatever you had when you woke up the first time is what you have the next infinite times.

However, we are adding the carrying of memories, emotional state, and [[http://en.wikipedia.org/wiki/Muscle_memory#Muscle_memory_encoding][muscle memories]]. All of these are unfortunately in the brain. I was hoping muscle memory was encoded in the muscles, but according to a quick Wikipedia search, there is evidence that it may not be.

So to carry something over, I would think it would need to be a state change of certain parts of the brain. Thus, my reckoning, would be that when the reset happens, the brain cells reorganize into the new pattern. If we go with that, then foreign objects would not be able to be passed to the next cycle (where would the excess silicon come from [no jokes]).

In my conclusion, I'd think that you'd have to find a way to scan the cells in your brain to determine their state, and have that be an encoding that can be 'uploaded' to a computer via scanning, and opened via .zip... then you can do your work, compress it at the end of the day, and 'download' it into your brain cells again. Though, I personally don't know if we have a way of purposefully rearranging portions of brain cells without causing more damage. Likewise, the storage space will still be limited (let's not compare brain masses), without interfering with other necessary portions of the brain.

However, if any of my assumptions are wrong, and there's a field with an 'inside' and 'outside' and everything in the inside gets replaced by the insides of the next cycle, then yeah, we can probably smuggle some things in~

*tl;dr* I imagine that the new cycle state starts from the base from the first morning, then reorganizes pieces of particular cells of the brain to get the effect, rather than porting in any material that didn't exist in that space beforehand.
:PROPERTIES:
:Author: UnfortunatelyEvil
:Score: 5
:DateUnix: 1400767832.0
:DateShort: 2014-May-22
:END:

**** The problem being that trauma can quite easily rearrange brain cells in ways you probably wouldn't want to carry over. Even in the original movie, I doubt that driving into the quarry left the guy's head intact for the next reset, yet he isn't a drooling zombie.
:PROPERTIES:
:Author: GeeJo
:Score: 3
:DateUnix: 1400927449.0
:DateShort: 2014-May-24
:END:


**** ***** 
      :PROPERTIES:
      :CUSTOM_ID: section
      :END:
****** 
       :PROPERTIES:
       :CUSTOM_ID: section-1
       :END:
**** 
     :PROPERTIES:
     :CUSTOM_ID: section-2
     :END:
Section 6. [[https://en.wikipedia.org/wiki/Muscle_memory#Muscle_memory_encoding][*Muscle memory encoding*]] of article [[https://en.wikipedia.org/wiki/Muscle%20memory][*Muscle memory*]]: [[#sfw][]]

--------------

#+begin_quote
  The [[https://en.wikipedia.org/wiki/Neuroanatomy_of_memory][neuroanatomy of memory]] is widespread throughout the [[https://en.wikipedia.org/wiki/Brain][brain]]; however, the pathways important to motor memory are separate from the medial [[https://en.wikipedia.org/wiki/Temporal_lobe][temporal lobe]] pathways associated with [[https://en.wikipedia.org/wiki/Declarative_memory][declarative memory]]. As with declarative memory, motor memory is theorized to have two stages: a short-term [[https://en.wikipedia.org/wiki/Memory_encoding][memory encoding]] stage, which is fragile and susceptible to damage, and a long-term [[https://en.wikipedia.org/wiki/Memory_consolidation][memory consolidation]] stage, which is more stable.

  The memory encoding stage is often referred to as [[https://en.wikipedia.org/wiki/Motor_learning][motor learning]], and requires an increase in brain activity in motor areas as well as an increase in attention. Brain areas active during motor learning include the motor and somatosensory cortices; however, these areas of activation decrease once the motor skill is learned. The prefrontal and frontal cortices are also active during this stage due to the need for increased attention on the task being learned.

  The main area involved in motor learning is the [[https://en.wikipedia.org/wiki/Cerebellum][cerebellum]]. Some models of cerebellar-dependent motor learning, in particular the Marr-Albus model, propose a single plasticity mechanism involving the cerebellar [[https://en.wikipedia.org/wiki/Long-term_depression][long-term depression]] (LTD) of the parallel fiber synapses onto [[https://en.wikipedia.org/wiki/Purkinje_cells][Purkinje cells]]. These modification in synapse activity would mediate motor input with motor outputs critical to inducing motor learning. However, conflicting evidence suggests that a single plasticity mechanism is not sufficient and a multiple plasticity mechanism is needed to account for the storage of motor memories over time. Regardless of the mechanism, studies of cerebellar-dependent motor tasks show that cerebral cortical plasticity is crucial for motor learning, even if not necessarily for storage.
#+end_quote

--------------

^{Interesting:} [[https://en.wikipedia.org/wiki/Muscle_Memory][^{Muscle} ^{Memory}]] ^{|} [[https://en.wikipedia.org/wiki/Proprioception][^{Proprioception}]] ^{|} [[https://en.wikipedia.org/wiki/Memory_Muscle][^{Memory} ^{Muscle}]] ^{|} [[https://en.wikipedia.org/wiki/Muscle_memory_(strength_training)][^{Muscle} ^{memory} ^{(strength} ^{training)}]]

^{Parent} ^{commenter} ^{can} [[http://www.np.reddit.com/message/compose?to=autowikibot&subject=AutoWikibot%20NSFW%20toggle&message=%2Btoggle-nsfw+choduws][^{toggle} ^{NSFW}]] ^{or[[#or][]]} [[http://www.np.reddit.com/message/compose?to=autowikibot&subject=AutoWikibot%20Deletion&message=%2Bdelete+choduws][^{delete}]]^{.} ^{Will} ^{also} ^{delete} ^{on} ^{comment} ^{score} ^{of} ^{-1} ^{or} ^{less.} ^{|} [[http://www.np.reddit.com/r/autowikibot/wiki/index][^{FAQs}]] ^{|} [[http://www.np.reddit.com/r/autowikibot/comments/1x013o/for_moderators_switches_commands_and_css/][^{Mods}]] ^{|} [[http://www.np.reddit.com/r/autowikibot/comments/1ux484/ask_wikibot/][^{Magic} ^{Words}]]
:PROPERTIES:
:Author: autowikibot
:Score: 3
:DateUnix: 1400767842.0
:DateShort: 2014-May-22
:END:


**** That's an interesting hypothesis; we'd have to test it. Where's Egon with his drill?
:PROPERTIES:
:Score: 1
:DateUnix: 1400769015.0
:DateShort: 2014-May-22
:END:


** If it's like Groundhog Day, you're limited to gaining more information or more skills. You can run experiments as much as you want, but you're limited to whatever you can do in however much time you have available (usually a day?). The skills won't really help you unless you anticipate getting out of the loop at some point, and the information you could gain would probably be negligible.

Depending on what year it is, you might be able to contact someone at a national laboratory and get them to run experiments that they can set up in a day, if you have lots of loops to figure out how to short-circuit their disbelief and get them to help you. I have no idea what you'd hope to gain by those experiments besides more knowledge, especially since you wouldn't have any hope of building something like a large hadron collider or something.

I guess if it were me, after I had exhausted all of the obvious fun things I would set to work improving my memory so that I could take more and more raw information with me in every loop. But if you can't get out of the loop, there doesn't seem to be a point, right?
:PROPERTIES:
:Author: alexanderwales
:Score: 8
:DateUnix: 1400720915.0
:DateShort: 2014-May-22
:END:

*** u/deskglass:
#+begin_quote
  But if you can't get out of the loop, there doesn't seem to be a point, right?
#+end_quote

There'd be no less of a point than usual. In fact, there'd maybe be more of a point since your existence would persist for longer.
:PROPERTIES:
:Author: deskglass
:Score: 6
:DateUnix: 1400721138.0
:DateShort: 2014-May-22
:END:

**** I think there'd be less of a point to living if you could never make an impact on the world, and if you only had a day to get to know any person. Eventually you'd have read every book within your reach, and it's not like you'd be able to make art that wasn't extremely temporary (and not any art that takes longer than a day to make and enjoy). In /Groundhog Day/ he's effectively trapped inside a town of 7,000, and I have to believe that eventually the completely unchanging nature of the town would grow dull.

I'm not making a general case against immortality (which I think would be great) but being trapped for thousands of subjective years in a single small town where I can literally make no change that lasts longer than a day sounds utterly terrible. Eventually there would be no challenges left to your half-life and no pleasures that haven't turned to ash in your mouth.
:PROPERTIES:
:Author: alexanderwales
:Score: 14
:DateUnix: 1400722051.0
:DateShort: 2014-May-22
:END:

***** I had interpreted your post as saying that there would be no point because all records of your actions would disappear. In response, I thought you would still be impacting the world, by making people experience happiness. It's just that the record of you having done so would be lost sooner.

I then thought that if records of action affect whether or not there is a point to it all, loop world wins out in the (very) long term because there will always be a record of your actions (you).

I hadn't thought you meant there would be no point due to boredom.
:PROPERTIES:
:Author: deskglass
:Score: 10
:DateUnix: 1400724633.0
:DateShort: 2014-May-22
:END:

****** Ah, so you're arguing that from a utility standpoint there's a purpose because you can make people happy and reduce suffering, even though there's no record of it the next day except what you remember. I guess I can buy that in the abstract, but I really think the psychological toll of "doing the most good" and then waking up to having everything reset would just be too large for me.

I sort of took for granted that other people in this scenario are essentially not a factor in my motivations, which I guess might say something about me or my philosophical outlook. I'm sort of tempted to say that a day that I'll remember is worth much, much more than a day that someone else won't remember, but I'm not sure that position is tenable. I'd have to think about it more.
:PROPERTIES:
:Author: alexanderwales
:Score: 7
:DateUnix: 1400725714.0
:DateShort: 2014-May-22
:END:

******* This is a moral question that I've been pondering over for a while now, and I haven't reached a conclusion yet.

My intuition is definitely very strongly that in a Groundhog Day scenario everyone else has no appreciable utility value whatsoever.

My intuition regards them as mindless automatons. And even though I know they're not mindless, there's something significant about the fact that on any given day you could commit whatever acts of atrocity you could think of upon them and that the next morning and every morning after they'd continue to get up as usual, no trace of your previous acts remaining.

But when I compare this to my thoughts about temporary intelligences simulated on a computer, I come up with a different response. If you could spawn a new intelligence in a computer simulation, I would be quite upset with you if you didn't look after it, even if you were planning to delete it after the next day.

I think it's the inevitability of the Groundhog Day scenario, the fact that it's not your fault that they're being respawned every day for 24 hours. If a computer were simulating somebody afresh every day and there was nothing you could do to prevent it, I think the same ennui about their utilitarian value would result.

EDIT: This starts to get even weirder for me, and completely beyond my ability to come up with an intuitive response, if you consider the following question.

What is the utility value of a series of saved snapshots of a simulated intelligence?

Assuming a simulated intelligence has utility, at what point does the utility arise? As it's being calculated? As it's being read from memory? What if you read the snapshots non-chronologically? How would I know if I were a simulation being run non-chronologically? Could I just be a series of snapshots stored in memory? Could I be just a single snapshot? Could I even just be a theoretically possible arrangement of molecules?

Makes my brain hurt.
:PROPERTIES:
:Author: Pluvialis
:Score: 4
:DateUnix: 1400775371.0
:DateShort: 2014-May-22
:END:

******** u/1794:
#+begin_quote
  My intuition is definitely very strongly that in a Groundhog Day scenario everyone else has no appreciable utility value whatsoever.
#+end_quote

So imagine doing every /barely/ interesting non-violent thing for many many times, so many times that every such thing has lost every tiny shred of their flavor. The number of barely interesting things could be HUGE, as would the number of times you find /any/ utility in doing those things. But you will still grow utterly bored of doing those things. Would you start torturing people in the search of novelty? Would a person with the average psychological make-up? Is it inevitable? (I hope no one ever tests this by simulating the scenario.)

Of course this too would just postpone the inevitable, as those things would become boring too. I wonder what would happen after the number of days approaches infinity. My best bet is that there would probably be some sort of "equilibrium point" in how people would choose to live their days, that would be roughly the same day after day.

I think [[http://www.fimfiction.net/story/69770/12/friendship-is-optimal-caelum-est-conterrens/12-transequinism][“Friendship is Optimal: Caelum est Conterrens”]] has a good bit on this:

#+begin_quote
  There were several types of immortals defined. The simplest was the Loop Immortal, a consciousness that endlessly repeated a finite set of general behaviors, in a (potentially, not necessarily) infinite number of increasingly subtle variations. Most ponies in the system were loop immortals, their possibilities defined by the finite possibilities of virtual lives that in some way approximated the Equestria of Friendship Is Magic. Her original self, before the alteration that began a steady climb in curiosity and intelligence had been - and was - a loop immortal.
#+end_quote

But would a typical day contain violent or non-violent things? Would it be similar to [[http://en.wikipedia.org/wiki/Stereotypy_(non-human)][stereotypical behavior]], "repetitive behaviors in captive animals, particularly those given inadequate mental stimulation" -- "Stereotypical behaviors are thought to be caused ultimately by artificial environments that do not allow animals to satisfy their normal behavioral needs. "

#+begin_quote
  Could I just be a series of snapshots stored in memory? Could I be just a single snapshot? Could I even just be a theoretically possible arrangement of molecules?
#+end_quote

Yes you could.

[[http://en.wikipedia.org/wiki/Boltzmann_brain]]

Although I don't think this particular case is very probable.
:PROPERTIES:
:Author: 1794
:Score: 0
:DateUnix: 1400795383.0
:DateShort: 2014-May-23
:END:

********* Okay so what are the implications of this? Should I care about a saved snapshot of a mind being tortured? 100 sequential snapshots? Theoretical ideas of tortured minds?

Wouldn't these snapshots just be numbers, if store digitally? Should I be worried about the existence of numbers that could be interpreted as a mind in pain? Couldn't I decide arbitrary rules for interpreting a number so that any number could in theory map to a mind in pain?

Where does the madness go? I really feel like I need to read more literature about this, but I don't know if anyone's written about it.
:PROPERTIES:
:Author: Pluvialis
:Score: 2
:DateUnix: 1400796374.0
:DateShort: 2014-May-23
:END:

********** I don't know what the implications are, I'm confused even by normal ethics. Maybe you should care about them if you really care about them, e.g. if thinking about those tortured snapshots activates any of the morality nodes in your brain?

#+begin_quote
  Should I be worried about the existence of numbers that could be interpreted as a mind in pain?
#+end_quote

Meh. What's the point?

#+begin_quote
  Couldn't I decide arbitrary rules for interpreting a number so that any number could in theory map to a mind in pain?
#+end_quote

No, I don't think you could do that. For the same reason that a random sequence of 0's and 1's doesn't automatically become a workable computer program. I think "mind in pain" has some objective criteria that needs to be satisfied in order for it to become a real mind in pain in any meaningful sense.

#+begin_quote
  I really feel like I need to read more literature about this, but I don't know if anyone's written about it.
#+end_quote

It's not about this specific scenario, but Nick Bostrom's [[http://www.nickbostrom.com/ethics/infinite.pdf]['Infinite Ethics']] might have some relevance to this.
:PROPERTIES:
:Author: 1794
:Score: 1
:DateUnix: 1400798367.0
:DateShort: 2014-May-23
:END:

*********** Why did Bostrom write that paper? Plainly our Hubble Volume is finite.
:PROPERTIES:
:Score: 0
:DateUnix: 1400963269.0
:DateShort: 2014-May-25
:END:

************ He seems convinced that the universe is infinite because its flatness is pretty much certain and it being infinite and flat best matches the data (even if it can't be directly tested). I personally don't know about the physics and if you can make that particular assumption.

So you're saying we shouldn't care about the universe outside Hubble Volume? Maybe so. Anyway, Bostrom seems to be seeking some kind of perfect ethics that would take into account even people you can never interact with. At least he seems to be having fun writing these papers.
:PROPERTIES:
:Author: 1794
:Score: 1
:DateUnix: 1400970826.0
:DateShort: 2014-May-25
:END:

************* u/deleted:
#+begin_quote
  So you're saying we shouldn't care about the universe outside Hubble Volume?
#+end_quote

Nah, I'm saying that we should only treat things we can causally interact with as actually real. So if FTL gets invented, Bostrom's paper becomes quite relevant. OTOH, if we remain strictly limited to our Hubble Volume, then whatever.

Besides which, "my life up to now" is always finite, so we're really talking about countable infinities, so we can always deal finitely with the finite amount of stuff we've /yet/ come into causal contact with.
:PROPERTIES:
:Score: 1
:DateUnix: 1400999463.0
:DateShort: 2014-May-25
:END:


***** u/deleted:
#+begin_quote
  I'm not making a general case against immortality (which I think would be great) but being trapped for thousands of subjective years in a single small town where I can literally make no change that lasts longer than a day sounds utterly terrible. Eventually there would be no challenges left to your half-life and no pleasures that haven't turned to ash in your mouth.
#+end_quote

You could just achieve Enlightenment, Buddhist-style, and stop caring about everything in a really beneficent way.
:PROPERTIES:
:Score: 1
:DateUnix: 1400963039.0
:DateShort: 2014-May-25
:END:


**** I'd point out that even the protagonist of Groundhog Day found a way out of the loop, albeit in his case accidentally.

Eventually, your experiments may allow you to determine how you ended up in the loop, and how you might escape it.
:PROPERTIES:
:Score: 3
:DateUnix: 1400764729.0
:DateShort: 2014-May-22
:END:


** Depending on how the memories are transferred, you might eventually be able to turn yourself into a self-improving AI that ran on human neurons.
:PROPERTIES:
:Author: EliezerYudkowsky
:Score: 9
:DateUnix: 1400879670.0
:DateShort: 2014-May-24
:END:

*** Waaaaiiiit... that's a /bloody great/ idea.

If you had enough space in your mind to hold other minds, you would be able to carry other people with you /through the loop-reset/, thus actually alleviating the whole "oh fuck I can't do anything and I'm so alone" problem.

Note: this is the only scenario in which I endorse creating self-improving AI willy-nilly, as a time-loop reset will inevitably destroy anything that's not you.
:PROPERTIES:
:Score: 1
:DateUnix: 1400963361.0
:DateShort: 2014-May-25
:END:


** [[https://www.fanfiction.net/s/5193644/1/Time-Braid]]

Sakura starts a Groundhog Day loop sequence, in which all she brings with her are her memories... and then various hijinks ensue, including munchkinry.
:PROPERTIES:
:Author: DataPacRat
:Score: 11
:DateUnix: 1400720794.0
:DateShort: 2014-May-22
:END:

*** Seriously, there must be something cool that could be done by someone /otherwise normal/ in a loop too.

Sakura ends up avoiding a loop reset when her body is atomised because that can't impair her combat abilities.

Normals are probably limited to Coil type tricks (from Worm). We could brute-force Dinah or /maybe/ Contessa, but I'd guess some sanity damage would ensue from the time that would take.
:PROPERTIES:
:Author: PeridexisErrant
:Score: 5
:DateUnix: 1400750671.0
:DateShort: 2014-May-22
:END:


*** This is great. It reminds me a bit of Fate/Hollow Ataraxia.
:PROPERTIES:
:Author: gabbalis
:Score: 1
:DateUnix: 1400745765.0
:DateShort: 2014-May-22
:END:


** In this scenario, do you have the ability to end the loop, or foreknowledge of when it will end?

If not, you could postulate that the loop would continue forever. The only thing you'd presumably be able to affect would be the contents of your mind/memory, meaning that eventually you're going to hit a stable loop and just start repeating a sequence of days. (The most likely scenario being that you descend into brain death and spend eternity as a drooling husk.)
:PROPERTIES:
:Author: Geminii27
:Score: 6
:DateUnix: 1400787346.0
:DateShort: 2014-May-23
:END:


** The first thing I'd do is figure out exactly how brains work, however many loops that takes. Then, I'd start optimizing.

First, I'd figure out some way to speed up my brain. Then, I'd find some way to create a body (or VR program) that can respond and move at a similar speed, and transplant my brain into it. Then, I'd keep repeating this process until the rate at which my brain time is multiplying exceeds the rate at which I am running out of time. This may take more than one loop.

Then, I'd start operating the same procedure on everyone else. Thus, I have created infinite brain time for everyone in a finite time, and the Singularity.

In the event that I reach a point where my brain will no longer speed up, I hope to be at a point where I can encode the memories of as many people as possible into the strings of my brain, then carry them and replace them next loop. This problem shouldn't be that bad, since there will probably be several thousand/billion subjective years between resets.
:PROPERTIES:
:Author: yewchung
:Score: 5
:DateUnix: 1400891389.0
:DateShort: 2014-May-24
:END:


** See: [[http://www.reddit.com/r/rational/comments/1s86mm/branches_on_the_tree_of_time_a_terminator_fanfic/]]
:PROPERTIES:
:Author: mcgruntman
:Score: 0
:DateUnix: 1400758324.0
:DateShort: 2014-May-22
:END:

*** While an excellent fanfic, that one involves actual complete-body time travel and an arbitrary temporal distance over which you can jump. The Groundhog Day loop is significantly more limited, although the intent behind my where's-the-boundary experiments is to try and overcome said limit.
:PROPERTIES:
:Score: 6
:DateUnix: 1400764675.0
:DateShort: 2014-May-22
:END:

**** Fair enough! Hopefully it still provides some inspiration as I feel the mechanic of time travel is very well used in BotToT.
:PROPERTIES:
:Author: mcgruntman
:Score: 2
:DateUnix: 1400770470.0
:DateShort: 2014-May-22
:END:
