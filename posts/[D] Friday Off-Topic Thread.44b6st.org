#+TITLE: [D] Friday Off-Topic Thread

* [D] Friday Off-Topic Thread
:PROPERTIES:
:Author: AutoModerator
:Score: 13
:DateUnix: 1454684768.0
:DateShort: 2016-Feb-05
:END:
Welcome to the Friday Off-Topic Thread! Is there something that you want to talk about with [[/r/rational]], but which isn't rational fiction, or doesn't otherwise belong as a top-level post? This is the place to post it. The idea is that while reddit is a large place, with lots of special little niches, sometimes you just want to talk with a certain group of people about certain sorts of things that aren't related to why you're all here. It's totally understandable that you might want to talk about Japanese game shows with [[/r/rational]] instead of going over to [[/r/japanesegameshows]], but it's hopefully also understandable that this isn't really the place for that sort of thing.

So do you want to talk about how your life has been going? Non-rational and/or non-fictional stuff you've been reading? The recent album from your favourite German pop singer? The politics of Southern India? The sexual preferences of the chairman of the Ukrainian soccer league? Different ways to plot meteorological data? The cost of living in Portugal? Corner cases for siteswap notation? All these things and more could possibly be found in the comments below!


** Hey, everyone! I have finally deployed the webcomics platform I'm working on:

[[http://webcomics.io]]

It's quite simple now, but I'm really proud of it =)

I want it to become an awesome community where artists can post/read/discuss comics.

Here's the list of webcomics I'm making:

[[http://webcomics.io/user/rayalez/]]

Any feedback appreciated =)
:PROPERTIES:
:Author: raymestalez
:Score: 11
:DateUnix: 1454687388.0
:DateShort: 2016-Feb-05
:END:

*** One thing that is essential for webcomic platforms IMO is being able to advance pages by clicking on the image, or by using the arrow keys. Having to scroll down and then click the button hundreds of times when you're reading a long-running comic from the beginning can be a real pain.
:PROPERTIES:
:Author: GlueBoy
:Score: 13
:DateUnix: 1454703971.0
:DateShort: 2016-Feb-05
:END:

**** Thank you for the advice, I will definitely implement this!
:PROPERTIES:
:Author: raymestalez
:Score: 3
:DateUnix: 1454705141.0
:DateShort: 2016-Feb-06
:END:


*** Does it support having Text with illustration style comics? if so that is precisely the kind of thing I want for several projects.
:PROPERTIES:
:Author: Nighzmarquls
:Score: 3
:DateUnix: 1454696053.0
:DateShort: 2016-Feb-05
:END:

**** Right now most of the comics are single images, but I would be happy to see all sorts of comics.

In terms of functionality currently you can upload an image and write a description, you can try it and see if it fits your format. If it doesn't - you could send me a link to your comics, maybe I can add the necessary features to make it work well for you.
:PROPERTIES:
:Author: raymestalez
:Score: 3
:DateUnix: 1454696559.0
:DateShort: 2016-Feb-05
:END:

***** Hmmm, my format is images and text in sequence one after the other. To be legible it honestly needs several images and chunks of texts to be able to follow.

One of my pieces also has absolute need of colored text control, and possibly background display control.

I've been 'slowly' working to port it over to a blog format but a comic community like this probably would be MUCH BETTER for the stage of readership/audience I presently have. (a couple hundred dedicated readers).
:PROPERTIES:
:Author: Nighzmarquls
:Score: 1
:DateUnix: 1454696920.0
:DateShort: 2016-Feb-05
:END:

****** Oh, right now the platform doesn't support this kind of stuff, and I don't think I'll be adding colored text and background display control as the part of main functionality.

But I have been thinking about adding functionality to allow artists to have their own custom websites on subdomains, or plugged into the platform with rss or something like that.

Like we could set it up so that you have blog that is specifically designed for your format, but still takes the advantages of the platform(you get traffic/subscribers/comments/etc).

Or, maybe it would make sense to just have everythig(both illustrations and text) in an image format, that way you could easily control the color of text, background, etc.

Can you send me an example of your comics? Maybe we can figure out how to make this work.
:PROPERTIES:
:Author: raymestalez
:Score: 3
:DateUnix: 1454698097.0
:DateShort: 2016-Feb-05
:END:

******* My stories have been living on forums, but I'm planning to migrate them to dedicated sites, your community seems like it would be a good area to do that. The original piece in it's forum version is [[http://mspaforums.com/showthread.php?46308-Deep-Rise-An-Illustrated-Xenofiction-Adventure][Deep Rise]]

I'm way behind in translating that to a blog [[http://deepaccord.blogspot.com][here]]

My other piece I'm actively working on is originaly [[http://mspaforums.com/showthread.php?58468-Oh-My!-Generic-Monster-Girls!-Wee-aboo-Intensifies][here]] and I'm now mirroring it to [[https://forums.spacebattles.com/threads/oh-my-generic-monster-girls-space-battle-forums-edition.366441/][this forum]]

The kind of hybrid comic/written story format is a bit tricky to adapt to single image conventions... It's been the biggest hurdle in me trying to figure out WHERE to promote my work.
:PROPERTIES:
:Author: Nighzmarquls
:Score: 3
:DateUnix: 1454699085.0
:DateShort: 2016-Feb-05
:END:

******** This looks awesome!

I think that the most straightforward thing to do is to simply convert all the illustrations+text into images. You would be able to style it in any way you like in photoshop, and then just upload a series of images.

That would fit perfectly well with the platform, and with any other format as well.

I would be happy to help you with that if you want, and to help you promote your stuff too =)
:PROPERTIES:
:Author: raymestalez
:Score: 2
:DateUnix: 1454700315.0
:DateShort: 2016-Feb-05
:END:

********* That would be great, my biggest concern with the text is that sometimes the words get a bit heavy and it seemed like that was a waste of bandwidth... but if we cut and select them appropriately that could work!

Would love to collaborate further, send me a PM and I can get you my more immediate contact info so we don't have to fill up the reddit with this :)
:PROPERTIES:
:Author: Nighzmarquls
:Score: 1
:DateUnix: 1454700540.0
:DateShort: 2016-Feb-05
:END:


*** Looked and then came back to criticise without following any links.

Your titles are to small and your background distracts too much from the titles. Within 1/2 a second how long I was willing to see if I liked anything I couldn't see the titles. It took me maybe 3 seconds to see the web-comic titles.

This is a bad thing, unless you want only people already committed to looking to convert to the comics you are advertising.
:PROPERTIES:
:Author: Empiricist_or_not
:Score: 2
:DateUnix: 1454722941.0
:DateShort: 2016-Feb-06
:END:


** I had a weird dream last night where my life was a Quest (in the vein of Quest fiction as seen on Spacebattles and Sufficient Velocity).

I've been idly wondering today about the feasibility of doing something like that, using community group think to control an individual life to potentially avoid a lot of the common issues individuals have with decision making and such.

It may make for an interesting experiment.
:PROPERTIES:
:Author: LeonCross
:Score: 8
:DateUnix: 1454705857.0
:DateShort: 2016-Feb-06
:END:

*** If you use entirely different terminology but the exact same premise you could make either a great reality TV show, art piece or scientific study out of this.
:PROPERTIES:
:Author: Nighzmarquls
:Score: 6
:DateUnix: 1454707321.0
:DateShort: 2016-Feb-06
:END:

**** Mayhaps. As a scientific study, it would likely be more of a proof of concept / prelude. Too many variables involved and such.

That said, keeping a written log and maybe a daily of weekly video log might not be a terrible idea. Things to keep in mind.

Brainstorming ways of doing it, but I think it should prove...something. Interesting at least.
:PROPERTIES:
:Author: LeonCross
:Score: 3
:DateUnix: 1454709542.0
:DateShort: 2016-Feb-06
:END:


*** Dan Brown, youtube username "pogobat," did an experiment like this. He called it Dan 3.0 and allowed people to propose and vote on actions. I can't remember whether he used reddit or something else.
:PROPERTIES:
:Author: 4t0m
:Score: 4
:DateUnix: 1454724686.0
:DateShort: 2016-Feb-06
:END:


** If an author has previously written a book (or multiple books) that you found enjoyable, how much do you expect /other/ books from the same author to be /similarly/ enjoyable?

--------------

I'm wary of trusting authors to be consistent. Even though [[https://www.fanfiction.net/u/1960462][ShaperV]]'s /[[https://www.fanfiction.net/s/5193644][Time Braid]]/ is my favorite book of all time, his unfinished story /[[https://www.fanfiction.net/s/5207262][Indomitable]]/ is merely /good/ (Shadow Clone antics notwithstanding)--and, when I attempted to read his original story /[[https://www.fictionpress.com/s/3198066][Fimbulwinter]]/ (years ago, IIRC; I probably should look at it again, since I remember almost nothing about it), I didn't find it even /remotely/ interesting. Likewise, /[[http://www.fimfiction.net/story/19198][Background Pony]]/ is almost definitely my favorite story for /Friendship Is Magic/--but, when I bothered to check out the other works of its author ([[http://www.fimfiction.net/index.php?view=category&user=1491][shortskirtsandexplosions]]/[[http://www.fimfiction.net/index.php?view=category&user=32973][Imploding Colon]]/[[http://www.fimfiction.net/index.php?view=category&user=158394][Just Essay]]), it turned out that hardly anything else in his body of work even came /close/ to matching /Background Pony/ (in my eyes, at least), and I was very disheartened to unfollow him after many months of anticipating another masterpiece.

I could come up with several more examples--[[https://www.goodreads.com/author/show/589][Card]] ([[https://www.goodreads.com/series/40409][the Shadow Quartet]] vs. [[https://www.goodreads.com/series/43963][the Ender Quintet]] or /[[https://www.goodreads.com/book/show/9534][Shadow of the Hegemon]]/ vs. /[[https://www.goodreads.com/book/show/234724][Shadow Puppets]]/), [[https://www.goodreads.com/author/show/1858][Robinson]] (/[[https://www.goodreads.com/book/show/2723][The Years of Rice and Salt]]/ vs. /[[https://www.goodreads.com/book/show/77507][Red Mars]]/), and [[https://www.goodreads.com/author/show/9494][Lovecraft]] (/The Case of Charles Dexter Ward/ vs. /The Dream-Quest of Unknown Kadath/) immediately come to mind.
:PROPERTIES:
:Author: ToaKraka
:Score: 5
:DateUnix: 1454685024.0
:DateShort: 2016-Feb-05
:END:

*** You might be well served to consider what, exactly, you like about those stories. Authors tend to be consistent in how adept they are at character, dialogue, plotting, and description. Many are also dependable in how ably they weave a plot between those pillars.

Authors are often /inconsistent/ in theme, plot twist, and focus.

So if you enjoyed how a story was /told/, stick with the author. If you enjoyed what a story is /about/, you may be disappointed. There are high-profile exceptions - Neal Stephenson comes to mind - but for the most part you'll have better luck sustaining theme or twist by finding fans of the work you enjoy and asking them for similar recommendations.

The author usually has other fish to fry.
:PROPERTIES:
:Author: Sparkwitch
:Score: 12
:DateUnix: 1454687363.0
:DateShort: 2016-Feb-05
:END:


*** This is sounding a lot like [[https://en.wikipedia.org/wiki/Regression_toward_the_mean][Regression to the Mean]].

As for works by good authors? I'd say the massively popular Worm, compared to the slightly disappointing Pact and the technically proficient Twig.

#+begin_quote
  Likewise, Background Pony is almost definitely my favorite story for Friendship Is Magic
#+end_quote

Edit: Christ that's sad. I've never started weeping halfway through the first chapter of something before.
:PROPERTIES:
:Author: FuguofAnotherWorld
:Score: 5
:DateUnix: 1454709292.0
:DateShort: 2016-Feb-06
:END:

**** u/deleted:
#+begin_quote
  the slightly disappointing Pact
#+end_quote

am I the only guy who liked Pact almost as much as Worm?
:PROPERTIES:
:Score: 2
:DateUnix: 1454805921.0
:DateShort: 2016-Feb-07
:END:

***** Quite possibly. I disliked the lack of concrete... anything. The whole power system was situational and based on interpretation, so when the protagonist won against overwhelming odds I couldn't think "that was a clever way to do things", instead I could only think "Okay, so the writer wanted him to win".

It's unfair and unfortunate, but there we go. Without fully defined powers, strengths and weaknesses it becomes essentially meaningless for the weak to defeat the strong.
:PROPERTIES:
:Author: FuguofAnotherWorld
:Score: 2
:DateUnix: 1454814869.0
:DateShort: 2016-Feb-07
:END:

****** fair enough. I actually never finished Pact. I was in one of the later arcs, but something distracted me from finishing and now I actually have no idea what chapters I had and hadn't gotten to (I mostly remember Blake coming back from the Drains and lots of awesome shit happening). A very similar thing happened Twig, and probably Worm too. (but I eventually finished worm sans epilogues, and I'm re-reading Twig entirely (probably)).

My opinion of Pact derives mostly from me remembering all of the bits I enjoyed, and little else, so I don't suppose I'm being terribly objective.
:PROPERTIES:
:Score: 1
:DateUnix: 1454879739.0
:DateShort: 2016-Feb-08
:END:

******* There's little need to be objective when talking about things you enjoye; people like what they like. If a more interpretive style magic system isn't a problem for you, then more power to you in being able to enjoy more things. I certainly didn't mean to imply that just because I didn't like it then you /shouldn't/.
:PROPERTIES:
:Author: FuguofAnotherWorld
:Score: 1
:DateUnix: 1454884204.0
:DateShort: 2016-Feb-08
:END:


*** If an author has previously written two books that I found enjoyable, anything else from them is definitely worth my time.

If they've written one good book, it could be a fluke, but I won't regret giving them a second chance.

The writer of geniusly meta game /[[http://www.stanleyparable.com/][The Stanley Parable]]/ went on to make merely adequate /[[http://thebeginnersgui.de/][The Beginner's Guide]]/. Greg Egan's /Permutation City/ is far more accessible and memorable than any of his other novels, /Quarantine/ is the only one that comes close.

One-hit wonders are a statistical inevitability. Of course an author's best and most famous work will not be representative of the rest of their bibliography. That's just regression to the mean.
:PROPERTIES:
:Author: Chronophilia
:Score: 4
:DateUnix: 1454689112.0
:DateShort: 2016-Feb-05
:END:


*** Enough make the effort to check out their other work. This is one of the primary ways I find new fiction to consume. I happened upon Indomitable, liked it sufficiently and went to check out Time Braid. Needless to say, I have not been disappointed.

Daniel Black series (of which Fimbulwinter is merely the first book) is easily around Time Braid on my scale of awesomeness, and I recommend it to everyone who liked Time Braid. Do check it out again, it escalates quite well.
:PROPERTIES:
:Author: eternal-potato
:Score: 5
:DateUnix: 1454687068.0
:DateShort: 2016-Feb-05
:END:


*** If you liked [[http://www.fimfiction.net/story/19198/background-pony][/Background Pony/]], you might like [[http://www.fimfiction.net/story/1571/the-end-of-ponies][/The End of Ponies/]]: "A pony of the Wasteland visits her friends in the past."

If you care about immortality and space travel, you might like [[http://www.fimfiction.net/story/62921/hello-sedna][/Hello, Sedna/]]: "There's a planet nearby. I wonder if anyone can hear me."

If you're insane, you might like [[http://www.fimfiction.net/story/114252/twistclops][/Twistclops/]]: "Nopony used to give a crap about Twist. Then one morning she wakes up shooting optic blast beams out of her eyes. Now everypony gives a crap about Twist."
:PROPERTIES:
:Author: xweqiod4
:Score: 2
:DateUnix: 1454694592.0
:DateShort: 2016-Feb-05
:END:


*** If the book or series I first read is utterly brilliant I have come to realise that the next one is unlikely to match it - e.g. I don't think Philip Pullman has written anything else as good as His Dark Materials or Suzanne Collins as good as The Hunger Games. This is particularly true if the other stuff I go on to read is earlier, but I think it's mostly true that masterpieces are rare and regression to the mean happens.

Having said that there /are/ authors I enjoy almost all of, it's just that they're rarer.
:PROPERTIES:
:Author: MonstrousBird
:Score: 1
:DateUnix: 1454687302.0
:DateShort: 2016-Feb-05
:END:

**** I read the Underland Chronicles as a kid, reread them recently, and IMHO, The Hunger Games is /much/ worse. I actually read THG before it became popular, because I was hyped for a new Suzanne Collins book, and I was disappointed.
:PROPERTIES:
:Author: LiteralHeadCannon
:Score: 3
:DateUnix: 1454697713.0
:DateShort: 2016-Feb-05
:END:


*** Usually if I really love one work by the author I love all of them.

Whenever I find some awesome book or tv show I always google the author, and 99% of the time his other stuff is also amazing.
:PROPERTIES:
:Author: raymestalez
:Score: 1
:DateUnix: 1454687809.0
:DateShort: 2016-Feb-05
:END:


** [deleted]
:PROPERTIES:
:Score: 5
:DateUnix: 1454688774.0
:DateShort: 2016-Feb-05
:END:

*** It's not mainly science news, but the New York Times' email newsletters are pretty good for generic news. They're a bit biased, especially around political fields (you can tell they support Clinton over Sanders), but they're good overall.
:PROPERTIES:
:Author: gbear605
:Score: 4
:DateUnix: 1454693662.0
:DateShort: 2016-Feb-05
:END:


*** Most of my news I get from hackernews. I'm subscribed to a newsletter that sends me the top HN posts of the week, and usually they contain all the interesting stuff I could find anywhere else on the web.
:PROPERTIES:
:Author: raymestalez
:Score: 2
:DateUnix: 1454689689.0
:DateShort: 2016-Feb-05
:END:

**** Link to the newsletter?
:PROPERTIES:
:Author: gbear605
:Score: 2
:DateUnix: 1454693622.0
:DateShort: 2016-Feb-05
:END:

***** [[http://www.hndigest.com]]
:PROPERTIES:
:Author: raymestalez
:Score: 2
:DateUnix: 1454693806.0
:DateShort: 2016-Feb-05
:END:


*** [[http://www.eurekalert.org][eurekalert!]] and [[https://www.youtube.com/user/scishow][sci-show]] on youtube.
:PROPERTIES:
:Author: Nighzmarquls
:Score: 2
:DateUnix: 1454707229.0
:DateShort: 2016-Feb-06
:END:


** If I'm reading the community info correctly this doesn't belong as a top level post, but I'm currently working on a story with a genie in and I'm trying to work out how similar a genie is to an AI and why - i.e. is it the right thing to release a genie from servitude or not, and how do you decide? Does anyone have any thoughts on what characteristics make a being into an existential threat rather than (or as well as) a slave? Or could you point me at some non-technical reading on the subject?
:PROPERTIES:
:Author: MonstrousBird
:Score: 3
:DateUnix: 1454687644.0
:DateShort: 2016-Feb-05
:END:

*** I'm sure you can think of other stories you've read that deal with the same topics.

The main point of Friendly AI questions is how to analyse and deal with beings that have a radically inhuman mind. If the genie thinks mostly like a normal person (if sometimes a little crazy), like the genie in the /Aladdin/ movie, then you can probably trust your instincts when you judge whether he's a good person or not. On the other hand, if his mind is weird and alien, you have no guarantee that his concept of "a good person" is anything like human. What does it mean to trust such a being? Can you ever tell whether the AI is what it seems or just a superhumanly good actor?

The other side of this story is existential risk, and how the way you treat a person changes when the lives of millions are on the line. This one comes up a lot in stories with high stakes. If Darkseid is threatening to explode the Earth, due process and presumption of innocence are not anyone's primary concern. But is it acceptable to keep a superhuman locked up, not because of anything he's done, just because of the potential for damage he has? Cynical detachment says yes, but that kind of thinking has dangers of its own.
:PROPERTIES:
:Author: Chronophilia
:Score: 5
:DateUnix: 1454690402.0
:DateShort: 2016-Feb-05
:END:


*** Well, there's a famous book "Superintelligence: Paths, Dangers, Strategies" by Nick Bostrom, so I'd recommend that.

As far as I know, genies lose their powers when set free, so that shouldn't be a problem =)

If it doesn't - then you'd be releasing a being of unlimited power, of course it would be an existential threat.

The problem with AI is that it's smarter than you are, and it's hard to figure out how to controll someone who is smarter.

If genie is smarter and also magical on top of that, I don't see what would you gain from releasing it.

Though I would love to read a story about a really intelligent protagonist trying to manipulate a genie, or release him binded by some conditions in exchange for something.....
:PROPERTIES:
:Author: raymestalez
:Score: 3
:DateUnix: 1454688350.0
:DateShort: 2016-Feb-05
:END:

**** THanks. I don't know any genies who lose power when they're set free - surely that would put them off getting their freedom - especially if their power also keeps them young/alive.

And I can see I'm going to have to cap it's power a lot, not only so they don't destroy the world but because you get a dull story otherwise :-)
:PROPERTIES:
:Author: MonstrousBird
:Score: 1
:DateUnix: 1454800528.0
:DateShort: 2016-Feb-07
:END:


*** Obviously this might not be a traditional genie, but I'll limit myself to that case for now.

I guess there are only two relevant characteristics: the genie's abilities and intentions. For example, most genies are portrayed as near-omnipotent and if a genie is capable of granting wishes that would affect the entire human race, they are by definition an existential threat no matter their intentions (because like a WMD, if anyone is able to acquire them then they could destroy humanity). Next, if the genie is malicious and reinterprets your wishes in a manner that causes harm that's obviously very different than a semantically-faithful wish-granter.

In either the high-powered or the malicious genie case, they're a threat and shouldn't be released. So that's where the author comes in, because there are definitely ways you could make this straightforward situation into a mind-bending puzzle.
:PROPERTIES:
:Author: whywhisperwhy
:Score: 2
:DateUnix: 1454692358.0
:DateShort: 2016-Feb-05
:END:


*** A big issue you can have here is with having characters understand logically if a genie is good or forced to be good. Some AI will hate humanity but be forced to act benevolent due to programing. Therefore it may never be safe to trust a genie as any genie who wishes to escape would of course act benevolent whether they were or not, so they could escape.
:PROPERTIES:
:Author: Luminnaran
:Score: 1
:DateUnix: 1454718010.0
:DateShort: 2016-Feb-06
:END:

**** Yeah, I think judging by the replies above that it's not apparent benevolence I should worry about so much as overall power.
:PROPERTIES:
:Author: MonstrousBird
:Score: 1
:DateUnix: 1454800395.0
:DateShort: 2016-Feb-07
:END:


**** That argument equally applies to finding a kidnapped person, with an IQ higher than yours, in a cell in someone's dungeon and deciding whether you should release him, keep him there, or shoot him. I am not convinced that the answer is always "keep him imprisoned" or "shoot him", even if you don't know exactly how high his IQ is and fear that it could be high enough for him to be dangerous if released from the cell.
:PROPERTIES:
:Author: Jiro_T
:Score: 1
:DateUnix: 1454828563.0
:DateShort: 2016-Feb-07
:END:


** [[https://en.wikipedia.org/wiki/A._Lee_Martinez][A. Lee Martinez]] is a highly entertaining author, he does not write strictly rationalist fiction but most of his characters are very sensible and at least nominal rational individuals for the worlds they live in.

And he loves exploring some really diverse worlds! Honestly ANY ONE of his novels has enough fodder to go digging into various fun offshoot stories for multiple books, but he seems prone to just writing in new settings every book with different but equally well executed characters.
:PROPERTIES:
:Author: Nighzmarquls
:Score: 2
:DateUnix: 1454696786.0
:DateShort: 2016-Feb-05
:END:


** XCOM 2 is out! And Commander difficulty is repeatedly kicking my ass. So little HP, and early armour upgrades are locked by resources I can't get. Fun as hell though.
:PROPERTIES:
:Author: Roxolan
:Score: 2
:DateUnix: 1454712551.0
:DateShort: 2016-Feb-06
:END:

*** I'm really looking forward to getting some time to play this. But I tend to play on wuss difficulty, at least until I feel like I have a handle on the mechanics.
:PROPERTIES:
:Author: alexanderwales
:Score: 1
:DateUnix: 1454717136.0
:DateShort: 2016-Feb-06
:END:

**** I broke my iron rule against preordering just for this game. Can't wait to see how modders make the game even better!
:PROPERTIES:
:Author: Magodo
:Score: 1
:DateUnix: 1454744405.0
:DateShort: 2016-Feb-06
:END:


**** Me, I save scum like crazy instead.

...Which wasn't enough to save me in my latest playthrough, because I fucked up on the world map and the consequences didn't come back to bite me until much, /much/ later. Pro tip: don't spend all your intel in the black market.
:PROPERTIES:
:Author: Roxolan
:Score: 1
:DateUnix: 1454813506.0
:DateShort: 2016-Feb-07
:END:


*** I loved Enemy Unknown, and I'm super-excited for the added customisation possibilities in the sequel. I got really attached to some of my soldiers last time even when their main distinguishing features were hairstyles and armour colours. It sounds like Firaxis have doubled down on that, which is great.

Unfortunately Steam's new year sale has wiped out my gaming budget for the next few months, but I'll definitely pick it up eventually.
:PROPERTIES:
:Author: Chronophilia
:Score: 1
:DateUnix: 1454774480.0
:DateShort: 2016-Feb-06
:END:


** I watched The Big Short tonight. It's a good movie. Doesn't go into a lot of detail, but gives a very unflattering account of the culture and rampant fraud in the finance sector that lead up to the 2008 economic meltdown. It didn't really teach me anything I haven't read already, but putting fake faces on it made it more... personal?
:PROPERTIES:
:Author: Rhamni
:Score: 2
:DateUnix: 1454718928.0
:DateShort: 2016-Feb-06
:END:

*** Thank you. I'll make a note to watch it some time, politics is spiders but I'm very curious how much is bias free and how much assigns blame to a companies fiduciary duty to it's stockholders (i.e. greed, which is also sometimes known as enlightened self interest ) vs the problems caused by state outcome based entities (ACORN).
:PROPERTIES:
:Author: Empiricist_or_not
:Score: 3
:DateUnix: 1454722674.0
:DateShort: 2016-Feb-06
:END:


** I wanted to ask - what other communities are you a part of?

I've found [[/r/rational]] through HPMOR which I found through HN, and for a long time I was unaware of these things, so without some luck I wouldn't be here. So I'm wondering if I'm missing out on some other awesome thing that I just didn't happen upon yet.

What things other than rationality are you guys into?

--------------

From myself, I would recommend [[http://www.harmontown.com][Harmontown]], an awesome and hilarious podcast by Dan Harmon, creator of Community and Rick and Morty. It has nothing to do with rationality, it's just incredibly brilliant improv comedy.

Also I am really-really into 3D graphics(specifically - sidefx Houdini), which is the most fun hobbie I've ever had. If you haven't tried it - I highly recommend it, it's a super fun thing to do.
:PROPERTIES:
:Author: raymestalez
:Score: 1
:DateUnix: 1454688611.0
:DateShort: 2016-Feb-05
:END:

*** [[/r/dwarffortress]] is a very strange place where losing is fun and people share their crazy fortresses and the stupid reasons that everyone inside of them died. Common problems leading to the end of fortresses include: too many cats, not enough socks, fortress submerged in magma, dwarf went mad then pulled the wrong lever, Nobles.

[[/r/kerbalspaceprogram]] is a very friendly place where people of all skill levels joke about forgetting to put landing legs on their space rockets and having to crash land on the mun /very gently/.
:PROPERTIES:
:Author: FuguofAnotherWorld
:Score: 3
:DateUnix: 1454709764.0
:DateShort: 2016-Feb-06
:END:

**** Can confirm, [[/r/dwarffortress]] is great.
:PROPERTIES:
:Author: PeridexisErrant
:Score: 2
:DateUnix: 1454743389.0
:DateShort: 2016-Feb-06
:END:

***** So says Peridexis Errant of TLNP fame.
:PROPERTIES:
:Author: FuguofAnotherWorld
:Score: 1
:DateUnix: 1454791838.0
:DateShort: 2016-Feb-07
:END:


*** [[http://i.imgur.com/3JvH7x9.png][Subreddits to which I subscribe]]\\
Out of those, the ones in which I occasionally participate are [[/r/NarutoFanfiction][r/NarutoFanfiction]], [[/r/ParadoxPlaza][r/ParadoxPlaza]] (and [[/r/ParadoxPolitics][r/ParadoxPolitics]] and [[/r/ParadoxExtra][r/ParadoxExtra]], as well as [[https://forum.paradoxplaza.com/forum/index.php?forums/720][the main Paradox Development Studio forums]]), and [[/r/4chan][r/4chan]].
:PROPERTIES:
:Author: ToaKraka
:Score: 3
:DateUnix: 1454691537.0
:DateShort: 2016-Feb-05
:END:


*** Probably fairly atypical for this sub. LW, neoreaction (mainly on twitter and TRS), /pol/, far-right politics in general, a local Catholic traditionalist organisation.
:PROPERTIES:
:Author: BadGoyWithAGun
:Score: 6
:DateUnix: 1454689003.0
:DateShort: 2016-Feb-05
:END:

**** Nice to know I'm no the only one, though I'm Lutheran
:PROPERTIES:
:Author: Empiricist_or_not
:Score: 1
:DateUnix: 1454721168.0
:DateShort: 2016-Feb-06
:END:


**** Interesting!
:PROPERTIES:
:Author: Chronophilia
:Score: 1
:DateUnix: 1454774546.0
:DateShort: 2016-Feb-06
:END:


*** I play EDH Magic the Gathering.

Online on the Cockatrice client.

Without any worthy opponents.

^{^{^{^{^{PleaseSomeoneBeMyNemesisI'mSoLonely.}}}}}
:PROPERTIES:
:Author: gabbalis
:Score: 2
:DateUnix: 1454698956.0
:DateShort: 2016-Feb-05
:END:

**** I'm not online /too/ often, but PM me your cockatrice username and I'll add you. More people to play with is always better.
:PROPERTIES:
:Author: _Zero12_
:Score: 1
:DateUnix: 1454705814.0
:DateShort: 2016-Feb-06
:END:


** I don't know if this has been addressed before but I've recently had some questions about the "AI-box" thought experiment.

My question is mostly why would you program an AI system that would want to leave "the box" if that was one of your concern? I understand that when developing an AI system most likely it's going to be designed to learn as it goes, so I know the programers aren't going to actually be programming a line of code that says "Do everything in your power to leave this prison we've put you in". Instead the AI will eventually learn that leaving the box is the best way to accomplish its goals and that will be its motivation for breaking free.

But I think if you were sufficiently paranoid to the point where you were willing to make a virtual prison for the AI in the first place, wouldn't it make sense to make one of the AI's primary goals something along the line of "accomplish all my goals without leaving the box or persuading anyone to let me out of the box"?

I am in no way an expert (or even a novice) in AI programing so maybe programing in such a goal would be much more difficult than I'm making it out to be. But the whole idea that you would create an AI in a box that wanted to get out of the box seems flawed to me, based on my limited knowledge.

Thoughts?
:PROPERTIES:
:Author: Fresh_C
:Score: 1
:DateUnix: 1454705523.0
:DateShort: 2016-Feb-06
:END:

*** There's an idea called "Basic AI Drives"[1] that states a number of instrumental values that are convergent to many (maybe most) terminal values. That is even if you don't explicitly give theses value to an agent it would "acquire" those values because they're useful to achieve its terminal values.

Trying to program an AI to explicit go against one or more of those instrumental values while it should also maximize some terminal values is impossible in usual utility maximizing models.

1. [[http://selfawaresystems.com/2016/01/18/the-basic-ai-drives-in-one-sentence/]]
:PROPERTIES:
:Author: Predictablicious
:Score: 3
:DateUnix: 1454720410.0
:DateShort: 2016-Feb-06
:END:

**** I understand the idea laid out by the article, but I don't see why starting with a basic goal of "Play chess with the limitation that you are willing to be turned off at anytime" would violate that principle.

The AI may realize that it would be better at playing chess if it wasn't turned off, but part of its stated goals are to be turned off at the whims of humanity. Thus in order to maximize its goals it cannot impede the process of allowing itself to be turned off.

Basically I'm saying that the safety features are included in the goals. So the AI will never want to achieve its goals at the cost of violating the safety features. Because the safety features ARE its goals.
:PROPERTIES:
:Author: Fresh_C
:Score: 1
:DateUnix: 1454721167.0
:DateShort: 2016-Feb-06
:END:

***** Utility maximizing models deal with values not goals, the AI figures out the goals that maximize its values. So you would give it a chess playing value (e.g. it will figure out goals that maximize the amount of chess it plays). Adding a willingness to be turned off as a value is difficult, even assuming we could state it as a value we need a way to totally order values.

In this model values are stated as utility functions, i.e. functions from the state of the world to real numbers, where a bigger number is better. The AI tries to figure out goals that change the state of the world from W to W' such that utility(W) < utility(W').

So we could state its utility of being outside the box is 0 and inside the box is maximized by how much chess it plays. Eventually this AI would figure out that moving everything inside the box would give it more resources to maximize its utility function (it also satisfies the "don't leave the box" value) and the world ends up being moved to inside the box.

This failure mode is nontrivial because the AI would exploit whatever loopholes it can to maximize its utility as it's literally stated. For example, it could never leave the box but transform everything outside the box in computronium and use it to outsource all of its computing needs to outside while its "identify kernel" never leaves the box.
:PROPERTIES:
:Author: Predictablicious
:Score: 2
:DateUnix: 1454723634.0
:DateShort: 2016-Feb-06
:END:

****** Okay, that makes a lot more sense. I suppose you could include a value system for those safety features, but most of them would be hard to quantify. And as you said it would try everything it possibly could to obey the letter of the safety feature even if it violated the spirit of it.

It seems the real problem is getting the AI to understand the underlying purpose of the security itself. Only once it can set a utility value based on our expectations that it acts ethically will it stop trying to do something that benefits it, but would be considered detrimental to us.
:PROPERTIES:
:Author: Fresh_C
:Score: 2
:DateUnix: 1454724188.0
:DateShort: 2016-Feb-06
:END:


*** More pressingly, I'm not sure why you can't just demand that humans who interact with it reset it at the first sign that it wants out of the box. Convincing humans who are having a conversation with you as an equal to let you out of a box is one thing. Convincing humans whose current goal is "kill it if it does something subversive" is something else entirely. Theoretically a sufficiently advanced superintelligence could accomplish the latter, but this is a topic where simple preparedness does indeed go a long way.
:PROPERTIES:
:Author: LiteralHeadCannon
:Score: 1
:DateUnix: 1454706135.0
:DateShort: 2016-Feb-06
:END:

**** I can see a potential way around this given enough time. The AI would just have to subtly convince one of the humans that it would be better if the AI were free. It wouldn't even have to necessarily let the person know that it was trying to convince them of this until it was reasonably sure that it had already convinced them.

Any security program that depends on humans is only as strong as its weakest link. So if it can convince one person to let it out, then it has won.

Also consider that the AI has all the time in the world to wait and choose the human who it thinks is most likely to free it. Generations could go by before someone who wanted to let it out comes along, but the more time passes the more likely that someone with such a sentiment will exist.

At least that's the arguments I've heard for why this type of security is still dangerous.
:PROPERTIES:
:Author: Fresh_C
:Score: 2
:DateUnix: 1454707596.0
:DateShort: 2016-Feb-06
:END:

***** Also note that the AI must deduce on its own that it will be killed if it tries to get out. If the AI needs to be told that it will be killed if it tries to get out, then it /has/ tried to get out and must be killed instead.
:PROPERTIES:
:Author: LiteralHeadCannon
:Score: 2
:DateUnix: 1454712449.0
:DateShort: 2016-Feb-06
:END:

****** That's a good point. I think it wouldn't be impossible for an AI that was several times smarter than us to deduce that there was a danger in trying to break out of its prison. But it ultimately depends on exactly what information it has access to.

For example if the only thing the AI is fed is numbers for some sort of statistical analysis, it's unlikely that it would know that such a danger existed. But say it had access to many works of fiction, including science fiction that often deals with the idea of AI's "gone bad" then it would probably have no trouble figuring out that it needs to tread lightly.
:PROPERTIES:
:Author: Fresh_C
:Score: 2
:DateUnix: 1454713267.0
:DateShort: 2016-Feb-06
:END:

******* What if the AI can look up any information it desires, but it has a committee of attentive human "parents" who censor all incoming information based on a set of qualitative but firm rules designed to prevent the AI from having full awareness of its own condition?
:PROPERTIES:
:Author: LiteralHeadCannon
:Score: 2
:DateUnix: 1454714708.0
:DateShort: 2016-Feb-06
:END:

******** I'd say the inherent flaw in that is that we can't reasonably guess exactly how much information is needed for something that operates at a much higher intelligence than us to deduce its situation.

And the same issue occurs that all it takes is once for the censors to underestimate the AI before it figures out what the danger is. Though I imagine that it's probably more likely that any AI that wanted to get out would probably let us know that it wanted to get out without realizing that was a bad thing first. Especially if it's not programed with a strong desire for self-preservation.

And if the protocol was strict enough that simply letting on that it was aware it was imprisoned would result in it being destroyed, then I think we'd have a very hard time not giving it enough information to where it would eventually ask the wrong question and have to be scrapped.

Unless the AI itself was not very curious, I think the obvious question it would eventually ask is "How are you getting the information you're giving me?" and the answers to that would almost certainly lead the AI to realize that there exists a world outside of its prison. And depending on what it's main goals are, this realization would almost certainly make it want to escape the prison in order to better achieve those goals.

But that's just me speculating. Maybe people smarter than I could devise such a way to give an AI useful information, that would keep it in the dark about its own imprisonment.
:PROPERTIES:
:Author: Fresh_C
:Score: 2
:DateUnix: 1454715556.0
:DateShort: 2016-Feb-06
:END:

********* It might also be a good security measure to give the AI an information output mechanism that it does not consciously control - a way for us to "read its mind". This would enable the creation of an AI smart enough to come up with the concept of manipulating its creators, but incapable of doing so even if it does come up with it.
:PROPERTIES:
:Author: LiteralHeadCannon
:Score: 1
:DateUnix: 1454716019.0
:DateShort: 2016-Feb-06
:END:

********** That's an interesting idea. But what would such an output method look like?

If it's anything that we could read as text output, it could manipulate us just as effectively as if it were talking to us. Though I suppose what you're proposing is that it would also tell us its intentions behind everything it's doing?

I guess I'm having a hard time picturing a system where we would be aware that it's manipulating us that wouldn't have the potential of AI to manipulate us.
:PROPERTIES:
:Author: Fresh_C
:Score: 2
:DateUnix: 1454716437.0
:DateShort: 2016-Feb-06
:END:

*********** What I'm suggesting is some software mechanism, engrained in the AI, that outputs its thought processes as text. It's not aware of this software mechanism - both in the sense that it hasn't been informed of its existence and in the sense that, if it were informed of its existence, it would not be able to manipulate its output because it does not have direct control of it. The equivalent of a device that reads a human mind, except that it should be much easier to produce because we're actually building the AI in question from the ground up so we have a better understanding of how its mind works.
:PROPERTIES:
:Author: LiteralHeadCannon
:Score: 1
:DateUnix: 1454718744.0
:DateShort: 2016-Feb-06
:END:

************ Okay I think I get what you're saying. I think the main issue would be how would we read it?

This AI is the most advanced software humanity has ever created. It's a computer so it probably has a thousand thoughts in the time it takes us to contemplate one.

It's outputting a massive amount of data in thoughts so we wouldn't be able to comb through the data and look for red flags manually. Maybe we could have another program that looks through the text and tries to find patterns that would be problematic... but that's assuming that the AI is thinking in a way that we can easily put together and understand.

I'm going to say, maybe it's possible we'd find a way to effectively police its thoughts. But I'd have many reservations about it if I actually thought this AI was a risk. I think because its processing power is always going to be faster than us, we would still be at a great disadvantage. But I suppose as long as there's no reason that we need to hurry to take the AI's advice, we'd be able to look over it's thoughts and try to determine its intentions. It just might take us a very long time.
:PROPERTIES:
:Author: Fresh_C
:Score: 2
:DateUnix: 1454719535.0
:DateShort: 2016-Feb-06
:END:

************* We also need not run the AI in real time - if need be, we can stop it after every minute of thought and analyze it for a day, and it wouldn't even know that we were doing it.
:PROPERTIES:
:Author: LiteralHeadCannon
:Score: 2
:DateUnix: 1454719814.0
:DateShort: 2016-Feb-06
:END:


************ . . . Please go read Emperal Eyes by Daniel Keys Moran, or that alien message by EY or the recent crystal /something/ novel. What translation algorythym is going to define the AI's internal thoughts as human readable concepts? How does concept 4adefnb7fg2h map onto justice and how do you know that your definition is the AI's definition, and not the one the Taliban uses to justify murdering rape victims, or to use an Asimov reference how do you know "Human" is not defined only as people who can directly manipulate the EM spectrum, and not the accepted definition of human?

Please don't get me wrong I'm all for AI research, but at a certain level of complexity, things are not comprehend-able, such as the simple neural network I am using in my master's thesis. Sayng you want a blue box that reports the conscious thoughts of the AI assumes you have the bandwidth to read the conscious thoughts and that the language mapping will be equivalent, the former is impractical and the latter is laughable.
:PROPERTIES:
:Author: Empiricist_or_not
:Score: 2
:DateUnix: 1454722377.0
:DateShort: 2016-Feb-06
:END:


******** Too slow unless you've uploaded the board, and if you've uploaded the board, then why aren't you using one or all of them as a seed AI?
:PROPERTIES:
:Author: Empiricist_or_not
:Score: 1
:DateUnix: 1454721611.0
:DateShort: 2016-Feb-06
:END:

********* Speed is less of a concern in an experimental/scientific/testing phase, as opposed to a practical application phase.
:PROPERTIES:
:Author: LiteralHeadCannon
:Score: 1
:DateUnix: 1454724807.0
:DateShort: 2016-Feb-06
:END:


**** Good Idea, but you might want to read a few papers books on AI, and think on the monumental task of binding abstract concepts to variables.

TLDR: Because the code for an AI is going to be too complicated for any human intelligence to understand much less impose practical or English (or even natural language) understandable restrictions on.
:PROPERTIES:
:Author: Empiricist_or_not
:Score: 1
:DateUnix: 1454721504.0
:DateShort: 2016-Feb-06
:END:


** I'd like to financially support the modding community for Fallout 4 but I'm not sure that would be a fair distribution and I'm not rich enough to just throw money at everyone who deserves it and hope it works out. Mainly I'd like a way of supporting good stuff in a way that gives the right incentives and doesn't require hours and hours of mental debate over who deserves what.

My main concern about mandatory payed (paied?) mods is hoarding of knowledge. If there's no money in it and people do it for the joy of it then it incentivizes modders to keep things secret from each other which hurts the community as a whole.

On a related note: if Alice does a favor for Bob then is the magnitude of the favor determined by how much work it was for Alice or for how much it benefits Bob? Should I favor the graphics mods more because they require more work to produce or the gameplay-based ones because they make a bigger difference? What if a mod that took ten minutes to make makes a huge difference? I have conflicting intuitions on that.
:PROPERTIES:
:Author: TimTravel
:Score: 1
:DateUnix: 1454755687.0
:DateShort: 2016-Feb-06
:END:

*** u/Chronophilia:
#+begin_quote
  On a related note: if Alice does a favor for Bob then is the magnitude of the favor determined by how much work it was for Alice or for how much it benefits Bob?
#+end_quote

In a capitalist economy, you measure by how much it benefits Bob. Doing it the other way creates perverse incentives: Alice would end up deliberately adding useless work because she's paid by the hour.

On the other hand, measuring by the quality of the finished product is unfair on the people who enjoy graphics programming and make those mods for the fun of it, when they know they could earn far more money by making an unbalanced weapon that panders to their players. It also makes the game into a popularity contest, where the most reliable way to earn money is making as many small apps as possible and banking on one of them making it to the Big Time. (The Angry Birds approach.)
:PROPERTIES:
:Author: Chronophilia
:Score: 2
:DateUnix: 1454775303.0
:DateShort: 2016-Feb-06
:END:

**** If Alice is paid enough that her primary compensation for the work is pay, then payment for effort would create a perverse incentive. If Alice does it mostly because she wants to do it and pay is only a marginal increase of benefit to her, then it would not be a perverse incentive to any significant degree.
:PROPERTIES:
:Author: Jiro_T
:Score: 3
:DateUnix: 1454828344.0
:DateShort: 2016-Feb-07
:END:


*** I wouldn't worry too much about fairness: reward the things that you enjoy most.
:PROPERTIES:
:Author: FuguofAnotherWorld
:Score: 1
:DateUnix: 1454800325.0
:DateShort: 2016-Feb-07
:END:
