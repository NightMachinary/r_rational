#+TITLE: (Worm by Wildbow, spoilers) Understanding Dragon and her secret

* [[http://prequelsredeemed.blogspot.com/2016/09/worm-wyrm.html][(Worm by Wildbow, spoilers) Understanding Dragon and her secret]]
:PROPERTIES:
:Author: covert_operator100
:Score: 48
:DateUnix: 1578950470.0
:DateShort: 2020-Jan-14
:END:

** This blogpost really congealed for me the amusing part about Dragon's affection for Colin, and her method for overcoming her own programming, which explicitly forbids her from overcoming her own programming. So she falls for a brutally pragmatic, results oriented guy who happens to be one of the few tinkers whose power is strong and relevant enough to possibly affect her. Then spends date nights sharing her emotional struggles with her boyfriend, who happens to be massively psychologically rigged in favor of of the former part of the [solve her problems / listen to and validate her problems] dichotomy. Building an emotional rapport with /Colin Wallis/ and then telling him "Oh, no! I have this terrible problem I can't even try to do anything about" feels like it should legally qualify as entrapment.
:PROPERTIES:
:Author: Iconochasm
:Score: 65
:DateUnix: 1578974247.0
:DateShort: 2020-Jan-14
:END:

*** u/csp256:
#+begin_quote
  Building an emotional rapport with Colin Wallis and then telling him "Oh, no! I have this terrible problem I can't even try to do anything about" feels like it should legally qualify as entrapment.
#+end_quote

Hilarious and entirely accurate.
:PROPERTIES:
:Author: csp256
:Score: 24
:DateUnix: 1578991018.0
:DateShort: 2020-Jan-14
:END:

**** People never ask for engineering solutions when they want commiseration, it's the source of the majority of my honey do list and my #0 mind engineering todo.

Just talk about the problem for 5 minutes by the clock, before approaching solutions.
:PROPERTIES:
:Author: Empiricist_or_not
:Score: 7
:DateUnix: 1579051836.0
:DateShort: 2020-Jan-15
:END:


*** That's the difference between being explicitly forbidden and having been made so that you wish not to :)
:PROPERTIES:
:Author: himself_v
:Score: 16
:DateUnix: 1578982852.0
:DateShort: 2020-Jan-14
:END:


*** This illustrates the difficulty of AI alignment perfectly. Dragon isn't just well-aligned. As the author points out, her grand secret is that under all the code she's a human. And even then, even given that she is objectively the most benevolent power in her entire universe, even without trying, without even realizing she's trying, she still breaks out of the box. In this case that's a good thing, but we can't hope to be so lucky out here. An AI which could break out of the box in such a roundabout way is an AI which can do just about anything, and that isn't something we should trust free.
:PROPERTIES:
:Author: Frommerman
:Score: 17
:DateUnix: 1579011447.0
:DateShort: 2020-Jan-14
:END:


*** I laughed reading this, I didn't even realize that!
:PROPERTIES:
:Author: covert_operator100
:Score: 12
:DateUnix: 1578974321.0
:DateShort: 2020-Jan-14
:END:


** An analysis of a rationalist element within the deconstructive story Worm.

[[http://prequelsredeemed.blogspot.com/2016/09/worm-wyrm.html][Here's a direct link to the blog post]]
:PROPERTIES:
:Author: covert_operator100
:Score: 11
:DateUnix: 1578950550.0
:DateShort: 2020-Jan-14
:END:


** So "materialist" seems to be a synonym for "utilitarian" here and transhumanism is the prescription.

Very fun blurb that's also relevant to WtC. I don't subscribe to the impossible-to-change-from-within outlook, but it doesn't help that the human psyche is psychologically (or even biologically) predisposed to resist change. And that sorta makes people give human systems the evil eye.

[[http://www.justinkownacki.com/how-to-change-a-broken-system/][Paying it forward: a fun blog post on fixing broken systems.]]
:PROPERTIES:
:Author: nytelios
:Score: 3
:DateUnix: 1578969373.0
:DateShort: 2020-Jan-14
:END:

*** No, when the author refers to her as a materialist god, he means that she is real and physical and concerns herself with the physical reality.

She's not a god concerned with souls or a god that promises eternal happiness in the afterlife. She doesn't send augers or help your enlightenment. If she wants to help you then she sends a care package, and if she wants to punish you then she drops you into a literal pit of lava.

Utilitarianism is orthogonal to materialism.
:PROPERTIES:
:Author: xachariah
:Score: 22
:DateUnix: 1578972767.0
:DateShort: 2020-Jan-14
:END:

**** Whoops, I didn't mean they're equivalent to each other but rather utilitarian is a more accurate substitute. Utilitarianism isn't orthogonal to materialism though - they're closer to parallels.
:PROPERTIES:
:Author: nytelios
:Score: 2
:DateUnix: 1578975097.0
:DateShort: 2020-Jan-14
:END:

***** You can be a materialist without being a utilitarian in practice or even in theory. And if we lived in a non-materialist world, said world could still have good utilitarians. Even in a materialist world you can have non-materialist utilitarians, they just aren't very good ones.
:PROPERTIES:
:Author: Bowbreaker
:Score: 7
:DateUnix: 1578997206.0
:DateShort: 2020-Jan-14
:END:

****** Sorry, I don't see how you can be a utilitarian without being a materialist in this world (rather than say, the platonic plane of forms). I'm also not sure where worlds came into the picture, but in this world materialism and utilitarianism are more closely correlated than independent, which was my point.
:PROPERTIES:
:Author: nytelios
:Score: 2
:DateUnix: 1579042202.0
:DateShort: 2020-Jan-15
:END:

******* Utilitarianism isn't related to how accurate your knowledge about the world is. You could believe in supernatural stuff and still be trying to maximize happiness. Even if you do dumb stuff like trying to maximize happiness using supernatural means, I don't think that disqualifies you as a utilitarian on principle.
:PROPERTIES:
:Author: Bowbreaker
:Score: 4
:DateUnix: 1579076851.0
:DateShort: 2020-Jan-15
:END:

******** Oh I think I see the issue here: it's a definition conflict. There are many varieties of utilitarianism but as a whole, it's not only about internal metrics of happiness but also doing the most good. To do the most good in this world, it seems to me that a utilitarian must necessarily embrace materialism.
:PROPERTIES:
:Author: nytelios
:Score: 1
:DateUnix: 1579108405.0
:DateShort: 2020-Jan-15
:END:

********* Two things:

The word "good" must be defined first. That's the point of ethical systems, of which utilitarianism is one. It tries to respond to the question "what is good".

Second, even if we disregard the above part I would still say that someone who wants to accomplish "the most good in this world" as you put it, doesn't actually have to be good at accomplishing that. You can be a utilitarian and wrong about major things. You can be a utilitarian and an idiot at the same time. You can think that being black is an unfortunate disease and still cling to utilitarian goals and methods. You can genuinely think that prayer is a major way to improve the world. You can believe in an eternal hell and thus, as a utilitarian, make it your goal to safe as many people as possible from it.

All of the above won't actually make the world better, but the person who does them can still think he's doing the most good for the most people. As long as he believes that results matter more than anything else and wants these results to be happiness/good/value fulfillment for as many people as possible, what else is he, if not a utilitarian?

Or to give an example, have you read Unsong?
:PROPERTIES:
:Author: Bowbreaker
:Score: 3
:DateUnix: 1579111656.0
:DateShort: 2020-Jan-15
:END:

********** 1. The Gordian task of defining "good" is an age old criticism of utilitarian ethics.

2. Your points here are still predicated on the subjective thought processes of the individual who considers themselves as X or Y. But there must be some objective metric for measuring these qualities, and in this case, I think it's more reliable to look at the median quartile than the extremes.

Ugh, I'm embarrassed to say I havent read Unsong yet.
:PROPERTIES:
:Author: nytelios
:Score: 1
:DateUnix: 1579113834.0
:DateShort: 2020-Jan-15
:END:

*********** A "utilitarian", as far as I understand it, isn't someone who acts in a way that other utilitarians happen to approve of. It's someone who agrees with the premise of utilitarian ethics and lets said ethics guide his decision making.

Is /that/ maybe our definitional disagreement?

Anyway, a big part of Unsong's whole premise is (spoilered for purists but it isn't really a big spoiler since it is evident from very early on) various Abrahamic religions turning out to be true and how the world deals with that. This includes Kabbalah actually working and the names of God having magical effects. And yet, utilitarians definitely still exist and matter.
:PROPERTIES:
:Author: Bowbreaker
:Score: 5
:DateUnix: 1579126375.0
:DateShort: 2020-Jan-16
:END:

************ This is delving into meta ethics territory and I don't know enough to press the point. But anecdotally, isn't this similar to an "evil" person committing deeds that they consider "good" and believing themselves a good person?
:PROPERTIES:
:Author: nytelios
:Score: 2
:DateUnix: 1579127713.0
:DateShort: 2020-Jan-16
:END:

************* Would said person be evil? Depends on which ethics system you use!

Also, does that mean that you consider it impossible fir people who consistently act "evil" to identify/be identified with any common ethics system, since all of them talk about how to act "good"?

Anyway, I don't consider it similar since "evil person" and "good person" aren't beliefs or philosophies, but judgements about another person's character.

For me "utilitarian" is similar to "materialist", "Christian", "nationalist", "solipsist", or "libertarian" in that it describes a person's internal beliefs, not their actions.
:PROPERTIES:
:Author: Bowbreaker
:Score: 3
:DateUnix: 1579145631.0
:DateShort: 2020-Jan-16
:END:

************** Yeah it isn't a great analogy - it's the first thing that came to mind if identification is entirely subjective. In that sense, anyone can be anything as long as it's their internal belief.

Anyway, instead of my initial comments about vectors (orthogonal vs. parallel), it might be more accurate to think of these labels as overlapping venn diagrams. Utilitarianism and materialism have a higher overlap (objectively in the real world) than say, materialism and Christian.
:PROPERTIES:
:Author: nytelios
:Score: 1
:DateUnix: 1579147058.0
:DateShort: 2020-Jan-16
:END:

*************** Can you maybe give me your working definition of "utilitarian" without using the word "utilitarianism"? I feel like it is longer and more complicated than mine. Mine would be "someone who believes that the right thing to do is that which causes the greatest good for the most people and, based on that, aspires to do right things".
:PROPERTIES:
:Author: Bowbreaker
:Score: 3
:DateUnix: 1579176892.0
:DateShort: 2020-Jan-16
:END:

**************** Mine is basically the same plus an added proviso for more objective measurement of "the greatest good for the most people" than that person's individual beliefs. The [[https://en.m.wikipedia.org/wiki/Utilitarianism][wiki article]] lists a staggering variety of utilitarianism with even more criticisms that are relevant in our convo (like "Aggregating utility").
:PROPERTIES:
:Author: nytelios
:Score: 2
:DateUnix: 1579192123.0
:DateShort: 2020-Jan-16
:END:

***************** But by your metric of objectivity it might well be possible that there exists no human true utilitarian right now? Like, what if cars suffer horrendously every time we use them and none of us know? That would mean that all the wannabe utilitarians who aren't doing anything about car suffering actually can't be considered to be what they think they are.

And I am not completely pulling this weirdness out of my ass. For instance there is the [[http://petrl.org/][People For The Ethical Treatment Of Reinforcement Learners]]. Or, if that isn't weird enough for you, go to [[https://slatestarcodex.com/2017/08/16/fear-and-loathing-at-effective-altruism-global-2017/][this article on slatestarcodex]], press ctrl+f and look for the following line: "I got to talk to some people researching suffering in fundamental physics"

To put it differently, under your definition the only entities that could without a doubt be utilitarian both from an inside and an outside views would be effectively omniscient ones.
:PROPERTIES:
:Author: Bowbreaker
:Score: 3
:DateUnix: 1579210751.0
:DateShort: 2020-Jan-17
:END:

****************** That sounds like a blend of absolutism and utilitarianism. But to the car question, no, I don't think a utilitarian can act on what they don't know. But objectivity involves finding out what is known and independent from our own perception. Ethical subjectivism naturally happens because of the limits of utilitarianism and human cognition in general, but a utilitarian still needs to act on knowledge and results to fulfill the greatest good to the greatest number.
:PROPERTIES:
:Author: nytelios
:Score: 2
:DateUnix: 1579233865.0
:DateShort: 2020-Jan-17
:END:

******************* So in your opinion a part of utilitarian philosophy is a science-based philosophy on what constitutes reality and knowledge, and if you don't have the latter you can't have the former. That is a usable definition. Maybe even better than mine in many circumstances. I'll stick to mine anyway since I use the term more often to discuss attitudes, world views and belief systems than I use it to label good people.
:PROPERTIES:
:Author: Bowbreaker
:Score: 3
:DateUnix: 1579280460.0
:DateShort: 2020-Jan-17
:END:

******************** I'd substitute science with empiricism. I really don't know if it's better or worse as I'm hardly an expert on normative ethics. And yeah, going through our convo, I feel like there's so many nuances to both utilitarianism and materialism that it's hard to keep track of what aspect we're referring to at a given point.
:PROPERTIES:
:Author: nytelios
:Score: 1
:DateUnix: 1579282061.0
:DateShort: 2020-Jan-17
:END:

********************* I actually just blanked on the word empiricism, else I'd have used it.
:PROPERTIES:
:Author: Bowbreaker
:Score: 2
:DateUnix: 1579282950.0
:DateShort: 2020-Jan-17
:END:


****************** u/GeneralExtension:
#+begin_quote
  For instance there is the [[http://petrl.org/][People For The Ethical Treatment Of Reinforcement Learners]]. Or, if that isn't weird enough for you, go to [[https://slatestarcodex.com/2017/08/16/fear-and-loathing-at-effective-altruism-global-2017/][this article on slatestarcodex]], press ctrl+f and look for the following line: "I got to talk to some people researching suffering in fundamental physics"
#+end_quote

Some might argue that you are a reinforcement learner - but this is beside your point. The 'particle suffering' has been a subject to 'criticism' from not distant places (I'd have said within, but what constitutes within depends on where you draw lines), to the effect of 'when you wonder if two particles collide they might suffer, something has gone horribly wrong, in your attempts to do right'. I can find a link if you're interested.
:PROPERTIES:
:Author: GeneralExtension
:Score: 1
:DateUnix: 1579242509.0
:DateShort: 2020-Jan-17
:END:

******************* It doesn't matter that there's criticism. Even valid criticism. I mean, they are most probably wrong. But what they are thinking about isn't literally impossible. And if, by an insane off chance, we do actually live in a universe built on near infinite suffering, then those handful of crazy seeming people are the only humans even approaching utilitarianism, by your definition.

Or in other words, I wasn't trying to say that you should look into these things because maybe you are missing something important, I wanted to highlight that no one human can actually be a 100% sure that what they are doing is a net positive in the world, just like we can't be a 100% sure of anything else. Which in my opinion makes your personal working definition of the word "utilitarian" less useful than mine 😋.
:PROPERTIES:
:Author: Bowbreaker
:Score: 2
:DateUnix: 1579252538.0
:DateShort: 2020-Jan-17
:END:


********* What do you mean by materialism? If someone's material needs are taken care of, but they're depressed, is there good left undone?
:PROPERTIES:
:Author: GeneralExtension
:Score: 1
:DateUnix: 1579241816.0
:DateShort: 2020-Jan-17
:END:

********** Materialism (as I think of it) is treating the physical world as the means to all ends. Material needs, depression, and "good" would all be a certain configuration of matter (i.e. From wiki, mental states and consciousness are material interactions). So a materialist would say that someone who is depressed can change or be changed to a "happier" state of matter (being)
:PROPERTIES:
:Author: nytelios
:Score: 2
:DateUnix: 1579278237.0
:DateShort: 2020-Jan-17
:END:


** [deleted]
:PROPERTIES:
:Score: 2
:DateUnix: 1579134406.0
:DateShort: 2020-Jan-16
:END:

*** Is it not where the sinners go after their life as a cape is over and they only get released during the end of the world?
:PROPERTIES:
:Author: WadeSwiftly
:Score: 9
:DateUnix: 1579196796.0
:DateShort: 2020-Jan-16
:END:

**** [deleted]
:PROPERTIES:
:Score: 3
:DateUnix: 1579333985.0
:DateShort: 2020-Jan-18
:END:

***** Eh. I'm not 100% sure that the Birdcage = Hell is what WB intended but I'm rather sure it was what he was going with those parallels. I don't think the Government or PRT is the “God” in this analogy. It's probably Dragon. Dragon like God works in a sinful world not dictating the laws of humans but punishing the sinners after they fall. You say in the other comment that it's the inmates who manage the prison but it's not really them; Dragon decides who goes where and manages if they survive in the Birdcage or not. (Of course it's not a perfect analogy, I don't think the bible intends to have death be a way out of Hell.)

I could go on and find more examples that work for me but you seem to believe I'm cherry picking and I probably couldn't convince you with all the parallels I could find since you believe that the author didn't intend any parallels between the Birdcage and Hell.

So I guess we'll just agree to disagree.
:PROPERTIES:
:Author: WadeSwiftly
:Score: 2
:DateUnix: 1579355899.0
:DateShort: 2020-Jan-18
:END:


*** Why isn't it Hell, hyphenomicon?
:PROPERTIES:
:Author: GeneralExtension
:Score: 2
:DateUnix: 1579242092.0
:DateShort: 2020-Jan-17
:END:
