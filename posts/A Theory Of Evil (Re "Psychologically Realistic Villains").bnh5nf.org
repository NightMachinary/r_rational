#+TITLE: A Theory Of Evil (Re: "Psychologically Realistic Villains")

* A Theory Of Evil (Re: "Psychologically Realistic Villains")
:PROPERTIES:
:Author: Goth_Dropping_In
:Score: 41
:DateUnix: 1557609505.0
:DateShort: 2019-May-12
:END:
*In this piece, I intend to do the following:*

1: Define what it means for someone to be "evil."

2: Examine the origins of evil people.

3: Show how this can make your villains stronger.

​

*The following things are taken as premises:*

A: People have an instinctive sense of "fairness" or "justice", which they try to satisfy. ("Natural Law exists.")

B: People are habitual: once we establish patterns, we find them difficult to deviate from. ("The Id exists.")

C: People have difficulty holding two contradictory ideas at once. ("Cognitive dissonance exists.")

D: Malice, defined here as "having another person's suffering as one of your terminal values", is Evil.

E: I'm writing about neurotypical humans, because it's lazy to make your villains weird to duck a hard problem.

​

*What does it mean for someone to "be evil"?*

Evil people are malicious. They seek the suffering of another as an end in itself.

This does not mean that they seek the suffering of /everyone,/ or that this is their primary and overriding goal: it merely means that they have the honest desire to see /someone/ hurt as a terminal goal.

​

*Everyone has malicious desires.* I would very much like to punch President Trump in the face, for example. However, I don't have that *as an end goal.* A world where everything is the same /except/ I got to punch Trump in the face is /unappealing/ to me.

When we act on malicious desires, we call that "cruelty." It's the action of /causing someone suffering for no other reason than because it makes you feel better./

Humans are cruel from time to time. You have likely been cruel to someone in the past. What differentiates the evil from the good is not /the lack of cruel actions,/ but the way we respond to them.

When humans do something cruel, we feel guilty - a form of cognitive dissonance. Our sense of justice is at odds with our actions.

The usual responses to this are:

A: Make an ethical exception due to "extenuating circumstances".

B: Attempt restitution.

C: Try not to do that again.

D: Ignore the problem and hope it goes away.

​

*People become evil when their internalized ethics allow malicious behavior.*

This may either happen semi-intentionally, as a long-term process of justification, or accidentally, as a training effect from a hostile environment where cruelty is adaptive. On the societal scale, dehumanization through propaganda is a common technique: after all, bigotry is nothing more than saying "these people don't count in my ethical calculus."

In other words, *everyone is currently in a fight over their own ethics.* Society tries to inculcate certain mores, which may in themselves be evil; simultaneously, everyone wants to believe their ethical system is perfect, because holding a self-image that says you /aren't a good person/ is incredibly maladaptive.

​

*How this lets you write better villains:*

*Villains are evil*. They were placed in a situation where they believed they had to be cruel, and remained in that situation for long enough that cruelty became a reflex. They /may/ be redeemable, but this will be a process of /unlearning an ingrained cognitive habit -/ something that takes years if not decades to make significant progress on.

*Villains are people.* They were /just like you,/ and then something happened that trained the reflex of cruelty into them. /That could happen to you./

No, seriously: you could become evil without having any actual control over it. /Moral luck exists./

Yes, this *is* terrifying. It also happens to be true.

​

Once you internalize this, your villains will immediately grow in depth, because you will understand the actual origins of malicious behavior. You will be able to write someone genuinely callous, awful and wretched /while maintaining a consistent mental model of them in your head./

Far from making your villains more relatable, modelling them at this level often makes them /evoke visceral hatred./ Your readers will recognize their abusers, their shitty bosses, their asshole roommates - and, in their quieter moments, the worst parts of themselves.

As rationalists, that truth is what we're looking for.


** One thing I think you're missing is that some people want to see others suffer /as a result of their innate sense of justice./

For example, people who think that prisoners getting raped is funny (Don't drop the soap!). Or people who think that people deserve to be tortured because they belong to a group (country/religion/etc.) which has harmed them. Hell*, over a billion people believe that the rest of humanity deserves eternal torture just for not choosing Jesus as their personal Lord and Savior.

To use the HPMOR example, the villain in that piece was, in the end, unable to abandon cruelty because he took joy /specifically/ in delivering pain and death to those he thought deserved it (in his case, "[[http://www.hpmor.com/chapter/108][idiots]]").

*Pun fully intended.
:PROPERTIES:
:Author: Nimelennar
:Score: 38
:DateUnix: 1557610827.0
:DateShort: 2019-May-12
:END:

*** Also not mentioning that even the most obvious of blame that can be directly laid upon people, any act done in the moment, will be a "rational act", rationalised by their feelings and thoughts at the moment. No blame from anyone will ever convince them otherwise. Evil and ignorance go hand in hand.

Personally I find evil to be a rather vapid term placed there by opponents and detractors. If you want to see why people do truly evil acts, start with the greatest hero in your life (that isn't yourself, because everyone except depressed people is the hero of their own lives), which would be your mother or father, usually. Imagine every time they've made you feel bad, ask yourself, and then them, how it made them feel. You felt bad, they felt better when yelling at you. They'll tell you they felt bad, but it was necessary. Which is also true, in their eyes. Now imagine how good you feel when you're chewing someone out online or in real life. Then imagine getting a thousand downvotes and negative comments and the feelings of consternation, rage, disappointment. Apply the same feelings to you and your parent, you and your victim,

Escalate that progression of feeling of power and gratification when posting the first post, thinking you'll "win". The "winning", being in power, being right, in control, justified. From the most petty things, all the way until you're the evil villain
:PROPERTIES:
:Author: Morghus
:Score: 12
:DateUnix: 1557613285.0
:DateShort: 2019-May-12
:END:

**** See my comment above. There's a long long list of reasons and justifications for habitual cruelty: I did not intend my post to be an exhaustive list.

If we're going to be doing this, though, I'll add my own major inciter:

*Spending a long period of time in close contact with someone who reminds you of your own failings.*

We hate few people as much as those who are "like us, but worse." It hurts to see someone else repeating all your mistakes - and it's even worse if you try to help and they /won't listen./ (Because our habitual selves take /training/ to change, regardless of how good of an idea our conscious mind may think an idea is.)
:PROPERTIES:
:Author: Goth_Dropping_In
:Score: 12
:DateUnix: 1557615513.0
:DateShort: 2019-May-12
:END:

***** Nice one.

Mine wasn't meant to do anything but point out the murky beginnings of it, according to psychology. The literature is absolutely fascinating. Reading about white nutters and the psych profile built up around them makes it quite apparent that a lot of it stems simply from neglect and ignorance
:PROPERTIES:
:Author: Morghus
:Score: 2
:DateUnix: 1557623088.0
:DateShort: 2019-May-12
:END:


*** People can want others to suffer for a very long list of reasons: my not including them is not about saying they don't exist, it's about the exact mechanisms there being unimportant.

It's the habit of cruelty that makes the evil, not the reasons we give ourselves for it.
:PROPERTIES:
:Author: Goth_Dropping_In
:Score: 3
:DateUnix: 1557615001.0
:DateShort: 2019-May-12
:END:

**** What I'm objecting to is not the overall thrust of your post, but a couple of specific lines:

#+begin_quote
  When we act on malicious desires, we call that "cruelty." It's the action of causing someone suffering for /no other reason than because it makes you feel better./
#+end_quote

Cruelty in the name of "justice" is generally /not/ done just for the reason of "because it makes you feel better;" it's done because people think that it will improve the prisoner, or deter crime, or right a cosmic balance, or whatever. Notably, to use the US as an example, "cruel" punishment for prisoners is not outlawed; it's only considered unconstitutional when it's both "cruel and unusual." Which, itself, has the implication that /some/ cruelty in the name of justice /should/ be usual.

#+begin_quote
  When humans do something cruel, we feel guilty - a form of cognitive dissonance. Our sense of justice is at odds with our actions.
#+end_quote

Again, cruelty which is /triggered by a sense of injustice/ generally /doesn't/ make people feel guilty. If someone, for example, gets attacked, they don't usually feel wracked by guilt at the notion of having to use violence to defend themselves. A lot of what goes into justifying cruelty is the idea that whoever the cruelty is directed at /has it coming/. It doesn't /have/ to be habitualized that way.
:PROPERTIES:
:Author: Nimelennar
:Score: 8
:DateUnix: 1557629682.0
:DateShort: 2019-May-12
:END:

***** Not all of what the U.S. does, necessarily deters crime; some things may be done even though they're ineffective at that - and are only for the purpose of making the 'wicked' suffer.
:PROPERTIES:
:Author: GeneralExtension
:Score: 2
:DateUnix: 1557783988.0
:DateShort: 2019-May-14
:END:

****** I agree; my point was that "making the 'wicked' suffer" often feels like justice itself, and not at all at odds with our sense of justice. I tried to cover the kind of cruelty you're talking about under "right a cosmic balance," but I can see that I didn't express that clearly.
:PROPERTIES:
:Author: Nimelennar
:Score: 1
:DateUnix: 1557785805.0
:DateShort: 2019-May-14
:END:

******* You expressed it well enough; It was an economics nitpick.

While I don't find it necessary to fight over the meaning of "justice" with someone if I know what they mean when they say it, what should we call policies that deter crime and serve no other purpose, if not 'justice'?
:PROPERTIES:
:Author: GeneralExtension
:Score: 1
:DateUnix: 1557796095.0
:DateShort: 2019-May-14
:END:

******** Disincentives?
:PROPERTIES:
:Author: Nimelennar
:Score: 2
:DateUnix: 1557803719.0
:DateShort: 2019-May-14
:END:

********* People also respond to positive rewards. Imagine paying people (or taxing them less? Might not work as well) to not speed, instead of, or in addition to, fining them for speeding.
:PROPERTIES:
:Author: GeneralExtension
:Score: 1
:DateUnix: 1557804507.0
:DateShort: 2019-May-14
:END:

********** As I understand it, the difference between incentive vs. disincentive isn't that the former is positive and the latter is negative; it's that the former encourages a particular action, while the latter discourages the same. So a lottery rewarding those who don't speed is as much a disincentive for speeding as (or, to be honest, probably a /better one/ than) a fine punishing those who do, because both make it less desirable to speed (or, framed another way, both are incentives to stay below the speed limit).
:PROPERTIES:
:Author: Nimelennar
:Score: 2
:DateUnix: 1557805218.0
:DateShort: 2019-May-14
:END:

*********** Ah. People tend to differentiate between classes along additional lines, so I did not know that. (Accelerate means an increase in speed, or a change in speed. Decelerate means a decrease in speed. I made some assumptions.)
:PROPERTIES:
:Author: GeneralExtension
:Score: 2
:DateUnix: 1557806956.0
:DateShort: 2019-May-14
:END:


****** u/SimoneNonvelodico:
#+begin_quote
  Not all of what the U.S. does, necessarily deters crime; some things may be done even though they're ineffective at that - and are only for the purpose of making the 'wicked' suffer.
#+end_quote

People believing in unsubstantiated, easily falsified claims just because they appear obvious at face value and have traditionally been considered so? When has that ever happened, right?
:PROPERTIES:
:Author: SimoneNonvelodico
:Score: 1
:DateUnix: 1558077445.0
:DateShort: 2019-May-17
:END:

******* Those who do not learn history may be doomed to repeat it - but if 'history' does not include whether history teachers are satisfied with life, then those who do learn it, may be more surely doomed.
:PROPERTIES:
:Author: GeneralExtension
:Score: 1
:DateUnix: 1558110472.0
:DateShort: 2019-May-17
:END:


***** I think this is true, but as a fictional trope tends to result in villains who are simply strongly partisan - knights templar and well-intentioned-extremists, who have a first loyalty to some ideal or group and fight ruthlessly to serve it.

I'm looking for ways to represent capital-E evil in a rationalist framework - cruelty that /represents an endorsement of the strong ascetic principle./ ("A world identical to this one in every way, save that it contains more suffering, is better than it.")

This isn't about evil that says "You should suffer, because...": this is about evil that says "you should suffer", full stop.
:PROPERTIES:
:Author: Goth_Dropping_In
:Score: 2
:DateUnix: 1557858205.0
:DateShort: 2019-May-14
:END:

****** u/Nimelennar:
#+begin_quote
  I'm looking for ways to represent capital-E evil in a rationalist framework - cruelty that /represents an endorsement of the strong ascetic principle./ ("A world identical to this one in every way, save that it contains more suffering, is better than it.")
#+end_quote

That doesn't seem to match what you said in your initial post:

#+begin_quote
  This does not mean that they seek the suffering of /everyone/
#+end_quote

If a rational person thinks that a world with more suffering is better for it, then they would, as a terminal goal, seek the suffering of everyone, just as a rational person who thinks that a world with less suffering is better for it would, as a terminal goal, seek to reduce everyone's suffering.

​

On another note, I don't think that I can accept the premises of "Natural Law exists" and "people can rationally adopt the 'strong ascetic principle'^{1}" as non-contradictory. You'd have to convince me of that idea.

​

That is, I can /totally/ accept rational people thinking that suffering, by its very nature, makes the world better. "Suffering is good" is a value judgement, and the deepest level of values in any person's head has to either be taught or inherited (any rationally derived value has to take the form "A is better than B because X is better than Y, and A implies X, and B implies Y," so there has to be at least one base value of "/this/ is better than /that/" which is not rationally derived). So, if someone believes, in their heart of hearts, that suffering is good (or some equally irrationally-acquired principle from which "suffering is good" rationally follows), that can absolutely be rational.

​

However, you're defining Natural Law as "People have an "instinctive sense of 'fairness' or 'justice.'" That's the base-level value you're imparting onto all human beings: that good things should happen to good people, and bad things should happen to bad people (or, at least, good things should happen proportionately *more* to good people, and the same for bad things and bad people). And that *can't* be rationally reconciled with "a world with more suffering is better" (unless the "more suffering" is distributed "fairly"/"justly" upon those who deserve it more, but that would no longer be "a world identical to this one in every way").

​

Please choose one or the other: that people believe in justice and fairness as an intrinsic, basic value, or that rational people can endorse that a world identical to this one in every way, save that it contains more suffering, is better than this world. Or convince me that the two are compatible.

​

^{1}I can't find any other reference on the Internet to the term "strong ascetic principle," so I'm going to assume you coined it yourself. I'll adopt it for the sake of this discussion, as you've defined it adequately enough to avoid confusion, but I'd just like to note that I don't accept the definition of "asceticism" as "the reverse of utilitarianism.^{2}"

^{2}I will also note that cruelty as "the action of causing someone suffering for no other reason than because it makes you feel better" /would/ fall under what I would define as "the reverse of asceticism," which is /libertinism/ (trying to maximize /only your own/ pleasure/happiness, at the expense of others' if necessary). Performing cruelty that "makes you feel better" cannot be practicing asceticism, by /any/ reasonable definition of "ascetic."
:PROPERTIES:
:Author: Nimelennar
:Score: 1
:DateUnix: 1557898416.0
:DateShort: 2019-May-15
:END:

******* You seem to be arguing past me, so let me try and define the strong ascetic principle in more detail for the purpose of formal argumentation:

"There exists a world identical to this one in every way, save that it contains more suffering, and that world is better than this one."

Postulate: There is some world that is identical to this one in every way, save that [insert your favored group of "bad people"] suffer more.

If you endorse that this world is better than the current world, /that is an endorsement of the strong ascetic principle./ You believe that /some world exists/ that is better than this one because it contains more suffering. This does not imply that /all/ worlds that contain more suffering than this one are better than it.
:PROPERTIES:
:Author: Goth_Dropping_In
:Score: 1
:DateUnix: 1557971459.0
:DateShort: 2019-May-16
:END:

******** From your previous post:

#+begin_quote
  I'm looking for ways to represent capital-E evil in a rationalist framework - cruelty that /represents an endorsement of the strong ascetic principle./
#+end_quote

From your most recent post:

#+begin_quote
  Postulate: There is some world that is identical to this one in every way, save that [insert your favored group of "bad people"] suffer more.

  If you endorse that this world is better than the current world, /that is an endorsement of the strong ascetic principle./ You believe that /some world exists/ that is better than this one because it contains more suffering.
#+end_quote

​

If cruelty that endorses the strong ascetic principle is capital-E Evil, then, by your most recent definition, anyone who thinks that, say, child molesters deserve the especially ill treatment that they receive in prison, is capital-E Evil, because they're wishing that cruelty onto a specific group of "bad people" that they think deserve it.

Personally, I think that's a horrific thing to wish on /anyone/, but I'd file that kind of urge to punish wrongdoers under "mundane everyday evil" rather than "capital-E Evil."

​

Also, your most recent post seems to be in direct contradiction to:

#+begin_quote
  This isn't about evil that says "You should suffer, because...": this is about evil that says "you should suffer", full stop.
#+end_quote

Either the extra suffering is "deserved" (e.g. happening to "bad people"), in which case there /is/ a "because," and (in my opinion) desiring it doesn't fall under the capital-E Evil you describe...

Or we're back to where I left off in my previous post and I don't see it as being simultaneously compatible with both Natural Law and rationality.
:PROPERTIES:
:Author: Nimelennar
:Score: 1
:DateUnix: 1557975057.0
:DateShort: 2019-May-16
:END:

********* Malice is capital-E Evil, yes. And yes, I do honestly believe that the vast majority of humans have a shard of capital-E Evil in them: if suffering is our ultimate opponent, then every act of cruelty (that is, every act that endorses the Strong Ascetic Principle) gives it a further advantage in a game it's already largely winning.

However, in order for /people/ to be capital-E Evil overall, they have to make cruelty /habitual/ - something they no longer need a justification for. Over long enough periods, "[Group] deserve to suffer because [justification]" reduces down into simply "[Group] deserve to suffer."
:PROPERTIES:
:Author: Goth_Dropping_In
:Score: 1
:DateUnix: 1558248513.0
:DateShort: 2019-May-19
:END:


****** Well, there's plenty of reasons to be that sort of evil. First, you assume there exists a natural aversion towards certain acts, but such a thing would obviously be a genetic feature of our brain and thus subject to mutation. You could have people who simply don't have that check (psychopaths, for example). Then you could have people that /actively work against that check/ until they're desensitised to it and thus end up being free from it (this can go for anyone who gets e.g. overused to violence, from soldiers to butchers. Inflicting suffering onto animals without even flinching can be a good first step to doing the same to humans). The societal expectations and habits drilled into you, the Id part, people could rebel against on purpose, seeing them as shackles imposed onto them by others. Considering that not all social customs are always sensible or rational, this is certainly an example of throwing away the baby with the bath water. Dunno, I can imagine a lot of patterns that don't square neatly into your starting hypotheses.
:PROPERTIES:
:Author: SimoneNonvelodico
:Score: 1
:DateUnix: 1558077756.0
:DateShort: 2019-May-17
:END:


*** Hell or some variation of it exists in a large percentage of religions.

My hypothesis is that people find comfort in a belief that people that harmed them will get punished for it, even if not while living.

​

It's a feel good belief that commonly sneaks it's way into religious thinking, myths and other early 'world explanation systems'. From Karma, to hell, to being reborn as a slug, it's a common idea humans have a tendency of adopting.
:PROPERTIES:
:Author: fassina2
:Score: 3
:DateUnix: 1557678394.0
:DateShort: 2019-May-12
:END:


** u/ShiranaiWakaranai:
#+begin_quote
  everyone wants to believe their ethical system is perfect, because holding a self-image that says you /aren't a good person/ is incredibly maladaptive.
#+end_quote

I don't think this is entirely accurate. People don't need to believe that they are good, they just need to believe that they are morally no worse than the people around them. The evidence for this is the bystander effect: when one person is in some kind of trouble and a thousand people are watching. In most ethical systems, the morally good thing for each of the thousand people to do is to help. Yet the likelihood of each person choosing to help is far lower than you would expect from a morally good person.

From this we can conclude that actual motivation to be *more morally good* than others or even to be *morally good* on an absolute scale is very rare and/or very weak: if it isn't, then the thousand people should be rushing to help for the mere opportunity to do good, even if no one else around them does. So we see that most people are only motivated to be *as morally good as* the others, even if that's actually morally evil on an absolute scale.

So I would say it is realistic to have villains that acknowledge their moral evils, but persist anyway because they believe they are not more morally evil than other people, and that if those other people can do so much evil (and get away with it), why shouldn't they do the same?
:PROPERTIES:
:Author: ShiranaiWakaranai
:Score: 20
:DateUnix: 1557619692.0
:DateShort: 2019-May-12
:END:

*** Thank you for your input! This seems entirely reasonable, and I concede the point.
:PROPERTIES:
:Author: Goth_Dropping_In
:Score: 2
:DateUnix: 1557857727.0
:DateShort: 2019-May-14
:END:


** I think you make it sound too much like evil people are rational pursuers of immoral desires. In reality, evil is almost always the result of some form of irrationality. If you ask war criminals if they ever regret their actions, the usual response (like in Dick Cheney's famous interview) is something along the lines of "I don't look back." It's a form of apathy, or a lack of imagination, that stops them from imaging alternative pathways to pursuing their goals, or from seeing their enemies as fully human.

Real evil is almost always banal. Yes, some of the nazi lackeys may simply enjoy cruelty, but like you say that's just lazy writing when it comes to the main villain. The more compelling question in fiction is always "why do good people do bad things" and the answer is almost never "because something bad happened to them in the past". That's Freudian nonsense, or romanticist nonsense, and certainly not what I would expect to see in rational fiction.

Good and evil is not something you learn or unlearn over a matter of decades, but rather something people flip between from one moment to another like flicking a switch. A soldier can fight for his country, see his friend get killed, get enraged and murder a whole family of foreigners, and then go back home to their family like nothing happened. I think that's the main thing that stops writers from writing 'evil' realistically: They think that because the consequences of evil are so terrible, therefore the causes must be equally grand. In reality, a school shooter might butcher all of their classmates because they got a bad grade.

If you want a pure evil villain, you can simply have them be born cruel and instead have the protagonist struggle with the question of how such a thing is even possible, have them wonder what wires need to be crossed for something like that to happen. But if you don't want your villain to be pure evil, you have to give them a blindspot. Give them a bias, an emotional flaw, an instinctive flinch away from the thing they cannot bring themselves to consider. Even HPMOR's Voldemort, who was as close to a pure evil villain as I've seen here, was some combination of the two. He could not bring himself to think of death because he was terrified of it, and that's also why he thought so little of killing others. That kind of flaw is what makes for interesting villains, without making them any less evil.
:PROPERTIES:
:Author: Sophronius
:Score: 8
:DateUnix: 1557661330.0
:DateShort: 2019-May-12
:END:

*** This is not intended to be an answer to "why do good people do bad things."

This is intended to be an answer to "how do good people become bad people"?
:PROPERTIES:
:Author: Goth_Dropping_In
:Score: 4
:DateUnix: 1557692491.0
:DateShort: 2019-May-13
:END:

**** Alright, but then you're talking about a very specific type of 'fallen hero' type villain that started out good but became evil based on a tragic backstory. As a Theory of Evil, or as a guide for writing good villains, that leaves it very incomplete.
:PROPERTIES:
:Author: Sophronius
:Score: 1
:DateUnix: 1557693722.0
:DateShort: 2019-May-13
:END:

***** This theory is actually developed based on my observations of /abusers specifically/, and may break down in other domains: On reflection, I also have hidden premise 5, which is "Most people are morally good or neutral."

This is about determining how active immorality comes to exist in what I consider psychologically normal people.
:PROPERTIES:
:Author: Goth_Dropping_In
:Score: 4
:DateUnix: 1557779350.0
:DateShort: 2019-May-14
:END:


*** u/GeneralExtension:
#+begin_quote
  He could not bring himself to think of death because he was terrified of it, and that's also why he thought so little of killing others.
#+end_quote

That was never established.
:PROPERTIES:
:Author: GeneralExtension
:Score: 2
:DateUnix: 1557784160.0
:DateShort: 2019-May-14
:END:

**** Hmm, true, but it was definitely established that he had an instinctive flinch that prevented him from thinking about death to the point where it stopped him from realizing that having 300 horcruxes did not actually offer any additional protection. At least that was Harry's interpretation, and Harry's darkside had such a gargantuan fear of death that it literally crippled his ability to think around dementors. So it's not much of a stretch to say that this influenced his affinity for the killing curse, to the point where he was one of the only people who could cast it without limitations.

(That last bit was also a clever way to make the protagonist and antagonist thematic opposites on Eliezer's part: Harry was the only one who could use the Patronum v2.0, Voldemort was the only one who could use the Killing Curse v2.0.)
:PROPERTIES:
:Author: Sophronius
:Score: 2
:DateUnix: 1557784647.0
:DateShort: 2019-May-14
:END:

***** u/GeneralExtension:
#+begin_quote
  did not actually offer any additional protection.
#+end_quote

Diminishing returns, and less than those obvious from examining limitations. The idea is that if you put a fence around your property you can call it secure. But past a certain point, making a bigger better wall is less useful than considering the other aspects of security. What about drone strikes, cosmic rays, mind control, aliens teleporting themselves/you/the building?

#+begin_quote
  it's not much of a stretch to say that this influenced his affinity for the killing curse, to the point where he was one of the only people who could cast it without limitations.
#+end_quote

Q implied the difference was empathetic*, though not unique***, and a requirement for using the v1 past a certain point.

***Common trait in Dark Wizards. The numbers involved weren't clear, and it does raise some interesting questions about Aurors, after using the Curse was made legal (possibly retroactively?) thanks to Monroe.

*This has the side effect that casting it for suicide purposes doesn't require self-hate (v1).
:PROPERTIES:
:Author: GeneralExtension
:Score: 2
:DateUnix: 1557798085.0
:DateShort: 2019-May-14
:END:


** I usually like villains who use the logic "the end justify the means" because it's something that makes perfect sense...if the person in question is a machine who can hold to their ethics no matter what instead of being a human being running on [[https://wiki.lesswrong.com/wiki/Corrupted_hardware][corrupted hardware]].

For example, I can absolutely conceive of a situation where it would be justifiable to murder someone and it would be the right thing to do over anything else I could do in this hypothetical situation. But I would most likely still choose to not murder due to an ethical injunction to never kill, because murder will fundamentally change who I am as a person and I wouldn't be able to trust my future murderous self to be as moral as my present non-murderous self.

Not to say that all murderers are beyond redemption for passing beyond a moral event horizon or anything like that. But if I have chosen to make an exception for my ethical injunction of */+THOU SHALT NEVER KILL+/* then after making one exception, it's more likely to make a second exception, a third, fourth, and so on.

Due to running on messy flawed hardware of our brains, I can't trust that I'll hold to any moral rules as tightly if I ever break it even once. Hence, "the end justify the means" is not something that I can ever use to justify violating any moral rule. No matter the consequences, in my mind, some actions are immoral by their very nature.

EDIT: This train of thought actually brings me to a very interesting idea about people who have to kill for their jobs such as a soldier in a war, or doctors who give euthanasia (even though this is not a thing in most countries). I can absolutely see someone who kills a patient still being moral if they follow strict rules about making sure there is no other option and the patient sincerely cannot continue any longer. Soldiers who kill are only morally permitted when ordered to do so against enemy combatants, and they aren't allowed to kill civilians, prisoners of war, and other uninvolved groups.

I'm most likely loosing a lot of nuance by summarizing the two examples too much, but to me, the only time people can still be moral while still killing, is if they follow strictly regimented rules and codes of conduct for occasions where the murder has been determined to be necessary.

For example, I would consider a soldier who killed dozens for his country to be more moral than a beggar who kills a single known criminal to steal his money. The beggar could be killing the worst criminal to ever live for his money to survive, but I would still consider the beggar to be committing an immoral action. The soldier is following a predetermined, necessary mandate to serve his country while the beggar is purely serving himself for survival.

EDIT 2: All of this musing brings up an interesting ethics puzzle to contemplate, is killing in self-defense moral, immoral, or neither?

EDIT 3: Some comment replies have made me think that I'm mixing up the meaning of ethics with morals (following a code of conduct versus values). So the example concerning the soldier versus the beggar is somewhat inaccurate in what I was trying to talk about in relating ethics to immoral behavior.
:PROPERTIES:
:Author: xamueljones
:Score: 5
:DateUnix: 1557617161.0
:DateShort: 2019-May-12
:END:

*** u/Nimelennar:
#+begin_quote
  the end justify the means
#+end_quote

My personal checklist for "the ends justifying the means" is:

- Are the ends better than the means are bad? (Gross positive outcome)
- Does this hold true when all consequences are taken into effect? (Net positive outcome)
- Am I sure that these means will actually achieve my ends? (Risk of /nothing/ justifying the means)
- Are there any /less harmful/ means that will achieve these same ends? (Minimal intervention)
- Will these actions create a precedent that might case the same means to be used towards the same ends without taking the above into consideration? (Slippery slope analysis)

Generally, the utilitarian analysis above comes out in agreement with the deontological result. For example, I wouldn't support (or conduct) torture to extract information, as it fails on pretty much every point above: it's generally more evil than the goal you're trying to get information to achieve is good; even if it isn't, torture is generally going to make you additional enemies that cancel out any benefit from your stated ends; torture /doesn't work/ to extract accurate information; even if it was effective, there are more effective, more humane ways of obtaining information; and that's the kind of human rights violation that tends to grow a whole bureaucracy built up around perpetuating it.

However, to use an example from the movie /The Dark Knight/: Batman's use of the cell phone sonar is a /horrible/ breach of the trust and the privacy of Gothamites. However, they were focused on their goal, so neither of the people hooked into the system (Lucius or Batman) learned much that would be considered a privacy invasion, and he saved dozens, if not hundreds, of lives by doing it. The only /other/ consequence for doing so was losing the trust of Lucius Fox, which still leaves the action a net positive. It /does/ actually allow Batman to find the Joker and save the lives. No other option for finding the Joker in a reasonable time presented itself. And the system was destroyed afterwards, so it can't be used again under less-justifiable circumstances.

The ends /can/ justify the means; it's just incredibly rare that they would (as evidenced by the /incredibly/ contrived scenario in TDK). As such, I default to deontology most of the time.

#+begin_quote
  I would consider a soldier who killed dozens for his country to be more moral than a beggar who kills a single known criminal to steal his money.
#+end_quote

Funny; I'd be tempted to go in the other direction. The survival instinct is something very strong and hard to override. If someone believed that murder was the only way for him and his family to survive, I'd be inclined to grant that person some moral leeway (not, you know, a /lot/, but enough for me to feel empathy for the person). The soldier, on the other hand, has delegated the moral decisions of whether or not certain people are worth killing to the leader of the country, and heads-of-state are not, by nature, notably moral people. There's a reason why "I was just following orders" is rightly sneered upon as a defense for bad deeds.
:PROPERTIES:
:Author: Nimelennar
:Score: 6
:DateUnix: 1557628464.0
:DateShort: 2019-May-12
:END:

**** u/xamueljones:
#+begin_quote
  There's a reason why "I was just following orders" is rightly sneered upon as a defense for bad deeds.
#+end_quote

Fair enough. That example was something I came up with on the spot. I was envisioning the soldier being as someone who needed to make the choice in the field based on his training rather than delegating the decision being made to his superiors.
:PROPERTIES:
:Author: xamueljones
:Score: 2
:DateUnix: 1557632507.0
:DateShort: 2019-May-12
:END:

***** And, to be clear, I do think that there are times that a soldier can kill without it being immoral: the classic example is "in your own (or an allied) country, defending against an invading army." It's when you get away from that case that you start to fall into "What ends can these means *really* justify?" territory.
:PROPERTIES:
:Author: Nimelennar
:Score: 3
:DateUnix: 1557634973.0
:DateShort: 2019-May-12
:END:

****** It also falls down to what consequences the soldier would suffer for his defection. I frankly can hardly muster much sympathy for people who enlist voluntarily in the army of a certain superpower I will not name these days, as the last decades have vastly shown how "moral" the ends they're likely to be employed for will be. But some poor sob conscripted and dragged to the front lines in WW1 to kill or be shot in the back for insubordination is more of a victim than a culprit to me.
:PROPERTIES:
:Author: SimoneNonvelodico
:Score: 2
:DateUnix: 1558078545.0
:DateShort: 2019-May-17
:END:


**** u/SimoneNonvelodico:
#+begin_quote
  I default to deontology most of the time.
#+end_quote

Yeah, I was just thinking the other day that a good one-sentence definition of these two philosophies is "dentology is utilitarianism that made it". In most cases, deontological principles are born just of that sort of analysis, more or less heuristically, and they were simply found to be the correct answer in such an overwhelming majority of cases that it gets easier to enshrine them as absolute principles than deal with the risk of idiots thinking /their/ flawed utilitarian analyses are better and use them as rationalisation to do whatever.
:PROPERTIES:
:Author: SimoneNonvelodico
:Score: 2
:DateUnix: 1558078373.0
:DateShort: 2019-May-17
:END:


*** u/ShiranaiWakaranai:
#+begin_quote
  For example, I would consider a soldier who killed dozens for his country to be more moral than a beggar who kills a single known criminal to steal his money. The beggar could be killing the worst criminal to ever live for his money to survive, but I would still consider the beggar to be committing an immoral action. The soldier is following a predetermined, necessary mandate to serve his country while the beggar is purely serving himself for survival.
#+end_quote

The line gets blurrier though. If killing for your country is allowed, what about killing for a company? A company can be a large organization that is similar to a government in many ways. If a soldier following orders from a government to kill is morally exempted, would an assassin hired by a company to kill a rival company's employees be morally exempted? What if the company isn't a large one, but just a small family-run business? Should the size of the company/country even matter? Would soldiers from bigger countries be more morally exempted than soldiers from tiny ones?

If size doesn't matter, then the next gray area is whether an assassin hired by an individual is morally exempted, compared to an assassin hired by a one-man company. In both cases, you're hired by a single person anyway, and ordered by them to kill the same target. So if the latter is morally exempted, so should the former. This boils down to a simple axiom: if you are ordered to murder by literally anyone other than yourself, then you have a moral exemption for that murder.

That doesn't sound right, so we crossed the line somewhere. The question then is, where? There did not seem to be a spot where the line fits, nor did there seem to be a gradient of moral exemption unless its size, which would be really strange.
:PROPERTIES:
:Author: ShiranaiWakaranai
:Score: 5
:DateUnix: 1557630103.0
:DateShort: 2019-May-12
:END:

**** u/xamueljones:
#+begin_quote
  That doesn't sound right, so we crossed the line somewhere.
#+end_quote

After reading yours and [[https://www.reddit.com/user/Nimelennar][u/Nimelennar]]'s comment, I'm starting to think that I have accidentally crossed a line somewhere too.

I was envisioning how cultures develop roles and strict traditions for dealing with immoral actions that need to be done such as carrying out the death penalty and killing others in wars. But you bring up a good point about how if there are any moral exemptions for a nation, what stops us from applying the same exemptions for smaller and smaller groups?

I suppose that I made a mistake when I mixed up ethics and morals when talking about soldiers.

What I should have said is that soldiers are ethical, since ethics are about codes and conducts one must follow while morals are about norms and values of what is good or bad. And soldiers have to deal with conflicts between organizational ethics versus personal morals.

Maybe I shouldn't have said that a soldier is more moral than the beggar, but rather more /ethical/ than the beggar.

Either way, I really enjoyed your comment and excellent rebuttal against my argument!
:PROPERTIES:
:Author: xamueljones
:Score: 3
:DateUnix: 1557633403.0
:DateShort: 2019-May-12
:END:


**** u/Nimelennar:
#+begin_quote
  If killing for your country is allowed, what about killing for a company? A company can be a large organization that is similar to a government in many ways.
#+end_quote

If you're interested in pursuing this tangent further, there's a book by Robert Asprin called "The Cold Cash War" that you might want to read.

I've only read the short story that he expanded into the novel, but it's about corporations training armies to battle against each other for supremacy, using "killsuits" which allow the armies to fight without causing any fatalities...>! but then the governments come in with real, lethal weapons, and the corporations change tactics to match.!<
:PROPERTIES:
:Author: Nimelennar
:Score: 2
:DateUnix: 1557634548.0
:DateShort: 2019-May-12
:END:


*** The morality of a soldier fighting for their country depends on the morality of the countries they're fighting for and against. I wouldn't say that a patriot fighting for the sake of Nazi Germany would be moral. In fact, I'd say that they were being actively immoral for fighting for such a clearly unjust cause. When you perform actions at the behest of someone else, you inherit the moral nature of whoever you fight for, whether good or bad, proportional to your contributions to the effort.
:PROPERTIES:
:Author: MartinZ02
:Score: 4
:DateUnix: 1557648335.0
:DateShort: 2019-May-12
:END:


*** I would say that "killing, regardless of circumstance, presents a moral risk that must be actively mitigated and guarded against in order to preserve one's own ethics."

Edit: I think "Moral Trauma" is the word you might want to look for here - IIRC, soldiers who have killed in war have higher rates of PTSD than those who have not, irrespective of relative intensity of conflict overall.
:PROPERTIES:
:Author: Goth_Dropping_In
:Score: 1
:DateUnix: 1557779625.0
:DateShort: 2019-May-14
:END:


** It's wrong on so many levels...

#+begin_quote
  People have an instinctive sense of "fairness" or "justice", which they try to satisfy. ("Natural Law exists.")
#+end_quote

Half of those perceived "Natural Laws" are like: "whatever benefit my family/tribe is fair and just", "political or economical assets should be inherited", "only our traditional way of thinking is ethical" etc

#+begin_quote
  People have difficulty holding two contradictory ideas at once.
#+end_quote

Citizen of any totalitarian state or member of organized religion can say it's assuredly wrong. In fact opposite is true: People have difficulty to make their beliefs to be consistent and not contradicting.

#+begin_quote
  "having another person's suffering as one of your terminal values"
#+end_quote

That is how most of society relate to criminals

#+begin_quote
  "Evil people are malicious. They seek the suffering of another as an end in itself."
#+end_quote

Some religion condemn sinners to eternal suffering.

#+begin_quote
  causing someone suffering for no other reason than because it makes you feel better.
#+end_quote

Revenge, criminals, sinners - most of people subscribe to one of those.

#+begin_quote
  People become evil when their internalized ethics allow malicious behavior.
#+end_quote

Not in real world. In real world people become evil then society allow or encourage it. Stanford prison experiment.

#+begin_quote
  Villains are evil. They were placed in a situation where they believed they had to be cruel
#+end_quote

In reality perceived evilness has more to do with politics or other tribal divides, with minor exception of some out of bound cruelty.

#+begin_quote
  Villains are people. They were just like you,
#+end_quote

They are on other side of some kind of conflict
:PROPERTIES:
:Author: serge_cell
:Score: 4
:DateUnix: 1557726414.0
:DateShort: 2019-May-13
:END:

*** 1: I'm not claiming that natural law is /actually good,/ merely that most people /attempt to avoid becoming actively malicious./

2: Yes, some religions condemn sinners to eternal suffering. Yes, that is how most people in society relate to criminals. Yes, most people have a venegance drive. /Malicious desires are commonplace./

3: Yes, society often encourages people to develop evil ethics. Society is amoral on the whole.

4: ...Are you claiming that cognitive dissonance doesn't exist?
:PROPERTIES:
:Author: Goth_Dropping_In
:Score: 1
:DateUnix: 1557779117.0
:DateShort: 2019-May-14
:END:

**** u/serge_cell:
#+begin_quote
  ...Are you claiming that cognitive dissonance doesn't exist?
#+end_quote

I suspect it really exist mostly on instinctual or instincually learned level, like distress caused by contradictory instinctual behavior. For higher concepts like ethics or ideology overwhelming majority of people don't pay attention to contradictions, or consider contradictions perfectly acceptable. Religious people revel in contradictions. Only extremely analytical people are capable to be distressed by contradictions of higher concepts.
:PROPERTIES:
:Author: serge_cell
:Score: 1
:DateUnix: 1557811010.0
:DateShort: 2019-May-14
:END:

***** I agree with your argument, save that I believe humans to possess moral intuitions that cause cognitive dissonance and emotional pain when we act against them. See the concept of [[https://en.wikipedia.org/wiki/Perpetrator_trauma][Perpetrator Trauma]]; I think the evidence is in favor of the idea that we become stressed and hurt when we violate our moral intuitions. (Which are distinct from our ethical or ideological beliefs! Moral intuitions live in our emotional, habitual selves: ideology and ethics live in our reasoning, conceptual selves.)
:PROPERTIES:
:Author: Goth_Dropping_In
:Score: 1
:DateUnix: 1557857377.0
:DateShort: 2019-May-14
:END:

****** You point of view would be reasonable if there would be substantial evidences that great apes posses moral intuition. There are only weak anecdotal evidences for it, and more evidences that they don't posses any moral, intuitive or not.
:PROPERTIES:
:Author: serge_cell
:Score: 1
:DateUnix: 1557903616.0
:DateShort: 2019-May-15
:END:

******* I can't prove moral intuition, obviously, but I can provide evidence for equability and vengeance as behaviors present in the great apes:

[[https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3158226/]]

[[https://www.ncbi.nlm.nih.gov/pmc/articles/PMC1941811/]]

If you accept this evidence, and accept the premise that these drives remain in humans at an instinctual level, then I feel it's reasonable to say that human moral intuitions operate at least partially on instinct.
:PROPERTIES:
:Author: Goth_Dropping_In
:Score: 1
:DateUnix: 1557971970.0
:DateShort: 2019-May-16
:END:

******** That's what I call weak evidences. It's well known that chimps are capable of behavior which benefit band as a whole and winch even impinge on alpha leader (sharing meat in the band where even weakest member have share of meat). You can call it precursor of moral but it's too far from human understanding of moral in my opinion.
:PROPERTIES:
:Author: serge_cell
:Score: 1
:DateUnix: 1557988861.0
:DateShort: 2019-May-16
:END:

********* What evidence would you consider strong?
:PROPERTIES:
:Author: Goth_Dropping_In
:Score: 1
:DateUnix: 1558033412.0
:DateShort: 2019-May-16
:END:

********** For example if chimpanzee establish some "fairness" rules in token-exchange experiments, or protected weakest members from alpha or show readiness to suffered injury protecting the band - behavior which human associate with moral which is not enforced by short-term common survival goal.
:PROPERTIES:
:Author: serge_cell
:Score: 1
:DateUnix: 1558093938.0
:DateShort: 2019-May-17
:END:


** I'm new to this sub but I just want to say that was very well written and I enjoyed reading it. I am going to add this to my writing. Thanks!
:PROPERTIES:
:Author: AfroRonin92
:Score: 3
:DateUnix: 1557615813.0
:DateShort: 2019-May-12
:END:


** Taking your layout as a challenge (Devil's advocate), two things stand out:

​

'People have an instinctive sense of "fairness" or "justice", which they try to satisfy. ("Natural Law exists.")'

*'What does it mean for someone to "be evil"?* Evil people are malicious. They seek the suffering of another as an end in itself.'

​

Two character types come to mind to challenge this. For the first character type, which I propose goes against both lines, I propose a Fang-Yuan-like 'amoral demonic-path' individual: strongly caring about oneself (such as one's own power/wealth/longevity), the person feels no qualms about hurting others, burning the world, et cetera if it gives benefits for the person. In modern reality, consider large-corporation CEOs whose choices often seem immoral or amoral. Also consider in contrast Google's "Don't be evil" intention. I would argue that such a character would not be seen as trying to satisfy fairness/justice, nor seek the suffering of another as an end in itself (unless coincidentally, rather than necessarily), yet would confidently be termed 'Evil' by most. What are your thoughts on this?

(...Hmm, the 'Better to reign in Hell than serve in Heaven' line also comes to mind, again valuing solely one's own interests in place of fairness/justice (there wanting to oneself reign rather than wanting an equal republic) and being motivated by one's own interests rather than others' suffering for its own sake.)

​

The second type that comes to mind (proposed to go against the second line only): imagine someone tasked with killing large numbers of otherwise-innocent members of a social group, whether according to poverty or ethnicity or something else. For questionable reasons, this person and most members of this person's society feel that this should be done, and that it is in line with fairness/justice--the person does not feel stress or guilt. Some people with the same job carry it out as simply as possible, some enjoy doing it cruelly, but this person puts in extra time and effort to kill them as humanely as possible, with the similar outlook to someone euthanising large numbers of abandoned pets. They die unknowing in their sleep, without fear or discomfort. Most members of this person's society would claim the person's actions/choices are not 'Evil'. My understanding is that most members of our current societies would claim the person's actions/choices are 'Evil', even if evaluated as more 'Good' than those of another who did the same things while taking pleasure in causing unnecessarily greater suffering. Following 'you are what you do', members of that person's society would not view the person as 'Evil' whereas we might. What are your thoughts on this?
:PROPERTIES:
:Author: MultipartiteMind
:Score: 2
:DateUnix: 1557652376.0
:DateShort: 2019-May-12
:END:

*** My argument here would be "Killing people is widely understood to be a Bad Thing, and as such doing it requires deliberate subversion of people's instinct towards justice/proportionality."
:PROPERTIES:
:Author: Goth_Dropping_In
:Score: 1
:DateUnix: 1557779490.0
:DateShort: 2019-May-14
:END:

**** u/GeneralExtension:
#+begin_quote
  people's instinct towards justice/proportionality."
#+end_quote

Unless it is a response, especially to the same.
:PROPERTIES:
:Author: GeneralExtension
:Score: 1
:DateUnix: 1557784340.0
:DateShort: 2019-May-14
:END:

***** I think there is a distinct instinct (the impulse towards mercy) that gets involved to try and forestall this: looking at Moral Foundations Theory again, I would label this as part of the Care/Harm axis of moral behavior.
:PROPERTIES:
:Author: Goth_Dropping_In
:Score: 1
:DateUnix: 1557857649.0
:DateShort: 2019-May-14
:END:


**** I also saw 'premise 5' in another comment just now, which looks to be a rephrasing of the part I'm questioning.

​

I don't want to go to full-blown Quirrelmort levels of pessimism, but I'm suspicious that you are misestimating the amount of selfishness and callous-cruelty (cruelty-for-the-sake-of-cruelty coming under the umbrella of the second line) in a neurotypical human. Specifically, that there's an instinct-level impulse against unfairness.

​

I'm familiar with people in groups acting to punish those who exploit their position, like someone who lets their cow eat more grass than allowed or pulling down a leader who hurts others with abuses of their power (and is also weak enough for a revolution to be successful). However, people suffering throughout their day because of the unfairness that others--not them--are suffering strikes me as the exception, an abnormal case, not the rule.

​

Speaking in benevolent ways and acting in benevolent ways can be taught, as signalling for self-protection. Some keep to this and agree benevolence to be desirable. Some do not, in and in situations where they won't be punished for deviation from this--like school playgrounds or city alleys--they do not keep to this. Past a certain point, I find it to be begging the question to ask 'Why are all these people acting as though they don't have an impulse-against-unfairness, even though they have an impulse-against-unfairness?'. Whether writing off large proportions of the population as neurologically abnormal (in which case, again, once you're writing off over 50% then they're the normal ones and the rest are abnormal), or claiming that they must actually be constantly exerting willpower to resist the urge to Do Good that they would otherwise fall prey to, Occam's Razor questions: is it possible that the strange absence of evidence for an Instinct To Do Good is because [[https://www.schlockmercenary.com/2005-10-09][there isn't one]]?

​

...though it actually might be better to search for primary literature rather than speculating...

​

While speculating, though: It is currently plausible to me that someone without an instinct can condition themselves to think in a certain way as though they have an instinct, with Pavlovian conditioning as an example. To an outside observer, the dog may seem as though it has a built-in instinct to salivate when it hears a bell. However, can you do the reverse and condition someone to act as though they don't have an instinct? Can you get rid of the instinct to jump at a loud noise, or to feel hungry when your energy levels are low, or to sleep when you haven't slept in a long time? Though then one gets into the question of if there's a distinction between instincts and physiological reactions... but for other things that you group together under the term 'instincts', can you train someone not to feel them, or do they have to hold back only-temporarily with difficulty? Are there any at all that can be withstood for a prolonged period of time, and are there any at all that a large portion of the human population lack entirely despite being detectably-strong and present in a large portion of the rest of the population?

​

That is, 'Is self-sacrificing altruism instinctive or adopted(/learned)'?
:PROPERTIES:
:Author: MultipartiteMind
:Score: 1
:DateUnix: 1557843952.0
:DateShort: 2019-May-14
:END:

***** My views/evidence on a few points here:

1: "Fairness" does seem to be encoded very low-level in the mind. Experiments with chimps and gorillas have demonstrated that they get annoyed when you stiff them. It's also one of the "five pillars" of [[https://en.wikipedia.org/wiki/Moral_foundations_theory][Moral Foundations Theory]], which seems to have a fairly decent evidence base for a social-sciences construct.

If I momentarily adopt Moral Foundations Theory for the sake of argument, I'm saying that "evil" people weight the Care and Fairness axes comparatively too low versus the Authority, Loyalty and Sanctity axes.

2: It /is/ actually possible to train out many reflexes; people training to break boards with their hands have to train out the flinch reaction that people naturally have when their hands impact a solid object.

3: "Is altruism nature or nurture" is a longstanding unsettled question, and as with most nature vs. nurture questions, it seems fairly clear that the answer is "yes."
:PROPERTIES:
:Author: Goth_Dropping_In
:Score: 1
:DateUnix: 1557856943.0
:DateShort: 2019-May-14
:END:

****** ' Experiments with chimps and gorillas have demonstrated that they get annoyed when you stiff them.' This is consistent with my 'because of the unfairness that others--not them--are suffering' paragraph, in that people (evidently and/including chimps/gorillas) are very sensitive to when people are hurting them, and punishing them to prevent that behaviour, but not necessarily sensitive to or reactive to unfairness which does not hurt them, such as to an effectively-powerless minority within that group while they are the majority. However, while writing this I come to the realisation that it could always be argued that any inconsistent apathy towards others is due to dehumanisation/moral-group-exclusion of those others, unless one can actually see how the person's neural network is functioning.

​

'Care and Fairness' weighted comparatively low--I have no argument at this time.

​

Flinch training: Definitely relevant! If I have been overestimating how hardwired certain things are in plastic brains, that opens up the model a lot to account for all sorts of stable behaviour patterns.

​

By the point that one is modelling altruism as a weak instinctual impulse that can be wholly replaced by a strong learned pattern of thought, has it not though become effectively 'nurture' rather than 'nature'? If you put two groups of people into an altruism-reinforcing tube and an altruism-extinguishing tube, and they come out according to which tube you put them in, then how can you distinguish between that world and a world in which they didn't have the altruism impulse from the start, and does it matter? Is it meaningful, for the final 'villain', if there was a 'fall from grace' or instead 'never rising to grace'? Though perhaps I should said 'benevolence', since 'grace' usually implies external favor.
:PROPERTIES:
:Author: MultipartiteMind
:Score: 1
:DateUnix: 1558236543.0
:DateShort: 2019-May-19
:END:


** u/lillarty:
#+begin_quote
  *What does it mean for someone to "be evil"?*

  Evil people are malicious. They seek the suffering of another as an end in itself.
#+end_quote

This seems incredibly reductive to the point of damaging your argument. Plenty people generally regarded as evil have committed morally reprehensible acts with the end goal ostensibly being noble. The suffering of others along the way wasn't the end goal, it was merely a convenient route to take to reach the actual goal. In fact, it even seems that you don't agree with this line yourself. Later in your post you state:

#+begin_quote
  They were placed in a situation where they believed they had to be cruel, and remained in that situation for long enough that cruelty became a reflex
#+end_quote

Even in this situation, you aren't saying that the cruelty is the end goal of this definitively evil villain. It may be a tool in their toolbox that they use often, but nobody uses a hammer as a goal unto itself, they use a hammer to drive in a nail.
:PROPERTIES:
:Author: lillarty
:Score: 1
:DateUnix: 1557860883.0
:DateShort: 2019-May-14
:END:
