#+TITLE: [HSF][DC]Android Stress Test

* [[http://imgur.com/gallery/oIDB4][[HSF][DC]Android Stress Test]]
:PROPERTIES:
:Author: Traiden04
:Score: 30
:DateUnix: 1432933169.0
:DateShort: 2015-May-30
:END:

** [deleted]
:PROPERTIES:
:Score: 7
:DateUnix: 1432976926.0
:DateShort: 2015-May-30
:END:

*** I'm curious, what are you're criteria for considering it equal to human?
:PROPERTIES:
:Author: rdestenay
:Score: 3
:DateUnix: 1432992817.0
:DateShort: 2015-May-30
:END:

**** In this case; pain, confusion, fear, human level emotions and expressions. Internal monologue involving conscious though even when muted. An AI designed to give the appearance of humanity without the attendant emotions would not have worried in such a manner about the broken finger after being muted. Obviously from such a short you can't get the full story but from what we can see it seems to be thinking just like a person with only a few differences regarding not being allowed to defend itself and the rather unimportant matter of using silicon instead of carbon as the computing substrate.
:PROPERTIES:
:Author: FuguofAnotherWorld
:Score: 6
:DateUnix: 1433012178.0
:DateShort: 2015-May-30
:END:


*** Just because a machine is capable of convincing you it has human level reaction to stimulus doesn't mean that it is actually sentient. I understand this particular piece may have been alluding to this bot being practically human, but there really is no evidence the machine truly is. We are quite a distance away from building true AI so I try to take this with a grain of salt; as we tend to murder simulations everyday.
:PROPERTIES:
:Author: MortalDaemon
:Score: 1
:DateUnix: 1433509437.0
:DateShort: 2015-Jun-05
:END:

**** If that were the case there would be no point in it maintaining a consistent, emotional internal monologue even after being muted and with no expectation that those thoughts would be heard. This is a fictional piece set an unknown amount of time in the future, our current distance away from making AI doesn't matter. It could be any time.
:PROPERTIES:
:Author: FuguofAnotherWorld
:Score: 1
:DateUnix: 1433793096.0
:DateShort: 2015-Jun-09
:END:


** I found this while surfing the internet and felt that I must share it with you fine folks here at [[/r/rational]]. I really think this might actually happen and need to have a good long think about this and how it made me feel. I would also like to hear your thoughts on this, and your reactions.
:PROPERTIES:
:Author: Traiden04
:Score: 6
:DateUnix: 1432933338.0
:DateShort: 2015-May-30
:END:

*** Well, at this time, the top imgur comment says roughly:

#+begin_quote
  I thought he was gonna rape it.
#+end_quote

I'm damn glad that didn't happen. Look, in real life, I don't think we're actually going to have androids with humanlike minds, emotions, and subjective experiences (unless someone already human ditched their meat-body and wanted a meat-like android body for some reason), but within the fictional conceit of doing so, I'm pretty damn ticked off. /Beating and murdering children is a special kind of evil./

Also, mangaka are still doing a good job of pretending Japan is a world leader in scifi-grade high technology despite two and a half Lost Decades.
:PROPERTIES:
:Score: 4
:DateUnix: 1432935422.0
:DateShort: 2015-May-30
:END:

**** u/BadGoyWithAGun:
#+begin_quote
  Also, mangaka are still doing a good job of pretending Japan is a world leader in scifi-grade high technology despite two and a half Lost Decades.
#+end_quote

This one's Korean, or at least the untranslated exclamation balloons are.
:PROPERTIES:
:Author: BadGoyWithAGun
:Score: 6
:DateUnix: 1432937109.0
:DateShort: 2015-May-30
:END:

***** Oh good.
:PROPERTIES:
:Score: 0
:DateUnix: 1432945114.0
:DateShort: 2015-May-30
:END:

****** How did you manage to conclude that from the available information anyway? Even if the companies are Japanese - which isn't clear as far as I can see - this takes place an unspecified amount of time in the future, so there's no way to tell how popular or advanced these robots are compared to other technology. Perhaps all the Western super-rich have fancy Google haptic-feedback capable VR chambers already. Japan is world leader with android technology, mostly because others don't really try that hard. Maybe they don't try in the future either.
:PROPERTIES:
:Author: philip1201
:Score: 3
:DateUnix: 1432989866.0
:DateShort: 2015-May-30
:END:

******* Honestly, I was just being a bit sarcastic about how tons and tons of manga seem to presuppose that we'll have androids and Future Stuff on Next Sunday AD.
:PROPERTIES:
:Score: 1
:DateUnix: 1432996694.0
:DateShort: 2015-May-30
:END:


** I think that on the one hand having a machine that did feel emotional things like a meat organism is kind of disgusting (I can't in good conscience say this is even just the purview of mammals when they are finding results that suggest fruit flies have a fear response).

But having an android that is willing to 'play the part' has it's place.

However the ethics of it shift in that regard from the actual torture of a self aware being, and it being a DEPICTION of the torture of a self aware being.

That is different ethical question for me.
:PROPERTIES:
:Author: Nighzmarquls
:Score: 6
:DateUnix: 1432942829.0
:DateShort: 2015-May-30
:END:

*** Um, you might have a fictional definition of consciousness, i.e. one not rooted in fact, non-psuedo-science, or ethics if you think there is any distinguishable factors to differentiate a sufficient emulation of consciousness and a conscious being. Then again we have a long way to go to defining consciousness and emulating it, but you might want to examine your assumptions, they are more than little frightening in their implications.
:PROPERTIES:
:Author: Empiricist_or_not
:Score: 1
:DateUnix: 1432994520.0
:DateShort: 2015-May-30
:END:

**** I think you have interpreted my statement as a bit less favorably then I actually mean.

Of course if you build it to act human in all ways it will be human. But that is not what I'm proposing. It's not about the external behaviors in entirety. It is about the external behaviors in very controlled contexts and then other behaviors being in different contexts.

For example an Actor pretending to be injured is DIFFERENT then some one being injured. That is the distinction I am making. The actor may be argued to potentially run a simulation of the injured consciousness but that gets kind of tricky to determine.

That is the kind of distinction I am making, artists, actors, fiction writers. These are of a comparable type of ethical question related to what you said.

BUT This is a DIFFERENT ethical thing then intentionally trying to make a consciousness that will suffer and put it in a body and torturing it.

It is a DIFFERENT ethical question to making a child and then tormenting it.

It is still an ethical question but making an AI who is conscious and choosing to 'play the role' of a victim with its own consent and not actually suffering in the sense of it does not actually care or possibly even enjoys it (but it makes a face like it does suffer in order to scratch whatever sick itch the human involved has) is not the same as one that does suffer and feel the pain and genuinely not want to be hurt.

Essentially I'm proposing androids will provide a way to have something even more extreme then present BDSM that people will probably make lots of noise about but is not in any way like what this comic shows except in immediate outside appearances.
:PROPERTIES:
:Author: Nighzmarquls
:Score: 3
:DateUnix: 1433008524.0
:DateShort: 2015-May-30
:END:


**** u/MugaSofer:
#+begin_quote
  However the ethics of it shift in that regard from the actual torture of a self aware being, and it being a DEPICTION of the torture of a self aware being.
#+end_quote

Dude, we make films and stories involvind torture of self-aware, conscious beings all the time. There is a huge ethical difference between depicting a suffering, conscious being and actual suffering.

Or are you up in arms about the mass-murder implied by modern TV shows?
:PROPERTIES:
:Author: MugaSofer
:Score: 3
:DateUnix: 1433020138.0
:DateShort: 2015-May-31
:END:

***** To be blunt I'm concerned about my own rights as a future upload which will likely first be classified as an emulation of my consciousness
:PROPERTIES:
:Author: Empiricist_or_not
:Score: 3
:DateUnix: 1433074468.0
:DateShort: 2015-May-31
:END:


** From the title, I thought it was about stress testing an Android phone.

From the comments, I thought it was about stress testing an Android phone's ability to make emotional sounds and this was a post to talk about the ethics of listening to a phone screaming and whimpering.

From the first few images, I thought it was going to be about rape and I was very annoyed that there wasn't a NSFW tag here. I wanted to click away, but I had to know why anyone would post it to here.

What I got was so, so, so much worse......

It was an ethical gut punch.

It wasn't visually horrible in any way. There was no gore, no blood, no viscerally disgusting images, or anything else that would make me have an instinctive reaction. But seeing one possible way humans could treat machines so good at emotional reactions that it's a challenge to say whether or not she's sentient (I already think of her as a person after just a few images!), this makes me feel sad to see the limitations of [[http://en.wikipedia.org/wiki/Dunbar%27s_number][human empathy]].
:PROPERTIES:
:Author: xamueljones
:Score: 7
:DateUnix: 1432949108.0
:DateShort: 2015-May-30
:END:

*** ***** 
      :PROPERTIES:
      :CUSTOM_ID: section
      :END:
****** 
       :PROPERTIES:
       :CUSTOM_ID: section-1
       :END:
**** 
     :PROPERTIES:
     :CUSTOM_ID: section-2
     :END:
[[https://en.wikipedia.org/wiki/Dunbar%27s%20number][*Dunbar's number*]]: [[#sfw][]]

--------------

#+begin_quote
  *Dunbar's number* is a suggested [[https://en.wikipedia.org/wiki/Cognition][cognitive]] limit to the number of people with whom one can maintain stable [[https://en.wikipedia.org/wiki/Interpersonal_relationship][social relationships]]. These are relationships in which an [[https://en.wikipedia.org/wiki/Individual][individual]] knows who each person is and how each person relates to every other person. This number was first proposed in the 1990s by British [[https://en.wikipedia.org/wiki/Anthropology][anthropologist]] [[https://en.wikipedia.org/wiki/Robin_Dunbar][Robin Dunbar]], who found a correlation between primate brain size and average social group size. By using the average human brain size and extrapolating from the results of primates, he proposed that humans can only comfortably maintain 150 stable relationships. Proponents assert that numbers larger than this generally require more restrictive rules, laws, and enforced norms to maintain a stable, cohesive [[https://en.wikipedia.org/wiki/Social_group][group]]. It has been proposed to lie between 100 and 250, with a commonly used value of 150. Dunbar's number states the number of people one knows and keeps social contact with, and it does not include the number of people known personally with a ceased social relationship, nor people just generally known with a lack of persistent social relationship, a number which might be much higher and likely depends on [[https://en.wikipedia.org/wiki/Long-term_memory][long-term memory]] size.
#+end_quote

--------------

^{Interesting:} [[https://en.wikipedia.org/wiki/Robin_Dunbar][^{Robin} ^{Dunbar}]] ^{|} [[https://en.wikipedia.org/wiki/Clique][^{Clique}]] ^{|} [[https://en.wikipedia.org/wiki/Attention_management][^{Attention} ^{management}]] ^{|} [[https://en.wikipedia.org/wiki/Social_thermodynamics_theory][^{Social} ^{thermodynamics} ^{theory}]]

^{Parent} ^{commenter} ^{can} [[/message/compose?to=autowikibot&subject=AutoWikibot%20NSFW%20toggle&message=%2Btoggle-nsfw+crphmxp][^{toggle} ^{NSFW}]] ^{or[[#or][]]} [[/message/compose?to=autowikibot&subject=AutoWikibot%20Deletion&message=%2Bdelete+crphmxp][^{delete}]]^{.} ^{Will} ^{also} ^{delete} ^{on} ^{comment} ^{score} ^{of} ^{-1} ^{or} ^{less.} ^{|} [[http://www.np.reddit.com/r/autowikibot/wiki/index][^{FAQs}]] ^{|} [[http://www.np.reddit.com/r/autowikibot/comments/1x013o/for_moderators_switches_commands_and_css/][^{Mods}]] ^{|} [[http://www.np.reddit.com/r/autowikibot/comments/1ux484/ask_wikibot/][^{Magic} ^{Words}]]
:PROPERTIES:
:Author: autowikibot
:Score: 2
:DateUnix: 1432949115.0
:DateShort: 2015-May-30
:END:


** That was...unpleasant. An interesting little picture story, I'll admit, and a good reflection of 'what measure is a non-human'. I half expected it to devolve into sexual elements, but the beating up and eventual death of the android girl was kinda worse.
:PROPERTIES:
:Author: liamash3
:Score: 1
:DateUnix: 1433245360.0
:DateShort: 2015-Jun-02
:END:
