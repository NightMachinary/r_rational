#+TITLE: [Q] Desensitization as video games get more realistic?

* [Q] Desensitization as video games get more realistic?
:PROPERTIES:
:Author: Kishoto
:Score: 10
:DateUnix: 1415640579.0
:END:
Ok, so I posed this question in the comment thread of ianyboo's question about the ethical concerns of killing AI, as we get more advanced, but I think it's worth its own post.

How realistic can we make NPC's, before we start significantly desensitizing people to killing other people? While our logical, conscious brains will always know "these people are fake, so it's okay", technology will progress to the point where all of the sensory input we are getting is essentially what we'd get from an actual person dying. So how long before that starts to take a toll on the human psyche?

Murky territory, I'm sure, but i pose a situation: I give you control over an armed robot in another room, and you're looking at the video feed. I tell you it's a highly realistic video game render (let's assume, at this point, technology's advanced enough for that to be viable) There are ten people in the room attacking you (the robot). I tell you to take them out, to win the game. You do. Then you leave, none the wiser to that you just killed 10 people, and never find out that you did.

In that situation, do you think there will be any psychological repercussions due to the stimulus despite the fact that, to you, it was just a simulation? If your answer to that question is yes, in any way, then it means we also need to examine the possible psychological toll of giving people the experience of fully immersive virtual murder.

I know there's already been heaps of discussion over desensitization in violent video games, but we've always been able to discern reality from fiction. They're clearly not real people that we are killing. And we WILL always know that. I'm just wondering if, as technology gets more advanced, the fact that the sensory input will be so identical to real murder will result in similar underlying effects. Maybe it won't, but it's something to think about.


** Human bodies are messy, squishy things. If you kill them, they release their bowels. Contact with your fist is nowhere near what it is in a game, it's nowhere near as solid or free; it's always painful. People don't die instantly, either: they cry out in pain, stagger around, clutch at wounds. I would argue that no video game would ever realistically show what killing someone looks like, because it simply wouldn't be fun, except for major sociopaths, and they were already desensitized.
:PROPERTIES:
:Score: 16
:DateUnix: 1415641833.0
:END:

*** So ok, there's a lack of tactile sensation, as no video game is going to be programmed to give painful feedback (hopefully)

As far as no game having people going through death throes, I don't think it's as unrealistic to have that as you're making it sound. 30 years ago when you shot a character, they disappeared. Now, when you shoot them (depending on the game rating), they stagger around, bleed and lay there for however long the game engine requires (and in some engines, they will sit there indefinitely)
:PROPERTIES:
:Author: Kishoto
:Score: 5
:DateUnix: 1415647667.0
:END:

**** But will enemies ever be programmed to release their bowels and bladders? Cry out for their children and wives? It's distasteful for most people (and, again, the people it isn't distasteful for already have problems). If video games ever do get to the point of showing the realistic process of murder, then it won't be a product of video games setting the new standard, it will be video games catching up with a common thing in all media.

Edit: I can see video games, as with all media, conditioning people to enjoy violence. People may connect the process of killing enemies with gaining a rewards (experience, level up, seeing more of the story, money, etc.) and connect that to real life, but I cannot see it being desensitization, as in "not caring." The people who are likely to form a close enough connection to a video game to be emotionally influenced by it are not going to /stop caring/ about the lives of their enemies, and by extension the people around them. They're going to care very much for it.

But again, this brings me back to what I said at the beginning of that statement: "as with all media." Video games are only special in their immediacy; all media has the capacity for conditioning.

Of course, this is all a common response to the idea of video games desensitizing people to violence. To get back to your original point: no, I don't see advancements in video games causing anything more than what they are currently causing in terms of desensitization *or* conditioning, but only because video games are already pretty damn realistic when they want to be.
:PROPERTIES:
:Score: 11
:DateUnix: 1415647889.0
:END:


**** Of course videogames are going to be programmed to give painful feedback. Look at the popularity of paintball, which leaves welts on the body. There are prototypes out in the world that give painful feedback - and for a certain crowd, that feedback will sell the realism, and be desirable. Haptics is one of the next great frontiers of videogaming, and I think it's fairly obvious that pain is going to be a desirable part of that for a certain subset of people.
:PROPERTIES:
:Author: alexanderwales
:Score: 5
:DateUnix: 1415649517.0
:END:


**** The dividing line between fantasy and reality is actually a lot more powerful than most people think. This applies to everything from video games to porn: what people would enjoy in an unrealistic simulation vs what they would enjoy in real life are like flipping a switch.

I don't really get grossed out by gore on a screen: it's just kind of annoying when there's too much of it. So I can play really gory games without issue. Visual depictions of blood and guts can be distasteful, but it's not shocking to me anymore, if it ever was.

But there was a game I played once where a young woman abruptly got electrocuted, and I immediately had to stop playing. Their screams were so realistic, the visuals so visceral, that it put me in a cold sweat, and I was trembling slightly after I walked away from it.

There will always be different buttons people have for what crosses the line from fantasy to reality. Just because we seem to be desensitized doesn't mean we are: it just means what we're seeing is safely compartmentalized into fantasy. If we saw it in real life, that compartment would shatter.
:PROPERTIES:
:Author: DaystarEld
:Score: 3
:DateUnix: 1415653053.0
:END:


**** #+begin_quote
  30 years ago when you shot a character, they disappeared. Now, when you shoot them (depending on the game rating), they stagger around, bleed and lay there for however long the game engine requires (and in some engines, they will sit there indefinitely).
#+end_quote

A large part of that is due to advances in technology, not just advances in bloodlust.

30 years ago, if you tried to have your characters stagger & bleed out in graphic detail, it wouldn't have been viable.
:PROPERTIES:
:Author: Subrosian_Smithy
:Score: 2
:DateUnix: 1415675990.0
:END:


*** Units in Dwarf Fortress stagger around, have wounds, bleed, feel horror, shock, pain in battle etc.
:PROPERTIES:
:Author: Putnam3145
:Score: 2
:DateUnix: 1415663485.0
:END:

**** ...I don't usually get a visceral sense of reality from DF. It's amazing, but not immersive.
:PROPERTIES:
:Author: PeridexisErrant
:Score: 3
:DateUnix: 1415674424.0
:END:


**** Oh, they're entirely different. Losing is fun, after all.
:PROPERTIES:
:Score: 3
:DateUnix: 1415686637.0
:END:


**** Dwarf Fortress players are already sociopaths though.
:PROPERTIES:
:Author: holomanga
:Score: 1
:DateUnix: 1416144719.0
:END:


*** An argument could already be made from the other point of view that we are not quite in a hurry to increase the fidelity of our gun-handlign simulations for instance. I doubt the sales of FPS' would increase if they suddenly all handled like [[http://www.youtube.com/watch?v=pYnafn6x_1c][Receiver]] so a case can easily be made that near-reality simulation is hardly desired.
:PROPERTIES:
:Author: Drexer
:Score: 2
:DateUnix: 1415718501.0
:END:


*** ...

I don't think I should admit to wanting to play that game.
:PROPERTIES:
:Author: Arizth
:Score: 2
:DateUnix: 1415643608.0
:END:

**** Oh, a game where all the enemies die realistically would be interesting, but I probably wouldn't end up playing it for hours on end...

(as required, [[http://xkcd.com/873/][relevant xkcd]])
:PROPERTIES:
:Score: 4
:DateUnix: 1415643814.0
:END:

***** [[http://imgs.xkcd.com/comics/fps_mod.png][Image]]

*Title:* FPS Mod

*Title-text:* Wait, that second one is a woman? ... wait, if that bothers me, then why doesn't ... man, this game is no fun anymore.

[[http://www.explainxkcd.com/wiki/index.php?title=873#Explanation][Comic Explanation]]

*Stats:* This comic has been referenced 29 times, representing 0.0725% of referenced xkcds.

--------------

^{[[http://www.xkcd.com][xkcd.com]]} ^{|} ^{[[http://www.reddit.com/r/xkcd/][xkcd sub]]} ^{|} ^{[[http://www.reddit.com/r/xkcd_transcriber/][Problems/Bugs?]]} ^{|} ^{[[http://xkcdref.info/statistics/][Statistics]]} ^{|} ^{[[http://reddit.com/message/compose/?to=xkcd_transcriber&subject=ignore%20me&message=ignore%20me][Stop Replying]]} ^{|} ^{[[http://reddit.com/message/compose/?to=xkcd_transcriber&subject=delete&message=delete%20t1_clykym1][Delete]]}
:PROPERTIES:
:Author: xkcd_transcriber
:Score: 3
:DateUnix: 1415643850.0
:END:


** Trauma results from the amygdala forming emotional memories which, for some reason, are poorly regulated- stress dampens regulation of the amygdala for example. Video games are repetitive and much lower in stress than most murder situations.

If you kill someone, you kill them once. If you kill someone in a video game you get to repeat kill them till less bad memories are formed.

I think in real life if you got to kill hundreds of people you could eventually feel better about it but that would be grossly immoral.
:PROPERTIES:
:Author: Nepene
:Score: 2
:DateUnix: 1415662189.0
:END:


** Until video games introduce more senses (smell, touch) I do not believe it desensitizes to killing.

I rather see the danger in killing becoming more like video games. Think about Ender's Game and drones. Is there an incentive for the military to deceive their drone operators about reality and simulation?
:PROPERTIES:
:Author: qznc
:Score: 2
:DateUnix: 1415696469.0
:END:


** Is sensitivity really a deciding factor in inclination to kill? The fact that murder is icky probably isn't what's preventing most people from going on killing sprees.
:PROPERTIES:
:Author: Oh_Hi_Mark_
:Score: 2
:DateUnix: 1415698067.0
:END:

*** I think you may be misinterpreting the meaning of the word desensitization. It's not about people being less grossed out, so they murder people because they can stomach it. It's about them being less repelled by killing overall (due to their respect for life or what have you)
:PROPERTIES:
:Author: Kishoto
:Score: 1
:DateUnix: 1415726969.0
:END:

**** Well I'm just confused then. I can sort of see how sufficiently realistic videogames might make the act of killing less uncomfortable, but I don't understand how they might degrade one's beliefs in the value of other minds, or moral behavior in general. Why do you believe that they would?
:PROPERTIES:
:Author: Oh_Hi_Mark_
:Score: 1
:DateUnix: 1415902248.0
:END:


** Slatestarcodex had an article a while back entitled [[http://slatestarcodex.com/2013/06/22/social-psychology-is-a-flamethrower/][Social Psychology is a Flamethrower]]. In it, Scott wrote about several examples where you could argue that there is scientific or logical evidence that contradicts a lot of popular opinion in certain areas.

In the first example given of contrary evidence, the author noted a study where violent movies were shown to decrease crime rates. Specifically, for violent movies:

#+begin_quote
  They found violent movies decreased crime 5% or more on their opening weekends, and that each violent movie that comes out probably prevents about 1000 assaults. Further, there's no displacement effect -- the missing crimes don't pop back the following week, they simply never occur.
#+end_quote

A similar effect occurs with games.

This hypothesis is certainly intriguing to me. It would suggest that as substitutes for actually killing people get better and better at allowing us to vicariously experience the act of killing, real and actual killing might decrease instead of increase.

Ultimately, I think more study should probably be done in this area - you can tell 'just so' stories that point in *either direction*, so actual studies that measure the impact of violence in various media in the long term in terms of actual murders prevented or created would probably be the most persuasive.
:PROPERTIES:
:Author: Escapement
:Score: 2
:DateUnix: 1415709609.0
:END:


** Should we even care about desensitizing?

From rationalist POV depending on the emotional part of brain (that can be desensitized) to prevent mass murderers seems suboptimal anyway.

Emotions aren't required to know not to kill people, you can rationaly decide not to do it. In fact emotions can be hijacked by ideology/religion and make you kill innocent people, stress can overcome you to stop feeling for others for a moment, and even without external influences emotions can push you to make wrong decisions (save 1 pretty kid of your race - let 10 ugly people of different race die).

So IMHO we should teach people morality depending on their rational brains, not on emotions. And then desensitizing isn't much of a problem.

BTW there was this brilliant Stanisław Lem short story about [[http://www.empathogens.com/altruizine/][altruizine]] - substance that turned empathy in people to 11. It made people feel everything others felt so they would be better to each other. End result should be obvious, but it still took me by surprise. Check it out - it's in short stories collection [[http://en.wikipedia.org/wiki/The_Cyberiad]] it's one of my favorite books - it's weird fairy-tales/sci-fi mix, but the stories show realistic consequences given the weird universe.

In fact I think Cyberiad is a rationalist book, it even deals with the usual problems (optimizing universe, friendly AIs, simulations within simulations, etc).
:PROPERTIES:
:Author: ajuc
:Score: 3
:DateUnix: 1415667526.0
:END:

*** I see what you're saying, I didn't think of it that way. I guess I don't think we can viably reach out and teach ourselves to be rational enough to counter the joy/pleasure psychopaths would receive from murdering people. And of course, for that, it assumes these psychopaths exist in the first place.

Anyway, based on history and even what we see today, it's easier to herd the masses, than it is to try and honestly educate them. Some things will take root, sure, so the average human is smarter now than they were, say, 80 years ago (although that one's debatable, it could easily be just that the average human has more knowledge, and the access to even more knowledge, than one a lifetime ago) but I don't think it's feasible to try and impart a rational mindset on the general populace. I don't think it will take. I feel like simpler, more baseline approaches need to be made.

Simply put, not everyone's smart enough (or cares enough about GETTING smart enough) to be a rationalist :(
:PROPERTIES:
:Author: Kishoto
:Score: 2
:DateUnix: 1415690224.0
:END:


*** #+begin_quote
  Emotions aren't required to know not to kill people, you can rationaly decide not to do it.
#+end_quote

Isn't that the core of the problem Yudkowsky and MIRI are trying to solve? As far as I know there is no solution. How can you make a strong AI decide not to kill (or torture or obliterate etc) humans if it makes purely rational decisions?
:PROPERTIES:
:Author: qznc
:Score: 2
:DateUnix: 1415696043.0
:END:

**** Making the rational decision not to kill people is far easier for people than for strong AIs. Strong AIs of the sort commonly postulated by EY et al. have sufficient strength that they neither require humans to continue their own existence, nor are they meaningfully subject to any human authorities. Humans, on the other hand, well, there are almost no people on the planet who suffer no repercussions from other authorities when killing random people.

The rational decisionmaking /context/ is completely different. And this context makes the decisionmaking algorithms far more difficult.

For most random US citizens it is:

Choose to kill people: You have good chances (~60%, according to googling for unsolved murder statistics) of going to prison for a long time, lose all good economic prospects and are permanently ostracized from society when released.

For AIs of the sort postulated by EY et al:

Choose to kill people: People are dead, no meaningful chance of meaningful punishment other than being in a universe with slightly more dead people.
:PROPERTIES:
:Author: Escapement
:Score: 2
:DateUnix: 1415708905.0
:END:


*** ***** 
      :PROPERTIES:
      :CUSTOM_ID: section
      :END:
****** 
       :PROPERTIES:
       :CUSTOM_ID: section-1
       :END:
**** 
     :PROPERTIES:
     :CUSTOM_ID: section-2
     :END:
[[https://en.wikipedia.org/wiki/The%20Cyberiad][*The Cyberiad*]]: [[#sfw][]]

--------------

#+begin_quote
  */The Cyberiad/* ([[https://en.wikipedia.org/wiki/Polish_language][Polish]]: /Cyberiada/) is a series of humorous [[https://en.wikipedia.org/wiki/Short_story][short stories]] by [[https://en.wikipedia.org/wiki/Stanis%C5%82aw_Lem][Stanisław Lem]]. The Polish version was first published in 1965, with an English translation appearing in 1974. The main [[https://en.wikipedia.org/wiki/Protagonist][protagonists]] of the series are Trurl and Klapaucius, the "constructors".

  The vast majority of characters are either [[https://en.wikipedia.org/wiki/Robot][robots]] or intelligent [[https://en.wikipedia.org/wiki/Machine][machines]]. The stories focus on problems of the individual and society, as well as on the vain search for human happiness through technological means. Two of these stories were included in the book /[[https://en.wikipedia.org/wiki/The_Mind%27s_I][The Mind's I]]./

  * 
    :PROPERTIES:
    :CUSTOM_ID: section-3
    :END:
  [[https://i.imgur.com/olvkKQm.jpg][*Image*]] [[https://en.wikipedia.org/wiki/File:TheCyberiad.jpg][^{i}]]
#+end_quote

--------------

^{Interesting:} [[https://en.wikipedia.org/wiki/Stanis%C5%82aw_Lem][^{Stanisław} ^{Lem}]] ^{|} [[https://en.wikipedia.org/wiki/Cyberiada_(opera)][^{Cyberiada} ^{(opera)}]] ^{|} [[https://en.wikipedia.org/wiki/Fables_for_Robots][^{Fables} ^{for} ^{Robots}]] ^{|} [[https://en.wikipedia.org/wiki/Krzysztof_Meyer][^{Krzysztof} ^{Meyer}]]

^{Parent} ^{commenter} ^{can} [[/message/compose?to=autowikibot&subject=AutoWikibot%20NSFW%20toggle&message=%2Btoggle-nsfw+clyxuwg][^{toggle} ^{NSFW}]] ^{or[[#or][]]} [[/message/compose?to=autowikibot&subject=AutoWikibot%20Deletion&message=%2Bdelete+clyxuwg][^{delete}]]^{.} ^{Will} ^{also} ^{delete} ^{on} ^{comment} ^{score} ^{of} ^{-1} ^{or} ^{less.} ^{|} [[http://www.np.reddit.com/r/autowikibot/wiki/index][^{FAQs}]] ^{|} [[http://www.np.reddit.com/r/autowikibot/comments/1x013o/for_moderators_switches_commands_and_css/][^{Mods}]] ^{|} [[http://www.np.reddit.com/r/autowikibot/comments/1ux484/ask_wikibot/][^{Magic} ^{Words}]]
:PROPERTIES:
:Author: autowikibot
:Score: 1
:DateUnix: 1415667544.0
:END:
