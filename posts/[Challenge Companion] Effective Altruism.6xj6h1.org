#+TITLE: [Challenge Companion] Effective Altruism

* [Challenge Companion] Effective Altruism
:PROPERTIES:
:Author: alexanderwales
:Score: 9
:DateUnix: 1504318402.0
:DateShort: 2017-Sep-02
:END:
*This is the companion to [[https://www.reddit.com/r/rational/comments/6xj599/biweekly_challenge_effective_altruism/][the biweekly challenge]]. Post comments, recommendations, discussion, or general chit-chat below.*


** So, here's a setting I've been thinking about, which might provide some inspiration:

Suppose, in the near future, someone engineered and released virus that caused people to develop an extreme amount of empathy and compassion. As in, so much empathy that hearing about the death of a stranger on the other side of the world would cause an emotional reaction like the death of a loved one, and hearing about a stranger giving birth would feel like having a child yourself. If most of humanity was infected, what might happen?

My take: in the short term, you'd see an enormous amount of chaos. There would be a global epidemic of severe PTSD as the traumatic experiences of individuals caused global effects. Most people might eventually learn to cope with both that and the constant mix of extreme joy and grief, especially with the entire world motivated to develop new psychological techniques and drugs. Initially, however, suicides would be a huge problem.

On top of that, industries and maybe even entire economies would collapse as consumers would feel uncomfortable about buying unnecessary goods while other people were still starving or suffering. Something like the economic mobilizations during WWII might occur, though focused on massive third world development projects. In first world nations, you might start to see things like food rationing, while people in extreme poverty would see a dramatic increase in standard of living.

A century later, the world might look like a kind of utopia- free of poverty and most kinds violence and abuse, with a global economy slowly reapproaching pre-virus first-world standards and with huge medical research initiatives. It might be a world where few people could endure learning about history, however, and where taking any kind of risk was severely discouraged.
:PROPERTIES:
:Author: artifex0
:Score: 10
:DateUnix: 1504335202.0
:DateShort: 2017-Sep-02
:END:

*** It seems to me that a few very powerful people might conclude that the suffering caused by the new empathy is the easiest problem to solve; we'd then wind up with a carefully-zoned world whose zones hear very little information about each other, which is carefully-controlled to only be positive; hospitals might fade away and become replaced with involuntary euthanasia factories and a state-mandated religion featuring a universal pleasant afterlife. And that's assuming negative utilitarianism (ie, altruistic omnicide) doesn't rear its ugly head, in which case we're all fucked.
:PROPERTIES:
:Author: LiteralHeadCannon
:Score: 9
:DateUnix: 1504383976.0
:DateShort: 2017-Sep-03
:END:

**** That's utterly horrifying and hits too close to home for me. When confronted with a source of traumatic information, people instinctively distance themselves from that source in order to preserve their mental stability. Unless eliminating the source of trauma is easier than killing the messenger, people will choose to cut themselves off because the costs and risks of doing anything else are higher. This has the makings of a Black Mirror episode.
:PROPERTIES:
:Author: trekie140
:Score: 4
:DateUnix: 1504401628.0
:DateShort: 2017-Sep-03
:END:


*** Obviously everyone in the world would become literally insane or commit suicide within minutes, since there are 150,000 deaths every day and if each of them feels like a loved one dying then that amount of grief is impossible to handle.

I don't know what this has to do with effective altruism though.
:PROPERTIES:
:Author: UmamiSalami
:Score: 1
:DateUnix: 1504403974.0
:DateShort: 2017-Sep-03
:END:

**** I'm not so sure; I think that human grief is probably bounded. If you hear news that two of your family members have died, you'll feel more grief than if only one had died, but would be severity of the emotion be doubled? Suppose you have a large extended family, and you hear that fourteen of them have died in a disaster- would your grief be substantially different than if only thirteen had died? I suspect that each additional death increases your experience of grief by a real, but diminishing amount, converging on a state of severe grief close to what a lot of people experience during wars and natural disasters.

Also, what we feel has a lot to do with what we focus on, and while there's a lot of death and suffering in the world, there's also a lot of profoundly felt joy. I think a person infected with this virus might slip from paralyzing grief to euphoric high just by scrolling through photos of strangers being married.

The effective altruism angle has to do with imagining a setting where almost everyone would be strongly motivated emotionally to behave altruistically- not just toward the people they normally interact with, but toward everyone, which is what effective altruism calls for- and trying to imagine the shocks to our present system that might produce, and the sort of civilization it might eventually result in.
:PROPERTIES:
:Author: artifex0
:Score: 1
:DateUnix: 1504413474.0
:DateShort: 2017-Sep-03
:END:

***** Then the scenario is not about everyone's death having the same impact that a loved one's death does. The scenario is about everyone's death having the same impact that a loved one's death /would/ have /if/ we had hundreds of thousands of loved ones. But it's physically impossible to have that many loved ones (cf Dunbar's Number), so the whole thing doesn't even make sense - we can't even define the possible amount of suffering. Meanwhile, if you flipped the question to being happy about other people's lives being saved, then we'd be ecstatically overwhelmed 100% of the time.

#+begin_quote
  The effective altruism angle has to do with imagining a setting where almost everyone would be strongly motivated emotionally to behave altruistically
#+end_quote

There are tons of ways to motivate people to behave altruistically. I could imagine a world where people get diarrhea every day that they don't donate to charity. The fact that this leads to them acting altruistically doesn't mean that speculating about it is the right way to talk about what would happen if people were more altruistic.

#+begin_quote
  not just toward the people they normally interact with, but toward everyone, which is what effective altruism proposes
#+end_quote

But most EAs are concerned with all forms of well-being, not just what is happening currently, not just humans, and not just deaths.
:PROPERTIES:
:Author: UmamiSalami
:Score: 1
:DateUnix: 1504414006.0
:DateShort: 2017-Sep-03
:END:


** Effective altruism is always an idea I've had trouble with implementing. As an economist, I believe the thing that would do the most good in the world is altering current behavioral incentives to encourage optimization of utilitarian humanism. However, even if you can do that, you have to contend with at least some people not knowing how, not understanding how, or simply not choosing to optimize the values you want.

Then you're up against the basic flaws of human psychology that have always hampered progress. Not everyone has empathy for everyone else, not everyone is willing to make the same sacrifices for the good of others, and not everyone's flawed reasoning can be corrected the same way. So in the end, I concluded that the most effective mindset of an altruist is to use whatever power you personally have to help people when you have the opportunity.

If you decide to alter human psychology so that these are no longer a problem, you then run into the problem of violating people's right to self-determination. If optimizing human well-being requires fundamentally changing what it means to be human, then I think you should reconsider your values and methods of optimizing them. One solution could be to make such alterations voluntary, though you'd have to be careful about inequality between these groups.

So some possible scenarios that come to my mind: sell sentient robots programmed to be rationalists and good samaritans when not working, give people the option of uploading into an altruistic hive mind, or construct an AI-operated communications network dedicated to sharing information about altruistic activities that people can do. All have potential failure states, but present opportunities for good things to happen that currently aren't without directly causing harm to humans.
:PROPERTIES:
:Author: trekie140
:Score: 3
:DateUnix: 1504403897.0
:DateShort: 2017-Sep-03
:END:


** The challenge thread has now been up for 19 days. In the thread itself, it is claimed that the new challenge would go up on September 13th. (8 days ago)

Is this delay intentional? Does it mean that the biweekly challenges may be over?

I'm sorry if I seem nosy, but I'd like some closure. Though I've only participated in three challenges so far, I've really grown to like them. (Also, my story for the next challenge is already finished, and I would love to post it. If the challenges are over, I would post it as a standalone.)
:PROPERTIES:
:Author: vi_fi
:Score: 1
:DateUnix: 1505977175.0
:DateShort: 2017-Sep-21
:END:

*** No, I went off to a wedding last Wednesday and missed the usual calendar event, then sort of forgot about it, so ... sorry about that. It's super-late in my time zone and I was just about to go to sleep, but I will have the next one up tomorrow around noon Central (UTC -6).

(You won quite handily; I gave you the gold and disabled contest mode, the announcement will be in the post tomorrow.)
:PROPERTIES:
:Author: alexanderwales
:Score: 2
:DateUnix: 1505977995.0
:DateShort: 2017-Sep-21
:END:

**** Thank you :) I thought it was something like that, but then saw that you posted today, which made me ask.
:PROPERTIES:
:Author: vi_fi
:Score: 1
:DateUnix: 1505978269.0
:DateShort: 2017-Sep-21
:END:


**** This raised a point I wanted to raise for some time now: could the rest of the regular threads be automated? AutoModerator posts weekly threads, but the recommendations thread is posted by a human, with them [[https://www.reddit.com/r/rational/comments/6rrew4/monthly_recommendation_thread/][having to plan ahead and recruit help]] if they expect to be unavailable, which I'm not sure they enjoy.

It would be more complicated with challenge threads, but having AutoModerator un-stick the old thread, disable the contest mode in it, and then the create and stick the new thread should be doable, with the theme of the new thread decided on your leisure during the corresponding two weeks, and the winner's info pulled from the old thread. I'm not sure that giving flair and gold is possible to implement, though, and formatting of top-level comments would need to be standardized.

*Edit:* [[https://xkcd.com/1319/][On second thoughts...]]
:PROPERTIES:
:Author: Noumero
:Score: 1
:DateUnix: 1506052058.0
:DateShort: 2017-Sep-22
:END:

***** Monthly rec threads really should be automated. I took ten minutes to do that just now, ping to [[/u/ToaKraka]] and [[/u/magodo]]. It should post at October 5, 2017 3:00 PM UTC, but one of the things I hate about Automoderator is that it's hard to actually test that it's not going to screw things up. (I had always said that I would do that if they were popular enough, and then never checked back or had anyone tell me that they were popular enough.)

Automating the challenges would probably take more time than automation is worth, though you're right that partial automation is probably a good halfway measure, which wouldn't be too hard for some of the most annoying things. I'll try to get to that sometime in the near future.

(I also want to automate adding the winners to the wiki page of winners; that's horribly behind, because it's grunt work that I never feel like doing and I don't actually know whether anyone looks at it.)
:PROPERTIES:
:Author: alexanderwales
:Score: 1
:DateUnix: 1506054028.0
:DateShort: 2017-Sep-22
:END:

****** u/ToaKraka:
#+begin_quote
  ping to [[/u/ToaKraka]]
#+end_quote

As far as I'm aware, I [[http://i.imgur.com/o6iOXcv.png][was instructed]] to post /only/ the thread for August, and retained no further responsibility for the Monthly Recommendation Thread after that instruction was fulfilled.
:PROPERTIES:
:Author: ToaKraka
:Score: 2
:DateUnix: 1506079620.0
:DateShort: 2017-Sep-22
:END:

******* I was about to post the September thread and found it was already posted. I was pretty confused too..
:PROPERTIES:
:Author: Magodo
:Score: 2
:DateUnix: 1506699718.0
:DateShort: 2017-Sep-29
:END:


****** Sweet.

#+begin_quote
  I also want to automate adding the winners to the wiki page of winners; that's horribly behind
#+end_quote

Actually it's not, [[https://www.reddit.com/r/rational/wiki/weeklychallenge][I've been updating it]]. Only the record of the latest development is not included in it.

I wholly support its automation, though. Keeping it up-to-date it is annoying and, yes, possibly pointless: we may be the only two people interested in its existence.

Hmm, while we're at it, can you also automate updates of wiki-pages for weekly and recommendation threads? Unless [[/u/ToaKraka][u/ToaKraka]] enjoys updating them, that is.
:PROPERTIES:
:Author: Noumero
:Score: 1
:DateUnix: 1506065155.0
:DateShort: 2017-Sep-22
:END:
