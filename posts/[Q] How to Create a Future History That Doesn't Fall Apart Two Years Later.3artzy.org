#+TITLE: [Q] How to Create a Future History That Doesn't Fall Apart Two Years Later

* [Q] How to Create a Future History That Doesn't Fall Apart Two Years Later
:PROPERTIES:
:Author: callmebrotherg
:Score: 26
:DateUnix: 1435018670.0
:DateShort: 2015-Jun-23
:END:
The biggest problem that I have in building a science fiction setting is that even slight unexpected advances in the real world can totally destabilize the setting. This doesn't matter /so/ much with a one-off story, but it's a prospect that's sort of bugging me whenever I think about building a setting that I use repeatedly over a number of years.

Does anybody else have this problem? Is there some trick that I'm overlooking? Does it just... not actually matter as much as I think it does, that I could have a running universe that was scientifically rigorous to begin with but (in order to keep continuity with previous stories) is less and less so as Science Marches On?


** Don't sweat it. Isaac Asimov managed to write a story that was obsolete before it was published.
:PROPERTIES:
:Author: ArgentStonecutter
:Score: 17
:DateUnix: 1435019156.0
:DateShort: 2015-Jun-23
:END:

*** Out of historical interest, which one was it?
:PROPERTIES:
:Author: callmebrotherg
:Score: 6
:DateUnix: 1435019644.0
:DateShort: 2015-Jun-23
:END:

**** [[https://en.wikipedia.org/wiki/Everest_(short_story)][Everest]] (wikipedia summary).

Part of the premise of the story is that Everest ends up being unclimbable; Asimov wasn't actually predicting that would be the case, but he figured it wouldn't be climbed until after the story was published.
:PROPERTIES:
:Author: imyourfoot
:Score: 11
:DateUnix: 1435033433.0
:DateShort: 2015-Jun-23
:END:

***** ***** 
      :PROPERTIES:
      :CUSTOM_ID: section
      :END:
****** 
       :PROPERTIES:
       :CUSTOM_ID: section-1
       :END:
**** 
     :PROPERTIES:
     :CUSTOM_ID: section-2
     :END:
[[https://en.wikipedia.org/wiki/Everest%20(short%20story)][*Everest (short story)*]]: [[#sfw][]]

--------------

#+begin_quote
  "*Everest*" is a [[https://en.wikipedia.org/wiki/Science_fiction][science fiction]] [[https://en.wikipedia.org/wiki/Short_story][short story]] by [[https://en.wikipedia.org/wiki/Isaac_Asimov][Isaac Asimov]]. It was first published in the December 1953 issue of /[[https://en.wikipedia.org/wiki/Universe_Science_Fiction][Universe Science Fiction]]/ and reprinted in the 1975 collection /[[https://en.wikipedia.org/wiki/Buy_Jupiter_and_Other_Stories][Buy Jupiter and Other Stories]]/. Asimov wrote the story in one sitting while visiting the [[https://en.wikipedia.org/wiki/Chicago,_Illinois][Chicago]], Illinois editorial offices of /Universe/ on 7 April 1953.
#+end_quote

--------------

^{Relevant:} [[https://en.wikipedia.org/wiki/List_of_media_related_to_Mount_Everest][^{List} ^{of} ^{media} ^{related} ^{to} ^{Mount} ^{Everest}]] ^{|} [[https://en.wikipedia.org/wiki/Mount_Everest][^{Mount} ^{Everest}]] ^{|} [[https://en.wikipedia.org/wiki/Into_Thin_Air][^{Into} ^{Thin} ^{Air}]]

^{Parent} ^{commenter} ^{can} [[/message/compose?to=autowikibot&subject=AutoWikibot%20NSFW%20toggle&message=%2Btoggle-nsfw+csfku0l][^{toggle} ^{NSFW}]] ^{or[[#or][]]} [[/message/compose?to=autowikibot&subject=AutoWikibot%20Deletion&message=%2Bdelete+csfku0l][^{delete}]]^{.} ^{Will} ^{also} ^{delete} ^{on} ^{comment} ^{score} ^{of} ^{-1} ^{or} ^{less.} ^{|} [[/r/autowikibot/wiki/index][^{FAQs}]] ^{|} [[/r/autowikibot/comments/1x013o/for_moderators_switches_commands_and_css/][^{Mods}]] ^{|} [[/r/autowikibot/comments/1ux484/ask_wikibot/][^{Call} ^{Me}]]
:PROPERTIES:
:Author: autowikibot
:Score: 2
:DateUnix: 1435033485.0
:DateShort: 2015-Jun-23
:END:


**** Someone wrote a story about canals on mars, and higher resolution photos became available before it was published. I think that example predates Asimov, though?
:PROPERTIES:
:Author: sparr
:Score: 2
:DateUnix: 1435020131.0
:DateShort: 2015-Jun-23
:END:


**** [deleted]
:PROPERTIES:
:Score: 1
:DateUnix: 1435052761.0
:DateShort: 2015-Jun-23
:END:


** My advice, which I don't see in the comments so far:

Preemptively obsolete yourself! Start writing a scifi story based on scientific knowledge that has already been expanded on, updated, or corrected in the present day! You're going to be obsoleted eventually no matter what, so just commit absolutely to creating an alternate history where physics works differently!

They can't kill you if you're already dead!
:PROPERTIES:
:Author: Detsuahxe
:Score: 16
:DateUnix: 1435029235.0
:DateShort: 2015-Jun-23
:END:

*** And so steampunk was born.
:PROPERTIES:
:Score: 9
:DateUnix: 1435076211.0
:DateShort: 2015-Jun-23
:END:

**** Plus the Fallout universe.
:PROPERTIES:
:Author: HereticalRants
:Score: 2
:DateUnix: 1435243042.0
:DateShort: 2015-Jun-25
:END:


*** Lol. Maybe.

Thanks for the advice. >:]
:PROPERTIES:
:Author: callmebrotherg
:Score: 2
:DateUnix: 1435030507.0
:DateShort: 2015-Jun-23
:END:


** Just make it into an alternate history at some point. Charles Stross has repeatedly grumbled about being taken over by the real world. Articles [[http://www.antipope.org/charlie/blog-static/2014/10/the-curse-of-laundry.html][here]] and [[http://www.antipope.org/charlie/blog-static/2006/09/truth_overtakes_fiction_in_str.html][here]]. I think that if you're doing the "near-future" thing right, this is always going to be an issue, and either you're going to have to drop the setting, or you're going to accept that you divert away from the real world starting around when the first bit is published.
:PROPERTIES:
:Author: alexanderwales
:Score: 9
:DateUnix: 1435021237.0
:DateShort: 2015-Jun-23
:END:

*** Oh, that's great. I feel sorry for the man.
:PROPERTIES:
:Author: callmebrotherg
:Score: 3
:DateUnix: 1435021882.0
:DateShort: 2015-Jun-23
:END:

**** Stross is really hardcore about consistency. He could have kept writing it as an alternate world or something.

He dropped his Eschaton ("Singularity Sky", "Iron Sunrise") series for not entirely dissimilar reasons.

On the other hand, he doesn't seem to worry about the Laundry series missing its apocalypse dates. CASE NIGHTMARE GREEN was supposed to hit years ago. :)
:PROPERTIES:
:Author: ArgentStonecutter
:Score: 4
:DateUnix: 1435053036.0
:DateShort: 2015-Jun-23
:END:

***** From the article that I linked:

#+begin_quote
  The Laundry Files /explicitly/ exists in an alternate history to our own, okay? Word Of God speaking here. "The Rhesus Chart" is set in mid-2013, and "The Annihilation Score" in summer/autumn of 2013. I'm going to kick "The Nightmare Stacks" (or whatever book 7 is titled) down the road into a 2014 which will be well in our past and nailed down by the time the book is handed in, in autumn of 2015.
#+end_quote

(I should also point out that CASE NIGHTMARE GREEN is a gradient, not a singular event; arguably, "The Rhesus Chart" was set at the beginning of CASE NIGHTMARE GREEN.)
:PROPERTIES:
:Author: alexanderwales
:Score: 2
:DateUnix: 1435078358.0
:DateShort: 2015-Jun-23
:END:

****** Hmmm. /Overtime/ says it's a 70 year long window, and that it started 9 months before the start of the story.

ISTR earlier versions of some of the Laundry stories having it starting as early as 2006, but I guess he's fixed that in the currently in-print versions.
:PROPERTIES:
:Author: ArgentStonecutter
:Score: 1
:DateUnix: 1435079724.0
:DateShort: 2015-Jun-23
:END:


***** u/deleted:
#+begin_quote
  On the other hand, he doesn't seem to worry about the Laundry series missing its apocalypse dates. CASE NIGHTMARE GREEN was supposed to hit years ago. :)
#+end_quote

Thus, the simplest hypothesis is that it did. So what's going on?
:PROPERTIES:
:Score: 0
:DateUnix: 1435076233.0
:DateShort: 2015-Jun-23
:END:

****** Since you didn't notice anything, you have already been uploaded into the mind-spaces of the Eater of Souls and are experiencing one of a myriad of alternate scenarios of the arc of your lifespan for its amusement.
:PROPERTIES:
:Author: ArgentStonecutter
:Score: 2
:DateUnix: 1435077074.0
:DateShort: 2015-Jun-23
:END:

******* Ah, I remember /A Colder War/. But that can't have happened. Cthulhu would have noticed certain things about my brain and killed me outright before I could kill him.

Also, where the hell is [[/u/GraduallyCthulhu]] when you need him?
:PROPERTIES:
:Score: 1
:DateUnix: 1435077232.0
:DateShort: 2015-Jun-23
:END:

******** Asleep. Dreaming, in fact.

It's funny how that works, but I won't complain too much. It makes life less monotonous, and my dreams--like any human's--are good exercise, for the day of awakening. Although I'm not sure what to do with this conversation.
:PROPERTIES:
:Author: GraduallyCthulhu
:Score: 4
:DateUnix: 1435078918.0
:DateShort: 2015-Jun-23
:END:

********* Eh, go back to sleep. Your alarm will ring when it's time to wake up.
:PROPERTIES:
:Score: 3
:DateUnix: 1435084115.0
:DateShort: 2015-Jun-23
:END:

********** Unless the power goes out. In which case you'll be late for work.
:PROPERTIES:
:Author: pleasedothenerdful
:Score: 1
:DateUnix: 1435344442.0
:DateShort: 2015-Jun-26
:END:


** u/deleted:
#+begin_quote
  Does it just... not actually matter as much as I think it does, that I could have a running universe that was scientifically rigorous to begin with but (in order to keep continuity with previous stories) is less and less so as Science Marches On?
#+end_quote

If it /was/ scientifically rigorous /to begin with/, that means you at least started with something like a coherent, non-self-contradictory model of how things work. That's interesting in itself, even if it turns out not to reflect reality.
:PROPERTIES:
:Score: 8
:DateUnix: 1435022624.0
:DateShort: 2015-Jun-23
:END:


** The easiest answer is to simply not set it in the light-cone of planet Earth, and avoid getting technical with the underlying physics in a way that advances in understanding would invalidate. On the other hand, feel free to get as nitpicky and technical as you want when it comes to physics you invent yourself -- just be consistent about it.

Making your own world not in our universe, with its own history, is an easy and popular way to accomplish this. If Earth scientists disprove a theory you were operating under, well, all you have to do is say that your world is different. Problem solved.
:PROPERTIES:
:Author: codahighland
:Score: 4
:DateUnix: 1435018986.0
:DateShort: 2015-Jun-23
:END:


** Create something self-consistent.

1. If you're worried the future won't work exactly as you predict, the point is you're detailing one conceivable route.

2. If you're worried future discoveries will prove your understanding wrong, decide to either write or not.

Consolation: as people find more things out, they'll be nostalgic for the time of possibilities, citizens of false realities whose physics they ordain, of which today's axiomatic fantasies will seem prescient, and/or obsolete/past the point where your fiction could hope to be relevant.
:PROPERTIES:
:Author: wendigo_days
:Score: 3
:DateUnix: 1435027611.0
:DateShort: 2015-Jun-23
:END:


** Star Trek has done surprisingly well, considering. As has the Culture 'verse.

(Although it isn't hard sci-fi, so that might be more difficult.)

So: firstly, don't pin down too much of Earth's immediate history. Star Trek has always had trouble with the whole "Eugenics Wars" thing, which fluctuates between "somewhere in the not-too-distant future" and "happened in the 90s in an alternate timeline to ours"; but it /does/ have the advantage of wiping out all information about the intervening years, preventing most of the gaffes you'd expect. Both the Culture and the Federation have only been shown visiting Earth in our past, or the fairly distant future, and the latter is kept very vague.

Secondly: high tech level. This doesn't necessarily mean "posthuman gods", or even transhumanism; but is does mean that pretty much everything should have been altered in some way by technology, and that technology should be /several steps above/ what we have now, so it'll take a while to catch up if it's even physically possible in the end.

Thirdly, generalize like mad. The least realistic part of both the Culture and Star Trek settings is that they're both filled with humanoids living in bizarrely earthlike societies; but it /works/, because that's an established minor scientific mystery/field of study in the setting. You could probably have Starfish Aliens just as easily (Three Worlds Collide does); as long as you don't base them on scientific speculation that might become outdated in the meantime. What matters is that you have a consistent vision for what kind of general rules we'll find govern planetary societies; that our world at least roughly fits those rules; and that they're acknowledged as in-universe things people study rather than giving the impression that you're just too dumb to imagine anything else.

That's my guess, anyway.

Oh, and one more thing: don't be afraid to handwave like mad if something /does/ come up. The Culture suddenly sprouted neural interfaces, and the Federation touchscreens everywhere, when the authors realized that they really should have had them from the beginning. And so /they did/, somehow, even though we never saw them; and they became an established part of the setting.
:PROPERTIES:
:Author: MugaSofer
:Score: 3
:DateUnix: 1435151546.0
:DateShort: 2015-Jun-24
:END:


** Are you talking about a near-future setting, in ten years or so, that you're worried will look odd when the time comes and the major world events of your story haven't happened? Or are you worried about a far-future setting that'll look outdated when our idea of space travel and AI changes?

In either case: do enough research that the flaws won't be immediately obvious to an amateur in the area (experts are a bad test audience, they'll find flaws in anything), try to focus on areas that are important to the story (nobody cares whether Greece left the EU in a story about the rise of telepresence robots), and beyond that don't worry about it. Sci-fi writers are not futurologists.
:PROPERTIES:
:Author: Chronophilia
:Score: 2
:DateUnix: 1435020701.0
:DateShort: 2015-Jun-23
:END:

*** u/callmebrotherg:
#+begin_quote
  Or are you worried about a far-future setting that'll look outdated when our idea of space travel and AI changes?
#+end_quote

This one. I'm probably staying away from any possible runaway AI singularities by ruling that some other species got to AI first and gave it the sole task of destroying any intelligences that attempted to increase their own intelligence and then used that heightened intelligence to do it again.

That, or I'm going with my Simulated Universe idea, which solves both AI and FTL.
:PROPERTIES:
:Author: callmebrotherg
:Score: 2
:DateUnix: 1435021134.0
:DateShort: 2015-Jun-23
:END:

**** That might be overcomplicating it - you're the author, if you say that singularity-level AI turned out to be impossible to get right, nobody will question it. Pick some problem that must be solved before AI can be built and just rule that nobody ever figured it out. Unless the existence of an AI faction is important to your story, there's no reason that I can see for AI to be possible.

Space opera with FTL and no superhuman AI is an established setting, a pre-existing trope you can use. People who've sat through Star Wars or Star Trek will assume that you're using the same basic framework except where you explicitly point out a difference. It's slightly further to the soft end of the science fiction spectrum than the place most of this sub hangs out, but there's nothing wrong with that. There's lots of good stories in soft science fiction.
:PROPERTIES:
:Author: Chronophilia
:Score: 5
:DateUnix: 1435025449.0
:DateShort: 2015-Jun-23
:END:

***** u/ArgentStonecutter:
#+begin_quote
  if you say that singularity-level AI turned out to be impossible to get right, nobody will question it
#+end_quote

Unless you're Vernor Vinge. The "Zones of Thought" in /A Fire Upon the Deep/ are a brute force solution to both that and the Fermi Paradox. Advanced civilizations don't come visiting because we're living in the galactic equivalent of a toxic swamp for AIs.
:PROPERTIES:
:Author: ArgentStonecutter
:Score: 4
:DateUnix: 1435053274.0
:DateShort: 2015-Jun-23
:END:

****** Yep. That's a confusing example, because the Powers do exist, they just can't survive this close to the galactic core. Due to a force that nobody really understands or controls, which blocks things above a certain technology level from working. A handwave if ever I've seen one, but the story works.
:PROPERTIES:
:Author: Chronophilia
:Score: 2
:DateUnix: 1435056392.0
:DateShort: 2015-Jun-23
:END:

******* The underlying plot token is really freaky: it's a change in /mathematics/. There are algorithms that only work when you're far enough outside the galactic core. Go into the Unthinking Depths, and math we know of breaks.

So there are algorithms that make consciousness easy to create, but they don't work down here, and the hacks that are possible are so complex that civilizations don't tend to last long enough to reverse-engineer them. That's why there's no AI.

Apparently in one early draft of AFuTD Vinge had the Tropical Collectives transcend, briefly, when Countermeasure fired... but he decided that wasn't consistent with his story. Not having evolved in the Transcend they wouldn't be using those algorithms, and the brief period before the Slow Zone returned wasn't long enough for them to develop them.
:PROPERTIES:
:Author: ArgentStonecutter
:Score: 4
:DateUnix: 1435060475.0
:DateShort: 2015-Jun-23
:END:

******** Man, this really makes me want to pick my fantasy rewrite of Zones of Thought back up ...
:PROPERTIES:
:Author: alexanderwales
:Score: 2
:DateUnix: 1435069057.0
:DateShort: 2015-Jun-23
:END:

********* DOOO EEET
:PROPERTIES:
:Author: ArgentStonecutter
:Score: 1
:DateUnix: 1435070846.0
:DateShort: 2015-Jun-23
:END:


******** That's new to me. Is this fanon, or is it explained in /The Children of the Sky/ which I haven't read?
:PROPERTIES:
:Author: Chronophilia
:Score: 2
:DateUnix: 1435110973.0
:DateShort: 2015-Jun-24
:END:

********* I dug around in my backups, and backups of backups, and i do still have some of my email discussions from 1993. They're not even vaguely complete, but here's the bits that are relevant.

#+begin_quote

  #+begin_quote
    So what happened during the brief period in which Countermeasure pulled the lower Transcend down around Tine World? What happened in the tropics? /(me)/
  #+end_quote

  At one time, I may have had a few sentences claiming that super-packs were briefly formed. I'm kinda glad it didn't make it into the final version, because without some acoustical augmentation and MAC (like more radio cloaks and a simple MAC protocol), I don't see how it could happen. /(Vernor)/

  #+begin_quote
    And what is it that the Zones limit, that blocks AI but lets Tine and Skrodes function unchanged deep into the slow zone? Or is that something you're just winging?
  #+end_quote

  Skrodes are not even close to sapient, so I don't see a problem with them. However, the question about Tines (and Humans) v AI was one of the major logic consistency problems of the background. Here's my explanation: An AI of human-equivalent capability could operate in the Beyond and even in the Slow Zone. (In fact, Vrinimi Org had concluded that Pham Nuwen was very close to being such a thing.)

  In principle, such an AI could even be /designed and built/ in the Slow Zone by a civilization native to that Zone. In practice, however, the work would require superhumanly competent development tools if it were to be accomplished within the lifetime of such a civilization (much less within the lifetime of an engineering project). Since such superhumanly capable tools are not runnable in the Lower Zones, this means that such projects are for practical purposes impossible. (I see semi-exceptions and perverse exceptions that are actually the fodder for some 'quels I have in mind.)
#+end_quote

That last bit presumably referencing the Emergents and Focus in /A Deepness in the Sky/.
:PROPERTIES:
:Author: ArgentStonecutter
:Score: 4
:DateUnix: 1435270465.0
:DateShort: 2015-Jun-26
:END:


********* Private correspondence.
:PROPERTIES:
:Author: ArgentStonecutter
:Score: 2
:DateUnix: 1435114341.0
:DateShort: 2015-Jun-24
:END:


***** the problem with superhuman AI in stories is that it's very hard to write a character twice as smart as you are, much less a billion times smarter.
:PROPERTIES:
:Author: buckykat
:Score: 1
:DateUnix: 1435041700.0
:DateShort: 2015-Jun-23
:END:

****** Not really. You just allocate far more time and information to that character than a 1:1 real-time ratio.
:PROPERTIES:
:Score: 1
:DateUnix: 1435076667.0
:DateShort: 2015-Jun-23
:END:


***** u/deleted:
#+begin_quote
  That might be overcomplicating it - you're the author, if you say that singularity-level AI turned out to be impossible to get right, nobody will question it.
#+end_quote

Or you can go the /Dune/ route and say that AI was deemed too dangerous to exist and exterminated.

#+begin_quote
  Pick some problem that must be solved before *X* can be built and just rule that nobody ever figured it out.
#+end_quote

This is extremely unwise and basically just dares your readers to solve the problem.
:PROPERTIES:
:Score: 1
:DateUnix: 1435076544.0
:DateShort: 2015-Jun-23
:END:


**** That sounds like HPMOR's Fidelius Charm being used to lock itself out of circulation.
:PROPERTIES:
:Author: Gurkenglas
:Score: 4
:DateUnix: 1435024473.0
:DateShort: 2015-Jun-23
:END:

***** Heh. It dodges the bullet of infinitely self-improving transforming society, though, since the alien-designed AI only cares about getting rid of other AI.
:PROPERTIES:
:Author: callmebrotherg
:Score: 1
:DateUnix: 1435024909.0
:DateShort: 2015-Jun-23
:END:

****** Why'd they design an AI like that? AIs with a utility function gone wrong should tend to convert their future light cone to computronium, since that's about as generally useful as getting control of the Hogwarts rumor mill, so the aliens would've had to solve their value alignment problem... only to find nothing better to do with their negentropy than leaving everything exactly as is.

Maybe the aliens have already converted the star's masses and are merely replicating their light to keep up appearances, and allow all the civilisations that already exist the time to live out their natural lifespans for the purposes of acausal trade: All the civilizations that would make an AI like theirs get an equal share of the negentropy saved up for the [[http://slatestarcodex.com/2014/06/07/archipelago-and-atomic-communitarianism/][Archipelago]]-style paradise set to go off in a few million years, all the civilzations that would take all their future light cone for themselves get nothing.
:PROPERTIES:
:Author: Gurkenglas
:Score: 2
:DateUnix: 1435027309.0
:DateShort: 2015-Jun-23
:END:

******* To my unenlightened mind it seems easier to set an AI's utility function to destroying self-improving intelligences than to set it to include all of the various values that a civilization would have.
:PROPERTIES:
:Author: callmebrotherg
:Score: 1
:DateUnix: 1435030768.0
:DateShort: 2015-Jun-23
:END:

******** What utility function do you propose? Negative the number of singularities leads us to a solution at least as effective as omnicide.
:PROPERTIES:
:Author: Gurkenglas
:Score: 1
:DateUnix: 1435032323.0
:DateShort: 2015-Jun-23
:END:

********* Pardon? I'm trying to parse the second sentence but I'm not sure if it's just oddly-phrased or if I'm getting too tired. Sorry.
:PROPERTIES:
:Author: callmebrotherg
:Score: 1
:DateUnix: 1435033058.0
:DateShort: 2015-Jun-23
:END:

********** Setting the utility function to minimize the expected number of singularities that will happen in our future light cone will make the AI bring about something that has at most as many singularities as a world where it just attempts to destroy everything.
:PROPERTIES:
:Author: Gurkenglas
:Score: 2
:DateUnix: 1435037325.0
:DateShort: 2015-Jun-23
:END:


******** "Destroy all self-improving intelligences" seems a quick way to accidentally instruct an AI to destroy your species. I like to believe that /I'm/ a self-improving intelligence, for some value of "improving".
:PROPERTIES:
:Author: Sceptically
:Score: 1
:DateUnix: 1435106100.0
:DateShort: 2015-Jun-24
:END:


******* Eh, some variation on this is very plausible. If "Non-omnicidal" AI is possible, then the size of the universe means someone has likely already done it. Once you have one, having it prevent the universe from being paper-clipped by some other species while otherwise altering reality as little as possible would be a thing to do. Which means that the biosphere of earth might well already be thinly sprinkled with nano-scale machinery set to stop anyone or anything from doing anything severely stupid. At least for fictional purposes, this works fine.
:PROPERTIES:
:Author: Izeinwinter
:Score: 1
:DateUnix: 1435045015.0
:DateShort: 2015-Jun-23
:END:


******* Oh Lord, an entire setting built out of SlateStarCodex ideas.
:PROPERTIES:
:Score: 1
:DateUnix: 1435076727.0
:DateShort: 2015-Jun-23
:END:


****** We're already in an infinitely self-improving society. It's just that the improvements are gradual, not hyperbolic. I don't see any particular reason why the future has to be different.
:PROPERTIES:
:Author: Uncaffeinated
:Score: 1
:DateUnix: 1435029684.0
:DateShort: 2015-Jun-23
:END:

******* Pardon my lack of clarity. I was meaning in a very short time, ala the traditional conception of the AI-led Singularity.
:PROPERTIES:
:Author: callmebrotherg
:Score: 1
:DateUnix: 1435030484.0
:DateShort: 2015-Jun-23
:END:


** You fear [[http://tvtropes.org/pmwiki/pmwiki.php/Main/Zeerust][zeerust]].

Most everyone just shrugs at it. The majority of 70s/80s/90s sci-fi failed to predict the ubiquity of mobile computing and communication, but they don't stop being good stories.
:PROPERTIES:
:Author: Harkins
:Score: 2
:DateUnix: 1435262424.0
:DateShort: 2015-Jun-26
:END:
