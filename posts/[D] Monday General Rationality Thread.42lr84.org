#+TITLE: [D] Monday General Rationality Thread

* [D] Monday General Rationality Thread
:PROPERTIES:
:Author: AutoModerator
:Score: 20
:DateUnix: 1453734082.0
:DateShort: 2016-Jan-25
:END:
Welcome to the Monday thread on general rationality topics! Do you really want to talk about something non-fictional, related to the real world? Have you:

- Seen something interesting on [[/r/science]]?
- Found a new way to get your shit even-more together?
- Figured out how to become immortal?
- Constructed artificial general intelligence?
- Read a neat nonfiction book?
- Munchkined your way into total control of your D&D campaign?


** In terms of general announcements, I hope to publish a couple of long-form stories on [[/r/rational]] starting soon. The two I really have pinned down are an original fic and a fanfic. (The fanfic is /not/ going to be the same one I planned several months ago; my interest in that project sadly faded during the planning stage.)
:PROPERTIES:
:Author: LiteralHeadCannon
:Score: 5
:DateUnix: 1453778196.0
:DateShort: 2016-Jan-26
:END:


** There is this friend of my family. A 50 year old man, who works as an honest to Albert inventor. He's been a tech wiz since childhood, and he and a few others have had their own company for decades where they are asked to make a piece of technology that does x and has to work with xyz, and they make it. Mostly electronics, but not exclusively. They are doing pretty well for themselves. I'm not sure if he's rich, it hasn't come up, but I'd be very surprised if he makes less than $10k/month. They have a tech lab at his place of work, but he also has one at home, where he fools around with things on his own. He is a very intelligent man, and whenever he gets guests he's super excited to show people what he's working on or reading about. Sometimes I can follow along with most of it, but usually it's too specialized. He's very interesting, and a nice person too, so I really like him.

But. He also gets very excited about things that most scientists would dismiss immediately. He's very interested in Cold Fusion, and thinks it's the way of the future. He thinks global warming is real but will be solved without detriment with future technology. His bookcases are full of books about conspiracy theories and 'alternative history' and aliens. And a few weeks back he told us he's been reading up for months on electromagnetism, including notes and journals by people like Maxwell and Tesla. And he's convinced that the Ether is a real thing. He's hoping to be able to come to a point where he can do meaningful experiments in the lab he has at home.

I just... The man is more intelligent than me. A lot more disciplined. And /massively/ more educated, especially regarding anything to do with physics. So I don't understand how he can get so 'into' things you'd only see taken seriously on the History channel. But at least he's sincere enough in his convictions that he spends thousands of dollars on lab equipment so he can go hunting for knowledge himself.
:PROPERTIES:
:Author: Rhamni
:Score: 12
:DateUnix: 1453742524.0
:DateShort: 2016-Jan-25
:END:

*** Self-confident autodidacts tend to trust their own judgement. They have a lot of experience doing so, and considerably less experience trusting so-called experts. An inventor, especially, is going to be well-versed in looking outside the box for ideas that have not been fully researched and explored. The [[https://en.wikipedia.org/wiki/Luminiferous_aether][Luminiferous Aether]] is actually a great example.

Physicists of the 19th century didn't believe it because they were blinded or stupid. They believed it because it was a widely-accepted, coherent model which had withstood significant experimentation. Give the Wikipedia article a look or, if you want old school, I recommend Max Born's chapters on the subject in his 1922 book on Relativity... which is out of copyright and available [[https://archive.org/details/einsteinstheoryo00born][here]]. You might even recommend that book to your family friend.

Identifying trustworthy experts does require some degree of intelligence, but deciding to trust them requires an entirely other sort of mental exercise. Don't think too ill of whom others choose to trust.
:PROPERTIES:
:Author: Sparkwitch
:Score: 13
:DateUnix: 1453757582.0
:DateShort: 2016-Jan-26
:END:


*** I know this kind of person as well. I found this talk [[https://www.youtube.com/watch?v=WRdJCFEqFTU]] - I dont remember the timestamp for this particular piece of info unfortunately- enlightening. The referent puts forth an at least partially plausible hypothesis.

The parameters of your own neural network are very carefully weighted to find a good balance between "inventing new hypotheses" and "disproving new hypotheses". Obviously "inventing new hypotheses" is what being creative is all about; crank this up too much and you get schizophrenia. But a successful buisness person needs to have passed both thresholds; not only "inventing an economic niche" but also "not immediately disproving it into the ground", which seems like its a very common failure mode(eg. not pursuing further because "will not work for XYZ reasons").
:PROPERTIES:
:Author: SvalbardCaretaker
:Score: 6
:DateUnix: 1453743601.0
:DateShort: 2016-Jan-25
:END:


*** I know a guy /just like that/. Incredibly brilliant, holds a bunch of patents, made a ton of money through his engineering company ... and believes in all sorts of crazy stuff. I attribute it mostly to an anti-authoritarian streak, though I did once talk with him about the JFK assassination, which I think had a profound effect on him and the search for meaning there made him much more open to fringe science.

Also, fringe science tends to be more fun to read about than established science, because everything is new and revolutionary, one step away from changing the world, which people really go in for.
:PROPERTIES:
:Author: alexanderwales
:Score: 5
:DateUnix: 1453762019.0
:DateShort: 2016-Jan-26
:END:


*** One of the various projects I'm considering writing for [[/r/rational]] is a memoir of some of my adolescent years with a focus on my father's pursuit of a perpetual motion machine and its effect on me. The man's a brilliant programmer who's been doing important work since computing was new, in many respects he's one of the smartest people I know, but he's just completely convinced, and has been for many decades, that free energy is relatively easy and it's just that no one's thought of it before. He managed to convince a young me of his position, and /man/ did it mess me up psychologically.

Would this be a good fit for [[/r/rational]]? It's an irrational nonfiction as opposed to a rational fiction.
:PROPERTIES:
:Author: LiteralHeadCannon
:Score: 6
:DateUnix: 1453771284.0
:DateShort: 2016-Jan-26
:END:

**** Sure. Just include the coda where you learn (or begin to learn) how to think more rationally.
:PROPERTIES:
:Author: TennisMaster2
:Score: 5
:DateUnix: 1453773747.0
:DateShort: 2016-Jan-26
:END:


** So what do you guys think about [[http://www.mirror.co.uk/tv/tv-news/derren-brown-convinces-three-people-7172605][pushed to the edge]] ? both in regards to what it says about people and about what it says when that passes for entertainment\is legal?

personally I don't think it really says a lot as is, because the participants were apparently selected(based on how "obedient" they were) and the fact that we can't even know how many people were tested to produce those 4 people which reached that last point, out of which only 3 actually did it.

I wouldn't be too surprised even if 75% was the actual number(of people willing to murder in some circumstances), but I tend to be skeptical as-is considering the motivation of the producers to sensationalize.

As for the legality of the show, I don't see an issue as long as the actions of the participants were not illegal, and even then i am not sure if its really a problem(to intentionally cause someone else to commit a crime)
:PROPERTIES:
:Author: IomKg
:Score: 5
:DateUnix: 1453735268.0
:DateShort: 2016-Jan-25
:END:

*** Have you read of the [[https://en.wikipedia.org/wiki/Milgram_experiment][Milgram experiment]]? It provides some context for this sort of thing - and makes me feel that the show could conceivably have been run unscripted/unprompted and achieved much the same results. However, as it is a TV enterprise, it would make the most sense for them to have a pretty strong script and manipulate things to deliver whatever narrative they think would resonate with viewers and drive audience interest and news reporting upward, in search of higher ratings, as all 'reality TV' has done forever. A show that came out with the message "most people are pretty decent and don't murder people" wouldn't make the news.
:PROPERTIES:
:Author: Escapement
:Score: 11
:DateUnix: 1453735841.0
:DateShort: 2016-Jan-25
:END:

**** There's been a good deal of criticism of the [[http://www.psmag.com/books-and-culture/electric-schlock-65377][Milgram Experiment]] as well as the [[https://www.psychologytoday.com/blog/freedom-learn/201310/why-zimbardo-s-prison-experiment-isn-t-in-my-textbook][Stanford Prison Experiment]].
:PROPERTIES:
:Author: ArgentStonecutter
:Score: 9
:DateUnix: 1453741111.0
:DateShort: 2016-Jan-25
:END:


**** Yeah i am aware of that experiment, from what i read the guy who designed this supposedly took lessons from that experiment as well as the stanford prison experiment(thus he made sure the subject felt "low status" compared to the people giving him orders).

Anyhow i think there is a difference between giving a shock which "may" kill a person and physically pushing someone from the roof..
:PROPERTIES:
:Author: IomKg
:Score: 5
:DateUnix: 1453741512.0
:DateShort: 2016-Jan-25
:END:


**** wait. do the victims of the murders in this show ACTUALLY die?
:PROPERTIES:
:Author: Sailor_Vulcan
:Score: 2
:DateUnix: 1453737575.0
:DateShort: 2016-Jan-25
:END:

***** They have the same guy (Bernie) being pushed over the edge of a roof multiple times, partly because of a homage to Weekend at Bernie's. So, no. It's all a setup. Everyone in the show that isn't one of the people deciding whether or not to push is definitely an actor / conspirator / etc. The people doing the pushing may also be acting rather than being genuinely bamboozled - with Reality TV-esque stuff like this, it's pretty safe to assume that the producers /make/ it interesting to televise, by hook or by crook.
:PROPERTIES:
:Author: Escapement
:Score: 8
:DateUnix: 1453738491.0
:DateShort: 2016-Jan-25
:END:


*** Have you seen the episode/feature where Darren Brown (the same guy) apparently hypnotises audience members to such a degree that they willingly rested in a bathtub of ice? After they were shown unable to keep their hand in the same tub for a prolonged period of time?

He's actually released a book about some of the techniques he uses. Its really hard to determine how much of it is real or what the trick is (as is the case with a lot of Darren Brown's stuff, which I would generally recommend watching). It would seem that some people are more readily suggestible than others.
:PROPERTIES:
:Author: Gigapode
:Score: 2
:DateUnix: 1453770419.0
:DateShort: 2016-Jan-26
:END:

**** This other episode sounds fairly suspicious for the same reasons as mentioned regarding the episode discussed already.

it sounds like something that could plausibly be real, but would require far more proof to really be believed.
:PROPERTIES:
:Author: IomKg
:Score: 1
:DateUnix: 1453811504.0
:DateShort: 2016-Jan-26
:END:

***** He does this stuff pretty regularly, I feel like he would have been exposed by now if he were a fraud.

I remember there was a big curfuffle a few years back when someone accused him of faking because one of his participants was an out-of-work actor, if it turned out to be real I imagine it would be an even larger story.
:PROPERTIES:
:Author: MugaSofer
:Score: 1
:DateUnix: 1453819906.0
:DateShort: 2016-Jan-26
:END:

****** it seems easy enough to make it extremely harmful for the conspirator to sell him off..

And not all of the ways to cheat this even require other people to be aware (for example how many people checked the temperature of the ice tub to verify it was as cold?)
:PROPERTIES:
:Author: IomKg
:Score: 1
:DateUnix: 1453821089.0
:DateShort: 2016-Jan-26
:END:

******* Oh, he definitely "cheats". He's a magician, and he's extremely upfront that the explanations he gives are sometimes misdirection. I'm just skeptical that he could be using stooges.
:PROPERTIES:
:Author: MugaSofer
:Score: 1
:DateUnix: 1453831442.0
:DateShort: 2016-Jan-26
:END:

******** well the reasons mentioned regarding the original series mentioned were less about stooges and more about selection(of the people, of which of the people to actually show on tv etc.) :)
:PROPERTIES:
:Author: IomKg
:Score: 1
:DateUnix: 1453831836.0
:DateShort: 2016-Jan-26
:END:


*** I don't think being "capable of murder" is necessarily a bad thing. You have to be very brave to act to defend yourself or your family. Sometimes people start fights, and you have to fight back. HPMoR called this "killing intent", and while all supervillains have it, plenty of perfectly virtuous people do too.

It's one thing to have the inherent capacity to kill another person. It's another thing to do it when you don't have a /very very very/ good reason.

So a reality TV show has manipulated people into revealing an aspect of their personality that they wouldn't usually show? How unexpected. Also, turns out the Pope is a Catholic and bears shit in the woods.
:PROPERTIES:
:Author: Chronophilia
:Score: 2
:DateUnix: 1453739899.0
:DateShort: 2016-Jan-25
:END:

**** It should probably be mentioned that the reason the people "murdered" was because they were brought to the situation where the victim, who was supposed to be some billionair, will sue them and generally make their life hell. As well as being instructed to to so by "higher status" people from a "board of directors". The entire thing was built to loosen their morals. Starting with a relatively "harmless" point where they were just helping to conceal his "death" so as to not cancel a fund raiser for poor children, all the way to being in a point where he is sitting alone on the edge of the roof with no witnesses and they get to choose if they want to push him or leave him
:PROPERTIES:
:Author: IomKg
:Score: 8
:DateUnix: 1453741343.0
:DateShort: 2016-Jan-25
:END:


** If everyone in a world had a magical device that displayed in what percentage of timelines they were alive in one year, what behaviors would emerge? What would the causal effects be like?
:PROPERTIES:
:Author: LiteralHeadCannon
:Score: 3
:DateUnix: 1453746141.0
:DateShort: 2016-Jan-25
:END:

*** If we built a simulation of the universe that /didn't/ take quantum effects into account, how often do you think that it would be wrong about whether I was dead in a year? I think that's the question that I'm left with.

On short timescales and with large objects, the universe appears to be deterministic. The motions of the planet can be predicted using even crude measurements, with the quantum-level stuff having very little to do with it. There are certain things that quantum-level changes are never going to have an appreciable effect on.

Now, does this extend down to the level of humans? Do quantum level effects have any bearing on what I'm going to eat for breakfast tomorrow morning, or whether I'll fall in love, or whether I can remember the right answer on a test? So far as I know, that's an open question that dips down into fringe science, mostly because we don't have a good way to experimentally test any of the predictions that people are making. But if humans /aren't/ (by and large) subject to quantum-level effects, and we live in a psuedo-deterministic world, then most of the time the death-o-meter is going to say 99.99% or 0.01%, because many-worlds just doesn't really enter into it, and the information gleaned from the death-o-meter won't be too useful unless you try to munchkin it.
:PROPERTIES:
:Author: alexanderwales
:Score: 8
:DateUnix: 1453763578.0
:DateShort: 2016-Jan-26
:END:

**** It's not particularly relevant to most human experiences, but I understand that the butterfly effect is extremely strong in most contexts familiar to humans. If you took a random January 1st 2016 descended from the January 1st 2015 we actually experienced, it would practically certainly be very, very distinct from the January 1st 2016 we actually experienced.
:PROPERTIES:
:Author: LiteralHeadCannon
:Score: 1
:DateUnix: 1453763977.0
:DateShort: 2016-Jan-26
:END:

***** See, that's what my question is though.

The butterfly effect is strong, in that weather systems are unpredictable, but that doesn't mean that given perfect information we wouldn't be able to predict weather. What we need to know is how much effect quantum-level changes have on the macro scale; it doesn't matter if weather systems have a sensitivity to initial conditions if those conditions are psuedo-deterministic. How much of a butterfly flapping its wings can we predict purely with classical physics and how quickly does deviance show up?
:PROPERTIES:
:Author: alexanderwales
:Score: 8
:DateUnix: 1453765016.0
:DateShort: 2016-Jan-26
:END:

****** The large complexity and small basic unit scale of brains strongly suggests to me that they, given the same starting conditions, will randomly make somewhat different decisions. This alone, given the butterfly effect, would be enough to change everything else about the environment, but I even find it doubtful that brains are the only thing in our common experience like this.
:PROPERTIES:
:Author: LiteralHeadCannon
:Score: 1
:DateUnix: 1453766026.0
:DateShort: 2016-Jan-26
:END:

******* What makes you think human brains are effected by that? does that mean you believe that if you were asked to answer the question "1+1=?" a thousand times you would give different results based on quantum events? if no what do you think is makes a particular brain event susceptible to quantum events?

I am having trouble seeing any support for quantum events effecting anything macro without artificial amplification.
:PROPERTIES:
:Author: IomKg
:Score: 1
:DateUnix: 1453905695.0
:DateShort: 2016-Jan-27
:END:


*** To get a little more specific, what should I expect to happen if I'm a queen in this world and I launch a plan to draft two million men, and, in thirteen months, send those with the highest odds of survival out to invade and conquer a neighboring nation?
:PROPERTIES:
:Author: LiteralHeadCannon
:Score: 3
:DateUnix: 1453750146.0
:DateShort: 2016-Jan-25
:END:

**** [deleted]
:PROPERTIES:
:Score: 6
:DateUnix: 1453751091.0
:DateShort: 2016-Jan-25
:END:

***** The trouble is that humans are also part of the system of probabilities. So it's not quite as simple as "modifying your intentions and rechecking repeatedly" - because whatever chance there was of your modifying your intentions was included in the original probability.
:PROPERTIES:
:Author: LiteralHeadCannon
:Score: 4
:DateUnix: 1453753066.0
:DateShort: 2016-Jan-25
:END:

****** actually, wouldn't -everything- be included? how could you model the probability calculation without either making it static or meaningless?
:PROPERTIES:
:Author: IomKg
:Score: 6
:DateUnix: 1453753901.0
:DateShort: 2016-Jan-26
:END:

******* At every instant, it looks at all universes descended from the current universe in exactly one year; it counts all universes wherein the bearer is alive, compares that number to the number of universes period, and displays the resulting ratio. This incidentally means that it's effected by information from indefinitely far into the future, for reasons I feel are fairly obvious.
:PROPERTIES:
:Author: LiteralHeadCannon
:Score: 2
:DateUnix: 1453754325.0
:DateShort: 2016-Jan-26
:END:

******** maybe i wasn't clear enough, how would you be able to utilize this information if it is already incorporated into the probability?

the numbers will basically be meaningless as an information source as they already incorporate you looking, or not looking, at them.
:PROPERTIES:
:Author: IomKg
:Score: 8
:DateUnix: 1453756097.0
:DateShort: 2016-Jan-26
:END:

********* You would be able to learn things from changes in the probability. For example, if at time A someone reads 0.8 and at time B someone reads 0.9, then you know something occurred between times A and B that had an effect on the person's survival.
:PROPERTIES:
:Author: LiteralHeadCannon
:Score: 1
:DateUnix: 1453757629.0
:DateShort: 2016-Jan-26
:END:

********** how could that number possibly ever increase? how could "probability" increase in such a context? the device has already obviously incorporated it.

also after thinking about it some more i am having even more difficulties with the definition you gave.

how could anyone ever know that the number is correct? even if supernatural forces made you assume it is correct as mentioned how could you ever use this information considering the fact that the device is basically absolute. if it is not absolute what is the model by which it works? wouldn't 99.99999% of the alternate universes where the person exist be exactly identical on the macro level, i.e. most "universe splitting" would happen because some atomic event happened\didn't happen. but for a specific quantum event to be felt on a level that may effect human lives you would need an amplified of some sort. but those would still be significantly less frequent. so essentially whatever kills 1 copy of you would kill 99.9999..999% etc percent of you, and those that aren't killed could be in completely different worlds. it would require some crazy modeling to get even an idea. and even then you go back to the original issue of not being able to know anything from the number. how do you even define a "you", i.e. a specific human being?
:PROPERTIES:
:Author: IomKg
:Score: 3
:DateUnix: 1453759207.0
:DateShort: 2016-Jan-26
:END:

*********** Well, in an ideal case, if you check the probabilities of a hundred people, and each of them are 50%, then a year later you would expect about fifty of them to still be alive. This wouldn't play out quite this well in practice, though, as it's entirely possible that their survivals are causally linked.
:PROPERTIES:
:Author: LiteralHeadCannon
:Score: 1
:DateUnix: 1453759571.0
:DateShort: 2016-Jan-26
:END:

************ ok that makes sense for an external observer, so you will indeed be able to tell if this works by observing other people and their meters.

in that case the closest i can model this world is basically pretty close to a world where you have a clock for when you die, unless i am missing something important. i mean, i basically get a paradox the moment i try to model how it will actually work. For example lets say someone is going to be hit by a car while crossing the street in a year. for now lets assume the probability of that is 99.999%(i.e. the watch will show 0.001% are alive) without the watch. but with the watch showing the number the probability is 0.0000001%(i.e. 99.9999999% are alive), so now you have a problem. either you show it and the number is not correct because actually only 0.000001% will die after seeing such a scary number, or you show 0.0000001% of death and then the person will not avoid the death. how is that resolvable? The only way i can model that is a world where people only die when there is nothing they could do about their death by knowing about it in advance..
:PROPERTIES:
:Author: IomKg
:Score: 2
:DateUnix: 1453760606.0
:DateShort: 2016-Jan-26
:END:

************* In what /possible/ world would someone be doomed to get hit by a car a year before it happens? That sounds like a fate thing to me, which isn't realistic. You probably don't have a 99.99999999% chance of getting hit by a car even a /minute/ before it happens.

It doesn't matter what probabilities exist in the counterfactual world where the device's readings are inaccurate; they are not relevant to the probabilities that the device shows, which are accurate.
:PROPERTIES:
:Author: LiteralHeadCannon
:Score: 1
:DateUnix: 1453761249.0
:DateShort: 2016-Jan-26
:END:

************** What makes you think the world is so random at the macro level that it would not be likely that most event that you experience are "predetermined" to such degree of assurance? as far as i can tell the world is very predictable on the human scale, which is good actually because it would be difficult to live in it otherwise, and as such except for "amplified" events such as for example atomic clocks, experimental particle physics and similar such things almost all other quantum events(of which there are -a lot-) all have practically no effect on human life.

Anyhow the percent is completely irrelevant, what is relevant is that while its easy to say "the device already compounds its own effect on the probability" there is no actual way for that to work unless you assume human reaction to it is somehow a quantum event, and that the event's probability could always find some equilibrium between the number the device will show and the probability of an action taken by the user to change it.
:PROPERTIES:
:Author: IomKg
:Score: 2
:DateUnix: 1453810338.0
:DateShort: 2016-Jan-26
:END:


************** As others have noted, this depends heavily on which events are "really" (quantumly) random and which are just complicated and difficult to predict.

Coinflips, for example, aren't actually random - they're just difficult enough for humans to predict that they may as well be for most practical purposes. You can model a coin's path and predict which side it will land on, given time and computing power.

Of course, this could also be a world of magic, where timelines split based on something other than quantum effects. Or you could argue that the butterly effect is really that powerful.
:PROPERTIES:
:Author: MugaSofer
:Score: 1
:DateUnix: 1453902607.0
:DateShort: 2016-Jan-27
:END:


*********** u/MugaSofer:
#+begin_quote
  how could that number possibly ever increase? how could "probability" increase in such a context?
#+end_quote

Because of quantum effects. If the "you" reading the dial is now in a universe where something "with 50% probability" happened, then the numbers are different /in this universe/ - whereas before you were seeing the aggregate of numbers for all possible universes.
:PROPERTIES:
:Author: MugaSofer
:Score: 1
:DateUnix: 1453902348.0
:DateShort: 2016-Jan-27
:END:

************ Ok I reread the definition given and see that there is an interpretation I can make of that text which would enable having the number grow, which I now assume is what was actually meant. But somehow i think this actually makes the number even less relevant, seeing as it would be going up and down seemingly randomly and would be massively effected by the number of splits in the tree at least as much as the actual length of them.
:PROPERTIES:
:Author: IomKg
:Score: 1
:DateUnix: 1453904176.0
:DateShort: 2016-Jan-27
:END:


********* Sounds like a Novikov Self-Consistency kind of thing.
:PROPERTIES:
:Author: MugaSofer
:Score: 1
:DateUnix: 1453902192.0
:DateShort: 2016-Jan-27
:END:


******** If I would ordinarily would have a 10% chance of dying in the next year, but then, before the first time I look at the device, decide to commit suicide iff it shows >50%, then there are two consistent replies at about 10% and 99%. How is the answer decided? Worse, what if I decide to commit suicide iff it shows <50%?
:PROPERTIES:
:Author: Gurkenglas
:Score: 1
:DateUnix: 1453926637.0
:DateShort: 2016-Jan-28
:END:


******** u/jesyspa:
#+begin_quote
  At every instant, it looks at all universes descended from the current universe in exactly one year; it counts all universes wherein the bearer is alive, compares that number to the number of universes period, and displays the resulting ratio.
#+end_quote

Elsewhere you say it takes into account its own effect on the timelines. However, for this to be possible it would have to know what probability it will show, at which point it needn't go through all the trouble of simulating stuff.
:PROPERTIES:
:Author: jesyspa
:Score: 1
:DateUnix: 1453939509.0
:DateShort: 2016-Jan-28
:END:

********* Did I say "simulate"? No, I didn't, I said "look".
:PROPERTIES:
:Author: LiteralHeadCannon
:Score: 1
:DateUnix: 1453940699.0
:DateShort: 2016-Jan-28
:END:

********** Look, simulate, the difference isn't essential here. Are you saying it also considers universes where it showed a different result than the one it will show here? That seems like the results can be significantly off, then.
:PROPERTIES:
:Author: jesyspa
:Score: 1
:DateUnix: 1453944971.0
:DateShort: 2016-Jan-28
:END:


*** Does the device include itself in its calculations? Do people who know they have a 50% chance of death get to improve their odds by changing their intentions, or will the device anticipate your change of decisions and thus make it impossible for the holder to actually change anything?
:PROPERTIES:
:Author: Frommerman
:Score: 2
:DateUnix: 1453756492.0
:DateShort: 2016-Jan-26
:END:

**** Yes, the device includes itself in its calculations. The device anticipates changed decisions, but once any uncertain probability becomes certain, the device will update. For example, if a certain event has a 50% chance of killing someone and a 50% chance of doing nothing to them, then after they survive it, the device's readings for them will double.
:PROPERTIES:
:Author: LiteralHeadCannon
:Score: 2
:DateUnix: 1453756623.0
:DateShort: 2016-Jan-26
:END:

***** Ok, that solves the update plans to update your reading problem, as it will give out a reading including the effects of its own readings.

It might be possible to make this a halting oracle, but I'm not exactly sure how to structure the experiment. Use death row inmates, set it up so they are executed if the algorithm halts. There's likely a better way to do this, but it at least lets us check some low-hanging fruit. It also lets us break passwords which take less than a year to check with your fastest computer.
:PROPERTIES:
:Author: Frommerman
:Score: 3
:DateUnix: 1453760001.0
:DateShort: 2016-Jan-26
:END:


*** If you want to know the probability of x happening in the future, precommit to suicide if it doesn't happen.

Precommit to suicide if the machine says you'll survive with high probability and cause a paradox.
:PROPERTIES:
:Author: TimTravel
:Score: 1
:DateUnix: 1453795958.0
:DateShort: 2016-Jan-26
:END:


*** Ok, I've got the People's Republic of China's next 5 year plan:

Year 1: Construct a bunch of new prisons specifically designed to prevent information from leaving them by unauthorized means and draft a set of protocols to accomplish this. All staff live on site for the duration of the 5-year plan and cannot leave, all shipments of food and other materials are automated once they reach the security perimeter, etc.

Year 2: All crimes in China which have a prison sentence of longer than 4 years will instead be punished with a suspended death sentence. Transfer all such prisoners into the new prisons.

Year 3: Calibration. Determine the average death rate in the new prisons, using the boxes. Nobody is executed this year, so all you need to do is figure out what the average percent across all prisoners for that year is. This number does not leave the prison system.

Year 4: Calculation. Use some hash search algorithm to search for a valid seed program for FAI which will unfold into a fully functioning AI deity in a year. At each step of the algorithm, a program outside the system chooses a set of random prisoners to stand for the different elements in your search algorithm, and then checks the death percentage for each of those prisoners. The ones whose percentages spiked above the average will be executed once the FAI has finished unfolding. Of course, this shouldn't work under normal circumstances, as the prisoners' percentages will jump precisely a year before their execution, rather than at the time they are chosen as a correct step forward in the hash, but by hiding all such information from the program doing the choosing, the jumps may be correctly isolated as having been caused solely by being a correct step rather than a random step. In addition, the execution happening after the unpacking is done means that the system gets to "check" whether the seed program was correct, completing the P=NP loop.

Year 5: You don't need a year 5.
:PROPERTIES:
:Author: Frommerman
:Score: 1
:DateUnix: 1453767127.0
:DateShort: 2016-Jan-26
:END:

**** Year 5: eaten by a Boltzmann Brain strong AI of /literally random/ goal structure.

(Actually, I think you might just get hit by a meteor, or a war, or a prison break - it's a more likely way for the numbers to be self-consistent.)
:PROPERTIES:
:Author: MugaSofer
:Score: 2
:DateUnix: 1453902808.0
:DateShort: 2016-Jan-27
:END:


** Does rationality, in its pursuit of perceiving truth in an effort to make the best decisions, negate the beneficial aspects of self-deception? Could that harm someone?

Self-deception seems in many ways protective of our own psychology and those without self-deception are more likely to be clinically depressed according to the psychologist interviewed in the latest rationally speaking podcast.

Is there a Lesswrong post someone cant point me towards about this topic? My brief search for one (which acknowledges that argument for self-deception) during my lunch hour was unsuccessful.
:PROPERTIES:
:Author: Gigapode
:Score: 5
:DateUnix: 1453770031.0
:DateShort: 2016-Jan-26
:END:

*** Depends on how mentally stable you are. If you can recognize the truth about a matter*, and it disturbs you beyond any technique of depression-mitigation save self-deception, then go ahead and deceive yourself. Just be aware you're doing it, and don't let it affect your decisions. Think of it more as a carefully curated cognitive dissonance.

*If the mere act of recognition will lead to a loss of emotional self-control, don't try to change your mind alone - too dangerous.

Here's [[http://lesswrong.com/lw/l6z/the_truth_and_instrumental_rationality/][one]] addressing the argument for instrumentally rational self-deception.

A final note: I'm not too confident in the veracity and quality of the advice I give here.
:PROPERTIES:
:Author: TennisMaster2
:Score: 5
:DateUnix: 1453774795.0
:DateShort: 2016-Jan-26
:END:

**** Seems almost like trying to force yourself to receive a placebo effect. Once you try doing it, you are tacitly acknowledging that you don't actually believe it and it falls over.
:PROPERTIES:
:Author: Gigapode
:Score: 1
:DateUnix: 1453775491.0
:DateShort: 2016-Jan-26
:END:

***** That would be variable from person to person; but yes, Eliezer makes just that argument in his post on the subject.
:PROPERTIES:
:Author: TennisMaster2
:Score: 1
:DateUnix: 1453779213.0
:DateShort: 2016-Jan-26
:END:


***** doublethink takes effort :)
:PROPERTIES:
:Author: IomKg
:Score: 1
:DateUnix: 1453814249.0
:DateShort: 2016-Jan-26
:END:


*** [deleted]
:PROPERTIES:
:Score: 2
:DateUnix: 1453772038.0
:DateShort: 2016-Jan-26
:END:

**** Correlation is not causation. It could be that researching the meaning of life tends to make people depressed or it could be that being anxious and depressed is what makes people try to find an intellectual meaning of life in the first place.
:PROPERTIES:
:Author: MrCogmor
:Score: 2
:DateUnix: 1453805086.0
:DateShort: 2016-Jan-26
:END:


**** /coughcorrelationdoesnotequalcausationcough/
:PROPERTIES:
:Author: Red_Navy
:Score: 1
:DateUnix: 1453783744.0
:DateShort: 2016-Jan-26
:END:


*** Well, for one thing, I think truth is more valuable than happiness. I'd rather be miserable than delusional.

Also, it's possible to face pain and horrible things, and stay happy/positive. It's certainly harder than just being dumb, It requires strenght, toughness, and mental discipline, but it can be done.

Personally, I'm definitely more miserable and scared now than a few years ago when I was more oblivious, but I sure as hell wouldn't trade it back.

Also there are mental tools like meditation and flow that help you to control your thoughts and emotions while staying honest about facing reality.

Personally, I'm making an effort to face all the things that are so difficult to face, but at the same time, once I did that, I can use meditation to stop the pointless and obsessive thoughts and anxieties, and focus on getting joy out of things I love about life and can control.

--------------

Edit:

To be honest, I probably do use self-deception to a degree, as a form of emotional management. But it's not really about lying to yourself and trying to convince your brain about false things, it's more like the rational part of my brain that knows what's up telling the emotional part "dude, be cool, focus on things you can control, and we're gonna be fine."

You can face the truth on one level, while on another still have your mind be engaged in pursuing goals and valuing and enjoying things, etc.

Frankly, I think even Eliezer uses this kind of stuff to a degree. It's not like when he's writing HPMOR or working on AI he stays constantly 100% aware of his mortality and futility of existence. It's not like he's constantly conscious of the fact that whatever he does universe will end up in the same dark, uniform, slightly warm state after the entropy.

I'm not sure mind truly can function in the complete void. People who practice Zen and such are supposedly trying to learn how to function while being truly aware of death, but I think even they are full of shit, they're just working hard to convince themselves that the world is okay and the fucked up thing not really a tragedy that they are.
:PROPERTIES:
:Author: raymestalez
:Score: 1
:DateUnix: 1453787048.0
:DateShort: 2016-Jan-26
:END:

**** u/callmebrotherg:
#+begin_quote
  Frankly, I think even Eliezer uses this kind of stuff to a degree. It's not like when he's writing HPMOR or working on AI he stays constantly 100% aware of his mortality and futility of existence. It's not like he's constantly conscious of the fact that whatever he does universe will end up in the same dark, uniform, slightly warm state after the entropy.
#+end_quote

I wonder to what degree depression is connected to the inability to push out these thoughts. It's a common theme when I'm suicidal, definitely, even though that chain of logic might not make much sense (but then, "not making sense" is kind of part of the definition of being mentally ill, isn't it?).
:PROPERTIES:
:Author: callmebrotherg
:Score: 1
:DateUnix: 1453884028.0
:DateShort: 2016-Jan-27
:END:
