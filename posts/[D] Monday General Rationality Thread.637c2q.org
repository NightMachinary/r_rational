#+TITLE: [D] Monday General Rationality Thread

* [D] Monday General Rationality Thread
:PROPERTIES:
:Author: AutoModerator
:Score: 15
:DateUnix: 1491231876.0
:DateShort: 2017-Apr-03
:END:
Welcome to the Monday thread on general rationality topics! Do you really want to talk about something non-fictional, related to the real world? Have you:

- Seen something interesting on [[/r/science]]?
- Found a new way to get your shit even-more together?
- Figured out how to become immortal?
- Constructed artificial general intelligence?
- Read a neat nonfiction book?
- Munchkined your way into total control of your D&D campaign?


** So I think [[/r/place]] is the best argument against anarcho-capitalism I've ever seen. Given unlimited freedom but limited resources, groups have banded together, waged war aginst other groups, solidified their territorial boundraries, and built alliances and civilizations (well, pixel art, but they're basically the same thing).
:PROPERTIES:
:Author: GaBeRockKing
:Score: 29
:DateUnix: 1491237491.0
:DateShort: 2017-Apr-03
:END:

*** What I found interesting is the cooperation that groups built. When the German and Belgian flag intercepted, they cooperated to make a hot dog thing. When PlaceHearts overlapped with FTB, FTB added a heart to their design. Somehow, PrequelMemes managed to write out their entire script, and there have been some big artworks. Even in this no-rules setting, cooperation beats out disorganization, easily.
:PROPERTIES:
:Author: NotACauldronAgent
:Score: 16
:DateUnix: 1491241471.0
:DateShort: 2017-Apr-03
:END:

**** And, everyone appears to have worked together to obliterate all swastikas/other symbols of hate and oppression as they showed up. Which is nice
:PROPERTIES:
:Author: Frommerman
:Score: 6
:DateUnix: 1491265232.0
:DateShort: 2017-Apr-04
:END:

***** Other than Australia's, it was kept pretty PC. Sure, Mami Tomoe lost her head and Rick was drunk, but all in all it self-moderated with surprising efficacy.
:PROPERTIES:
:Author: NotACauldronAgent
:Score: 3
:DateUnix: 1491265484.0
:DateShort: 2017-Apr-04
:END:


***** Interesting. Has anyone been keeping a record of what's been happening, so that other people can read about it in the future?
:PROPERTIES:
:Author: callmebrotherg
:Score: 1
:DateUnix: 1491323346.0
:DateShort: 2017-Apr-04
:END:

****** I dunno. All I know is that, in the entire million pixels, there doesn't appear to be a single swastika. Which is odd considering that this is the internet.
:PROPERTIES:
:Author: Frommerman
:Score: 3
:DateUnix: 1491324385.0
:DateShort: 2017-Apr-04
:END:

******* I don't have the source but I remember reading that people who contribute to swastikas/hate-symbols were banned from placing more pixels.
:PROPERTIES:
:Author: Imperialgecko
:Score: 2
:DateUnix: 1491358267.0
:DateShort: 2017-Apr-05
:END:

******** Ahh, well that's not self moderation, then.

Csnt give the swastikas a fair chance to survive if god keeps wandering by with the magnifying glass.
:PROPERTIES:
:Author: Arizth
:Score: 2
:DateUnix: 1491477599.0
:DateShort: 2017-Apr-06
:END:


****** Here's a [[https://www.youtube.com/watch?v=RCAsY8kjE3w][timelapse]] of what happened, it lacks context, but is a fun watch.
:PROPERTIES:
:Author: BlueSigil
:Score: 2
:DateUnix: 1491348484.0
:DateShort: 2017-Apr-05
:END:

******* Oh wow. Thanks. This is great.
:PROPERTIES:
:Author: callmebrotherg
:Score: 1
:DateUnix: 1491349173.0
:DateShort: 2017-Apr-05
:END:


*** Sounds to me like people managed to compete, cooperate and create without a central authority with a monopoly on legitimate violence. How is this a point /against/ anarcho-capitalism?
:PROPERTIES:
:Author: BadGoyWithAGun
:Score: 5
:DateUnix: 1491254075.0
:DateShort: 2017-Apr-04
:END:

**** People created their *own* central authorities with monopolies on legitimate violence. You had to run changes through your own faction or territory owners, or the faction at large would revert your changes. Indeed, there were even super-factions that regulated the efforts of individual factions. For example, [[/r/ainbowroad][r/ainbowroad]] was closely watching the area around helix, and required permission before modifying or creating stuff around it. I had to check into their discord to make sure the [[/r/parahumans]] sign expansion was OK.
:PROPERTIES:
:Author: GaBeRockKing
:Score: 20
:DateUnix: 1491254276.0
:DateShort: 2017-Apr-04
:END:

***** There's nothing about anarcho-capitalism that forbids hierarchical authorities, as long as submission is voluntary and exit is free.
:PROPERTIES:
:Author: BadGoyWithAGun
:Score: 2
:DateUnix: 1491254480.0
:DateShort: 2017-Apr-04
:END:

****** u/GaBeRockKing:
#+begin_quote
  There's nothing about anarcho-capitalism that forbids hierarchical authorities
#+end_quote

It's not really an anarchy if there's a hierarchical authority.

#+begin_quote
  as long as submission is voluntary and exit is free.
#+end_quote

By that definition, we (that is, americans) currently live in an anarcho-capitalist state, because there's nothing preventing someone from renoucing their citizenship and leaving the nation.
:PROPERTIES:
:Author: GaBeRockKing
:Score: 5
:DateUnix: 1491254794.0
:DateShort: 2017-Apr-04
:END:

******* u/ZeroNihilist:
#+begin_quote
  By that definition, we (that is, americans) currently live in an anarcho-capitalist state, because there's nothing preventing someone from renoucing their citizenship and leaving the nation.
#+end_quote

Not strictly true. Anarcho-capitalist states permitting X does not mean that the presence of X implies anarcho-capitalism.

Anarcho-capitalist states presumably also permit breathing and existing, after all.
:PROPERTIES:
:Author: ZeroNihilist
:Score: 2
:DateUnix: 1491255557.0
:DateShort: 2017-Apr-04
:END:

******** u/GaBeRockKing:
#+begin_quote
  Not strictly true. Anarcho-capitalist states permitting X does not mean that the presence of X implies anarcho-capitalism.
#+end_quote

I was speaking in conjunction with the "hierarchical authority" part. That is, [[/u/BadGoyWithAGun]] said that hierarchical authority can be a part of anarcho-capitalism, so long as conditions x and y are filled. I was pointing out that allowing for a heirarchical authority with control over legitimate violence dilutes the meaning of anarcho-capitalism to the point where ancaps might as well just choose a new term.

Essentially, my argument goes like this:

1.) Take a broadly anarcho capitalist landscape\\
2.) If some group creates a hierarchical authority, voluntarily or otherwise, they are no longer anarcho-capitalist, but instead their own type of government (Whether tribal, feudalistic, democratic, or whatever) that is surrounded by anarcho-capitalism, rather than being ancaps themselves. The [[/r/place]] equivalent is factions who decide to work on projects in the middle of the chaos.\\
3.) From here, as demonstrated by the pixel arts that flourished across [[/r/place]] replacing the chaos or single-person projects, established factions will outcompete and either incorporate (convince people to join in making a piece of art) or subjugate (immediately replace changes made by free agents) the surrounding unorganized people.

tl;dr: anarcho-capitalism gets outcompeted
:PROPERTIES:
:Author: GaBeRockKing
:Score: 7
:DateUnix: 1491256723.0
:DateShort: 2017-Apr-04
:END:


******* u/BadGoyWithAGun:
#+begin_quote
  By that definition, we (that is, americans) currently live in an anarcho-capitalist state, because there's nothing preventing someone from renoucing their citizenship and leaving the nation.
#+end_quote

There is, the "exit tax". Exit from the US isn't free, a final submission to the authority of the US government is required - followed by, in all likelihood, going on to live in an even more authoritarian state in terms of property rights, unless you're taking up seasteading.

Total exit rights would constitute to renounce your recognition of the government and to leave at any point in time with no confiscation of property.
:PROPERTIES:
:Author: BadGoyWithAGun
:Score: 1
:DateUnix: 1491258290.0
:DateShort: 2017-Apr-04
:END:

******** note: I use the 2nd person quite a bit here. I'd like to clarify that it's not addressed at you, [[/u/BadGoyWithAGun]] specifically, but an arbitrary "you" instead.

#+begin_quote
  There is, the "exit tax". Exit from the US isn't free, a final submission to the authority of the US government is required
#+end_quote

So then the US is anarcho capitalist so long as you're sufficiently wealthy for the exit tax to be nominal, or sufficiently poor for it to be nonexistent?

#+begin_quote
  Total exit rights would constitute to renounce your recognition of the government and to leave at any point in time with no confiscation of property.
#+end_quote

The existence of "property" is a collective delusion. A useful collective delusion, for sure, but something is only "yours" so long as someone else doesn't take it. Or more specifically, something is only yours so long as you have some mechanism that prevents people from taking it, like, for example, a state. If you leave a non anarcho-capitalist state for an anarcho-capitalist existence, you're effectively giving up all property rights regardless. The "exit tax" isn't a tax on your property, as once you stop residing in a state, you no longer have any enforcement mechanism to retain it. The exit tax is a voluntary agreement with the United States that stops it from taking /all/ of your property, instead of just some of it.

Now, I'm aware that the anarcho-capitalist solution is to have some sort of private organization to enforce privacy rights. But those private organizations will behave exactly like the united states, in that they'll require a payment in return for protection. And if any private organization can reach a sufficient level of clout (or even just make agreements with other, similar oganizations), they're perfectly free to modify perform rent-seeking behavior like demanding their own exit fees, as, after all, in a free market companies will "change what the market will bear" until which point it's in your best interest to stop dealing with them in spite of that.

#+begin_quote
  followed by, in all likelihood, going on to live in an even more authoritarian state in terms of property rights, unless you're taking up seasteading.
#+end_quote

If "being surrounded by authoritarian states" disquailfies a state from anarchocapitalism, then it's entirely impossible to have anything resembling anarchocapitalism because any relationship between three people where one of the people is coerced by the others makes an authoritarian state.
:PROPERTIES:
:Author: GaBeRockKing
:Score: 6
:DateUnix: 1491262452.0
:DateShort: 2017-Apr-04
:END:

********* I'm tagging you as "Person who actually understands ancap issues."
:PROPERTIES:
:Author: callmebrotherg
:Score: 2
:DateUnix: 1491323992.0
:DateShort: 2017-Apr-04
:END:


********* u/KilotonDefenestrator:
#+begin_quote
  Now, I'm aware that the anarcho-capitalist solution is to have some sort of private organization to enforce privacy rights. But those private organizations will behave exactly like the united states, in that they'll require a payment in return for protection. And if any private organization can reach a sufficient level of clout (or even just make agreements with other, similar oganizations), they're perfectly free to modify perform rent-seeking behavior like demanding their own exit fees, as, after all, in a free market companies will "change what the market will bear" until which point it's in your best interest to stop dealing with them in spite of that.
#+end_quote

I have a problem understanding anarcho-capitalism, because I immediately think that the organizations providing security, privacy and property rights services (with enough clout to provide quality service) would also have the option to decide that there will no longer be a free market on those services within their region of control.

Why let your customer exit if you don't have to? Once you have monopoly or near-monopoly on force in a region, why would you allow any other players? Why would you allow people to cancel their subscription? Why would you allow dissent?
:PROPERTIES:
:Author: KilotonDefenestrator
:Score: 1
:DateUnix: 1491287169.0
:DateShort: 2017-Apr-04
:END:

********** That's it.

I find anarcho-capitalism is inherently self defeating, at most it would devolve to some kind of neo-feudalism.

Or at least it would immediatly revert to a some kind of state, may it be a particularly powerful monopoly or something else.
:PROPERTIES:
:Author: Zeikos
:Score: 6
:DateUnix: 1491301714.0
:DateShort: 2017-Apr-04
:END:


*** I think you're underestimating the pre-existing condition of people doing those things /on purpose/, purely for fun. What I saw was a bunch of people wanting to form factions as quickly as possible and start building storylines, especially those reenacting the button. There was a huge roleplay element to it in the "primative tribal" stages which shouldn't go unmentioned. The bigger argument is the meta-problem of rampant botting advertisements, IMHO.
:PROPERTIES:
:Author: AmeteurOpinions
:Score: 9
:DateUnix: 1491244811.0
:DateShort: 2017-Apr-03
:END:

**** u/GaBeRockKing:
#+begin_quote
  I think you're underestimating the pre-existing condition of people doing those things on purpose, purely for fun.
#+end_quote

But that too is part of the argument-- people already exist in a state where they want societies. Even if the ancaps managed to systematically dismantle the government, they wouldn't manage to change /everyone/ minds, and like on [[/r/place]], the uncoordinated majority gets overtaken by the coordinated minority.
:PROPERTIES:
:Author: GaBeRockKing
:Score: 21
:DateUnix: 1491247621.0
:DateShort: 2017-Apr-03
:END:


*** What actually was [[/r/place][r/place]]? I keep seeing posts about it but don't know how it worked or what art had to do with it. Maybe it's because I'm using BaconReader so I'm missing something visual from the website.
:PROPERTIES:
:Author: trekie140
:Score: 2
:DateUnix: 1491261863.0
:DateShort: 2017-Apr-04
:END:

**** yeah, baconreader didn't have it, although evidently the offical reddit app did.

But in short, it was a 1000x1000 pixel canvas, where each account created before april 1st could place one pixel every 'x' minutes, where 'x' was common through all accounts, but was changed multiple times over the project. (First 'x' was proportional to the number of people on, capping out at ~10 mins, and then it was changed to 5 minutes.)

Because of that time requirement, placing anything virtually mandated cooperation between people. The larger the group, the larger the item they could work to create, although there were diminishing returns as bigger items attracted more vandals (See: the OSU! near the bottom right-hand corner.)

Groups tended to coordinate either on their home subreddits, specific place-based subreddits linked to on their home subreddits (what [[/r/parahumans]] did), discord channels, private messaging anyone who flipped your pixel when you tried to do something new (I did a /lot/ of this), or just basic pattern recognition (for example, the flags, the rainbow road, the green lattice, and most infamously, the all-consuming blue corner.)

If you look near the center of the map, above and to the right of the american flag and the rainbow, there's a squirtle holding the portuguese flag, and a kangaroo on a box. Between those two items is the "read parahumans" banner I wager most of the [[/r/rational]] people who frequented [[/r/place]] worked to create, expand, elaborate on, and defend.

The whole thing was a lot of fun, so it's a pity you missed it.
:PROPERTIES:
:Author: GaBeRockKing
:Score: 8
:DateUnix: 1491262850.0
:DateShort: 2017-Apr-04
:END:


** An immortality idea - Possible now, but a very long shot. More realistically doable in the next 100-200 years, though still a long shot then I'd say.

To start out with, a lengthy six paragraph intro. Fair warning in case you want to skip the justification for the approach, and get straight into the approach.

biology is hard. As a biologist it is staggering the amount of mathematics actually involved with understanding systems like the genome let alone the brain. The interdisciplinary interplay between biology, is necessary to understand something is incredible. Math, chemistry, and physics are all necessary to understand what is going on and be able to learn more. You can get summaries, but that's different from really understanding something. You need a large number of people working together to understand these interdisciplinary subjects, which makes understanding something as large and complex as the human life span a daunting task.

I'm not an expert, just completing undergrad, but the amount we have yet to learn about the genome, let alone gene expression makes me think progress on that front is going to be very slow.

We're not particularly close to understanding aging. We don't have a good idea of how gene expression changes with age. Gene expression is difficult to study in part because we don't understand the human genome completely, so the epigenome is more difficult to study because of that. Then there are ethical limitations on human experimentation (which we really do need to have) that slow research down. Even if we were to get rid of those ethical considerations human beings are not good model organisms. We have small numbers of kids with generations times at minimum of around 13 years. Consider to study a single gene generally dozens of generations of an organism are observed.

Working with model organisms can speed up studying homologous areas, but there are inevitably large differences between human beings and say /C. elegans/ that studying the nematodes will simply not be applicable. In effect, I think it is going to be more than 100 years before we make serious progress on understanding human aging let alone doing something about it.

Given that I think aging research is going to be slow and I'd like to see something happen in my lifetime, I think it would be better to narrow the area of research one is trying to do. The brain is the interesting part related to consciousness. "Well duh," says everyone, but bear with me. Narrowing our focus further; For our immortality purposes, we aren't interested in genetics or gene expression in the brain, We are interested in the connectivity and signaling.

If there are zero signals ([[https://en.wikipedia.org/wiki/Action_potential][action potentials]]) in your brain, you're brain dead. If there are no connections in your brain you are also brain dead, considering with no connections there is no way to pass a signal, and in effect no signals can be passed.

Pardon the large intro, but I hope it gives context for my approach.

I think to take a shot at immortality in our lifetimes we need to focus on generating new connections with the brain from outside of the brain. I think that given that the connections made, and the signaling patterns that result, are what ultimately make up consciousness, we might be able to extent some part of our consciousness outside of our skull and into a neuronal circuit in vitro. Something like a cell culture.

The main sticking point is can you actually use or somehow interact in a meaningful way with a neuronal circuit grown outside your brain? This is tricky and would require a lot of research, but requires far less work than a total understanding of aging.

The advantage of this approach is that we don't necessarily need to understand anything about aging or consciousness. We just need to understand enough to introduce a new connection to our nervous system and then grow that system. We don't have to necessarily understand how the circuits we've connected to are growing and work. We just have to know enough to initiate development.

The general approach is basically to let the developmental processes that resulted in our brain happen again outside of our skull while we are attached to this developing nervous system. It may then be possible to imprint ourselves onto this developing in vitro nervous system, such that when the body that houses our skull dies the nervous system dies we suffer something more akin to brain damage than death.

If we were able to utilize enough of the in vitro nervous system for our conscious processes before our body died we may have then been able to train the system to house our consciousness. Whether such an existence would be worthwhile is another question.

tl;dr It might be possible to exploit developmental processes rather than wholly understand them, and thus allow for some continued existence after our normal life span.
:PROPERTIES:
:Score: 6
:DateUnix: 1491243265.0
:DateShort: 2017-Apr-03
:END:

*** If you look at the efforts of organisations like SENS to achieve longevity and eventually immortality, they agree with you. Biology is hard.

But fixing the things that break does not require an understanding how that thing came to be and the intricate processes that led to it breaking down (and especially no need to understand how you would edit a human to not break down in the first place).

It just requires observation of a problem and working out how to fix the problem (temporarily is fine, as long as it can be repeated or superceded).

Building a car that runs forever is very hard. Keeping a car in working condition is comparatively easy.

Aubrey DeGrey of SENS often speak of "longevity escape velocity". You develop some techniques to fix some issues and give people some extra years. During that time, medicine advances and some more things become fixable, granting some more years. Since technology develops exponentially, we can expect even more breakthroughs during this time, granting more years. And so on. Eventually the technology to prolong your life (or rather, prevent your death) is constantly available within your latest lifespan, effectively granting immortality without actually turning any human into an immortal.

This aproach feels to me like the most realistic to work anytime soon.
:PROPERTIES:
:Author: KilotonDefenestrator
:Score: 6
:DateUnix: 1491287787.0
:DateShort: 2017-Apr-04
:END:


*** It's an interesting concept. I assume you'd need good VR and full body paralysis during transition so that you don't end up jostling the mechanism (unless it's small enough to be wearable?), then you'd need a good brain tissue culturing system that isn't going to break down over the long term.

You could also ensure the new brain tissue comes with built in cybernetic electronic devices (sensors to allow you to send mental commands and control virtual / robotic bodies, memory modules to allow eidetic memory, transmitters to form non-biological communications links from one spot in the tissue system to another, and so on), and genetically engineer the stem cells it grows from with better ability to survive cryonics in the event that it is needed, avoid neurodegenerative illness, and survive better without normal organs.

It's sort of like the brain in a jar idea, but it doesn't have to be shaped like a human brain normally is, and would more closely resemble the neural cultures we can realistically experiment with.
:PROPERTIES:
:Author: lsparrish
:Score: 3
:DateUnix: 1491271522.0
:DateShort: 2017-Apr-04
:END:


*** you might be interested in some discussion about this in [[http://gnusha.org/logs/2017-04-03.log]]
:PROPERTIES:
:Author: kanzure
:Score: 3
:DateUnix: 1491273015.0
:DateShort: 2017-Apr-04
:END:

**** Goddamn, reading through it, it's pretty funny to see an idea like this interpreted as being a ship of theseus because that's exactly how I've previously described it to people IRL. Good stuff.

Edit: where exactly did this conversation come from?
:PROPERTIES:
:Score: 1
:DateUnix: 1491277490.0
:DateShort: 2017-Apr-04
:END:

***** u/kanzure:
#+begin_quote
  where exactly did this conversation come from?
#+end_quote

We are a group of engineers that focus on transhumanist projects. You're welcome to join us. See details at [[http://diyhpl.us/wiki/hplusroadmap]] for how to connect to IRC.
:PROPERTIES:
:Author: kanzure
:Score: 3
:DateUnix: 1491278436.0
:DateShort: 2017-Apr-04
:END:

****** Thanks mate.
:PROPERTIES:
:Score: 1
:DateUnix: 1491278777.0
:DateShort: 2017-Apr-04
:END:


**** Sorry for the double reply but this looks like an IRC chat. I'd be interested in joining in to explain some of the idea a little bit more, but then again the idea is pretty much in its infancy.

So on the matter of continuity, I know that just creating a connection won't cause any sort of continuity in consciousness to occur. The idea is that one is able to create a connection (My guess would be figuring out a bit more on how the corpus callosum integrates the two hemispheres and trying to patch connections in a similar man around that area) and then using that connection training the neuronal circuit in vitro.

Over time(years) the idea is eventually you'll be able to train the neuronal circuits in vitro to take over functions and also being able to train memories into them. Ideally over time the in vitro part would make up the majority of one's consciousness so that when the body dies it's only brain damage. You would have to find some way to actively use those in vitro neuronal circuits and imprint what you wanted to retain on them.

There will of course still be the issue of the in vitro part still aging, but if somehow (big if) you manage to accomplish some sort continuity in consciousness between the first two systems you might be able to repeat the process with the remaining entity Ad infinitum.

It's a pretty shaky idea, but it's an idea.
:PROPERTIES:
:Score: 1
:DateUnix: 1491278717.0
:DateShort: 2017-Apr-04
:END:


** Re: AI in a box experiment. (I thought to comment in the original thread, but I'm a little late to the party)

I always thought that the source of the problem is that you actually want something from the AI (for example, a cure for cancer). Else, why build a gate at all? (or the AI itself for that matter)

The gate keeper's goal is to allow some information flow (that could be helpful and beneficial) without risking freeing the AI (and world destruction).

The point is, when you're dealing with an entity that is vastly more intelligent than you, you can never be sure of the full consequences of your actions (the cure for cancer could somehow lead to freedom for the AI).

On a more general note, I'm not entirely sure that the required level of intelligence for that kind of trick is even possible. A lot of people fear an AI because it might be able to improve itself, but I'm not sure that it is possible to self improve in a consistent way. Moreover, intelligence itself is not a linear property, i.e. , in order to be twice as intelligent, you would have to invest a lot more than twice the effort. And that means that even if some entity could self improve, this exponential process does not lead to an intelligence explosion.

Edit: Formatting
:PROPERTIES:
:Author: liveoi
:Score: 9
:DateUnix: 1491236642.0
:DateShort: 2017-Apr-03
:END:

*** u/vakusdrake:
#+begin_quote
  in order to be twice as intelligent, you would have to invest a lot more than twice the effort.
#+end_quote

I'm not sure what evidence you could possibly be basing this on.. Do you have evidence that might support this such as animals with larger brain to body ratios requiring exponentially more resources from their brain than should be expected for their relative size? Because that would certainly draw my attention (though how much that would apply to a different computational medium would still be unclear) however I can't seem to find anything indicating this is the case.

I certainly hope you're not trying to use humans as your evidence given we can't even change our hardware (and can make only relatively tiny software changes) and on an absolute scale we have quite little hardware variation compared to other species, plus attempts to increase IQ tend to be rather lackluster and work best on who score lower due to lack of familiarity with mental problems of that sort. Also given how much difference a relatively tiny advantage in social intelligence can make among humans I'm not sure the "absolute" increase in intelligence needed to make something seem incomprehensible to us would be very much.
:PROPERTIES:
:Author: vakusdrake
:Score: 3
:DateUnix: 1491241698.0
:DateShort: 2017-Apr-03
:END:

**** Well, Intelligence is not a very well defined term, and I don't have a rigorous proof for my claim (that intelligence is not linear).

I could try to explain my reasoning about it. In the most general sense, I consider intelligence as the capacity for problem solving ([[https://en.wikipedia.org/wiki/Intelligence][Wikipedia sort of agrees with me]]).

A lot of the interesting problems are of the NP complexity class. That means that in order to become better at solving them, you need to invest an exponential amount of resources. This is true regardless of your hardware/software choice.

In a more abstract sense, I think that the most interesting aspects of intelligence (such as creativity and self-awareness) are poorly understood, and we have no reason to believe that simply throwing more computational resources will increase them.
:PROPERTIES:
:Author: liveoi
:Score: 4
:DateUnix: 1491245512.0
:DateShort: 2017-Apr-03
:END:

***** I think you're overestimating how much of a limit exponential problems are here. Remember that people find out ways to use clever tricks to solve problems that ought to require far more computation at the cost of not being 100% certain they found the best possible solution.\\
It's of note that the travelling salesman problem has been solved for millions of cities within less than a percent of the optimal solution. The point is that the AI doesn't need to be perfect, that's why machine learning uses heuristics, once you only require solutions that are good enough many seemingly insurmountable problems become manageable.

Just because there may be problems that require exponential increases in intelligence doesn't mean they are the sort of thing that is going to significantly matter in the context of an AI foom.

As for just "throwing computational ability" at intelligence improvements, well nobody is seriously proposing that most performance breakthroughs are due to software improvements. Similarly the idea is that human level AI will make improvements by changing it's software which for something with an ability to hyperfocus on tasks indefinitely at vastly accelerated speeds compared to a human could occur quickly.
:PROPERTIES:
:Author: vakusdrake
:Score: 2
:DateUnix: 1491248919.0
:DateShort: 2017-Apr-04
:END:

****** Hm. I understand what you're saying, and am no longer convinced that intelligence is not linear.

Still, my intuition might be flawed, but I think that the fact that an AI might be self improving does not immediately imply that it will become superhuman intelligent.
:PROPERTIES:
:Author: liveoi
:Score: 1
:DateUnix: 1491249863.0
:DateShort: 2017-Apr-04
:END:

******* Yeah if you haven't already I definitely suggest that you read Bostrom's superintelligence, because otherwise discussions with a lot of the people on this subreddit will involve a lot of just reiterating what is for them common GAI knowledge.

See while some people try to say it would take a substantial amount of time for an AI to improve itself (though if it is run at substantial speed then a substantial time for it may not be very long at all), the position that self improvement /wouldn't/ entail corresponding intelligence isn't one that I've ever heard even mentioned, because intelligence is the obvious thing you'd be improving and that improvement would then make you immediately better at finding new more clever ways to improve yourself.\\
Just a look at humans should start to make it obvious how massive a slight improvement to intelligence can be, as is often said the hardware and software differences among humans is really pretty small (people can't even hack their brains to be very good at things the simplest computer can do with ease!).

Here's a alternate thought experiment: Some world class genius scientists come up with a intelligence boosting drug that fundamentally changes one's neurology so there are clearly ways to make better versions of the drug. As soon as the drug's available it's going to be used by the scientists working on making its next iteration. Except this time the scientists ability to make breakthroughs is as far above what is was before, as their original ability was over average researchers. This time despite the next iteration being more difficult it comes much faster since they are both building on previous research and are step above einstein level.\\
Of course there's no reason to think there's something special about the human intelligence level specifically, so the next few iterations shouldn't be insurmountable compared to the previous one's (at least to the boosted intelligence of the researchers) except now the scientists are no longer just "smart" they're fundamentally on a different level than human like we are on a different level from chimps, despite the hardware differences not being really that massive.\\
Of course with the AI scenario things are much quicker because of how much faster silicon is, it's ability to spend literally all it's time at top performance working on self improvement, and other such benefits.

This really short article likely makes these points better: [[http://yudkowsky.net/singularity/intro/]]
:PROPERTIES:
:Author: vakusdrake
:Score: 1
:DateUnix: 1491252213.0
:DateShort: 2017-Apr-04
:END:


******* I don't think that improving the ai to be slightly superintendent would be that difficult, because narrow ai it's already better in a lot of things. An human level ai would get to human level thanks to the advantages computers have compared to brains , once we get an algorithm that it's as good as the one evolution produced it will already be slightly superinteligent or at least better than us in math and other things that computers do better. This is not really what we normally think superinteligent is but better maths and less biases that aren't usefull would be a good advantage. Even if the increase in intelligence goes linearly or even if this doesn't happen and it stays human level for a while that doesn't mean the ai isn't a problem. The ai could wait until it's intelligent enough for revealing it's true intentions , or a security breach could let the ai connect to internet were it could stay for years hiding learning everything it can , Improving itself , or it could convince it's creators it it's safe( I think over a lot of years an human level intelligence can probably do that since at some e point people would start to take the treat less seriously) .

But people like Yudkowsky don't seem to think a slow take of like that is likely, an that's because :

1. Evolution didn't require that munch changes to go from primate level intelligence to human level.

2. As discussed before it could be exponential , and even if there are Np problems that doesn't mean the limit of the growth has to be human level, there are also physical limits in transistors and that didnt 't mean the limit of transistor size was anywhere near where it was when it started growing exponentialy.

   3.Even if evolution already reached the point where you no longer can easily get big increases in intelligence and if intelligence increases linearly that doesn't imply no superinteligence, since if you have human level ai once you have more computing power you can run it faster , and at some point you will be able to run it wayy faster than humans , and even if it is still linear improvement now a a little time can be subjective years for the ai And just an human level mind running really fast is aleady really dangerous .

3. Other things about the field of ai give the impression that improvements in ai can mean qualitative changes in performance, alpha go for example is ( arguably ) an example of this.
:PROPERTIES:
:Author: crivtox
:Score: 1
:DateUnix: 1491308074.0
:DateShort: 2017-Apr-04
:END:


******* I agree that it a self-improving AI does not immediately imply superhuman intelligence. However, there is a chance that it will lead to superhuman intelligence (no further human intervention necessary) and there is a chance that that superintelligence will be hostile or uncaring towards humans.

A lot of the FAI community focuses on the worst case because the worst case it potentially /really really bad/.
:PROPERTIES:
:Author: CCC_037
:Score: 1
:DateUnix: 1491425476.0
:DateShort: 2017-Apr-06
:END:


*** Bostrom's /Superintelligence/ has a whole chapter on the balance between optimizing power and recalcitrance, and I think he lays out a strong argument that the difficulty curve really depends on the system in question. You can't simply say "intelligence is not linear" without knowing anything about the system implementing that intelligence, and we don't know enough about what artificial intelligence solutions will look like to say whether or not adding more intelligence is as simple as adding more processors.
:PROPERTIES:
:Author: alexanderwales
:Score: 3
:DateUnix: 1491248716.0
:DateShort: 2017-Apr-04
:END:

**** Interesting. But that is basically saying that we wouldn't know if it is possible to create a super intelligence before we have built one.

Anyway, is /superintelligence/ worth reading? sounds interesting
:PROPERTIES:
:Author: liveoi
:Score: 3
:DateUnix: 1491250217.0
:DateShort: 2017-Apr-04
:END:

***** I think it's worth reading, though having read through the majority of the Sequences there wasn't a lot that was new to me. It is a well-organized and cited overview of many of the arguments surrounding superintelligence (though I don't fully buy his conclusions).
:PROPERTIES:
:Author: alexanderwales
:Score: 3
:DateUnix: 1491250522.0
:DateShort: 2017-Apr-04
:END:


**** That sounds... un-Bayesian? There /ought/ to be strict statistical/probabilistic rules governing how smart you can get. You /can't/ predict correctly with less data than a Solomonoff Inducer would use, for example, unless you have an informed (non-maximum-entropy) prior.
:PROPERTIES:
:Score: 1
:DateUnix: 1491262167.0
:DateShort: 2017-Apr-04
:END:


*** u/Brightlinger:
#+begin_quote
  And that means that even if some entity could self improve, this exponential process does not lead to an intelligence explosion.
#+end_quote

If true, this implies that recursive self-improvement should level off somewhere. It doesn't imply that it has to level off near any particular threshold: if the process "only" becomes as smart as a network of ten thousand geniuses, or even only as smart as /one/ human genius, that's still a pretty big deal.
:PROPERTIES:
:Author: Brightlinger
:Score: 1
:DateUnix: 1491597039.0
:DateShort: 2017-Apr-08
:END:


** My rational gay vampire romance is very nearly finished! I'm so excited. I don't have a title yet which is killing me. I made a GIANT list of possible titles, including every single one no matter how bad they were, and I hate almost all of them and the ones I like don't really tell you anything about the story.

Note that to make things even /more complicated/ the story is also the first “volume” of three. So I'm looking either for a title that could be for all three volumes (which together would make one full-length ~100-150k word novel) or just for this volume.

Also anything with the word ‘vampire' makes it sound really low rent but the title probably should tell you to expect vampires??

Anyway... I'm desperate so I'm going to post my list of ideas here. No more Sunday Writing Skills Thread so this will do???

Themes: Fitting in, learning about a new society, making a relationship work, being in over your head, relationship between two different people, new customs

Other thing to note: the "point of vision" character (the human who falls in love with the vampire) is named Red. My boyfriend suggested a bunch of titles with a pun on that and they make very little sense if you don't know that.

Also it's set in the 1940s, mostly Corsica (France) but also Rome and Columbus, Ohio.

*Possible Titles*

- Victorian Flower Language

- Speaking his Language

- Vampire Languages

- Symbolism

- Deeper

- Understanding

- One's Sorrow Two's Mirth (or something else from one of those counting rhymes)

- Seeing Red (Gimmicky but there's an upside: can do a series: Seeing Red / Blood Red / Red Carpet or something using idioms with red in them)

- Red (could be just the title of the three volume story made of the above)

- A Platinum Tree (Somewhere I read you should title a story based on a line from the story, or an object that appears in the story. A character being given a platinum tree as a gift is what starts everything going on a downward spiral.)

- Lemon and Lavender (Lemon and lavender also falls in there (what I made the vampire's cologne smell like after googling popular 1940s colognes), it seems like the sort of thing that kind of could be like symbolic?)

- Electrum

- When In Rome (so cliched)

- When In Rome, do as the Vampires

- Do as the Romans/Vampires(???) Do

- Gift Horse

- In the mouth (way too sexual but maybe that's a good thing? .... no)

- -->It is necessary to howl with the wolves (a literal french equivalent of “When in Rome”)

- Howl(ing) with/like the Wolf (I really like that "when in rome" in French is "howl with wolves when you're with wolves", because wolves = predators = vampires, but the universe has werewolves in it, so using a wolf-oriented title in a vampire book might be weird??)

- ---> À la guerre comme à la guerre (“at war is as at war”: French equiv of “All's fair in love and war”)

- Love and War (central conflict is a Vampire War, but this title has been taken a lot)

- À la guerre (no english speaker will know how to pronounce this, probably: "guerre" more or less rhymes with "fair", at least in my accent)

- All's Fair

- At War

- At war

- At war is at war

- When at War

- Custom (current favourite: all chapters have one-word titles, /Death Note/ style, and it's a great double meaning: custom = job, custom = behaviours both of which are important here??? - but it really doesn't tell you what to expect from the story (vampires, romance))

- Strange Ways

- His Ways

- Learning the Ropes

- Present

- Presentation

- Gift

- The Gift

- Vampire's Gift

- Hearts Fangs and Abs (I suggested this as a joke on a thread here a few months ago)

- Pounded in the Butt by Vampire Worldbuilding (this is a serious suggestion)
:PROPERTIES:
:Author: MagicWeasel
:Score: 3
:DateUnix: 1491269126.0
:DateShort: 2017-Apr-04
:END:

*** I like Seeing Red by far the best out of those. Implies blood, conflict, and passion, just from red symbolism, and since we should find out the character is named Red right from the start, works as a pun. Plus, it sounds like a paranormal romance title to me, which lets readers know what to expect
:PROPERTIES:
:Author: thequizzicaleyebrow
:Score: 5
:DateUnix: 1491270102.0
:DateShort: 2017-Apr-04
:END:

**** Thanks for the feedback! I really appreciate it!

But: it's so cheesy!!!!! Argh. Might have to do though, it's actually been growing on me. Since, you know, "Seeing Red" is literally what the vampire is doing.

I was trying to think of more red puns/idioms since if I'm going to do three "volumes" I'll have to think of three of them. Blood Red works pretty well for either the second or third volume (first volume: Red is human. second volume: Red is a human augmented by vampire blood. third volume: Red becomes a vampire). Plus probably a third title to use for the set. But I'm really getting ahead of myself....

List of Red Idioms:

- Rolling out the red carpet

- Red card

- Be in / out of the red

- Red flag (oooooo)

- Blood red (a gimme)

- Red hot (whoever wants to write tingler fanfiction of it has my blessing to use this)

- Red herring

- Red handed

- Red eye

- Red tape

- Red-letter day

- Red light

- Paint the town red

- Red cent

- Red meat

- Red sky at night, shepherd's delight / red sky at morning shepherd's warning

- Red tide (no)

- Red alert

- Better dead than red (ha ha ha ha)

- Red light district

- Red mist (apparently UK slang for being really angry?)

- Red dog (apparently an American football term. Not being American... is it well known? it can probably be used for some neat symbolism since it means: /a defensive tactic in which the offensive player who receives the ball from the snap (usually the quarterback) is charged at by multiple defensive players/ - also, Red does adopt a dog in the first book)

- Red wine

I can /probably/ get a second title from one of those depending on what actually happens in volume 2. I've laid down a few things in volume 1 that might come up.
:PROPERTIES:
:Author: MagicWeasel
:Score: 1
:DateUnix: 1491271617.0
:DateShort: 2017-Apr-04
:END:

***** I mean, you don't have to stick with puns just because you start with one... You could switch to cryptically referencing pop songs, or something :P Like "The touch of a hand," or "Ordinary strangers," or "Everybody sees the wind blow."
:PROPERTIES:
:Author: Charlie___
:Score: 2
:DateUnix: 1491279673.0
:DateShort: 2017-Apr-04
:END:

****** Is seeing red a pop song??? I am clearly pop culturally deficient.
:PROPERTIES:
:Author: MagicWeasel
:Score: 2
:DateUnix: 1491280853.0
:DateShort: 2017-Apr-04
:END:


*** I'm ambivalent on puns, personally, and tend to only like one word titles when they're nouns that both specify and are specified by the book (e.g. Mars, or Thud!, or Luminosity), but I understand that other people like one-word titles when they're thematically or emotionally resonant (e.g. Twilight, since we're talking supernatural romance).

If you want a one-word title, then, I'd suggest either something that is key to your book but is otherwise rare, or something that is evocative of the mood of the book (Of your list, Electrum seems most powerful in this sense. If there's a metaphor for alloying silver and gold in there somewhere, that could be cool). Totally alternately, what's your first (or possibly last) chapter title?
:PROPERTIES:
:Author: Charlie___
:Score: 2
:DateUnix: 1491279596.0
:DateShort: 2017-Apr-04
:END:

**** Here's all my chapter titles because why not???

- Opera

- Procurement

- Flight

- Corsica

- Chestnut (dog's name)

- Lucia (character's name)

- Elodia (character's name)

- Ritual

- War

- Sardinia (chapter is one sentence long because I'm ~artistic~ like that)

- {untitled}

- Homecoming (actually I might call it Columbus instead)

- Dogwood

- Reunion

Just realised I use names and places a lot as chapter titles, so having Red in the title of the novel is less weird. I think a few of these chapters might get combined though as they're very short (probably Corsica and Chestnut, maybe Lucia and Elodia I think). War/Sardinia/Untitled used to all be one chapter (War) but I split them as that single chapter was 25% of the word count.

Electrum unfortunately does not really suit on any metaphorical level :(. It's more related to the general worldbuilding and even then only tangentially and the reader is not going to get any information about the significance of electrum in the first volume.

Didn't choose one word titles for any particular reason. I was naming chapters as I went and most of them were one word, so I just ran with it.
:PROPERTIES:
:Author: MagicWeasel
:Score: 1
:DateUnix: 1491280831.0
:DateShort: 2017-Apr-04
:END:


*** Oh no! I totally forgot to read what you sent. o.o

Well, it's almost the end of the semester, so I can probably read it this weekend, if the links you sent still work.

I like

- Lemon and Lavender

- It Is Necessary to Howl with the Wolves

- Custom

- Pounded in the Butt by Vampire Worldbuilding
:PROPERTIES:
:Author: callmebrotherg
:Score: 2
:DateUnix: 1491326823.0
:DateShort: 2017-Apr-04
:END:

**** u/MagicWeasel:
#+begin_quote
  Oh no! I totally forgot to read what you sent. o.o
#+end_quote

It's OK; beta reading is doing me a huge favour, so you are welcome to do it at your leisure. Besides, I've fixed a whole bunch of stuff since I first sent you the link, so everything's good.

Thanks for your feedback on the titles. Those four are definitely among the strongest, along with probably Seeing Red. I'm concerned that /Lemon and Lavender/ does not really relate to the story, that /It is Necessary to Howl with the Wolves/ might make people expect werewolves, /Custom/ doesn't tell you to expect vampires or dudes kissing each other, and /Pounded in the Butt by Vampire Worldbuilding/ might get me into copyright trouble. Meanwhile /Seeing Red/ is very... pulp/corny.

I guess nothing is ever perfect, is it?
:PROPERTIES:
:Author: MagicWeasel
:Score: 1
:DateUnix: 1491345265.0
:DateShort: 2017-Apr-05
:END:

***** u/callmebrotherg:
#+begin_quote
  Pounded in the Butt by Vampire Worldbuilding might get me into copyright trouble.
#+end_quote

Luckily for you, titles cannot be copyrighted.

per the [[https://www.copyright.gov/help/faq/faq-protect.html][U.S. Copyright Office]]:

#+begin_quote
  *Can I copyright the name of my band?*

  No. Names are not protected by copyright law.

  [...]

  *How do I copyright a name, title, slogan, or logo?*

  Copyright does not protect names, titles, slogans, or short phrases.
#+end_quote

There is also this CO document that straight-up called [[https://www.copyright.gov/circs/circ34.pdf][Copyright Protection Not Available for Names, Titles, or Short Phrases]].

(For bonus points, make /that/ the title of your next story. >:P )

I look forward to the megadollar Hollywood adaptation of /Pounded in the Butt by Vampire Worldbuilding/. >:]
:PROPERTIES:
:Author: callmebrotherg
:Score: 2
:DateUnix: 1491345671.0
:DateShort: 2017-Apr-05
:END:

****** So, /Pounded in the Butt by Vampire Worldbuilding/ it is.
:PROPERTIES:
:Author: MagicWeasel
:Score: 1
:DateUnix: 1491345742.0
:DateShort: 2017-Apr-05
:END:

******* The title alone is going to drastically increase your odds of getting featured in articles or something.

Also, increase your odds of a Chuck Tingle parody, but that might be better than a Hugo.
:PROPERTIES:
:Author: callmebrotherg
:Score: 2
:DateUnix: 1491345846.0
:DateShort: 2017-Apr-05
:END:

******** I don't think Chuck Tingle has even parodied /Twilight/, so I can't set my sights too high, can I?

Seriously though, this is a personal project, so I don't really care about being featured anywhere in particular. My "far-fetched achievable goal that will make me feel like I have achieved something impossible" is to sell 100 copies on Kindle. My "lofty contributing to society goal" is for this story to be popular enough on this sub that it starts to remove the stigma associated with the romance genre in the community and contributes to a trend of more diverse rational fiction (in terms of genre). I don't suspect I'd achieve either of them, but they're the lofty dreams I fantasise about sometimes.

My realistic goal is for my husband and boyfriend to read it, and for my bff/sort-of-coauthor and me to squee over the fact that we've finally achieved our childhood dream of having something novel-ish written based on our mythology. And that I get to feel proud for starting a project and finished it. And those are virtually guaranteed!
:PROPERTIES:
:Author: MagicWeasel
:Score: 2
:DateUnix: 1491346229.0
:DateShort: 2017-Apr-05
:END:

********* u/callmebrotherg:
#+begin_quote
  I don't suspect I'd achieve either of them, but they're the lofty dreams I fantasise about sometimes.
#+end_quote

We might need better romance writers before we see more rational!romance here. At least personally, I've no problems with writing romance, but I'm not sure that I could write a good romantic subplot, let alone a story that centered around it.
:PROPERTIES:
:Author: callmebrotherg
:Score: 2
:DateUnix: 1491346523.0
:DateShort: 2017-Apr-05
:END:

********** The annoying thing is I haven't read any romance myself, so I can't really comment on the genre. I listened to [[http://www.theallusionist.org/allusionist/covers-i][a podcast about it]] last month, and it really spoke to me. I think the scorn that romance as a genre generally get is tied up in history and the patriarchy and all of that.

You think of stereotypical pulp sci-fi and it's generally "just as bad" as romance in terms of how shallow it is - man goes to mars, shoots a blaster at the bad guys, beds a green-skinned woman. But pulp sci-fi doesn't have the same level of scorn as pulp romance does. It's interesting to think about.

Anyway... getting a bit sidetracked. I'm hoping that my story hits the romance notes. I always wonder whether it doesn't have /enough/ romance. But the entire thing is centred around them trying to make their relationship work despite everything, so I hope it does.
:PROPERTIES:
:Author: MagicWeasel
:Score: 2
:DateUnix: 1491346947.0
:DateShort: 2017-Apr-05
:END:


*** u/SevereCircle:
#+begin_quote
  Hearts Fangs and Abs
#+end_quote

+1, LOL
:PROPERTIES:
:Author: SevereCircle
:Score: 2
:DateUnix: 1491405256.0
:DateShort: 2017-Apr-05
:END:


*** - I've grown accustomed to his fangs.
:PROPERTIES:
:Author: Charlie___
:Score: 1
:DateUnix: 1491946240.0
:DateShort: 2017-Apr-12
:END:
