#+TITLE: [BST/WIP] [RT] Rational ways to deal with subconscious/unconscious reality-warping powers?

* [BST/WIP] [RT] Rational ways to deal with subconscious/unconscious reality-warping powers?
:PROPERTIES:
:Author: CauldronCape
:Score: 7
:DateUnix: 1428586674.0
:DateShort: 2015-Apr-09
:END:
Note: This is an ongoing project so I'll probably be posting here again asking for advice at various writing stages.

Anyway. I'm writing a story that involves unconscious reality-warping powers. So far I'm envisioning a low-fantasy modern world setting with very, very few characters having this ability, let along being able to use it properly.

Mechanically, control over changes effected varies inversely with how much area you can change and how drastically you can change it. Though some characters with the ability achieve a middle ground, there are two irreversible states: on the very low-control end of the scale, you manipulate reality such that all your observations confirm your subconscious beliefs. On the high-control end you can grant yourself eternal youth and have complete conscious control over your own biology, but cannot affect anything else (anything produced by your body through use of your power vanishes after travelling some small distance away from it -- a millimeter, say).

Obviously there are benefits and drawbacks to being at either end. Notably, with low control, you cannot learn new things -- and you're at the mercy of the impulses and instincts of your monkey-brain. At the high end, you can manipulate your brain-matter, but don't necessarily know which specific changes will achieve which results, largely eliminating the ability to experiment.

First, *does anyone know whether there is any fiction that has similar abilities as a plot device?* There's a concept called /unmada/ in the roleplaying game [[https://sites.google.com/site/moochava/genius][Genius: The Transgression]] that is similar, but unfortunately it being from a roleplaying game means I don't get to see how it plays out in characterization or narrative.

Speaking of narrative: *how the heck would I write the perspective of a rational character approaching the low-control end of the scale?* Would they even be able to act "rationally" if they can't make viable observations? How would they interact with other characters, and what would count as holding the Idiot Ball?

Third, in order to really make this a rational story, *what science should I brush up on?* Obviously I'm going to need to stress test the premise further -- which physics/cognitive science questions should I keep in mind?

Thanks for any help/advice. I'll probably get a blog and start posting chapters when I have a viable first draft.

EDIT: A possible example of a low-control character analogue would be Haruhi Suzumiya.


** u/NotUnusualYet:
#+begin_quote
  does anyone know whether there is any fiction that has similar abilities as a plot device?
#+end_quote

The anime series "The Melancholy of Haruhi Suzumiya" is an example. Haruhi has the power to reshape reality to fit her expectations and wishes, but doesn't realize it. It centers around a group of characters trying to prevent her from completely destroying or reshaping reality.

[[#s][Spoilers]]

EDIT: See DCarrier's comment below if you're interested in an Eliezer Yudkowsky fanfiction of Haruhi Suzumiya! Fair warning, you really shouldn't read it if you haven't watched the anime first.
:PROPERTIES:
:Author: NotUnusualYet
:Score: 10
:DateUnix: 1428594225.0
:DateShort: 2015-Apr-09
:END:

*** Somewhat amusingly, the other popular fiction example is the orcs from Warhammer 40k, an entire species with abilities like this but too dumb to realize it.

They only reload when they think they should have to, weapons break or continue working based only on expectations, red vehicles go faster because everyone knows that painting your war truck red makes it go faster.
:PROPERTIES:
:Author: Junkle
:Score: 6
:DateUnix: 1428612284.0
:DateShort: 2015-Apr-10
:END:


*** And for the rationalist perspective, there's Eliezer's fanfic, [[https://www.fanfiction.net/s/5588986/1/Trust-in-God-or-The-Riddle-of-Kyon][Trust in God, or, The Riddle of Kyon]]. And I'll take this opportunity to advertize my (mostly complete) [[http://dcarrier.deviantart.com/art/Trust-in-God-or-The-Riddle-of-Kyon-499378337][visual novel adaptation]].
:PROPERTIES:
:Author: DCarrier
:Score: 3
:DateUnix: 1428620245.0
:DateShort: 2015-Apr-10
:END:

**** Wow, I didn't know about this story. He didn't get the characters exactly right, but it managed to be hilarious, thought-provoking, and touching all at once. Thanks for mentioning it!

(I checked out your adaptation too. I'm not familiar with visual novels, so all I can really say is that it was a novel experience. Thanks for making it.)
:PROPERTIES:
:Author: NotUnusualYet
:Score: 1
:DateUnix: 1428634084.0
:DateShort: 2015-Apr-10
:END:

***** Um. . . what happens when a a Harui like character who suffers from Solipsism dies?
:PROPERTIES:
:Author: Empiricist_or_not
:Score: 1
:DateUnix: 1428724408.0
:DateShort: 2015-Apr-11
:END:

****** Depends on what the true nature of their power is. In Haruhi's case I'd guess that it's not actually possible for her to die.
:PROPERTIES:
:Author: NotUnusualYet
:Score: 1
:DateUnix: 1428725136.0
:DateShort: 2015-Apr-11
:END:


*** I'm looking into this, and it's almost exactly what I'm going for. Thanks!
:PROPERTIES:
:Author: CauldronCape
:Score: 2
:DateUnix: 1428594357.0
:DateShort: 2015-Apr-09
:END:

**** Just so you know, it's an extremely popular anime, and the light novel series it's based on is apparently even more popular in Japan. This is what people will immediately think of when hearing about a story like this, so it would probably be a good idea to become familiar with the plot so you can make sure you aren't retreading any ground.
:PROPERTIES:
:Author: NotUnusualYet
:Score: 5
:DateUnix: 1428594971.0
:DateShort: 2015-Apr-09
:END:

***** I don't think I will be, since my plans feature characters like her as either antagonists or viewpoint characters. Is there any content in the series, or fanfiction even, that has Haruhi as a viewpoint character? From what I've looked at so far, the main character is more of an observer.
:PROPERTIES:
:Author: CauldronCape
:Score: 1
:DateUnix: 1428595975.0
:DateShort: 2015-Apr-09
:END:

****** I don't think there is in canon material. Fanfiction, undoubtedly.
:PROPERTIES:
:Author: NotUnusualYet
:Score: 2
:DateUnix: 1428596422.0
:DateShort: 2015-Apr-09
:END:


** "you manipulate reality such that all your observations confirm your subconscious beliefs."

I... hrm. Headache trying to wrap my thoughts around this, and how it would impact state of mind.

There are so many ways that this could go horribly bad, or extremely well. Does the ability develop when very young, or would there be an opportunity to establish a fairly solid personality before onset?
:PROPERTIES:
:Author: Farmerbob1
:Score: 5
:DateUnix: 1428589572.0
:DateShort: 2015-Apr-09
:END:

*** Even those with the latent ability can't activate it without training in mental discipline. They learn how to control it through esoteric meditation practices (like those that allow control of your body temperature), and through lucid dreaming. Both practices rely on keeping your mind and body separate from your surroundings -- erecting a barrier of sorts between them. Knocking down this barrier is dangerous without the tools to rebuild it if necessary. Practicing outside of the safety of your own mind/body too early can, worst case, lead to a downward spiral that ultimately prevents you from ever having any level of control.

So, option two. What specifically do you mean by horribly bad or extremely well?
:PROPERTIES:
:Author: CauldronCape
:Score: 4
:DateUnix: 1428591133.0
:DateShort: 2015-Apr-09
:END:

**** Well, on the bad side, being a hypochondriac. On the good side, being an optimist.

You could go to some really, really wrong places with regards to sex and interpersonal relationships.
:PROPERTIES:
:Author: Farmerbob1
:Score: 3
:DateUnix: 1428591634.0
:DateShort: 2015-Apr-09
:END:

***** ... Huh. You know, I never considered that the reality-warping would be anything other than a bad thing for everyone else. One of the major antagonists I'm planning is a guy with low-control and a Jim Jones-esque island cult. It's exactly as wrong as it sounds.

An optimist would probably be less bad, but I'd see it as being creepy more than anything else. Probably a false-utopia rather than a real one.

I was going to get around the question of an optimist meeting a cynic by only giving low-control types power over a certain specific area. I wonder if the headache of finding a reasonable answer would be worth it.
:PROPERTIES:
:Author: CauldronCape
:Score: 2
:DateUnix: 1428593101.0
:DateShort: 2015-Apr-09
:END:

****** With the existence of a prior life, something to base your new reality on, you could probably avoid disturbing people too much if your earlier life wasn't too traumatic.

It would still require a level of self control that one commonly sees in fictional characters with overwhelming mental powers, like Marvel's Professor Xavier. Not how he was portrayed in the movies, which has been remarkably weak, but from the comics, where when he took the gloves off, he became extraordinarily dangerous.

Then there's Franklin Richards on the childish sane side, and Proteus on the young adult insane side in Marvel. DC probably has their reality-warpers too.

EDIT In fact, I think Franklin Richards is probably almost exactly what you describe.
:PROPERTIES:
:Author: Farmerbob1
:Score: 2
:DateUnix: 1428593821.0
:DateShort: 2015-Apr-09
:END:

******* Thanks for the examples! I'll look into them.

EDIT: I think Franklin Richards has a bit more conscious control over his surroundings than what I'm going for. Thanks for the suggestion, though!
:PROPERTIES:
:Author: CauldronCape
:Score: 1
:DateUnix: 1428594124.0
:DateShort: 2015-Apr-09
:END:

******** Franklin, in Canon, CAN exert direct control, when he hasn't locked away his own powers from himself, which he does from time to time. However, he's done quite a few things over the years that have ended up with people being very careful around him. He's a child though, and you are probably more interested in adult behaviors.
:PROPERTIES:
:Author: Farmerbob1
:Score: 2
:DateUnix: 1428600270.0
:DateShort: 2015-Apr-09
:END:


** From a theoretical perspective, this is one of those times when "acting rationally" requires a different approach.

Normally we assume that the mind is a black box, that it only matters what decision you make and not what thought process led you to that decision. Now, this isn't 100% true, for example a poker player might give away his thought process by his expression, or an athlete might be more motivated by his trainer's disapproval to complete a painful exercise. But in general, it's a pretty good approximation to say that your thoughts don't affect reality until you convert them into deliberate actions.

But, if your subconscious beliefs directly impact reality, then it might be to your advantage to /deliberately/ hold false beliefs. To not think about certain things, refuse to acquire particular pieces of information, because they might be dangerous to yourself or the world. Example:

#+begin_quote
  On the high-control end you can grant yourself eternal youth and have complete conscious control over your own biology
#+end_quote

I'm sure someone in this subreddit is going to point out the potential for increasing your own brainpower and becoming a superintelligence. But you wouldn't even /try/ that if you didn't realise it was a possibility. Ideally, you'd deliberately not learn about superhuman AIs because you risk creating an evil AI just by knowing about them... but how could you possibly know that knowledge presented a risk before you learned it?

It's been pointed out on this subreddit that the protagonists of /Gurren Lagann/, while not exactly rationalist, are generally acting optimally considering they live in a world where believing in yourself and doing incredibly awesome things /is the power source that fuels their gear/. Same basic principle: we normally encourage thinking logically and being aware of your own biases, but in some settings that's the wrong approach.

In conclusion, a lot of what we call "rational thinking" doesn't apply here, a lot of the traits we associate with rational characters would be terribly dangerous with this power, so there's some assumptions to be rethought.
:PROPERTIES:
:Author: Chronophilia
:Score: 4
:DateUnix: 1428597617.0
:DateShort: 2015-Apr-09
:END:

*** Interesting analysis, I'll keep these points in mind.

However: you wouldn't risk creating an evil AI just by knowing about them because on the high-control end you're only affecting your surroundings consciously, not subconsciously.

Edit: I like your interpretation of how low-control characters make decisions, but which pieces of information do you think would be most damaging? Would your view of an ideal low-control character immediately cease learning about the world because anything that actually happened would prevent the character from instating something better? And how do you think villainous, selfish, or megalomaniac characters would control their own learning?
:PROPERTIES:
:Author: CauldronCape
:Score: 3
:DateUnix: 1428599496.0
:DateShort: 2015-Apr-09
:END:

**** That's just one example. If you believe aliens exist, then depending on how your subconscious thinks interstellar civilisation should work, they could be completely harmless or they could destroy the Sun on a whim. And thinking and learning about aliens would cause them to move around on that spectrum. Which is bad, because the more they move around, the better the chance they'll eventually hit the "extinction event" marker. So once you've created aliens, you should avoid learning about them as much as possible.

Same for angels, gods, vampires, werewolves, zombies, robots, superheroes, and winning the lottery.
:PROPERTIES:
:Author: Chronophilia
:Score: 3
:DateUnix: 1428600529.0
:DateShort: 2015-Apr-09
:END:


** The Marauder concept from Mage: The Ascension is kind of like this. There's a quest on Sufficient Velocity by Panopticon where the Marauder is a conspiracy theorist. A hardcore conspiracy theorist, who thinks her life is the plot of an action movie. At one point, she rides in on a motorcycle and leaps off of it; it /accelerates in mid-air/ and does an action-movie explosion on impact with the baddies.

Anyway, I would imagine that, if this is a phenomenon that can be trained by prior experience, you could raise a child from birth to have very specific experiences - like, whenever they made a certain hand gesture, a computer would identify the target, and a sniper rifle would shoot it. Once their power activated, they wouldn't need the rifle anymore. What about virtual reality? Raise a child in a virtual reality, and the rules of that place would follow them into the real world.
:PROPERTIES:
:Score: 3
:DateUnix: 1428633309.0
:DateShort: 2015-Apr-10
:END:


** u/deleted:
#+begin_quote
  First, does anyone know whether there is any fiction that has similar abilities as a plot device?
#+end_quote

The Melancholy of Suzumiya Haruhi
:PROPERTIES:
:Score: 2
:DateUnix: 1428599028.0
:DateShort: 2015-Apr-09
:END:


** Ursula Le Guin's [[#s][]] kinda has this as an idea via dreams.
:PROPERTIES:
:Author: bbrazil
:Score: 1
:DateUnix: 1428612711.0
:DateShort: 2015-Apr-10
:END:

*** +Really? Where?+ Ah, didn't see the spoiler at first. Will check it out.
:PROPERTIES:
:Author: CauldronCape
:Score: 1
:DateUnix: 1428619627.0
:DateShort: 2015-Apr-10
:END:


** To have a low control character be rational they would have to learn rationality, therefor they either aren't in the solipsistic god level where they can't learn anything, or you need some plobotenum that turned their power off enough to train them. Maybe a high control character?

On the Haruhi side the level to which this can goi bad is why many there are interesting ideas (head-cannon or unconfirmed theory?) that Haruhi is Lovecraft's Azuoth, and her handler Kyon is Nyarlenhotep eir's seneschal.
:PROPERTIES:
:Author: Empiricist_or_not
:Score: 1
:DateUnix: 1428723476.0
:DateShort: 2015-Apr-11
:END:


** u/philip1201:
#+begin_quote
  on the very low-control end of the scale, you manipulate reality such that all your observations confirm your subconscious beliefs.
#+end_quote

1. Grok Löb's theorem.

2. Complete gruelling mental training to get to this "low-control" level state.

3. "If I believe that 'if I believe that the universe is about to be rewritten according to my CEV, then the universe is about to be rewritten according to my CEV', then I believe that the universe is about to be rewritten according to my CEV".

4. The universe is rewritten according to my CEV.

So... either this doesn't work for some unspecified reason, or the first logician who stumbles across Löb's theorem wins everything forever.

Okay, so suppose you're a dumbass and you chose perfect self-control instead of perfect universe-control. In that case, since "Anything produced by my body through use of my power vanishes after travelling some small distance away from it", the munchkin-key is "my body". Your goal is to consume everything and optimise it as part of your undying body. Also to upgrade your mind to find a way to eat planets and to have astronomical objects all be part of one singular body.
:PROPERTIES:
:Author: philip1201
:Score: 0
:DateUnix: 1428682766.0
:DateShort: 2015-Apr-10
:END:

*** Unfortunately, it's the grueling mental training that lets you /stay away/ from the two irreversible ends of the scale -- the mental discipline required to merely activate it only takes a month or so of regular meditation exercises. So steps 2 and 3 don't work unless you go into the training already with a super-intuitive understanding of mathematics and a fully-realized CEV, which you wouldn't necessarily know to do.

I'm sort of imagining every character who makes it to the "low-control" stage an UFAI, since remaking the world in the image of any imperfect human is going to have negative consequences when that human can't perfectly grok all the changes they're making to their environment -- not to mention that they can't learn anything once they get to that state either.

The benefits of being high-control are salient in the context of existing low-control UFAI, since high-control people are the only ones who can reliably kill UFAI -- or change them, since they have the power to not-fit in with the UFAI's model of the world.

On the other hand, if some normal genius mathematician/logician stumbles across people with the latent ability, and manages to track one down in their youth -- well. That's another story. I'll think about this.
:PROPERTIES:
:Author: CauldronCape
:Score: 2
:DateUnix: 1428684634.0
:DateShort: 2015-Apr-10
:END:

**** Löb's theorem is not hard enough to grok to require "super-intuitive understanding of mathematics". [[http://agentyduck.blogspot.com/2014/02/lobs-theorem-cured-my-social-anxiety.html][People claim to have used it]] for comparable purposes. Professional mathematicians ought to be able to do it as a matter of course.

I subconsciously expect(ed) the universe to be able to derive my CEV from my brain automatically, and for it to go all right.

I was also under the impression that low-control people are able of changing their own body and mind, if they expected it to change. My body and mind would therefore also automatically be CEV-optimised, which means it cleverly avoids traps like "not being able to learn anything" by expecting to receive truly accurate information, and storing it in a brain lobe believed to be unalterable, which doesn't automatically alter the world, either by being conscious, by expecting it not to alter the world, or by not putting it through the mental method required to turn thought into fact. Similarly, through transhumanism, I would expect my mind to expand to the point of being able to comprehend reality well enough to verify that CEV is truly being applied smoothly.

Actually, come to think of it, that isn't the optimal way to handle things, and I did give the universe a blank slate to optimise towards my CEV without regards for self-preservation. So it could just restart everything with the most CEV-wise optimal physical laws possible, plus the minimal definition of "me" necessary to observe that all is well.

I didn't expect other players to be a problem either: this should be an instantaneous self-recursive and (if mind-magic is coded in at a higher level than relativity) retroactive foom. If high-control people can't be affected by my magic directly, I'd expect black holes to appear to remove them from time, or inflation to magically restart locally to throw them across a Hubble horizon, or false vacuum decay to start and somehow stop again a nanosecond later, starting at their location, collapsing the space they occupy into zero volume.
:PROPERTIES:
:Author: philip1201
:Score: 1
:DateUnix: 1428687694.0
:DateShort: 2015-Apr-10
:END:

***** u/CauldronCape:
#+begin_quote
  Löb's theorem is not hard enough to grok to require "super-intuitive understanding of mathematics". People claim to have used it for comparable purposes.
#+end_quote

It's hard enough to grok that not everyone can use it for comparable purposes, or else you'd never see someone with knowledge of Lob's theorem who has social anxiety.

#+begin_quote
  I subconsciously expect(ed) the universe to be able to derive my CEV from my brain automatically, and for it to go all right.
#+end_quote

Yes, and it would go alright from your perspective, I suppose, but not necessarily from everyone elses', and you wouldn't be able to perceive any difference in how happy they were because you can't have knowledge of previous states of things you've changed.

#+begin_quote
  My body and mind would therefore also automatically be CEV-optimised, which means it cleverly avoids traps like "not being able to learn anything" by expecting to receive truly accurate information, and storing it in a brain lobe believed to be unalterable, which doesn't automatically alter the world, either by being conscious, by expecting it not to alter the world, or by not putting it through the mental method required to turn thought into fact. Similarly, through transhumanism, I would expect my mind to expand to the point of being able to comprehend reality well enough to verify that CEV is truly being applied smoothly.
#+end_quote

How can you acquire information that surprises you -- that you don't expect -- if the world that you perceive changes specifically to fulfill your expectations? Any information you acquire would be altered to not surprise you, and the very act of looking for more information would change more things.

Not to mention that altering your brain with that level of precision isn't possible if you're only able to affect reality subconsciously. If any radical changes happened, chances favor optimization in the direction of a flawed CEV, not a perfect one. Hence, UFAI.

Also, thanks for the tip on relativity! If I now make the authorial decision that the magic is /not/ coded in at a higher level than relativity, what are the implications, in your opinion?
:PROPERTIES:
:Author: CauldronCape
:Score: 1
:DateUnix: 1428695895.0
:DateShort: 2015-Apr-11
:END:

****** u/philip1201:
#+begin_quote
  How can you acquire information that surprises you -- that you don't expect -- if the world that you perceive changes specifically to fulfill your expectations?
#+end_quote

Simple: My 'subconscious' expects to be truly surprised. It would be surprised if the information it receives is generated by its own expectations rather than by the information-feeding lobe.

Perhaps it's more simple to put it like this: I'd sort of split myself into two people. One a blank slate low-control reality warper and the other a high-control internal self-modifier, where the former Löb-believes the latter to be outside of his control and capable of controlling him, and the latter holds accurate beliefs and determines what kind of information to feed the former.

#+begin_quote
  Not to mention that altering your brain with that level of precision isn't possible if you're only able to affect reality subconsciously.
#+end_quote

What makes a thought "subconscious"? How does the universe decide to make something into law - where do the neural XML tags switch from 'conscious' to 'subconscious'?

As for changing your brain precisely according to your CEV being impossible, /I'm sure it isn't really that hard and that my brain can change itself to work that out/.

#+begin_quote
  Also, thanks for the tip on relativity! If I now make the authorial decision that the magic is not coded in at a higher level than relativity, what are the implications, in your opinion?
#+end_quote

No retroactive causality means that a lot of expectations would be faked by the universe. If I expect to see my friend (healthy) when I open the door in 1 second, and I know what the room looks like, and I don't expect to see any spatial distortion, and my friend is 500 meters away in a different room, the universe can't easily comply with my expectations. Would it create a copy of my friend, with fake memories of coming to this room instead? Would it hijack my senses to make me believe I'm seeing my friend?
:PROPERTIES:
:Author: philip1201
:Score: 2
:DateUnix: 1428719050.0
:DateShort: 2015-Apr-11
:END:
