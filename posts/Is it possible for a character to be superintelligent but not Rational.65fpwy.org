#+TITLE: Is it possible for a character to be superintelligent but not Rational?

* Is it possible for a character to be superintelligent but not Rational?
:PROPERTIES:
:Author: Nulono
:Score: 32
:DateUnix: 1492209398.0
:DateShort: 2017-Apr-15
:END:
I've been toying with the idea of a character who wishes to max out his INT score, but doesn't think to do the same to his WIS score, so he ends up having a vast intellect but not really knowing how to use it (e.g., he can quickly figure out a riddle if given the clues but often overlooks fairly obvious details, or he can figure out the answer to a question fairly quickly but struggles to ask the right questions in the first place). He might be aware of the principles of rationality on an intellectual level but fail to put them into practice.

Obviously, we're talking about an intelligence that can't easily self-modify, but other than that, could such a character be written in a consistent manner, or would contradictions start popping up?


** Try a character who thinks really fast (and can therefore brute-force problems he knows how to do easily) but isn't great at synthesizing information, and falls prey to logical fallacies relatively often.
:PROPERTIES:
:Author: GaBeRockKing
:Score: 35
:DateUnix: 1492210618.0
:DateShort: 2017-Apr-15
:END:


** Real life people are wildly inconsistent. Hardcore Vulcan in one area. fuzzy headed Hippie in another. It's absurd.
:PROPERTIES:
:Author: pixelz
:Score: 21
:DateUnix: 1492211736.0
:DateShort: 2017-Apr-15
:END:


** Being superintelligent will let you guess the consequences of actions and predict events with uncanny clarity, but it doesn't in and of itself help you understand what you want. At the least, deception should be fairly easy to spot, but without introspection from such superintelligence implicit assumptions will still go unchallenged and contradictions can lie in wait until they make a problem 'unsolveable'.

It should be trivial for a person with superintelligence to start noticing internal inconsistency through introspection, but with the INT/WIS divide you're dealing with I have to assume such influences are forbidden. Thus, your character is not just superintelligent but also forbidden from using that superintelligence for introspection. Perhaps they're limited to just normal human cognition for such a task, or their seeming internal contradictions can only be removed through buffing WIS.

The rules that human brains tend to come packaged with sort of derive from our core values, but also from expected context. Certain lines that you can't help but see as sinister, for example, because our brains come packaged knowing that most usages of that line are sinister, so it's okay to just automatically read the line as sinister. If it's not sinister, this leads to dissonance in the sense that we 'know' that it's a sinister line but can't see any reason for that. Superintelligence should let your character realize that it's just /usually/ a sinister line, but not automatically, and note that the reflex cannot be trusted, but with the INT/WIS divide all that can result is they notice confusion but trying to analyze the situation is like slamming their head against a brick wall.

If you want a descriptive way to present it, you might be able to say that he looks inwards, but gets caught up in the minutia of his thought and the workings of his thought processes are far too intricate for him to comprehend, leaving him frustrated and unable to solve the problem, as if his own intelligence became a trap ensnaring his attempts at introspection in a web of detail and useless information.
:PROPERTIES:
:Author: InfernoVulpix
:Score: 15
:DateUnix: 1492215060.0
:DateShort: 2017-Apr-15
:END:

*** I think what I had in mind was more along the lines of a character who knows what his common errors are, but lacks the patience and discipline necessary to train himself out of them.
:PROPERTIES:
:Author: Nulono
:Score: 15
:DateUnix: 1492229694.0
:DateShort: 2017-Apr-15
:END:

**** me_irl
:PROPERTIES:
:Author: ShareDVI
:Score: 12
:DateUnix: 1492272555.0
:DateShort: 2017-Apr-15
:END:


** They were so caught up with the fact that they /could/ that they never stopped to consider whether they /should/.

It could be written as the type of personality which is easily sidetracked by intellectual possibility. Or one which has little to no self-awareness (or will), and thus tends to do what they're told (or what's suggested) without regard for longer-term consequences.

One literary example which is sort of in the same ballpark is Terry Pratchett's [[https://wiki.lspace.org/mediawiki/Leonard_of_Quirm][Leonard da Quirm]]; the sort of person who doesn't bother to check if they're about to walk off a cliff because they'd probably be able to figure out a solution to falling - or gravity - before they hit the bottom.
:PROPERTIES:
:Author: Geminii27
:Score: 13
:DateUnix: 1492217986.0
:DateShort: 2017-Apr-15
:END:


** Several people have pointed out that nominally intelligent but irrational characters are rife in media, but the hard part isn't just making a Lex Luthor or Dr. Strange, it's rationally constructing a character who's believably very intelligent but also irrational.

I think this is quite doable, because such people exist. Issac Newton is a perfect example; blisteringly intelligent, but going in the wrong directions an awful lot of the time.

As you point out, in order for a very intelligent person to be irrational, there has to be something blocking their intelligence from engineering its own rationality. As far as I can tell this usually manifests in two ways: Hardware and Firmware.

Hardware is when they've got a pathological mental state. This was a big factor with Newton--he poisoned himself pretty badly with mercury and other chemicals that left him more than a little crazy. He had pretty bad paranoia that manifested in his lashing out at friends over imagined offenses and engaging in very odd practices and behaviors.

I've heard that there have been some studies that posit a link between extreme intelligence and mental illness. Mathematical modeling of neurons suggests that humans are about at the limit of how far you can push that processing architecture before error rates start to soar. In other words, if you get someone whose brain works abnormally fast, it will probably encounter an abnormal amount of errors. Can't find the source for that right now, though, so take with salt.

The second way brains malfunction, which is usually present along with the first but doesn't necessitate it, is Firmware. In human terms, epistemology. Without an epistemic basis conducive to rationality, the ability of even a very intelligent mind to self-correct toward that state is severely hindered. There are smart people who gamble, are religious, or [[https://www.quora.com/Pseudoscience-What-are-some-of-the-craziest-ideas-held-by-Nobel-Prize-winners][work very hard on pseudoscience]].
:PROPERTIES:
:Author: Tinfoil_Haberdashery
:Score: 10
:DateUnix: 1492233892.0
:DateShort: 2017-Apr-15
:END:

*** Nicely put.

I was a little disappointed that you put "are religious" as a go-to-fail label. Are there people who substitute belief for thinking? Absolutely. That, however, is a mistake of the people - not necessarily the belief.
:PROPERTIES:
:Author: thrawnca
:Score: 1
:DateUnix: 1492249672.0
:DateShort: 2017-Apr-15
:END:

**** For starters, the fact that there are very smart people making religious claims in multiple, mutually exclusive religions is sufficient evidence that most of them must be wrong. If Mormons are right, then Hindus and atheists and everybody else are so glaringly wrong that they can't possibly be examining the evidence rationally. If Hindus are right, then the same goes for Mormons et al. This holds true for pretty much anyone whose level of religious belief is any stronger than humanism with metaphors.

That's not to say I'm backing down from the implication of my statement that religious belief is inherently irrational. The healing power of prayer (as just one example) has been as thoroughly debunked as the healing power of homeopathy or acupuncture. It's disingenuous to be willing to accept the pseudosciences pursued by the Nobel Laureates I linked to as obvious markers for irrationality but claim that religious belief is somehow a bridge too far.

If we can't dismiss religious belief out of hand because nothing can be 100% certain, or because some religious people /do/ think critically about their beliefs, or because it's impossible to prove a negative, then the same goes for telepathy and astrology.

Is it possible I'm wrong? Obviously. It's possible I'm wrong about literally everything, and I'm frequently demonstrably wrong about a lot of things. But strong religious belief has all the markings of a self-reinforcing, anti-rationalist epistemology structure, and if it just so happens that one of them is coincidentally correct in spite of that, then the usefulness of rationality itself is debunked.
:PROPERTIES:
:Author: Tinfoil_Haberdashery
:Score: 11
:DateUnix: 1492272660.0
:DateShort: 2017-Apr-15
:END:

***** u/thrawnca:
#+begin_quote
  so glaringly wrong that they can't possibly be examining the evidence rationally.
#+end_quote

Well, I wouldn't go so far. Ptolemy's crystal spheres were an incorrect idea, sure, but does that mean everyone who accepted the idea was failing to think? I'd instead assume that they simply lacked information. If, upon being presented with a superior theory, they reject it out of hand due to emotional or political attachment to the old theory, that is when they have problems (though technically, depending on what they value, their rejection might strictly speaking be "rational" - just not scientific).

So yes, most or all religious belief systems must be largely wrong, where they contradict. That's cause for any believer to have a humble and open-minded attitude toward belief systems that they disagree with, certainly - but not necessarily cause to discard the whole field.

#+begin_quote
  religious belief is inherently irrational
#+end_quote

First off, "irrational" is probably the wrong word, since religious belief might well help someone achieve what they value, depending on what that value is. But I'm pretty sure you meant that religious belief is inherently unscientific, that it cannot reasonably be expected to be correct. We both value truth, so rationality then requires a reasonable possibility of truthfulness. Yes?

Is it really so unreasonable to suppose that /someone/ has already achieved HJPEV's goals of agelessness, space exploration, stellar manipulation and harvesting, and reaching "a /shockingly/ high standard of being so incredibly, unbelievably rational that you actually started to /get things right/, as opposed to having a handy language in which to describe afterwards everything you'd just done wrong" - and that the earth is the result of such a person building more cradles of intelligent life? If we can aspire to someday as a race be capable of such things, how can we dismiss the possibility that someone else might have already succeeded?
:PROPERTIES:
:Author: thrawnca
:Score: 2
:DateUnix: 1492338007.0
:DateShort: 2017-Apr-16
:END:

****** My two pence: There is a large difference between not dismissing something and supposing it to be true, particularly in the face of all available evidence plus Occam's razor.

Edit: A further line of thought might claim 'a sufficiently aloof deity is indistinguishable from an uncaring universe' and argue that a system qualified to be referred to as 'religious' revolving around faith and prayer (where the faith relates to the willingless as well as the ability to respond to the prayers) would at most be parallel to and unrelated to any coincidental reality. That is, even if Oxlep seeds life, and in one of those cradles a person happens to decide their deity's name is Oxlep, and with faith in their heart prays "Oxlep, please interfere and save us from drought and angst and malice!", the Oxlep religion would be a mistaken path even with the existence of an Oxlep reality. One could then respond "But a deity might really have set up a software mind-copying and virtualised afterlife structure!", then "In that case it's again unrelated to religions in which jealous gods withhold a pleasant afterlife in the absence of faith", "But such a deity might actually build in such requirements!", "Then, in the absence of sufficient evidence, the deity is indistinguishable from an /evil/ deity, rather than an uncaring universe,", "But then rational to take the path of believing just in case,", "But then which option to choose, and in the desire for truth why think 'indistinguishable from evil deity' rather than 'indistinguishable from uncaring universe' if arguing from imagining what sorts of existences we want to become"... the line of thought before the edit is much more succinct.
:PROPERTIES:
:Author: MultipartiteMind
:Score: 4
:DateUnix: 1492345266.0
:DateShort: 2017-Apr-16
:END:

******* Your argument seems to revolve around the idea that if a deity exists, then it has remained uninvolved in human affairs and is therefore meaningless - which seems like a curious claim in the context of a discussion about epistemological errors, because believer after believer has claimed the opposite, that they have indeed experienced contact with the divine in one form or another. Of course, you are quite at liberty to consider them factually mistaken; however, if they sincerely believe that they have encountered evidence of a supreme being, then to act on that alleged evidence does not look to me like a failure of rationality.

Occam's Razor, meanwhile, is a tricky thing to wield correctly in this kind of debate. It can really only be properly used when various explanations would all be adequate to explain observations - but in this case, the adequacy of various explanations of existence is part of the subject of debate, so by the time you swing the razor, you have already made a decision about the answer. Your bottom line about the reasonableness or unreasonableness of God was already written.
:PROPERTIES:
:Author: thrawnca
:Score: 2
:DateUnix: 1492427784.0
:DateShort: 2017-Apr-17
:END:

******** u/derefr:
#+begin_quote
  if they sincerely believe that they have encountered evidence of a supreme being, then to act on that alleged evidence does not look to me like a failure of rationality
#+end_quote

It seems like a /severe/ failure of rationality to privilege the hypothesis of personal contact with the divine, over that of your mental hardware having entered an error state. Regardless of the fact-of-the-matter (which I don't have direct access to), I'd hope to remain skeptical of a proffered messiah until they managed to do something to outweigh the /entire/ probability-mass of other explanations for the same evidence. And that "tweaking my mind to directly have an experience I would describe as 'contact with the divine'" would no more qualify as such evidence, than the singing of a Siren would qualify as a evidence that I am rationally justified in choosing to steer my ship into some rocks.
:PROPERTIES:
:Author: derefr
:Score: 2
:DateUnix: 1492498201.0
:DateShort: 2017-Apr-18
:END:

********* Exactly. With what we know of the brain and how easy it can be taken for a spin by anything from hormones and gut bacteria to recreational drugs I find it very hard to call it rational to argue that a divine being is the most likely explanation.
:PROPERTIES:
:Author: KilotonDefenestrator
:Score: 1
:DateUnix: 1492702652.0
:DateShort: 2017-Apr-20
:END:


******** Second part: Ideally, I would hope that the razor is part of the decision-making process, rather than a separate quantification brought in(/swung) later as justification. Here, incomprehensible motives(/modus operandi) on one side, versus simple underlying rules (on which are built complicated wetware, with some bugs) on the other. Neither (as with Russell's teapot) can for the moment be objectivey ruled out, but one can at least attempt to weigh them on a scale.

First part: Indeed, I was attempting to respond to the base idea of cradles of life built. If we bring 'getting things right' to the level of active interference, then we reach the question of 'why is there so much suffering/injustice?'. Then, 'evil/lazy/incompetent' versus 'non-interference (hands-off)'.

Middle part: There we have the Scrooge perspective: "Why do you doubt your senses?" "Because a little thing affects them." Rather than subjective feelings only, though, this can be approached in terms of the entire range of content, including perceptions of outside verifiable information communicated (one can also note the anthropic view there of a lottery winner reporting foreknowledge of winning, while vast numbers of non-winners had not-inferior 'foreknowledge'). --It comes down to that, when a researcher is looking at data, there is a point at which they must set aside their own hopes and impressions and biases and fallible pattern-matching and submit the data to an impartial statistical test, to ask "Is what I'm seeing real?". There are those who do not accept the answer if it's not the answer they expect, but if such expectations were reliable then there would be no need for the test. Such people may torture/'massage' the data, or try lots of different tests until they find one that coincidentally gives them an answer they're happy with, but those cannot hope for meaningful answers from their work. When your statistical test tells you that there's nothing there, that your data is not /convincing/--that it is not sufficient to convince everyone else--then one must accept "If it isn't sufficient to convince everyone else, then it shouldn't be sufficient to convince me, either.". Granted, I'm using a somewhat loose term for 'everyone'.

A sufficiently-motivated deity could, of course, interfere in precisely those ways that would not be credible, altering and potentially improving the world in lots of small ways that no one could justify to others or to themselves were verifiably meaningful, rather than an overlap of noise and coincidence. A deity could indeed limit it to those ways, forsaking large-scale easy-to-recognise communication, much like aliens could indeed choose to abduct only those people who no one else would believe (instead of opening communications on a global scale). However, if a powerful existence were willing to go that far to make itself implausible to the bulk of humanity, then what hope for the bulk of humanity to judge it plausible despite that, and what motivation to judge it plausible in the face of that overt implausibility?
:PROPERTIES:
:Author: MultipartiteMind
:Score: 1
:DateUnix: 1492497938.0
:DateShort: 2017-Apr-18
:END:


****** I really appreciate this comment. It's quite well thought out.

I think if we look at people who accepted Ptolemy's crystal spheres or those who currently accept a fairly strong form of most religions, we can say that they're failing to think. That's hardly a damning insult; I don't pretend I would've gotten to the heart of the heliocentrism question if I'd been born in that time. But if we say they were 'rational but unscientific', I think that renders the term 'rational' pretty much meaningless.

This ties into your point about religious belief helping people achieve what they value. I think "pragmatic" is a closer word than "rational" for that, but even pragmatism implies intent.

If I'm deathy afraid of manticores, but believe manticores can be warded off by laser-etching Art Garfunkel's face onto a slice of bread every morning, that behavior isn't somehow rational just because I'm acting in my best self-interest /assuming all my premises are true/, or because I get toast for breakfast as a happy side-effect.

As for your final paragraph...I mean, I can think of a few reasons why that's improbable, but more to the point that's not what /any/ religions claim. Saying we can't dismiss religion because maybe God's a metaphor for an alien Johnny Appleseed is entirely dismissive of the actual claims of those religions.

Ultimately I think the best brief summation of my problem with this argument from a rationalistic perspective was from Dara O'Briain:

"Just because Science doesn't know everything doesn't mean you can fill in the gaps with whatever fairy tale most appeals to you."

And I'd point out that that extends to fairy tales with modern sci-fi set dressing.
:PROPERTIES:
:Author: Tinfoil_Haberdashery
:Score: 2
:DateUnix: 1492613187.0
:DateShort: 2017-Apr-19
:END:

******* u/thrawnca:
#+begin_quote
  If I'm deathly afraid of manticores
#+end_quote

Well, in that case, it's rational to take whatever action will be most likely to repel manticores. I couldn't say exactly what action that might be without knowing more about manticores, but it seems likely that there are options that would give a better expected return than making toast. If you can get data about the effectiveness of each type of manticore repellent, then it's possible to run the numbers.

#+begin_quote
  that's not what /any/ religions claim.
#+end_quote

No? Perhaps not put exactly that way, but the idea that God was once comparable to ourselves, and progressed, learning and growing over an unknown period of time to reach the point of being able to form planets and stars and even galaxies from raw materials - that is sound Mormon doctrine. I wasn't speaking of a hypothetical religion.

#+begin_quote
  fairy tales with modern sci-fi set dressing
#+end_quote

Sure, HPMoR is fantasy. But achieving that kind of godhood - technological sophistication and psychological refinement that make interstellar and even intergalactic projects feasible - that is, ultimately, a real ambition, yes? You're not dismissing Eliezer as a quack for aspiring to it?
:PROPERTIES:
:Author: thrawnca
:Score: 1
:DateUnix: 1492773452.0
:DateShort: 2017-Apr-21
:END:

******** I...can't really tell if you're serious. If it's rational to indulge in paranoia based on blatant and /effortlessly/ dismissed fictions, then what on earth is /irrational/ at that point? The guy my dad treated who kept trying to bite his fingers off because the Buddha told him to was behaving quite logically--at least, logically based on his beliefs. That particular gentleman had an obvious mental illness, but epistemic errors characterized by religion are quite sufficient to engender similar behaviors in perfectly sane but--I maintain--still irrational individuals.

And you're correct. I forgot about The Book of Abraham. But...on an object level, that's probably one of the worst arguments one could make for the rationality of religion. The cosmology would've embarassed a schoolchild /of that time/, the provenance is possibly the most obvious hoax one could come up with, and the authority presenting it has so little credibility based on his other claims that if he said the sky was blue I'd be inclined to double-check.

This is what I meant by "fairy tales with modern sci-fi set dressing"--not HPMOR. Just because a hypothesis (Elohim is a Kolob-dwelling alien who seeded Earth with life) isn't /directly/ contradicted by our current understanding of science, doesn't mean one is rational to believe it's true. I'll cite Russel's Teapot as a concise metaphor for why this is the case.
:PROPERTIES:
:Author: Tinfoil_Haberdashery
:Score: 1
:DateUnix: 1492787574.0
:DateShort: 2017-Apr-21
:END:

********* u/thrawnca:
#+begin_quote
  blatant and effortlessly dismissed fictions
#+end_quote

Ah, I was responding more to the absurdity of the laser toast approach. If you want to focus more on the absurdity of fearing manticores, then sure, you can examine the evidence for and against manticores existing. However, this doesn't apply very neatly to the discussion about religion, because the very nature of claims of personal contact with the divine is that they cannot be demonstrated to others, yet may be considered good evidence by the individual.

In other words, you won't be able to achieve mutual agreement on whether religion can be effortlessly dismissed, because the two parties aren't working with the same evidence.
:PROPERTIES:
:Author: thrawnca
:Score: 1
:DateUnix: 1492807369.0
:DateShort: 2017-Apr-22
:END:

********** Setting aside that all religions I know of claim a lot more than personal emotional contact with the divine as evidence for their truthfulness, I'd argue that those qualia aren't some special category of irrefutable evidence even taken on their own. A rational cannon-accepting Catholic can't assert perfect certainty that /their/ religious experiences are more meaningful than those of a Sufi Muslim, for example, yet one of them /must/ be misattributing those experiences--which of course, makes it quite possible that /both/ are.

I've had experiences so intense--and unfortunately, in my case, horrific--that I had a hard time imagining that anybody else had ever experienced anything like it. Then a buddy described something very similar he'd felt on shrooms. I'm not.../thrilled/ that I apparently have pharmaceutical-grade psychedelic waking nightmare hallucinations even when sober, but I think it would be irrational of me to let the intensity of the experience persuade me that the galaxy really /is/ sentient, or that it wants me to kill myself, for that matter.

And yeah, someone could say that their experience of God's grace was like that times infinity, and I could say my nightmare was like that times infinity plus one...but maybe if we're being rational, we'd both just throw that out as non-evidence.
:PROPERTIES:
:Author: Tinfoil_Haberdashery
:Score: 1
:DateUnix: 1492833714.0
:DateShort: 2017-Apr-22
:END:

*********** I'm sorry to hear that you've suffered through those kinds of experiences. Hope you're doing better now.

We could probably discuss quality of evidence issues for days on end, but I suspect we'd go in circles, because whether internal or external, claimed religious experiences tend not to be demonstrable to others. So, as a case to convince others, they have little or no weight, certainly.

On the original topic, though, of whether religion is a mental failure mode: I'd still maintain that if someone has evidence sufficient that they are convinced, then it is /more/ reasonable for them to act on that evidence than ignore it. Unless and until they have reason to suppose that their evidence was inadequate or flawed.
:PROPERTIES:
:Author: thrawnca
:Score: 1
:DateUnix: 1492917792.0
:DateShort: 2017-Apr-23
:END:

************ What would you consider irrational, then? By your standards, there would seem to be no pursuit of pseudoscience, conspiracy theory, delusion or zealotry that could be considered irrational. No one intentionally acts in a way they believe to be at odds with reality, after all. Even the profoundly insane are just reacting 'rationally' to flawed stimuli.

My whole contention is that it is the way people evaluate evidence--that is to say, their epistemology--that determines the degree to which their beliefs themselves can be considered rational.

By my standards, someone who believes the earth is flat, even someone who was taught this their entire lives and only recently stumbled across the notion that there's some controversy over the matter, is irrational. There is simply no way someone with a healthy epistemology can look at the evidence each side can bring to bear on the topic and maintain the belief that "flat" is the way to go. There are simply too many established facts that directly contradict the flat earth hypothesis--for example, the fact that flights from Buenos Aires to Johannesburg take about the same amount of time as flights from Los Angeles to Beijing.

Hell, there are even experiments one can do personally that unambiguously demonstrate the curvature of the earth. There is just no way one can genuinely hold this position without a "mental failure mode".

Yet people still have "evidence sufficient that they are convinced" of the Earth's flatness, so they must, by your definition, be rational. Is this not the case?
:PROPERTIES:
:Author: Tinfoil_Haberdashery
:Score: 1
:DateUnix: 1492924387.0
:DateShort: 2017-Apr-23
:END:


**** Religion would be the /perfect/ example of an intelligent person being epistemically irrational, were it not for the fact that the analogy is both lost on and offensive to everyone who isn't at the point of understanding why religion is irrational, which is most people (including most non religious people).

A better go to for "failure mode" is probably the monothematic delusion, except... it's too bizarre for most people to relate to. So opposite problem.
:PROPERTIES:
:Author: eroticas
:Score: 9
:DateUnix: 1492276875.0
:DateShort: 2017-Apr-15
:END:


** What if they were prone to reacting badly to things and getting iveremotional? No-one is super rational when they're angry or afraid (or in love, for that matter)
:PROPERTIES:
:Author: MonstrousBird
:Score: 7
:DateUnix: 1492211362.0
:DateShort: 2017-Apr-15
:END:


** There's a comic called The Gamer where the main character did that literally. But his intelligence is mostly just used for getting lots of mana rather than actually solving problems, so it doesn't feel like much of an example.

In Harry Potter and the Methods of Rationality, he often runs into problems from not having enough wisdom. For example, he came up with some theory for how magic didn't really depend on the words you say and that it was just to make you focus on the spell, put tons of work into this whole set of experiments for it, and then found out that he was completely wrong on the first experiment. He just assumed his theory was right and wanted to test details of it.
:PROPERTIES:
:Author: DCarrier
:Score: 6
:DateUnix: 1492218194.0
:DateShort: 2017-Apr-15
:END:

*** I don't think the HPMOR example is him being irrational.

I mean he had a hypothesis and he tested it. That's the basis of scientific inquiry. It doesn't mater that he was wrong.

I guess maybe your point is that he put too much effort into thinking about future tests to try in the event that his first test was a success?

Even if that's the case I still don't think that's exactly irrational so long as he didn't use up time/resources that he absolutely should have been spending on something else.
:PROPERTIES:
:Author: Fresh_C
:Score: 6
:DateUnix: 1492229243.0
:DateShort: 2017-Apr-15
:END:

**** A better HPMOR example is when he abused time travel to "win" an argument with Snape.

He did all this ridiculous stuff to "beat" him, and almost ended up leaving the school and alienating some very powerful people, just to "win".
:PROPERTIES:
:Author: stale2000
:Score: 4
:DateUnix: 1492639112.0
:DateShort: 2017-Apr-20
:END:


** Is it possible\plausible? Yes. Will including such a character harm the story's quality though? Likely, if done incorrectly or with a wrong character (especially with the protagonist).

Here are several ways in which I see such a combination working:

- high intelligence that's running on inefficient principles:

  - highly intelligent but not rational character --- the high intelligence in this case could be defined in terms of memory, reaction time, imagination and visualisation, abstract thinking, reading speed, “processing power”, etc. The Intelligence attribute in /[[http://tvtropes.org/pmwiki/pmwiki.php/Fanfic/RyuugisTheGamesWePlay][The Games We Play]]/ was kinda responsible for these kinds of things, for example. And it's possible for the character to have all these enhanced qualities and have no idea what to do with them, how to use them efficiently, rationally, and wisely.\\
  - highly intelligent but not wise character --- depends on how Intelligence and Wisdom are defined in your story, but overall still workable.
  - highly intelligent character with an ineffective worldview system and principles --- a prejudiced or biased intelligent character, for instance, will have some blind spots and a pattern of making certain types of bad decisions (e.g. Voldemort).
  - highly intelligent character with certain psychological inhibitions --- e.g. an intelligent character with [[https://en.wikipedia.org/wiki/Learned_helplessness][learned helplessness.]]
  - highly intelligent character with severely limited worldview --- The protagonist of /[[https://www.goodreads.com/series/202735-the-girl-with-all-the-gifts][The Girl with All the Gifts]]/ is like this at the beginning of the story (then it slowly slides into being an [[http://tvtropes.org/pmwiki/pmwiki.php/Main/InformedAttribute][InformedAttribute).]] She was described as being very intelligent, but all the information about the outside world she could get was the unbalanced and measly bits and pieces received from her teachers, so she didn't have much ground to work on.

- highly intelligent character that has bad emotional control --- an intelligent but lazy character, or one that can't make themselves stop caring about revenge even when it's harming their long-term goals. Or one that's having problems with focusing on delayed gratification.
- highly intelligent character that has an outbalancing mental disorder --- paranoia, for example, or delusions.
:PROPERTIES:
:Author: OutOfNiceUsernames
:Score: 4
:DateUnix: 1492219164.0
:DateShort: 2017-Apr-15
:END:


** Lots of characters are like that in mainstream media: Take super villains like Lex Luthor for example.
:PROPERTIES:
:Author: Nashkt
:Score: 3
:DateUnix: 1492214205.0
:DateShort: 2017-Apr-15
:END:

*** What's irrational about Lex Luthor?
:PROPERTIES:
:Author: Oh_Hi_Mark_
:Score: 1
:DateUnix: 1492250771.0
:DateShort: 2017-Apr-15
:END:

**** This can vary wildly based on the version of Lex you're talking about. But, generally speaking, his reasons for being against Superman are fairly irrational, both from the perspective of "you're crazy for picking a fight with Cthulu" and from the perspective of "you haven't done a proper cost benefit analysis for slaying Cthulu"
:PROPERTIES:
:Author: Kishoto
:Score: 1
:DateUnix: 1492389808.0
:DateShort: 2017-Apr-17
:END:


** Not the way you'd like them to be. "Superintelligent" typically means "Thinks better than a human" and "Rational" means "Thinks well". They're evaluative claims that include the observer's standards of good thinking. If you have very high standards for what qualifies as good thinking, then you can have a non-rational superintelligent character, but that is trivial since "rational people" is probably is an empty set in that case.

As other commentors have noted, you can have characters that think fast but not well, or characters that know lots of things but apply the knowledge poorly. I would avoid explicitly labling your contrasting properties as "rational" and "superintelligent", though.
:PROPERTIES:
:Author: Oh_Hi_Mark_
:Score: 3
:DateUnix: 1492250630.0
:DateShort: 2017-Apr-15
:END:


** This sounds a lot like a manwha I picked up a while back called The Gamer. Main character basically for REASONS OF PLOT^{TM} gains classic-era RPG character properties (inventory, numerical stats, skills, etc), and decides to dump most of his points into INT. Has a massive mana pool and can memorize and recall facts instantly and in great detail, but outside of his personal specialty of essentially being a korean MMO grinding addict, he's actually not that bright, having left WIS almost completely at base stats.

He seems pretty internally consistent, often having to brute-force problems with more magical firepower rather then by outwitting his foes.
:PROPERTIES:
:Author: Arizth
:Score: 3
:DateUnix: 1492251095.0
:DateShort: 2017-Apr-15
:END:


** This sort of character appears commonly in fiction; it's the 'mad scientist' archetype. They have the raw intelligence to solve whatever problem attracts their attention... but even if they aren't actually 'mad' in the sense of being afflicted with a mental illness, they tend to be obsessive and narrowly-focused.

Such a character may well come across as inconsistent, if written poorly. To get around this, you need to demonstrate their reasoning to the audience, especially if it's flawed. The mad scientist shouldn't make mistakes simply because he picked up the idiot ball. Instead, perhaps he got bored partway through and went to do something else... or, inversely, was so totally focused on his one specific project that he neglected to handle some critical but mundane detail.
:PROPERTIES:
:Author: Endovior
:Score: 3
:DateUnix: 1492255281.0
:DateShort: 2017-Apr-15
:END:

*** Humans are /really/ good at compartmentalizing things. Being able to apply bleeding-edge statistical techniques to your research on immortality elixers does not necessarily mean you're good at finding your keys in the morning, even if, say, constructing a probability distribution of places-your-keys-generally-are and finding an efficient search pattern looks like a very similar problem.
:PROPERTIES:
:Score: 3
:DateUnix: 1492265090.0
:DateShort: 2017-Apr-15
:END:


** I imagine such a character would waste lots of time having intellectual fun on internet forums ;)
:PROPERTIES:
:Author: eroticas
:Score: 3
:DateUnix: 1492276454.0
:DateShort: 2017-Apr-15
:END:

*** Or [[https://mlthesis.wordpress.com/2015/01/09/26/][Infinite Fun Space]]
:PROPERTIES:
:Author: ArgentStonecutter
:Score: 1
:DateUnix: 1492284069.0
:DateShort: 2017-Apr-15
:END:


** Larry Niven's Pak. They're superintelligent but have some nasty hardwired goals that make cooperation almost impossible. The Pak homeworld is covered in radioactive craters. The Ringworld almost gets destroyed like twice because basically every variety of Pak has the same problem. Louis Wu ends up having to trick himself to get rebuilt as a human to keep his Pak nature from messing him up.

OK, maybe this could be "Larry Niven can't write superintelligent characters" but they're not completely unconvincing.
:PROPERTIES:
:Author: ArgentStonecutter
:Score: 3
:DateUnix: 1492283021.0
:DateShort: 2017-Apr-15
:END:


** One variant of this that I have enjoyed playing in RPGs is the very clever but does a poor job of considering the long term consequences of their actions variety. Good at coming up with creative plans for solving the immediate problem that they are faced with, but often having longer term consequences (for example when the web of lies finally collapses) that are totally ignored.
:PROPERTIES:
:Author: Daneels_Soul
:Score: 2
:DateUnix: 1492222149.0
:DateShort: 2017-Apr-15
:END:


** I suppose, for example, a character who is very good at the deducing, but for some reason has very... questionable assumptions. Simplest way is to make said character a bit insane, which can be played for laughs, I guess.
:PROPERTIES:
:Author: ABZB
:Score: 2
:DateUnix: 1492307108.0
:DateShort: 2017-Apr-16
:END:

*** I think Luna Lovegood is a good example of this. She has startlingly great insights intermixed with her normal delusional thinking.
:PROPERTIES:
:Author: tokol
:Score: 1
:DateUnix: 1493224215.0
:DateShort: 2017-Apr-26
:END:


** I feel like that is the majority of characters in popular fiction
:PROPERTIES:
:Author: monkyyy0
:Score: 1
:DateUnix: 1492219503.0
:DateShort: 2017-Apr-15
:END:
