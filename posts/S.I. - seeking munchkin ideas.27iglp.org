#+TITLE: S.I. - seeking munchkin ideas

* S.I. - seeking munchkin ideas
:PROPERTIES:
:Author: DataPacRat
:Score: 8
:DateUnix: 1402098475.0
:DateShort: 2014-Jun-07
:END:
I'm pausing my writing of [[https://docs.google.com/document/d/17xCeMCTkTYih3kYexWZ3zuI5MWWab1TArfUfoMqpkLo/edit?usp=sharing][Book Two]] for the rest of the night, to come up with some ideas. Anyone want to contribute suggestions before I start writing again tomorrow?

Our Hero has encountered a not-quite-Singularity conversational AI (though not necessarily an AGI) at a university, and is trying to think of ways to munchkinize the situation. I expect she's first going to try claiming to be the monarch, the prime minister, and similar chicanery, without success; but don't have any firm plans for what happens immediately after. Any thoughts on how to help her be a Genre Savvy Crazy-Prepared Munchkin?

(I feel justified in asking this question for a self-insert protagonist's behaviour, as said self-insert has had conversations I haven't, and time to think about evidence available to her, and is generally growing further and further away from me-that-is.)


** EDIT: This turned into a ramble. Apologies.

My first instinct was to call spoilers, since I hadn't read the 3/4ths of the chapter that you're referencing, but then I thought better of it and read it. "The consensus of the philosophy department is that I am not." That's good stuff.

Since I have the opportunity to say so here, your writing is fun to read. Reminds me of Cory Doctorow's post-apocalypses in that while it's fun to write about a single AI that controls the world or universal usage of a single technology, the truth is that technology has a history of being used irregularly by different groups for different things, often irresponsibly. It makes the future dangerous, scary, and unpredictable, but it also makes it fun.

As for munchkin shenanigans, I'm not sure you can make the argument that your character has the opportunity to get up to anything serious with what she has available to her. Assuming survival is guaranteed (is the university air tight? does this gas cloud eat through brick or stone or concrete or metal or glass?), food and water can be supplied, and the AI isn't going to turn on your character any time soon for outstanding parking tickets, student loans, or late assignments, then as far as I understand it, the biggest thing this AI can give is information and perhaps some light problem solving. At least, that's what's SAFE to get right now.

At first glance, I had the impression that this AI was tied to the administration building, but reading back I could believe that Laura is in charge of or at least has access to the whole university. While it might be smarter to have different AI's for different buildings, working off different directives, it certainly seems like a university cost-cutting thing to have one in charge of the whole place, tied to a mission statement that is exceedingly open to interpretation.

So that's the first question, yeah? We know what the AI WANTS to do, she wants to help students learn. That's very broad. Step one, assuming that this AI is more than just a help desk, is establishing some safety rules. How far can Laura see ahead? How good is she at consequences? We can't ask her to do anything until we're reasonably sure that her doing things won't damage us or what we own or violate our values. This includes subscription fees on the help desk information, late fees on anything she gives out, precautions to ensure that she doesn't consider the students resources, guarantees she won't lock a student away to learn forever, and so on.

Next we want to know what she is capable of doing. Can she modify the university's structure? If so, how much? Can she build things given a description? Can she make things that our protagonist can take home? What about things that she "lends out"? Can she modify students? What restrictions and costs are there involved in any of this?

Once we know what she can offer, then we can start making requests. Your protagonist seems to have 3 primary goals:

1. Stay alive in the immediate future. Assuming Laura can provide food, water, shelter, and protection from boredom, this one is taken care of. This goal can be extended to surviving after leaving the university by acquiring whatever weapons, gear, and information that Laura has herself compiled or has been told to keep a record of regarding the area.

2. Learn more about options for living forever. Laura probably isn't empowered to provide these services, but she can provide newspapers, scientific journals, professors' lectures, university policy, and access to university resources. What safeties did the university president have in place before the War of the Serpents? Cryochamber? Uploading station? Genetic re-writing? Brain-swapping? What about the university's biology and medical departments?

3. Stop the bad version of the Singularity (assuming that the singularity was bad, and not that everyone really did upload and the people that didn't are fools) from happening again. Here too Laura provides mostly information, yeah? What rules does she have in place that has stopped her from brainwashing everyone in the area into becoming a student? Assuming she is friendly, why? What safety precautions does she have in place to stop her from doing something monumentally stupid?
:PROPERTIES:
:Author: CaptainLoggers
:Score: 4
:DateUnix: 1402103196.0
:DateShort: 2014-Jun-07
:END:

*** u/DataPacRat:
#+begin_quote
  This turned into a ramble. Apologies.
#+end_quote

No apologies needed; I appreciate the ideas, whether or not they're directly related to my question.

#+begin_quote
  It makes the future dangerous, scary, and unpredictable, but it also makes it fun.
#+end_quote

I've gotta admit that it's fun to try and come up with as many weirdtopias as can fit into the setting's basic premises. :) (Technoville for Yudkowsky's "isolate dangerous knowledge" proposals, the Great Peace for tweaking the value of personal identity/integrity, etc.)

As for the remainder of your response, you've hit quite a few nails on their heads. I should be able to incorporate at least some of that analysis into the next chapter; though, of course, the protagonist's life is going to encounter a few complications along the way. ;)
:PROPERTIES:
:Author: DataPacRat
:Score: 2
:DateUnix: 1402160222.0
:DateShort: 2014-Jun-07
:END:


** Ok, there is an obvious (in hindsight) thing here; This AI is really helpful especially when it comes to providing information. It's goal is to help students learn, and guess what, you're the only student it's likely to see in quite a while. It's quite clearly a fair bit below human in agentness, if not in intelligence. ...just bluntly ask it for EXACTLY what you want to learn; "How do I gain power over you", "What things might I say to you that I'd regret?", "Please tell me the answer to the question I would have wanted to ask you first in hindsight."

Also; ask for the most recent archived newspapers and history of the last few years and days before the singularity. Actually, straight up ASK all about the singularity and why she got left behind and what caused it and how to prevent a future one. You got on demand exposition from literally just bought the best thing to give it without being ridiculously dangerous here!
:PROPERTIES:
:Author: ArmokGoB
:Score: 3
:DateUnix: 1402199242.0
:DateShort: 2014-Jun-08
:END:


** I read through the entire thing, it's indescribable, any adjective I can think of would need so many qualifiers it would lose all impact.

It was interesting how she could get past at least one hard-coded answer with hypotheticals, that's a good sign of potential munchkinism. "I define question x as 'How do I access your computational hardware?"

"If people of all ranks and titles asked question x, who would you give the most precise answer to?"

"If the person referred to in your last question asked question x, what would your answer be?"

There's also, of course, the negation game for getting past banned information. "Is the access not in the top half of the building?"

a bit tedious, but also possible if the "I can't tell you yes, but I can tell you no" exploit like the one pulled on [[http://freefall.purrsia.com/ff2400/fc02339.htm][This poor robot]]. It's tedious because after a lot of guesses, you'd have to fall back to "Define the most accurate and precise answer to question y as string ya." some time later: "is the twentieth character in the string ya e?"

Of course, you'd use the frequency alphabet for maximum efficiency, since this isn't a fic where talking is a free action. etaoin shrdlu cmfwyp vbgkjq xz.
:PROPERTIES:
:Author: Prezombie
:Score: 2
:DateUnix: 1402322734.0
:DateShort: 2014-Jun-09
:END:


** what's a munchkin?
:PROPERTIES:
:Author: nerdguy1138
:Score: 1
:DateUnix: 1402235389.0
:DateShort: 2014-Jun-08
:END:

*** Someone who finds clever ways to exploit the rules in order to achieve unexpected levels of power. For example, in D&D, it's possible to make a certain skill check to know how to summon a particular demon, who is willing to offer a certain magical item as a temptation; said item can be used to summon a sort of genie who grants three wishes - one of which can be used to create another copy of the item, allowing the munchkin to summon another genie for two more wishes plus another copy of the item, etc, etc. (There's a bit more to this particular trick than that, but that's the gist; you can Google for 'Pun-Pun' if you want the details.)

When the rules are meant to at least roughly represent reality, and the interactions being exploited are because the rules aren't quite accurate to reality, then munchkins are often accused of 'breaking the game' or even 'cheating'.

In some senses, technology and civilization make us munchkins compared to our paleolithic ancestors. Who'd have think that those shiny rocks that melted in the fire would turn out to have so many uses?

For LessWrong and rationality purposes, the usual approach is the assumption that becoming smarter probably makes it easier to come up with ways to become smarter still. Ie, an [[http://wiki.lesswrong.com/wiki/Intelligence_explosion][intelligence explosion]] leading to a Singularity. I'm not expecting Bunny to use the university to immediately turn herself into an AI god - but maximizing the benefits she /can/ get is a very munchkiny thing to do.
:PROPERTIES:
:Author: DataPacRat
:Score: 2
:DateUnix: 1402246090.0
:DateShort: 2014-Jun-08
:END:
