#+TITLE: [D] Saturday Munchkinry Thread

* [D] Saturday Munchkinry Thread
:PROPERTIES:
:Author: AutoModerator
:Score: 14
:DateUnix: 1504364808.0
:DateShort: 2017-Sep-02
:END:
Welcome to the Saturday Munchkinry and Problem Solving Thread! This thread is designed to be a place for us to abuse fictional powers and to solve fictional puzzles. Feel free to bounce ideas off each other and to let out your inner evil mastermind!

Guidelines:

- Ideally any power to be munchkined should have /consistent/ and /clearly defined/ rules. It may be original or may be from an already realised story.
- The power to be munchkined can not be something "broken" like omniscience or absolute control over every living human.
- Reverse Munchkin scenarios: we find ways to beat someone or something /powerful/.
- We solve problems posed by other users. Use all your intelligence and creativity, and expect other users to do the same.

Note: All top level comments must be problems to solve and/or powers to munchkin/reverse munchkin.

Good Luck and Have Fun!


** Imagine a timer which, when held, displays the date on which the holder will die. Works only on human beings.

All attempts to avoid dying on the provided date meet with failure. Refuse to go on a dangerous mission, a car accident kills you instead. Try to shoot yourself a day early and the gun misfires.

I've been thinking about trying to write an SCP about this item. What are some non-obvious things you could do with it?

Keep in mind that a lot of bad things could happen to you short of death. Jumping off a building while shouting "I am invincible!" (because the timer has told you will not die today) might land you in an excruciatingly painful near-death state.
:PROPERTIES:
:Score: 7
:DateUnix: 1504369742.0
:DateShort: 2017-Sep-02
:END:

*** You might be interested in [[http://machineofdeath.net/ebook][Machine of Death]], which has a (somewhat) similar premise.
:PROPERTIES:
:Author: alexanderwales
:Score: 6
:DateUnix: 1504370496.0
:DateShort: 2017-Sep-02
:END:

**** Thanks. I definitely need to read that.
:PROPERTIES:
:Score: 2
:DateUnix: 1504370980.0
:DateShort: 2017-Sep-02
:END:


*** Sending people with long lifespans on a one way trip to Mars. They can't die, so they must discover alien life or something.

That or the rocket fails to get them to Mars. But how could it? If the rocket explodes, they die, so that can't happen. Especially if you surround the rocket launch zone with a bunch of people with long lifespans too. With enough of them, the improbability of finding life on Mars should become less than the improbability of a rocket refusing to launch several times in a row without killing any of the several fragile people in incredibly precarious positions.
:PROPERTIES:
:Author: ShiranaiWakaranai
:Score: 5
:DateUnix: 1504370633.0
:DateShort: 2017-Sep-02
:END:

**** Keep in mind that the machine can manipulate future events but not past events. If there is life on Mars, there has been life on Mars for a long time, and if there isn't life on Mars, there hasn't been life on Mars for a long time and the machine can't retroactively magic it into existence. The most it could do is convince aliens to stop by Mars at exactly that right time.

However, I think it's more likely that the machine would cause all of the astronauts to get diarrhea on the day of the launch or get hit by a car and break a leg, or something. The rocket doesn't have to be the thing that fails.
:PROPERTIES:
:Author: InfernoVulpix
:Score: 6
:DateUnix: 1504376591.0
:DateShort: 2017-Sep-02
:END:

***** This reminds me of the drink in hpmor that causes them to spit/spray it. Good point.
:PROPERTIES:
:Author: ColeslawHappiness
:Score: 2
:DateUnix: 1504409074.0
:DateShort: 2017-Sep-03
:END:


***** u/waylandertheslayer:
#+begin_quote
  However, I think it's more likely that the machine would cause all of the astronauts to get diarrhea on the day of the launch or get hit by a car and break a leg, or something. The rocket doesn't have to be the thing that fails.
#+end_quote

That would also be interesting just as a way of gathering data - if there were life on Mars, the rocket would be more likely to take off, so we can lower our probability estimate. Enough similarish trials can get you a lot of bits of evidence for/against something.
:PROPERTIES:
:Author: waylandertheslayer
:Score: 1
:DateUnix: 1504551789.0
:DateShort: 2017-Sep-04
:END:


*** I mean for one it's pretty trivial to hook up any number of complex systems designed to kill somebody unless a given event happens. All you need to do is ensure the likelihood of your system failing is less than the likelihood of the thing you're trying to force to occur.

So with a reliable enough method you can definitely leverage the future to a staggering degree with many, many probability pumps.
:PROPERTIES:
:Author: vakusdrake
:Score: 6
:DateUnix: 1504374956.0
:DateShort: 2017-Sep-02
:END:


*** Robert Heinlein's [[https://en.wikipedia.org/wiki/Life-Line][Life-Line]] (full text available [[http://www.baen.com/Chapters/0743471598/0743471598___2.htm][at Baen's site]]), features such a machine. IIRC the story talks about how it would affect insurance companies.

There are a bunch of questions that such device would raise, for example:

- What's the precision of the information?
- How does it work wrt human constructs of date/time (e.g. leap seconds, time zones)?
- How does it work wrt time dilation effects?
- Where does the energy to prevent the early deaths or ensure the timely deaths comes from?
- What does death mean? Can the dead person be later resurrected? Could the dead be cryopreserved and thawed later on or they would be dead forever?
- What counts as human beings? What would it show for people that are already brain dead?

We can probably get FTL communication out of it, maybe even free energy and entropy reversal, depending on how it behaves.
:PROPERTIES:
:Author: Predictablicious
:Score: 6
:DateUnix: 1504378713.0
:DateShort: 2017-Sep-02
:END:

**** Interesting! Could you outline a scenario where we get FTL communication out of it?

Also thanks for the Heinlein story, will take a look.
:PROPERTIES:
:Score: 1
:DateUnix: 1504379322.0
:DateShort: 2017-Sep-02
:END:

***** I'm not thinking of anything concrete right now, but physics is very finicky about space and time, so depending on how the time of death works (e.g. ignores time dilation effects) or how the effort to ensure the timely of the death works (e.g. entropy reversal shenanigans) we could end up with something that violates locality or some other essential law.
:PROPERTIES:
:Author: Predictablicious
:Score: 2
:DateUnix: 1504391848.0
:DateShort: 2017-Sep-03
:END:


*** If you ever needed to destroy it, you just hand it to Dr. Bright.
:PROPERTIES:
:Author: Frommerman
:Score: 2
:DateUnix: 1504372882.0
:DateShort: 2017-Sep-02
:END:

**** Because it's impossible to tell if a person was /always/ going to die on the date given, or if giving them the device sets their death in stone, the entire O-5 council is in agreement that under no circumstances should Dr. Bright be given the device, lest it force an XK-class end of the world scenario (or higher) to ensure Bright's demise.
:PROPERTIES:
:Score: 8
:DateUnix: 1504376088.0
:DateShort: 2017-Sep-02
:END:

***** Beautiful. If this ever gets written, may I steal this bit?
:PROPERTIES:
:Score: 3
:DateUnix: 1504377180.0
:DateShort: 2017-Sep-02
:END:

****** But of course.
:PROPERTIES:
:Score: 4
:DateUnix: 1504377830.0
:DateShort: 2017-Sep-02
:END:


*** Reminds me of [[http://www.scp-wiki.net/scp-988][988]] a little. I think I actually prefer this idea, it has that extra little morbid flair
:PROPERTIES:
:Author: TempAccountIgnorePls
:Score: 2
:DateUnix: 1504377665.0
:DateShort: 2017-Sep-02
:END:


*** I'm curious. If you were to physically destroy someone's body before their death date (ie. Incinerate it) how could they live in a near death state? Does something stop the incineration every time?
:PROPERTIES:
:Author: TheJungleDragon
:Score: 1
:DateUnix: 1504370190.0
:DateShort: 2017-Sep-02
:END:

**** Right, something goes wrong every time.

The setup is analogous to "you can travel back in time but can't kill your own grandfather." Something unexpected always happens that prevents you no matter how hard you try.
:PROPERTIES:
:Score: 3
:DateUnix: 1504370291.0
:DateShort: 2017-Sep-02
:END:

***** That severely limits munchkin scope, since whatever you try to set up to exploit the death date, it may get sabotaged.

Probably your best shot is to go into life insurance.
:PROPERTIES:
:Author: thrawnca
:Score: 1
:DateUnix: 1504427722.0
:DateShort: 2017-Sep-03
:END:


*** Possible unexpected side effect: a spike in suicide bombers.

But potential uses depend a lot on how exactly attempts at early suicide fail. For example, if they fail in the most likely way you could try to use this to win the lottery by precommiting to try really really hard to commit suicide unless you win the lottery.
:PROPERTIES:
:Author: Daneels_Soul
:Score: 1
:DateUnix: 1504374667.0
:DateShort: 2017-Sep-02
:END:


*** Boring (but true) answer:

Such a timer is impossible--or at least, it's impossible if it /only/ does what it's advertised to do (which is display someone's date of death), and nothing else. To be more precise, there exists no timeline such that (a) humans exist, (b) the timer exists and is accessible to said humans, and (c) that timeline is self-consistent. But of course all possible timelines /must/ be self-consistent, which means that there /are/ no timelines in which this hypothetical timer exists and is accessible to humans. Therefore, asking us to imagine such a timer is equivalent to saying "Imagine you had a device that could force 2 + 2 to equal 3." The only correct answer you can give is "No can do; it's impossible."

(If the timer is actually a reality-warping device that violates ordinary causality in order to force its own predictions to come true, then it /could/ actually exist. If you were extremely unwise, you could then attempt to use the timer as an [[http://lesswrong.com/lw/ld/the_hidden_complexity_of_wishes/][Outcome Pump]] and end up inadvertently causing a series of huge disasters because Outcome Pumps are not Friendly.)
:PROPERTIES:
:Author: 696e6372656469626c65
:Score: 1
:DateUnix: 1504416760.0
:DateShort: 2017-Sep-03
:END:

**** I don't really understand the distinction between doing "only" what it's advertised to do and "reality warping." Some level of "reality warping" necessarily happens in the trivial sense that your behavior will be different if you use the device as opposed to the counterfactual when you don't.

*Edit:* for example, here is how it could work.

- The universe is a simulation.

- The simulation is described by an 4 dimensional array (3 spatial dimensions and a time dimension). Each entry in the array tells me whether a particle is present at a certain location at a certain time.

- This array satisfies some deterministic relationships (i.e., "laws of nature").

- Given the state of the whole array at time t, these relationships allow you to compute the state at all future times.

- I am a being outside the universe (perhaps the simulation is running on my laptop).

- Once I detect a human being in the simulation holding the timer I search over all the possible things I could choose the timer to display and compute the evolution of the universe. Out of all the possibilities, I find a "fixed point" so the displayed time of death is accurate.

- For various technical reasons relating to the mathematics of the laws of the universe, such a fixed point always exists.

Note that *all* the timer does is this scenario is display a time, and otherwise reality proceeds using the same laws as always. Any "reality warping" effect comes only through the way people respond to what the timer shows.

--------------

As for using it as a probability pump, there is a further problem. There is no guarantee that all the ways in which you could die on a certain date will happen in any uniform way.

For example, it could be that whatever happens is ironic or gruesome. In the simulation scenario above, perhaps I will examine all the fixed points and choose the one where the user of the timer suffers the most. It isn't merely poor modeling or inability to predict the possibilities that is the issue, but actual malice.
:PROPERTIES:
:Score: 1
:DateUnix: 1504418716.0
:DateShort: 2017-Sep-03
:END:

***** u/696e6372656469626c65:
#+begin_quote
  For various technical reasons relating to the mathematics of the laws of the universe, such a fixed point always exists.
#+end_quote

Yes, this is the part that is false. You seem to be making this assumption for literally no reason /except/ to make the situation you describe possible, when in fact it's almost certain that the /opposite/ is true: the fact that you have an "adversarial" human intelligence trying to actively mess up your timer's predictions for their own benefit may simply lead to there being /no fixed point possible/.

Moreover, there is no set of "technical reasons relating to the mathematics of the laws of the universe" that can fix this issue. We're talking about an inconsistency in the most fundamental sense here: for every causal chain of events involving some kind of time-travel analogue, either it successfully loops back on itself or it does not, and if all causal chains within a certain subset (for instance, the set of all chains that involve humans playing around with a death-prediction device) turn out to fall into that second category, that's just how the solution space happens to be structured.

#+begin_quote
  For example, it could be that whatever happens is ironic or gruesome. In the simulation scenario above, perhaps I will examine all the fixed points and choose the one where the user of the timer suffers the most. It isn't merely poor modeling or inability to predict the possibilities that is the issue, but actual malice.
#+end_quote

Yes, this is more or less what I described in my initial comment, except that (a) you replaced reality warping with the whole fixed point idea, and (b) replaced neutrality with malice. The first change doesn't really work (see above), and the second isn't really necessary--I already opined that trying to use an Outcome Pump to perform significant optimization would likely lead to disaster, and this is true regardless of whether there's actually a malevolent intelligence inside of said Pump.
:PROPERTIES:
:Author: 696e6372656469626c65
:Score: 1
:DateUnix: 1504453997.0
:DateShort: 2017-Sep-03
:END:

****** You seem to be using the words "false" and "impossible" in ways that deviate from their usual meaning.

#+begin_quote
  You seem to be making this assumption for literally no reason except to make the situation you describe possible,
#+end_quote

Correct.

If you want to say my setup is impossible, give a proof of the impossibility (at any level of formality).

There are tons of theorems in math that say that under such and such conditions functions have fixed points. I fail to see why someone could not design the laws of the universe to make the underlying map I described have a fixed point.

#+begin_quote
  the fact that you have an "adversarial" human intelligence trying to actively mess up your timer's predictions for their own benefit may simply lead to there being no fixed point possible.
#+end_quote

First: "adversarial human intelligence" is nothing more than a way of talking about entries of a function in my simulation sketch.

Second: Here you seem to have hedged your claim with that word "may." I agree this /may/ be impossible, but that does not mean it's actually impossible.

*Edit:* After I wrote the above, you added the following:

#+begin_quote
  there is no set of "technical reasons relating to the mathematics of the laws of the universe" that can fix this issue. We're talking about an inconsistency in the most fundamental sense here: for every causal chain of events involving some kind of time-travel analogue, either it successfully loops back on itself or it does not
#+end_quote

This doesn't make sense to me (or, alternatively, it needs to be spelled out more). What does it mean to "loop back" or not? There is no actual time travel in the scenario I've sketched out -- just finding maps of fixed points. '

And then there is your next sentence which says "*if* all chains..." Your argument seems to be a motte-and-bailey trick -- you claim "this is impossible" but when asked to provide reasons you only justify the weaker claim "this may be impossible."
:PROPERTIES:
:Score: 1
:DateUnix: 1504455067.0
:DateShort: 2017-Sep-03
:END:

******* u/696e6372656469626c65:
#+begin_quote
  If you want to say my setup is impossible, give a proof of the impossibility (at any level of formality).
#+end_quote

This is not proper debating procedure, but if you were using this as a rhetorical technique to force me to admit that I cannot /prove/ my assertion in the strictest sense, then fine, I do admit that. This doesn't actually impact the argument much, though.

#+begin_quote
  There are tons of theorems in math that say that under such and such conditions functions have fixed points. I fail to see why someone could not design the laws of the universe to make the map have a fixed point.
#+end_quote

There may be "tons" of functions that have fixed points, but there are tons /more/ (literally 100% more, in a [[https://en.wikipedia.org/wiki/Measure_(mathematics][measure-theoretic sense]]) that don't. For any arbitrary function that you pluck out of thin air, the probability that it has a fixed point the way you describe is mathematically 0, and the laws of the universe are /not/ designed with time-travel in mind.

That alone pretty much suffices to demonstrate that you're not getting a fixed point in your function that comes out of literally nowhere. If you want to say that the laws of the universe are such that the existence of a fixed point is certain (why? how?), the onus is on /you/ to give /me/ a proof (at any level of formality); otherwise there's no reason to even consider the hypothesis.

Of course, you can't actually give me such a proof, just as I can't give you a proof of /impossibility/. So I suppose one possible claim someone might think to make is that because our positions happen to be symmetrical in this one respect, they are equally likely to be correct. This claim would be [[http://www.patheos.com/blogs/friendlyatheist/2013/01/05/they-must-not-teach-probability-in-seminary-school/][false]], of course.

--------------

*EDIT:* I was using a slightly different computational model than you were when writing that section, sorry. To be more precise, I was using Yudkowsky's model presented [[http://lesswrong.com/lw/fok/causal_universes/][here]], but in the interest of saving you the time of reading a decently lengthy article (unless of course you want to!), here's the relevant bit:

#+begin_quote
  Suppose we had a more complicated set of cellular automaton rules, on a vastly larger grid, such that the cellular automaton was large enough, and supported enough complexity, to permit people to exist inside it and be computed. Presumably, if we computed out cell states in the ordinary way, each future following from its immediate past, the people inside it would be as real as we humans computed under our own universe's causal physics.

  Now suppose that instead of computing the cellular automaton causally, we hack the rules of the automaton to add large time-travel loops - change their physics to allow Time-Turners - and with an unreasonably large computer, the size of two to the power of the number of bits comprising an entire history of the cellular automaton, we enumerate all possible candidates for a universe-history.

  So far, we've just generated all 2^{N} possible bitstrings of size N, for some large N; nothing more. You wouldn't expect this procedure to generate any people or make any experiences real, unless enumerating all finite strings of size N causes all lawless universes encoded in them to be real. There's no causality there, no computation, no law relating one time-slice of a universe to the next...

  Now we set the computer to look over this entire set of candidates, and mark with a 1 those that obey the modified relations of the time-traveling cellular automaton, and mark with a 0 those that don't.
#+end_quote

My claim was basically that there are some bitstrings that get marked with 0, and some that get marked with 1 (a claim you find unobjectionable, I hope!). And if all the bitstrings that could reasonably be described as "intelligent beings try to hack time travel" get marked with a 0, I hope you also agree that this is simply how thing /are/, with no way of altering the situation.

Yes, there is an "if" there in that last sentence; that is very intentional. The reason this isn't a motte-and-bailey is because I'm not attempting to swap between these two arguments; they're two different arguments that are related but distinct, and I'm arguing both simultaneously. This second argument is aimed at your (implied) claim that it's possible to somehow fix the "all bitstrings in a certain set getting marked with a 0" problem by grafting on a set of extra laws(?), which makes no sense whatsoever.
:PROPERTIES:
:Author: 696e6372656469626c65
:Score: 1
:DateUnix: 1504455959.0
:DateShort: 2017-Sep-03
:END:

******** Our positions are not symmetrical. You seem to be claiming (at times) that my setup is logically impossible; the onus is 100% on you to justify this claim.

#+begin_quote
  ... and the laws of the universe are not designed with time-travel in mind.
#+end_quote

How do you know this? Perhaps the laws of the fictional universe where the Foundation is investigating the timer were actually designed with the timer in mind.

#+begin_quote
  There may be "tons" of functions that have fixed points, but there are tons more (literally 100% more, in a measure-theoretic sense) that don't. For any arbitrary function that you pluck out of thin air, the probability that it has a fixed point the way you describe is mathematically 0, and the laws of the universe are not designed with time-travel in mind.
#+end_quote

The function was not chosen randomly. In my hypothetical, the function was chosen by a designer, who designed it in such a way that the timer would exist.

#+begin_quote
  If you want to say that the laws of the universe are such that the existence of a fixed point is certain (why? how?), the onus is on you to give me a proof (at any level of formality); otherwise there's no reason to even consider the hypothesis.
#+end_quote

If you don't see a reason to consider my hypothesis, then don't. But don't go around saying that it is "impossible" (or that certain claims are "false") when what you actually mean is that it's not clear whether they are possible.
:PROPERTIES:
:Score: 2
:DateUnix: 1504457787.0
:DateShort: 2017-Sep-03
:END:

********* u/696e6372656469626c65:
#+begin_quote
  Our positions are not symmetrical. You seem to be claiming (at times) that my setup is logically impossible; the onus is 100% on you to justify this claim.
#+end_quote

My claim is that your setup leads to inconsistencies, yes. I already gave my argument as to why it leads to inconsistencies: time-travel does not have a natural tendency to generate self-consistent timelines, so there's no reason to suppose that said timelines exist. Your counterargument (so far as I can tell) is literally "well maybe it /does/". Do I really have to "disprove" an argument of /this/ caliber? How do you suggest I go about doing so?

#+begin_quote
  How do you know this? Perhaps the laws of the fictional universe where the Foundation is investigating the timer were actually designed with the timer in mind.
#+end_quote

Okay, so /give an example/. Give me a set of laws of physics--/any/ laws--that has the property you describe. Because right now, I can't even /imagine/ such a set of laws, and my hunch is that you can't either (otherwise you would have described them in your initial reply).

#+begin_quote
  The function was not chosen randomly. In my hypothetical, the function was chosen by a designer, who designed it in such a way that the timer would exist.
#+end_quote

There is literally no reason to suppose either (a) that this /is/ the case, or that (b) such a function is /possible/. Again, you have given no examples of a function that behaves this way, and until you do, it's all just nonsense.

#+begin_quote
  If you don't see a reason to consider my hypothesis, then don't. But don't go around saying that it is "impossible" (or that certain claims are "false") when what you actually mean is that it's not clear whether they are possible.
#+end_quote

You haven't even given a coherent way to guarantee that they're /not/ impossible. My point is that without such a guarantee, the probability of them turning out to be possible is /literally 0/.

--------------

*EDIT:* Also, I'm puzzled by your assertion that the onus is on me to disprove your claim. You have provided a claim with zero justification behind it; how the /hell/ is it my job to disprove it, especially when it's as vague as it is?
:PROPERTIES:
:Author: 696e6372656469626c65
:Score: 1
:DateUnix: 1504458574.0
:DateShort: 2017-Sep-03
:END:


** In response to [[/u/vi_fi]]'s work, and my response to it. Spoilers for the latest chapter of [[http://archiveofourown.org/works/11539230/chapters/27124041][The Library Unpublished]]

#+begin_quote
  36) I woke up hungover and disoriented. It was raining outside. I wondered what... oh shoot, Sein was in the library and I needed to... I had already been to the library? My memory was a disoriented mess of fragments and I seemed to recall dying multiple times, being brainwashed by a cult, and obtaining near omnipotence at the expense of losing my ability/interest to return to ordinary reality. The most recent memory was accepting my own death in an attempt to avoid suffering. Worse yet, my thoughts felt off, as though they were being generated by a different source than usual. I checked the time and the date... had I not even left to rescue Sein yet? Well, assuming I wasn't insane, I think I knew the "winning" strategy, save for the fact that the chance of self-modifying would become addictive. The "winning" ending also seemed to have made a logical error... Sein had somehow been able to get text out the library so it wasn't true that I couldn't take anything out. I just needed to restrict what I wanted to take out to a single book bags worth (and avoid a runaway feedback loop of self-modification). It would also help to write into existence a useful book to use ahead of time. I had just the idea... I could make a reddit post and get munchkining ideas for the best books to take out. The post's responses itself would be sufficient to write books into existence.
#+end_quote

And the rules for those that don't plan on reading it:

#+begin_quote
  After a few minutes of writing and a few hours of searching, as my books did not turn up in the Index, I had established some ground rules. The Library had a very specific notion of what counted as a book. Books made of non-typical materials were out, as were sentient books, magic books and (sadly) rocket launcher books. However, books with information that was unknown to me were possible, as were books with subtle but mundane effects. For example, implementing something like the King in Yellow wouldn't have been possible by stating it to be magic, but stating it to be a particularly maddening and insidious piece of poetry was possible. After all, even something as innocuous as Goethe's The Sorrows of Young Werther had driven people to suicide.
#+end_quote
:PROPERTIES:
:Author: scruiser
:Score: 3
:DateUnix: 1504478322.0
:DateShort: 2017-Sep-04
:END:

*** Sorry to joss this. The actual ending 36) has been posted now; it was a simple editing mistake.

In case any of you still want to munchkin this, you have both my blessing and my enthusiastic attention. [[/u/scruiser][u/scruiser]], I will remember you as the first one to write fanfic of something I have written :)
:PROPERTIES:
:Author: vi_fi
:Score: 2
:DateUnix: 1504484602.0
:DateShort: 2017-Sep-04
:END:


*** Well, there's an obvious right answer here: +free the benevolent genie+.

Basically, there's two possibilities: either the Library is a malevolent bounded wish-granting omniscient being, or a benevolent one. If former, you've most likely already lost; if you didn't, you should run away from this place and never come back.

If latter, you should word you request in such a way as to force the Library itself to decide what book to create. PtV-lite? Self-help books that let you self-modify into superintelligence? A "Write Your FAI In N Easy Steps" book? Outcome pumps, prophetic books? Those are all ideas baseline humans came up with. An actual superintelligence would think of something /much/ better, so, my idea:

Specify "a book which is the best book for me to find in this situation".
:PROPERTIES:
:Author: Noumero
:Score: 1
:DateUnix: 1504546871.0
:DateShort: 2017-Sep-04
:END:
