#+TITLE: [HSF] After Life - Simon Funk

* [[http://interstice.com/~simon/AfterLife/][[HSF] After Life - Simon Funk]]
:PROPERTIES:
:Score: 12
:DateUnix: 1393688388.0
:DateShort: 2014-Mar-01
:END:

** Reading now.

#+begin_quote
  Chapter 1
#+end_quote

That prank would not have worked if you'd just chosen a "trust me" password in advance. Stupid.

-Man, this really wants to be a movie.

#+begin_quote
  Chapter 2
#+end_quote

Wait, apparently this is our setting now? Okay? Okay.

#+begin_quote
  Chapter 3
#+end_quote

They didn't. They did not. Oh come on. (I might be slightly skipping through this.)

#+begin_quote
  Chapter 5
#+end_quote

They realize this is rape, right. They do, right.

#+begin_quote
  Chapter 6
#+end_quote

No wonder he doesn't realize the answer. The answer is insane. (Or practical, depending on how it works.) But he should have at least thought of it.

#+begin_quote
  Chapter 7
#+end_quote

OH NOW he thinks of it. Late, champ.

#+begin_quote
  Chapter 9
#+end_quote

Promising title, at least. Maybe we can get some sense back into this story.

Why would you use /physics/ for that?!

#+begin_quote
  Chapter 10
#+end_quote

Finally some answers here.

#+begin_quote
  Chapter 11
#+end_quote

Where the fuck is /here/?! Please tell me this is not the afterlife bugging out. (The name of the story worries me in that regard.)

#+begin_quote
  Chapter 12
#+end_quote

A house. Okay.

Oooohoo. Clever monkey.

#+begin_quote
  Chapter 13
#+end_quote

It's somehow adorably catlike.

[note] I still have absolutely no idea where this is going.

#+begin_quote
  Chapter 14
#+end_quote

I'm way more comfortable with this setting. At least I understand what's going on.

#+begin_quote
  Chapter 15
#+end_quote

And I'm confused again.

#+begin_quote
  Chapter 16
#+end_quote

Name-drop Alcor. Nice.

#+begin_quote
  Chapter 17
#+end_quote

Oh What. What. Also Catlike Robothing is just the dorbest.

#+begin_quote
  Chapter 18
#+end_quote

This is the most clear description of Patternism that I have ever seen.

-God module. Snort.

#+begin_quote
  Chapter 19
#+end_quote

This is the first chapter that I have to scientifically disagree with. There's a bit more variation to it than that, you know. (Lord, deliver us from the Evopsych just-so stories...)

#+begin_quote
  Chapter 20
#+end_quote

Well, this seems unfriendly. They're surprisingly hands-off, considering.

#+begin_quote
  Chapter 21
#+end_quote

This is the most utilitarian definition of love I have ever seen.

#+begin_quote
  Chapter 22
#+end_quote

This really reminds me of Bioshock Infinite.

Up to

#+begin_quote
  Chapter 24
#+end_quote

and you still haven't explained what that place is. Better hurry up.

.... Okay. Okay, what.

WHY WOULD YOU NOT USE A SIMULATION.

#+begin_quote
  Chapter 25. "Closure"
#+end_quote

WELL NAMED YOU FUCKS. Man, what a hook. Can't fault you though.

Okay.

In summary.

/Nice/.

Niiiice.

Kind of a UFAI story, of course. Not very ethical. Not very CEV. Kind of genocide. I can't fault th-- wait, yes, they're humans, I can totally fault them. Can't fault the realism of it though. I like to tell myself I wouldn't do this, but we all know how malleable humans are under power.

So.

Cool future. Let's hope it never comes to pass.
:PROPERTIES:
:Author: FeepingCreature
:Score: 6
:DateUnix: 1393772495.0
:DateShort: 2014-Mar-02
:END:


** I highly recommend this one! When I read this for the first time, I was extremely amazed! This story kind of changed how I look at the world and my consciousness.
:PROPERTIES:
:Author: IWillNotLie
:Score: 1
:DateUnix: 1393734865.0
:DateShort: 2014-Mar-02
:END:

*** I'm a busy nerd. What's this novella about?
:PROPERTIES:
:Score: 0
:DateUnix: 1393762623.0
:DateShort: 2014-Mar-02
:END:

**** Basically, a guy uploads his consciousness to a computer and the computer becomes sentient. Can't say anything else or I'll spoil the twists in the story.
:PROPERTIES:
:Author: IWillNotLie
:Score: 2
:DateUnix: 1393766431.0
:DateShort: 2014-Mar-02
:END:

***** u/deleted:
#+begin_quote
  Basically, a guy uploads his consciousness to a computer and the computer becomes sentient.
#+end_quote

What? /Again?/

#+begin_quote
  Can't say anything else or I'll spoil the twists in the story.
#+end_quote

I mean, ok, fair enough, but mostly I just want some indication to answer how much /fun/ I will have reading this novella.
:PROPERTIES:
:Score: 3
:DateUnix: 1393766632.0
:DateShort: 2014-Mar-02
:END:

****** I'm not sure how much fun you will have, but I sure as hell did. I couldn't stop talking about it for weeks after reading it.
:PROPERTIES:
:Author: IWillNotLie
:Score: 3
:DateUnix: 1393767217.0
:DateShort: 2014-Mar-02
:END:


****** Okay, I read it and I can confirm that, as much as I'd question the plausibility of some of the decisions, it's 100% materialistic. No consciousness shenanigans going on, no mysticism behind the mystery. Not sure if I /enjoyed/ it; it's an interesting glimpse into a honestly p terrifying future, in a sort of Lovecraftian way, and it doesn't really say anything /novel/ to people in this subreddit. Made me smile though. Well-executed at the least.

It's about the slowest-ever human-bootstrapped non-friendly GAI singularity.
:PROPERTIES:
:Author: FeepingCreature
:Score: 3
:DateUnix: 1393778554.0
:DateShort: 2014-Mar-02
:END:

******* Why are you terrified of it?
:PROPERTIES:
:Author: RMcD94
:Score: 1
:DateUnix: 1393962486.0
:DateShort: 2014-Mar-04
:END:

******** It's a non-friendly GAI singularity. That commits genocide.

This is bad.
:PROPERTIES:
:Author: FeepingCreature
:Score: 3
:DateUnix: 1393983335.0
:DateShort: 2014-Mar-05
:END:

********* When does it commit genocide? It halts breeding, that's not the same as committing genocide.

Also if you're going to make genocide be defined like that then you're going to have to justify why it's bad.
:PROPERTIES:
:Author: RMcD94
:Score: 0
:DateUnix: 1393997250.0
:DateShort: 2014-Mar-05
:END:

********** u/FeepingCreature:
#+begin_quote
  When does it commit genocide? It halts breeding, that's not the same as committing genocide.
#+end_quote

Yyyyeah it is. To quote WP:

#+begin_quote
  [Genocide is] a coordinated plan of different actions aiming at the destruction of essential foundations of the life of national groups, with the aim of annihilating the groups themselves.
#+end_quote

--[[http://en.wikipedia.org/wiki/Genocide][Raphael Lemkin]]

#+begin_quote
  Also if you're going to make genocide be defined like that then you're going to have to justify why it's bad.
#+end_quote

Because as humans, we value humans to exist? Idk, at least I do.
:PROPERTIES:
:Author: FeepingCreature
:Score: 2
:DateUnix: 1394025275.0
:DateShort: 2014-Mar-05
:END:

*********** That doesn't seem like anything rational. Transhumanism is dead common in future scifi.

How do you jusitfy valuing humans over say sentience
:PROPERTIES:
:Author: RMcD94
:Score: 1
:DateUnix: 1394026907.0
:DateShort: 2014-Mar-05
:END:

************ I'm ... a human? I think it's pretty normal for humans to value humans. And in any case, this is not some sort of trading-off - it's just "lol let's stop humans from breeding because we fucked up our intelligence enhancement and are now monstrous".
:PROPERTIES:
:Author: FeepingCreature
:Score: 1
:DateUnix: 1394028917.0
:DateShort: 2014-Mar-05
:END:

************* u/RMcD94:
#+begin_quote
  I think it's pretty normal for humans to value humans
#+end_quote

Sure but I'm also a guy that doesn't mean I value guys more than girls.

There's no reason I should value humans over other sentient beings.

You're not exactly rationally explaining this either.

#+begin_quote
  it's just "lol let's stop humans from breeding because we fucked up our intelligence enhancement and are now monstrous".
#+end_quote

Depends on your definition of monstrous, considering most of the humans switched to avatar bodies and also took the upgrades can't be that bad. Seems to me that the world was better there was way more life on it.
:PROPERTIES:
:Author: RMcD94
:Score: 1
:DateUnix: 1394049453.0
:DateShort: 2014-Mar-05
:END:


****** [deleted]
:PROPERTIES:
:Score: 2
:DateUnix: 1393792080.0
:DateShort: 2014-Mar-02
:END:

******* /read read read/

/spoiled/

Oh Lord. Is there some mood people get in where they start looking for all the possible ways that things we like can destroy us? Seriously: I don't even have good genetics; my ancestors are inbred as fuck and my fiancee is a wonderful person but /also/ a carrier for several heritable illnesses. I'd pay money just to be able to have a /normal, healthy/ child at all, let alone a superhumanly loveable child!

God fucking dammit people. How likely is it that fun will actually kill you versus that some scifi author will think it a /really intriguing premise/ (read: a "subversion" of your usual expectations, except that most societies are so anti-fun that it's actually a /repetition/ of usual social expectations) to write a story about how fun kills you?

EDIT: my conscious mind just noticed to whom I was replying. This comment just got 20% more applicable... you evil person.
:PROPERTIES:
:Score: 1
:DateUnix: 1393795593.0
:DateShort: 2014-Mar-03
:END:

******** It wasn't so much the fun itself, as it was [[#s][Spoiler]]
:PROPERTIES:
:Score: 3
:DateUnix: 1393811212.0
:DateShort: 2014-Mar-03
:END:

********* That distinction is so subtle as to be useless. One of the /pleasant/ things about the rationalist movement is supposed to be its blatant pro-transhumanist propaganda and its refusal to stoop down to having everything [[http://tvtropes.org/pmwiki/pmwiki.php/Main/GoneHorriblyWrong][go horribly wrong]] all the time.

(I'm trying to find David Brin's blog post about this dead horse of a trope, and failing. Better stop hung-overingly redditing and get ready for work.)

Mind, one of these days I'd like to see a rationalist author /so/ clever and creative that they don't even have to stoop down to things [[http://tvtropes.org/pmwiki/pmwiki.php/Main/GoneHorriblyRight][going horribly right]]. One of the great reliefs of reading HPMoR, say, as opposed to many of [[/u/EliezerYudkowsky]]'s short scifi works posted on LW, or as opposed to [[/u/iceman-p]]'s fic, is that you /know/ the magic system keeps everything contained roughly in the domain where it takes a lot of really deliberate Munchkining to blot the stars out of Heaven, and won't just happen by default because some idiot said, "Oh wow, I wish [[#s][]]."
:PROPERTIES:
:Score: 1
:DateUnix: 1393829628.0
:DateShort: 2014-Mar-03
:END:

********** Point taken. Sounds like Yvain's [[http://squid314.livejournal.com/308666.html]["Against Dystopias"]]. I don't think if I'd call it a dystopia or "gone horribly right" [[#s][]], but it's been a while since I've read it and YMMV.

Let me know if you find that essay!
:PROPERTIES:
:Score: 1
:DateUnix: 1393833723.0
:DateShort: 2014-Mar-03
:END:

*********** Ok, I now /need/ to say: [[/u/Yvain]], I freaking love you and want to grow up to be like you.

Mind, I think the "standard dystopias" are more of a problem in reality than in fiction (let's face it: North Korea /is a problem/), but in fiction they're just such a /cheap/ way of creating conflict.

That, or Agent Smith was partially right, and some large subset of the human race really do define their existence by pain, suffering, and general horribleness. I'm not sure what we're going to have to do with such people.
:PROPERTIES:
:Score: 2
:DateUnix: 1393836058.0
:DateShort: 2014-Mar-03
:END:


******** u/FeepingCreature:
#+begin_quote
  God fucking dammit people. How likely is it that fun will actually kill you
#+end_quote

If there is a real issue, annoyance will not protect you from it. Nor will it help you discover whether the issue is real.
:PROPERTIES:
:Author: FeepingCreature
:Score: 2
:DateUnix: 1393828622.0
:DateShort: 2014-Mar-03
:END:

********* True statement, but the problem is that I simply don't have any significant degree of belief that video games, cute babies, candy bars, or anything else will wipe out the human race by being /too fun to handle/. Hell, the vast majority of video games, babies, and candy bars don't even damage the lives of their "users", and addictive "superstimuli" often affect only people with some predisposed vulnerability to addiction.

And I hate to say this, but the very fact that those with a predisposition to life-crippling addictions wipe themselves out before reproducing... yeah. It's a selection pressure. Over time, the human species is probably getting less vulnerable to addiction precisely because addiction sufferers reproduce at significantly lower rates. Cold but true.

So, uh, yeah. If someone wants me to believe in the genocidal dangers of "superstimulus" (a term which could use a more precise scientific definition, since I tend to regard evo-psych as a suspicious semi-science), they're going to need to show me a significant amount of /very good/ evidence that I have yet to see.

Until then, I will continue enjoying fun and exercising moderation just like most of the rest of the species.
:PROPERTIES:
:Score: 2
:DateUnix: 1393830657.0
:DateShort: 2014-Mar-03
:END:

********** u/RMcD94:
#+begin_quote
  they're going to need to show me a significant amount of very good evidence that I have yet to see.
#+end_quote

Skinner box experiments?

Not that anything you could do physically is likely to cause it, but just hitting the button in your brain.
:PROPERTIES:
:Author: RMcD94
:Score: 0
:DateUnix: 1393962608.0
:DateShort: 2014-Mar-04
:END:

*********** You don't make a good case for the existence of superstimuli by attempting to hot-wire my brain.
:PROPERTIES:
:Score: 1
:DateUnix: 1393962987.0
:DateShort: 2014-Mar-04
:END:

************ Okay well I'd like you to ask to define superstimuli since the Wikipedia article has it already as accepted fact that somethings are superstimuli.

[[http://en.wikipedia.org/wiki/Supernormal_stimulus#In_Psychology]]

In reference to genocide I'm not seeing how hotwiring your brain is not causing genocide, mass willing suicide of the entire human race because they give up everything for stimulating their brain.
:PROPERTIES:
:Author: RMcD94
:Score: 1
:DateUnix: 1393964696.0
:DateShort: 2014-Mar-04
:END:

************* ***** 
      :PROPERTIES:
      :CUSTOM_ID: section
      :END:
****** 
       :PROPERTIES:
       :CUSTOM_ID: section-1
       :END:
**** 
     :PROPERTIES:
     :CUSTOM_ID: section-2
     :END:
Section 3. [[http://en.wikipedia.org/wiki/Supernormal_stimulus#In_Psychology][*In Psychology*]] of article [[http://en.wikipedia.org/wiki/Supernormal%20stimulus][*Supernormal stimulus*]]: [[#sfw][]]

--------------

#+begin_quote
  Harvard psychologist [[http://en.wikipedia.org/wiki/Deirdre_Barrett][Deirdre Barrett]] argues that supernormal stimulation govern the behavior of humans as powerfully as that of animals. In her 2010 book, Supernormal Stimuli: How Primal Urges Overran Their Evolutionary Purpose, she examines the impact of supernormal stimuli on the diversion of impulses for nurturing, sexuality, romance, territoriality, defense, and the entertainment industry's hijacking of our social instincts. In the earlier book, Waistland, she explains [[http://en.wikipedia.org/wiki/Junk_food][junk food]] as an exaggerated stimulus to cravings for salt, sugar, and fats and [[http://en.wikipedia.org/wiki/Television][television]] as an exaggeration of social cues of laughter, smiling faces and attention-grabbing action. Modern artifacts may activate [[http://en.wikipedia.org/wiki/Instinct][instinctive]] responses which evolved in a world without magazine centerfolds or double cheeseburgers, where breast development was a sign of health and fertility in a prospective mate, and fat was a rare and vital nutrient.
#+end_quote

--------------

^{Interesting:} [[http://en.wikipedia.org/wiki/Fixed_action_pattern][^{Fixed} ^{action} ^{pattern}]] ^{|} [[http://en.wikipedia.org/wiki/Evolutionary_psychology][^{Evolutionary} ^{psychology}]] ^{|} [[http://en.wikipedia.org/wiki/Neuroethology][^{Neuroethology}]] ^{|} [[http://en.wikipedia.org/wiki/Julodimorpha][^{Julodimorpha}]]

^{Parent} ^{commenter} ^{can} [[http://www.reddit.com/message/compose?to=autowikibot&subject=AutoWikibot%20NSFW%20toggle&message=%2Btoggle-nsfw+cfuchzm][^{toggle} ^{NSFW}]] ^{or[[#or][]]} [[http://www.reddit.com/message/compose?to=autowikibot&subject=AutoWikibot%20Deletion&message=%2Bdelete+cfuchzm][^{delete}]]^{.} ^{Will} ^{also} ^{delete} ^{on} ^{comment} ^{score} ^{of} ^{-1} ^{or} ^{less.} ^{|} [[http://www.reddit.com/r/autowikibot/wiki/index][^{FAQs}]] ^{|} [[http://www.reddit.com/r/autowikibot/comments/1x013o/for_moderators_switches_commands_and_css/][^{Mods}]] ^{|} [[http://www.reddit.com/r/autowikibot/comments/1ux484/ask_wikibot/][^{Magic} ^{Words}]]
:PROPERTIES:
:Author: autowikibot
:Score: 1
:DateUnix: 1393964709.0
:DateShort: 2014-Mar-04
:END:


** My comment on chapter 14 is that sticking to a bipedal robot it just so goddamn dumb. Robocopters are the way to go, get yourself a dozen remote control quadcopters and be way better at moving
:PROPERTIES:
:Author: RMcD94
:Score: 1
:DateUnix: 1393955177.0
:DateShort: 2014-Mar-04
:END:

*** Nah, everyone knows giant spiders are the way to go.
:PROPERTIES:
:Score: 2
:DateUnix: 1394124530.0
:DateShort: 2014-Mar-06
:END:
