#+TITLE: [Q][BST] Seeking LWist Caricatures

* [Q][BST] Seeking LWist Caricatures
:PROPERTIES:
:Author: DataPacRat
:Score: 11
:DateUnix: 1414598816.0
:END:
I've written the existence of a cult-like "Bayesian Conspiracy" of mostly rebellious post-apocalypse teens - and now I'm looking for individuals to populate it with. What I /want/ to do is come up with as many ways that someone who's part of the LW/HPMOR/Sequences/Yudkowsky-ite/etc memeplex could go wrong, that tend not to happen to members of the regular skeptical community. Someone who's focused on a Basilisk, someone on Pascal's Mugging, someone focused on dividing up an infinity of timelines into unequal groups...

Put another way, I've been trying to think of the various ways that people outside the memeplex see those inside it as weirdos.

(My narrative goal: For my protagonist to experience trying to be a teacher. I'd be ecstatic if I could have at least one of the cultists be able to teach her a thing or two in return, but since I've based her knowledge of the memeplex on mine, that's kind of tricky to arrange.)

I can't guarantee that I'll end up spending more than a couple of sentences on any of this - but I figure that the more ideas I have to try building with, the more likely I will.


** The hypocrite: has absolutely taken to heart the idea of cognitive biases and takes great delight in pointing them out in others (using overly formal language all the while) without regard for whether it's an appropriate moment and without noticing their own enormous biases.

The calculator: insists on multiplying together a bunch of made up numbers before making any decision, no matter how trivial. Likely while muttering quietly about their utility function.

The "surely technology will save me": can talk at great length about existential threats to humanity and how we're morally obliged to oppose death with a convulsive effort and ought to be funding cryonics and life-extension like a new Manhattan Project, but hasn't seen fit to take any simple steps to extend their lifespan the 'regular way' through lifestyle changes involving their diet and exercise.

The phony-physicist: is very firmly convinced that the Many-Worlds Interpretation is the only correct way to view the universe but would be utterly lost within minutes if asked to solve (or even write down) any Schrödinger Equation.

The "obsessively consistent under reflection": spends a lot of time deliberating about how they ought to make decisions, under the assumption that all other agents sufficiently similar to them will follow the same logical process and reach the same decision. May very well still be neglecting some of the more commonplace tragic-commons situations, because other people aren't literal self-clones.
:PROPERTIES:
:Author: noggin-scratcher
:Score: 16
:DateUnix: 1414601119.0
:END:

*** #+begin_quote
  The hypocrite
#+end_quote

This is the baseline I've been keeping in mind: teens who get a kick out of being able to out-argue their parents.

Your other four ideas are exactly the sort that I was hoping my post would evoke. :)
:PROPERTIES:
:Author: DataPacRat
:Score: 6
:DateUnix: 1414616328.0
:END:


*** #+begin_quote
  Phony physicist
#+end_quote

This would be the one who reads every popsci article, singles out far-fetched high-level hypotheses as soon as they're proposed, and then asserts them to be obviously true -- even if they contradict his previous claims.

#+begin_quote
  Of /course/ our universe is just on the edge of a black hole in the fourth dimension! Our perception of "time" is just us moving towards the center! And of course this must be compatible with the holographic universe /and/ Barbour's timelessness /and/ Bryanton's dimensions /and/ Tegmark's multiverses /and/ Smolin's fecund universes ...
#+end_quote
:PROPERTIES:
:Score: 5
:DateUnix: 1414632302.0
:END:


*** #+begin_quote
  The phony-physicist: is very firmly convinced that the Many-Worlds Interpretation is the only correct way to view the universe but would be utterly lost within minutes if asked to solve (or even write down) any Schrödinger Equation.
#+end_quote

Not wanting to be this guy is why I don't discuss QM. I understand QM enough that the typical layman's office conversation on QM (today's sample, "There should be a Schrödinger's Wikipedia, where everybody gets a different page about every topic, and you don't know which one you get till you look". I have a weird office.) is ridiculous, but not well enough to either correct people, or have a discussion with a physicist.
:PROPERTIES:
:Author: trifith
:Score: 1
:DateUnix: 1414768000.0
:END:


*** #+begin_quote
  The phony-physicist: is very firmly convinced that the Many-Worlds Interpretation is the only correct way to view the universe but would be utterly lost within minutes if asked to solve (or even write down) any Schrödinger Equation.
#+end_quote

The phony-evolutionist is very firmly convinced that the theory of evolution is the only correct way to view the universe but would be utterly lost within minutes if asked to write down any sequence of amino-acids.

If one is wrong, why not the other?
:PROPERTIES:
:Author: itisike
:Score: 1
:DateUnix: 1414769857.0
:END:

**** Well, I know virtually nothing about quantum mechanics, so perhaps I'm not contributing anything here, but you can understand and believe in the theory of evolution without knowing anything about genetics or DNA - and in fact, the theory predates the discovery of DNA (and even the rediscovery of Mendel's work on inheritance) by a large number of years. The theory of evolution can be summed up in eight or so bullet points that you need virtually no background or intelligence to understand.

I do not believe that the same can be said for the Many-Worlds interpretation - because while I generally understand the layman's concept of branching timelines, I do not understand that underlying math that causes this view to be "correct".
:PROPERTIES:
:Author: alexanderwales
:Score: 2
:DateUnix: 1414770645.0
:END:

***** Ok, both sides makes sense to me now, hopefully that'll let help with the discussion. Both technical and nontechnical standards are acceptable but nontechnical ones held to higher standards in other ways. Question is then if particular nontechnical arguments for MWI are good enough to overcome the lack of consensus among those who understand the technical arguments for your particular epistemic standards. Correct?
:PROPERTIES:
:Author: ArmokGoB
:Score: 1
:DateUnix: 1414926321.0
:END:


**** Solving Schrödinger equations is perhaps a slightly unfair demand, really meant more as a shorthand for "doesn't understand the technical details of a very technical subject that they nonetheless claim to have strong reasons to believe specific things about".

But there is also a difference of kind; evolution (the change of allele frequencies in a population over time) is an observable brute fact, and the Theory of Evolution is entirely and uncontroversially accepted by biologists as an explanation for that fact, with the disagreement between professionals being about details rather than the broad picture. QM is much harder to observe for yourself and question of deciding between the interpretations is still open, even among physicists.

I feel like the physics equivalent to evolution (easily observed, more or less settled theory, don't need to necessarily understand the nut-and-bolt details to have an informed opinion as a layman) would be something like gravity.
:PROPERTIES:
:Author: noggin-scratcher
:Score: 2
:DateUnix: 1414775548.0
:END:


*** #+begin_quote
  The "surely technology will save me": can talk at great length about existential threats to humanity and how we're morally obliged to oppose death with a convulsive effort and ought to be funding cryonics and life-extension like a new Manhattan Project, but hasn't seen fit to take any simple steps to extend their lifespan the 'regular way' through lifestyle changes involving their diet and exercise.

  The phony-physicist: is very firmly convinced that the Many-Worlds Interpretation is the only correct way to view the universe but would be utterly lost within minutes if asked to solve (or even write down) any Schrödinger Equation.
#+end_quote

OHMYGOD I've seen so many of these guys!
:PROPERTIES:
:Score: 0
:DateUnix: 1414663426.0
:END:


** The obsessed: Someone who, rather than being a rationalist (though they could be) is instead obsessed with the /idea/ of being a rationalist, or with Yudkowsky.
:PROPERTIES:
:Score: 6
:DateUnix: 1414621572.0
:END:

*** I think this accurately describes all the characters in this thread.
:PROPERTIES:
:Score: 8
:DateUnix: 1414631943.0
:END:


** The Epistemist

He (or she) spends a very large amount of time on the internet or reading books, honing his philosophical skills and understanding the nitty gritty of epistemic rationality. He understands a great many other topics as well - he's well versed in science, health, politics, social skills, and a great many other topics besides. He has the ability to perfectly articulate exactly what mistakes in thinking and action every other character is making (including himself). He sees the world clearly and is rarely horribly wrong about anything. He analyzes everything, spends hours thinking about word meanings and whether a certain bit of logic is /really/ sound and which hypothesis is /truly/ more parsimonious. He has boundless energy to do this, because it fascinates him.

However, he doesn't actually have the drive to do anything practical or accomplishing anything meaningful in real life.

(In general, I think the archetype of "genius who chronically underachieves because of some issue" - be it a mental health issue or mild personal defect, growing up in poverty, too many family responsibilities, or simply lack of desire to do things, is exceedingly common in all circles where smart people tend gather for some reason unrelated to practical networking or jobs - simply because the smart people who do accomplish things are too busy to participate.)

You could potentially give him a happy ending by putting him on stimulant drugs or something. Or maybe he could be the teacher!
:PROPERTIES:
:Author: E-o_o-3
:Score: 6
:DateUnix: 1414637584.0
:END:


** Mostly I think you'd have to have people that have other issues that are exacerbated by the memeplex.

- The guy who only sees human suffering in the context of the wider world and fails to empathize with people's petty problems when millions of people are dying around the world
- The guy who thinks that two people shouldn't take offense when arguing if they're trying to change their mind (I forget the name for this) and gives a lot of offense to people because he thinks they're being unreasonable by not taking his offensive comments in the spirit they're intended (and it might be that he uses his bluntness as a weapon and reasonableness is just his defense).
:PROPERTIES:
:Author: alexanderwales
:Score: 5
:DateUnix: 1414602802.0
:END:

*** #+begin_quote
  The guy who thinks that two people shouldn't take offense when arguing if they're trying to change their mind
#+end_quote

Yees, this so much. I did this for about a month, and it's very very annoying to deal with. You're referring to the principles of "Radical Honesty" and "Crocker's rules", both of which are passed off with the excuse "People should be able to convey information optimally to help others make rational decisions, without worrying about offending anybody!" [[http://www.esquire.com/features/honesty0707][It can have some pretty +disastrous+ +hilarious+ interesting consequences.]]
:PROPERTIES:
:Score: 5
:DateUnix: 1414631861.0
:END:

**** Also included: not acknowledging the fact crockers rules are explicitly opt-in.
:PROPERTIES:
:Author: ArmokGoB
:Score: 5
:DateUnix: 1414633391.0
:END:

***** I think the name "Crocker's Rules" is misleading. "Crocker's Concession" or "Crocker's Courtesy" would be better and even be an alliteration.
:PROPERTIES:
:Author: qznc
:Score: 1
:DateUnix: 1414675381.0
:END:


*** #+begin_quote
  The guy who only sees human suffering in the context of the wider world and fails to empathize with people's petty problems when millions of people are dying around the world
#+end_quote

Well that guy's just a regular old emo kid, since he's missing the trivially obvious fact that "people's petty problems" are sufferings he can actually address.
:PROPERTIES:
:Score: 1
:DateUnix: 1414663543.0
:END:


** The typical SSC reader, who has gone so many levels of "meta" up in their reasoning and meta-reasoning that they now place no epistemic trust in anything whatsoever, considering all thought to be inherently tribal-political. In Bayesian terms (well, actually, Jaynesian terms), their subjective distribution assigns almost all of its mass to various levels of "deception" and "cognitive bias" hypotheses, and almost none to actual beliefs. When questioned, they mutter something about Loeb's Theorem and try to flee.

Oh, and then, of course, the typical Robin Hansonian, who believes that /absolutely everything/ is done just to get wealth and status, and whose plan is to take over the world by mind-uploading and then fork-bombing.
:PROPERTIES:
:Score: 8
:DateUnix: 1414601414.0
:END:

*** #+begin_quote
  mind-uploading and then fork-bombing
#+end_quote

Oddly enough, I'm pretty sure that I came up with the '_____' Spores for Orion's Arm ( [[http://www.orionsarm.com/eg-article/4ba1012793821]] ), as an initial exploration of such a lifestyle, well before I'd ever heard of Hanson.
:PROPERTIES:
:Author: DataPacRat
:Score: 1
:DateUnix: 1414616527.0
:END:

**** Oh, and another one, based on that one Facebook post Eliezer made:

- A Randian libertarian, full-retard mode, who really, genuinely understands that ultra-proprietarian ultra-capitalism is /horrible/ for society, and supports it /for that reason/, on grounds that making civilization stagnate and stagger backwards reduces existential risk.
:PROPERTIES:
:Score: 6
:DateUnix: 1414649805.0
:END:

***** #+begin_quote
  who really, genuinely understands that ultra-proprietarian ultra-capitalism is /horrible/ for society, and supports it /for that reason/
#+end_quote

Where I'm from those are called [[http://www.antipope.org/charlie/blog-static/2013/11/trotskyite-singularitarians-fo.html][accelerationists]].
:PROPERTIES:
:Score: 1
:DateUnix: 1415222783.0
:END:

****** You know, I rather enjoy reading /Spiked Online/.
:PROPERTIES:
:Score: 1
:DateUnix: 1415224463.0
:END:


**** You're trying to go for an immortality-via-reconstructive-simulation, aren't you?
:PROPERTIES:
:Author: traverseda
:Score: 1
:DateUnix: 1414638349.0
:END:

***** I'll put it this way - when I made my cryonics arrangements a couple of years ago, I seemed to be the first cryonicist who'd ever made arrangements to also have my library digitized onto long-lasting media and stored along with my body. (CI allows its members to buy 'personal perpetual storage' drawers.)
:PROPERTIES:
:Author: DataPacRat
:Score: 1
:DateUnix: 1414638855.0
:END:


*** #+begin_quote
  The typical SSC reader, who has gone so many levels of "meta" up in their reasoning and meta-reasoning that they now place no epistemic trust in anything whatsoever
#+end_quote

i admit to being one of these people. in my defense, the rest of the world doesn't do an awful lot to inspire confidence (badum-tiss)
:PROPERTIES:
:Author: capsless
:Score: 1
:DateUnix: 1414677084.0
:END:


** The brand-namer. "Rational cooking. Rational training. Rational babies. So many babies. 400 babies."

The self-helper. "I've been working on implementing this sock-folding system I read on a blog." (this caricature is a bit more unfair than the others, but there are plenty of bad habits plausibly associated with consuming lots of self-help advice)

The casual insight junkie. "I don't see how this could be false."
:PROPERTIES:
:Author: Charlie___
:Score: 3
:DateUnix: 1414639939.0
:END:

*** Rational babies. 107633/7 babies.
:PROPERTIES:
:Author: CantorsDuster
:Score: 2
:DateUnix: 1414892759.0
:END:


** I can't think of any way that someone could follow ALL of the rules of good, logical reasoning and rational thinking, and still make these kind of mistakes. It seems almost paradoxical. The only ideas I can come up with involve taking one aspect of rationality too far, to a fault, while ignoring some others. And I'm sure that is covered in the Sequences somewhere. (If it wasn't, once it was noticed that this over-specialization was occurring, "do not focus too much of one aspect of rationality at the expense of others" would simply be added to the scripture).

Assuming the memeplex taught real Bayesian/rational thinking/etc, and not phony stuff, any instances of flawed logic or irrational thinking would be noticed, isolated and corrected. Every time I think of how it could fail, I think of an article in the Sequences on Less Wrong that takes that possibility into account.

Having said that, you could have people who focus too much on developing their rational mind and eliminating their biases, to the expense of other skills they need to survive. Or be a master of hypotheticals but unable to apply their skill, or fail to notice when their hypothetical scenarios occur in the real world (possibly related to the void, from the twelve virtues).

Or simple human weakness: even if somebody tries to avoid all of the cognitive biases at once, they'll probably slip up at some point. We aren't robots.
:PROPERTIES:
:Author: Vermora
:Score: 2
:DateUnix: 1414609851.0
:END:

*** #+begin_quote
  I can't think of any way that someone could follow ALL of the rules of good, logical reasoning and rational thinking, and still make these kind of mistakes.
#+end_quote

If it helps, I'm thinking of the [[http://wiki.lesswrong.com/wiki/Valley_of_bad_rationality][Valley of bad rationality]], the idea that some of the initial stages of learning about reasoning can leave you worse off than before you started.

As an alternative approach, the cultists aren't necessarily /real/ rationalists, they're just the gang of kids who would have snuck into the occult section at their local library to find spells to try to cast, but got caught up in an alternative source of hidden knowledge to Have A Secret About instead. Possibly in the form of some surviving listicles, instead of the full Sequences.
:PROPERTIES:
:Author: DataPacRat
:Score: 3
:DateUnix: 1414616804.0
:END:

**** Hm, if we're "allowed" to suggest ideas for characters who have picked up the wrong end of the stick and applied the LW tropes badly... that may create some extra latitude.

I'm thinking of the kinds of mistakes that EY describes his younger self making in pursuit of being "rational" like moving awkwardly and robotically because he thought that ought to be more efficient.

Or the other pseudorationalist failure-mode that can be concisely referred to as "Spock"; eliminating emotion in favour of logic (ignoring the perfectly real motivating forces of emotion) and expressing things as percentages with far more decimal places than you could possibly have real confidence in. If we assume that the particular post warning against that failure-mode was lost to the ages.
:PROPERTIES:
:Author: noggin-scratcher
:Score: 3
:DateUnix: 1414619911.0
:END:

***** #+begin_quote
  moving awkwardly and robotically because he thought that ought to be more efficient.
#+end_quote

Oh wow that's bad
:PROPERTIES:
:Score: 5
:DateUnix: 1414631916.0
:END:

****** ...for five seconds before I noticed it didn't work, and then I stopped. It's not like I was doing this for an hour, let alone six months.
:PROPERTIES:
:Author: EliezerYudkowsky
:Score: 9
:DateUnix: 1414717432.0
:END:

******* Oh I know, just the principle of it. Rest assured, I didn't mean it as a personally.
:PROPERTIES:
:Score: 3
:DateUnix: 1414717640.0
:END:


** #+begin_quote
  Another problem of LessWrong, is that its isolationism represents a self-made problem (unlike demographics). Despite intense philosophical speculation, the users tend towards a proud contempt of mainstream and ancient philosophy[36] and this then leads to them having to re-invent the wheel. When this tendency is coupled with the metaphors and parables that are central to LessWrong's attraction it explains why they invent new terms for already existing concepts.[37] The compatibilism position on free will/determinism is called "requiredism"[38] on LessWrong, for example, and the continuum fallacy is relabeled "the fallacy of gray." The end result is a Seinfeldesque series of superfluous neologisms.
#+end_quote

[[http://rationalwiki.org/wiki/LessWrong#Criticism]]
:PROPERTIES:
:Author: traverseda
:Score: 2
:DateUnix: 1414641636.0
:END:

*** I'm, shall we say, generally a little leery of relying on RW's editorial processes. However, for an outsider's negative perspective, it might be vaguely usable.
:PROPERTIES:
:Author: DataPacRat
:Score: 5
:DateUnix: 1414686708.0
:END:


** I question whatever authorial process led you to ask this question. I expect the results to be horrible reading. If you don't know real people who've made mistakes, caricatures you construct of Mistaken People are not going to end up as believable characters. I question your story purpose, and wonder if you're trying to do Display of Independence a la

#+begin_quote
  It's like going to a library, and when you walk in the doors, everyone looks at you, staring. Then you walk over to a certain row of bookcases---say, you're looking for books on writing---and at once several others, walking with stiff, exaggerated movements, select a different stack to read in. When you reach the bookshelves for Dewey decimal 808, there are several other people present, taking quick glances out of the corner of their eye while pretending not to look at you. You take out a copy of The Poem's Heartbeat: A Manual of Prosody.

  At once one of the others present reaches toward a different bookcase and proclaims, "I'm not reading The Poem's Heartbeat! In fact, I'm not reading anything about poetry! I'm reading The Elements of Style, which is much more widely recommended by many mainstream writers." Another steps in your direction and nonchalantly takes out a second copy of The Poem's Heartbeat, saying, "I'm not reading this book just because you're reading it, you know; I think it's a genuinely good book, myself."
#+end_quote
:PROPERTIES:
:Author: EliezerYudkowsky
:Score: 3
:DateUnix: 1414717761.0
:END:

*** #+begin_quote
  I question whatever authorial process led you to ask this question.
#+end_quote

My response is going to be a spoiler for anyone reading the story as it's written, but I don't want to make EY have to go through ROT13ing to read my reply:

.

.

.

My protagonist's mysterious enemy is actively-but-subtly trying to sabotage the rationality group, and I wanted a baseline selection of believable errors (as compared to unbelievable ones), so I could try to work out how many clues it would take for my protagonist to realize that such interference is going on.
:PROPERTIES:
:Author: DataPacRat
:Score: 3
:DateUnix: 1414719133.0
:END:

**** Then I very strongly recommend errors that you remember your own past self actually making, or finding very tempting; or at second-best errors that you have personally /seen/, not heard someone talking about someone else allegedly making. 'Errors' imagined by someone who holds the error-maker in contempt do not realistic characters make.
:PROPERTIES:
:Author: EliezerYudkowsky
:Score: 5
:DateUnix: 1414793814.0
:END:

***** ...So how much time have you spent around blood purists, anyway?
:PROPERTIES:
:Score: 9
:DateUnix: 1414795730.0
:END:

****** That's just a find-replace of racism.
:PROPERTIES:
:Author: ArmokGoB
:Score: 2
:DateUnix: 1414886530.0
:END:

******* Not /yet/. They need to invent "neoreaction" first, to explain how their entire societal structure is actually a perversion designed to destroy their blood-purity so that Dementors can Kiss them all.
:PROPERTIES:
:Score: 2
:DateUnix: 1414922487.0
:END:


** *Sqee, senpai noticed me*
:PROPERTIES:
:Author: traverseda
:Score: 1
:DateUnix: 1414633065.0
:END:

*** That's... nigh-certainly going to be a significant part of the chapter, yes.
:PROPERTIES:
:Author: DataPacRat
:Score: 1
:DateUnix: 1414686454.0
:END:
