#+TITLE: Worth the Candle - Soul self-modification ethics

* Worth the Candle - Soul self-modification ethics
:PROPERTIES:
:Author: AlexAlda
:Score: 41
:DateUnix: 1606205292.0
:END:
I'm rereading WTC, and what really bugs me is Juniper's attitude to modifying one's own soul.

Obviously, modifying someone else's soul without their consent is capital-letter *Evil*. But why does Juniper think modifying /your own/ soul is almost just as bad?

When Amaryllis made herself aromantic towards Joon, it saved a lot of trouble and problems, both long-term and short-term. Why does Joon find it so creepy? Why didn't he want to do this to himself after the "therapy" session with Fenn?

IIRC, the only reasoning he gives amounts to "changing the person you are is spooky". But we constantly change ourselves. Why is going to therapy to deal with emotional problems OK, but changing them in the soul isn't? Is it because it's too abrupt? Or "too easy to be good"? But Joon can change so many aspects of himself just by changing some numbers in his mind, or by wearing a magical object. Doesn't make sense to me.

What is your take on this? Would you change your soul that way if you could?


** It's not about morality. It's about a slippery slope which is in fact kinda slippery.

Say you have some ordered list of values S. Now consider the set of ordered lists of values which would be acceptable to you (as a replacement for your current values.) Let's say that this set can be derived from your current set of values S and call it S'.

So for example, an ordered list of values which is identical to S except that the value of vanilla ice cream has been swapped with the value of strawberry ice cream is probably also acceptable to you and so would be a member of S', but an ordered list of values which is identical to S except that the value of your own life has been swapped with the value of strawberry ice cream is probably not acceptable to you, and is therefore not a member of S'. Notably, S' contains S and also very likely some ordered lists of values which are not S.

Now consider the set of ordered lists of values which are acceptable to some version of you that has altered your values to be some member of S'. We can call this S''. Once again, S'' includes all members of S', and also likely some ordered lists of values which are not in S'. You can think of S'' as the set of possible souls which are "reachable" from your original soul in two steps of alteration.

As you may have noticed, the set of reachable souls increases with each allowed step. Also, the set of souls reachable after n+1 steps likely includes some souls not reachable after n steps.

This is quite concerning, because if a soul is not reachable after n steps, that means that it's not acceptable to a version of you which has modified its soul n-1 times.

So if you modify your soul a bunch of times, even if the modifications are acceptable to you at each step, your soul might reach a state which would be unacceptable to the version of you with your initial soul.

Now, notice that it is not /necessarily the case/ that after modifying your soul a bunch of times you reach a state that would be unacceptable to the original you. It could be, for example, that you swap the values of strawberry ice cream and vanilla ice cream back and forth 20 times.

However, if you model each successive decision as having some element of randomness, such that at each step each acceptable soul state has a non-zero chance of being selected, then as you modify your soul more and more times, the probability of you reaching a state which would be unacceptable to your original self approaches 1.

Thus it's /very risky/ to not set some kind of Schelling fence on modification to one's soul, and more conservative fences are stronger. If you just modify your soul whenever doing so seems convenient, you're very likely to end up someone that the original you would not have wanted to become. If you modify your soul only when it seems absolutely necessary, you're less likely to end up as an unacceptable person. Whenever you modify your soul for some reason which is less significant than your reasons for modifying your soul thus far, you effectively lower your threshold for soul-modification, and increase your chances of becoming an unacceptable person.

Now, how is this different from modifying yourself in other ways, like therapy, or growing as a person, or making friends?

The difference is that soul modification has no cap on how fast or drastic it can be. Changing as a person tends to be a gradual process, and so there's some element of slipperiness (a risk of becoming a person that you-from-the-past would not have wanted to become) but not nearly as much. You do actually want to be kinda careful about drastically changing yourself through means other than soul magic. If my friend suddenly went from being a total introvert to an extreme extrovert or vice versa, I'd be concerned. If that change was due to self-modification of their soul, I would simply be /much more/ concerned.

TL;DR: If you modify your soul willy nilly you might end up as Murder Ghandi, which would be bad, and modifying your soul for at all (particularly in ways that aren't /absolutely necessary/) can make you more likely to modify your soul in the future and end up as Murder Ghandi.
:PROPERTIES:
:Author: Audere_of_the_Grey
:Score: 62
:DateUnix: 1606220580.0
:END:

*** You don't need to trust that every change you make will be an improvement, though, just that the net effect of /all/ the changes you make will remain in S'.

Personally, I self-modify /a lot/, and sometimes very quickly. (It took me maybe a minute or two, once I figured out self-hypnosis, to remove longstanding aversions to the smell of vinegar and the taste of ginger which had up to that point been plaguing me since childhood.) And it seems very plausible that some of the changes I make go against the values of the earliest me who decided that self-modifying a lot was a good thing to do. But nonetheless /my life, overall/, is far more in accord with her values than a more restrained approach to self-modification would have left me.

(And this holds even given a shift in /terminal values/ at one point. The me who got into self-modification was something vaguely resembling an egoist. After some consideration, a later me decided that the optimally-selfish thing to do would be to turn into a utilitarian. And she was right; the change made me notably happier.)

In short: you don't just need to account for the risk of ending up in not-S', you also need to account for the /reward/ of ending up in a /better/ part of S'. If a given change has an 80% chance of increasing utility by 2, and a 20% chance of enabling undesired value drift in such a way as to decrease utility by 4, that's still a change worth making. And risk of undesired value drift /is/ predictable; I'm a lot more cautious when I go anywhere near editing my terminal values than I am when I edit how much I like foods, for example, because a clumsy perturbation to the former will potentially pretty thoroughly derail my future actions, whereas a clumsy perturbation to the latter will most likely just change my liking of the relevant foods in the wrong direction, generally fixably.
:PROPERTIES:
:Author: LunarTulip
:Score: 11
:DateUnix: 1606230048.0
:END:

**** I once researched self-hypnosis for precisely this reason, but all I found were shady, unscientific resources that strongly set off my inner skeptic. It just.. sounds too good to be true for this to be a thing. Do you have any resources or an approach to self-hypnosis you'd like to share?
:PROPERTIES:
:Author: WildFowl82
:Score: 26
:DateUnix: 1606231507.0
:END:

***** Nothing much in the way of resources. As far as approach... I'm not sure the way I approached it will work for everyone? It was pretty thoroughly improvised, not dependent on any external advice-sources, and it was very plausibly dependent on quirks of how my mind is structured. But I can try to summarize it anyway, just in case it /does/ work for other people.

Step 1: get hypnotized by not-yourself, ideally several times, and get a sense of what the experience of it is like. (I personally did this by way of the various not-too-hard-to-find hypnosis audio files one can dig up online; alternatives exist, if you're not inclined in that direction or if you find it ineffective. Being hypnotized is very much a skill one picks up with practice, so the first time is likely to be the hardest.)

Step 2: while /not/ being hypnotized by someone else, run through the same sorts of mental actions you run through during the induction when being hypnotized by someone else, and try to enter the same sort of mental state. The trance will probably not be as deep; but hopefully you'll be able to enter it at all.

Step 3: use whatever corners of your mind /aren't/ tranced (which, due to the aforementioned not-as-deep thing, will probably be present) to generate suggestions for the hopefully-larger parts which are. Suggest whatever seems both useful and easy-to-do-with-hypnosis.

(The first time I did self-hypnosis, I was testing it out as an idle distraction while waiting for a friend to show up for a Nerf axe fight; I used it to help prevent myself from forgetting my planned tactics mid-fight (which had happened to me during several previous such fights). That sort of attention-redirection is, at least for me, among the easiest effects to produce. Other things I did, over the next couple weeks, included ignoring discomfort from a too-cold floor, and shifting myself from adrenaline mode back to sleep mode after a false fire alarm woke me up several hours early.)

Step 4: practice and experiment. Practice getting the trance deeper; try out different ways of generating suggestions for yourself to see what's most effective; try new sorts of mental actions, and see which ones do or don't work; try setting some triggers for yourself to access useful effects more quickly when not mid-trance, and then try to learn the mental actions which result from those triggers so well that you no longer /need/ the triggers, you can just do the actions directly; try other things I'm failing to think of while writing this; in general, see what you can or can't do, and try to stretch the limits of that as far as you can.

...and that's it. When I followed this trajectory, in the first couple weeks, the effects I could get mostly were interpretable as placebo effects, albeit ones that it was very convenient to be able to generate on demand; after a couple weeks of practice, I became able to do much more unambiguously not-placebo actually-hypnosis effects. The first couple months were filled with huge numbers of low-hanging fruit of suddenly-easy self-modification that was previously inaccessible, as well as some scary moments of realizing that things I'd rather /not/ do self-modification-wise were /also/ suddenly easily accessible if I were to get clumsy. Eventually I cleared most of the low-hanging fruit, and from there self-hypnosis became a much less central part of my self-modificatory arsenal, moving from being The New Big Dramatically Overpowered Thing to being just one more useful tool among many.

Your experiences may or may not match mine, in terms of all of this; but hopefully this summary is useful regardless.
:PROPERTIES:
:Author: LunarTulip
:Score: 13
:DateUnix: 1606234971.0
:END:

****** Fascinating, thanks for taking the time to type that out! I'd love to hear more about the "low-hanging fruit of suddenly-easy self-modification that /was previously inaccessible/" part. But I understand if you don't want to over-share.

Does this mean you're able to act according to your values near-100% of the time now? Do you prefer veggies over sweets? Do you enjoy exercising? Are you able to get to bed at a set time every day and fall asleep rapidly? (Assuming you'd want those things.) Put differently, are you able to always act rationally (meaning congruently with your values)?

That does seriously sound overpowered. I could do anything with powers like that. Why aren't people like you taking over the world?
:PROPERTIES:
:Author: WildFowl82
:Score: 3
:DateUnix: 1606257519.0
:END:

******* I /tried/ the act-according-to-my-values-basically-all-the-time thing, but it didn't really work. It /is/ possible for me to use hypnosis to hack willpower, but the hacking looks like /increasing the amount of willpower I can throw at a problem/, not like /reducing willpower costs/. Still potentially useful in the short-term, but not long-term sustainable. When I try to do self-hypnosis to get myself to do a thing I lack the willpower to keep myself doing normally, I can potentially get it to work for a while, but if I /keep/ pushing it I end up developing an aversion to /hypnotizing myself with the expectation that I'll make myself do the thing some more/ in the same way that I'm averse to the thing itself.

(Which doesn't mean that I /can't/ use it to contribute useful willpower-mustering effects when needed---during those first couple months, two examples I noted down were using it in order to help myself focus on writing papers for my finals in school (notably, that was the most intensely stressful paper-writing week of my entire time at school), and then later to get myself to start the occasional conversation which I had a strong social-anxiety-induced aversions to starting---but it means that I need to be relatively restrained with it, rather than having anything close to the superpower that you're envisioning.)

In terms of low-hanging fruit... I don't have direct memories of everything, but I did some digging through my diary from the time, and I can at least give a broad sampling.

So, first, there were various short-term maneuvers, like the previously-mentioned "focus less on the unpleasantness of the cold floor" thing and "go back to sleep after the fire alarm" thing, fuzzing my perceptions of text I was reading in order to avoid absorbing any of the spoilers I knew were littered around, calming myself during a particularly-stressful afternoon, getting up sooner after waking up in mornings, et cetera. Nice to be able to do where needed, even in the absence of direct long-term effects.

In terms of long-term effects, there was the previously-mentioned thing with removing my aversions to the smell of vinegar and the taste of ginger. The central idea there was to generate a short-term hypnotic effect (a long-term one wouldn't have stuck in place, and would have been too high-effort to refresh constantly) to render them non-unpleasant, then use that short-term non-unpleasantness to reset my priors on how unpleasant they'd be next time, thereby bootstrapping the short-term effect into a new default.

(How easy that maneuver is for me to pull off, I should note, is dependent on exactly where the unpleasantness of a given thing comes from; in this case, it was by longstanding negative associations dating back to my childhood, rather than by any more concrete in-the-moment effect, so it was relatively easy. But trying to do the same thing with apples, which cause an unpleasant physical sensation when I bite into their skin, was harder, because I'd need to remove the unpleasantness of /that entire class of sensations/ rather than just of the narrow experience of biting-into-an-apple; I got partial results from that one, but it wasn't nearly as unambiguously effective.)

By a similar token, I got rid of my tendency towards fainting when medical people stuck needles into me, which was previously somewhat inconvenient. I did that one by giving myself a trigger to shift my brain in a non-fainting-shaped direction and then activating it while being poked. It took a couple applications before I was really confident in that one and able to activate it by habit without needing to think hard about it, but ultimately it worked.

Also, I managed to somewhat reduce my body-related dysphoria by giving myself a habit of avoiding paying attention to the most unpleasant-to-pay-attention-to bits of my body. I didn't come anywhere close to actually /getting rid/ of it, but the reduction was still nice.

Overall... self-hypnosis works as a willpower substitute for me, but only limitedly, and using it that way is much less sustainably effective than using it in certain other ways. Said other ways include redirecting my attention in non-willpower-demanding ways (as with the dysphoria and the spoiler-dodging), and putting myself into short-term altered mental states which /do/ cost willpower but which don't need to be held for long enough or repeated often enough for that cost to be a problem (either because they serve their purpose quickly (as with putting myself to sleep) or because they can be bootstrapped into habits which don't require further maintenance (as with the smell of vinegar)).
:PROPERTIES:
:Author: LunarTulip
:Score: 7
:DateUnix: 1606265037.0
:END:

******** Are there any hypnosis recordings you recommend? Seems like one of those areas where there would be a lot of junk.
:PROPERTIES:
:Author: Amonwilde
:Score: 2
:DateUnix: 1606330752.0
:END:


*** I think this shift problem is self-averted, considering that in order to self-modify a value (provided it's done deliberately) you need to have a stronger set of values to push against the one.

The ice-cream example doesn't work well because you're not modifying the "enjoy a specific taste of ice-cream" value, but the particular parameter of that value. If you had to reduce "enjoy a particular taste of ice-cream" to "not enjoy ice-cream", chances are you wouldn't, unless another more prominent value superseded your enjoyment of ice-cream, like "eat healthy food" (subset: "favour consuming less calories").

I think that, given this, all you can really do by deliberate soul-editing is either shift parameters or optimise for higher weighted values.
:PROPERTIES:
:Author: xartab
:Score: 1
:DateUnix: 1606257415.0
:END:


*** This logic of course applies to any change we make in our lives about anything

Ergo don't do anything because it might change you so you won't be so into it

After all it's only the odd changes and you can be almost certain that you in 50 years or you as a 10 year old vs 20 year old will not be so tightly in S'
:PROPERTIES:
:Author: RMcD94
:Score: 0
:DateUnix: 1606238177.0
:END:

**** I think that is an unfair comparison. Being able to change your values by an arbitrary ammount effortlessly and instantly (and outside any context related to the value being changed) is very different from organically changing your values through life experiences.
:PROPERTIES:
:Author: KilotonDefenestrator
:Score: 3
:DateUnix: 1606403304.0
:END:

***** Maybe so but I don't feel like you made that case

If it's different it's only in scale and that becomes a rather arbitrary distinction in my opinion
:PROPERTIES:
:Author: RMcD94
:Score: 1
:DateUnix: 1606407509.0
:END:

****** I disagree. Do you think there is just an "arbitrary distinction" between a knife and a nuclear bomb? Both can kill millions of people, one of them "just" does it faster and easier. Would you say they are the same? Would you argue that we might as well decriminalize personal nukes because they are essentially just knives?
:PROPERTIES:
:Author: KilotonDefenestrator
:Score: 2
:DateUnix: 1606408500.0
:END:

******* Well, in some respects yes, they are on the same slope.

If knives had no other purpose than murder then I might very well ban them along the same line as nukes

Similarly if everyone used nukes in their daily lives for some pragmatic purpose then they may remain unbanned

Of course, this ignores that you could use utilitarian calculations on the above which admittedly may also be arbitrary.

I suspect that any utilitarian calculation of soul modification is going to be strongly in favour however

There are of course other distinctions between the two but capacity for murder is certainly a line that they are both on.

At the end of the day even though the morality of myself in 40 years or 1000 years or from 5 years old to 20 years probably (based on past experience and other people) will have left the S' group I make no effort to sabotage my future self or even to try to continually indoctrinate myself to make sure I stay where I am now
:PROPERTIES:
:Author: RMcD94
:Score: 1
:DateUnix: 1606412696.0
:END:


** I think at least a portion of it is Joon's ego and that the /specific/ change Amaryllis was making was, effectively, to like him less. It's not noble, but knowing that someone---someone you yourself find incredibly attractive---pines for you is gratifying in a very base way.

If the change Amaryllis was making was instead to fall out of love with Grak, my model of Joon as a person is that while he would still have reservations, he would not have put up quite the same level of resistance. It would be an "Amaryllis and Grak" problem rather than an "Amaryllis and me" problem. That she modifies herself out of love with him feels on some level like a rejection.
:PROPERTIES:
:Author: GeeJo
:Score: 46
:DateUnix: 1606206580.0
:END:

*** I think that's true for that one change. however /everyone/ seems super freaked out by soul modification, even self soul modification.

There is a cultural/historical source for this, but it needs to have some real basis as well that made me he culture fear it in the first place.

I think there is fear of addiction and snowball effects. Yes, people change naturally all the time, but the ability to make root level permanent changes to every aspect of personality and values with the flick of a switch is dangerous. It is the same thing that makes self-mosifying supe-AI scary.

When you make one change, you can't be certain that the new you won't want further changes that the current self doesn't. The runaway effect could essentially (heh) destroy you as a person, and create a monster that only cares about "improving" itself...and others.

This is apparently what happened with many soul mages, and why it became illegal. The tempation of continued changes snowballs into destroying the self and becoming an optimization machine.
:PROPERTIES:
:Author: wren42
:Score: 24
:DateUnix: 1606228541.0
:END:

**** The Ghandi Murder pill isn't something anyone seriously worries about in real life because it doesn't exist.

I imagine it is well worried about in Aerb, since they've had to deal with it probably hundreds of independent times.
:PROPERTIES:
:Author: xachariah
:Score: 9
:DateUnix: 1606251322.0
:END:

***** right, the nature of the magic available makes this a very real possibility.
:PROPERTIES:
:Author: wren42
:Score: 3
:DateUnix: 1606254972.0
:END:


**** I wonder what a good schelling fence would look like if you wanted to commit to one before doing the changes. At max you're allowed to change X values with Y%?
:PROPERTIES:
:Author: Sonderjye
:Score: 1
:DateUnix: 1606235642.0
:END:


**** The cultural aspect is not because of self-modification, it's because of modifying others. This has lead to fear of any soul modification that is not tightly controlled.
:PROPERTIES:
:Author: Luck732
:Score: 1
:DateUnix: 1606237158.0
:END:


**** This I can understand, somewhat.

It still seems good to me. I'd go that way deliberately.
:PROPERTIES:
:Author: AlexAlda
:Score: 1
:DateUnix: 1606229646.0
:END:

***** it's not good, simply because the more you soul edit the lower your treshold for what's acceptable become, if you can just remove any inconvenience by changing what you think about it you lose your morals.

you don't like to think about how much pain and suffering doing something will cause, so you just change so you don't think about that any more, that's one of the paths the slope lead too, while it begin in a benign way that's not where it ends.
:PROPERTIES:
:Author: Banarok
:Score: 6
:DateUnix: 1606247670.0
:END:

****** You can just artificially up your 'hesitance to soul modification' value each time immediately before. If you notice you are having to inflate in more frequently over time, then you have discovered empirical evidence you are in a modification cascade and slam on the brakes until your hesitance value can be naturally leveled out without requiring manual changes. Once its stable again, you are clearly no longer addicted to change.
:PROPERTIES:
:Author: Slyvena
:Score: 2
:DateUnix: 1606281339.0
:END:

******* until that one day you think this hesitation thing is a hassle because it make you uncomfortable and do away with it.

when you can edit what you like and dislike on a whim, anything that's annoying stand in the crossfire, and hesitation to do "what's needed" is probably one of the things that are on the chopping block.
:PROPERTIES:
:Author: Banarok
:Score: 3
:DateUnix: 1606304563.0
:END:

******** Sure, but I doubt someone considered enough to set up such fallbacks would ever be that criminally stupid in the short to medium or even a lifetimes length.

In fact, when you start feeling frustrated about setting up safeguards. *That* is your signal to go to the next level and think about if you need to tweak your satisfaction levels. Although honestly, you don't need soul magic for that. You just need to sit down with a nice sandwich and remember that only a raving lunatic doesn't use safeguards for self-surgery (and that all further modification is completely off limits until the obvious truth of that fact is once again clear).
:PROPERTIES:
:Author: Slyvena
:Score: 1
:DateUnix: 1606392869.0
:END:


******** Make changing your hesitation value your highest value then ez
:PROPERTIES:
:Author: RMcD94
:Score: 1
:DateUnix: 1606948350.0
:END:


** I'm not sure I'm the best person to explain it but I think the basic idea is: once you make that sort of thing you're not you anymore, you're a new person. And who's to say that new person won't decide there's some other modification they'd like to do (maybe one the original you wouldn't even really object to) and now they're a third person. Said person decides on another modification and so on and on... it's a slippery slope thing... at some point the person deciding on the next modification is so far removed from the original that they're likely to make changes the original wouldn't want, maybe even that they'd find unacceptable. I think that's the basic reasoning for Juniper's rejection of the idea. Which isn't to say his feelings and his ego don't play any part in it, but I think it's uncharitable to say that's all there is.
:PROPERTIES:
:Author: Fredlage
:Score: 26
:DateUnix: 1606215742.0
:END:

*** #+begin_quote
  I'm not sure I'm the best person to explain it but I think the basic idea is: once you make that sort of thing you're not you anymore, you're a new person.
#+end_quote

If you think changing your ideas, thoughts, and knowledge equates to killing yourself and creating a new person, I've got bad news to relate to you about what happened to ten-years-ago-you.
:PROPERTIES:
:Author: SimoneNonvelodico
:Score: 9
:DateUnix: 1606221329.0
:END:

**** The problem is the speed and mechanism of the change, and that soul mages can do this to /other people./. You start "optimizing" yourself, and soon become a person that only cares about optimization, and then start secretly optimizing others to fix the world and align it to your values. It's an addictive mental virus, in effect. There's evidence this happened with other souls mages which is why it was made illegal.
:PROPERTIES:
:Author: wren42
:Score: 13
:DateUnix: 1606228722.0
:END:

***** Well, but OP says that obviously doing it to other people is bad. I agreed myself above that it's super dangerous, but dangerous is not the same as evil. It all depends on what safeguards you put in place, but not the act of self-change itself.

I guess as a comparison I could use this: is drinking alcohol evil? No. Is drinking alcohol, despite knowing specifically that you lose all control of your actions when drunk, while you're working at the control station of a nuclear power plant, evil? Well...
:PROPERTIES:
:Author: SimoneNonvelodico
:Score: 4
:DateUnix: 1606229083.0
:END:

****** that's exactly the problem though. a future version of you may cease to believe that doing it to other people is bad. what safeguard can you put in place, other than what they are doing? (no changes without approval from the council, regular check-ups from other soul mages to ensure no drift or changes occurred)

the metaphor fails because drinking the alcohol in this case changes your mental state /permanently/, and you could potentially keep drinking more to change it further, indefinitely.
:PROPERTIES:
:Author: wren42
:Score: 6
:DateUnix: 1606233596.0
:END:

******* It doesn't really matter much, the time horizon is what matters. What you say holds on the time horizon of a lifetime; the "drunk in the control room" scenario lasts a lot less, but also gives you a much shorter horizon to cause irreparable damage. Point is, it's not that the action itself is evil, but rather, whether it is performed in a context in which it makes it probable for you to cause damage against the better judgment of your current self.
:PROPERTIES:
:Author: SimoneNonvelodico
:Score: 1
:DateUnix: 1606234176.0
:END:

******** soul modification is near instantaneous and we have evidence and examples of soul mages who went off the deep end to become optimization monsters. I'm unclear how you think a human lifetime is not enough to cause damage.
:PROPERTIES:
:Author: wren42
:Score: 2
:DateUnix: 1606234307.0
:END:

********* No, obviously it is. My point was that "soul magic + a lifetime" can be compared to "a lot of alcohol + 15 minutes messing around with the controls of a nuclear power plant". The alcohol is reversible in theory, but by the time it would be, you will probably be dead, and so will be a few square kilometres around your current position.

Or to avoid arguing about the safeties built in into nuclear power plants, make that the controls to fire a nuclear ICBM from a silo, which is even worse.
:PROPERTIES:
:Author: SimoneNonvelodico
:Score: 2
:DateUnix: 1606236804.0
:END:


**** Your soul in WtC isn't your "ideas, thoughts, and knowledge." It's your preferences. Your preferences are all /you/ are.

Think about it this way: if a clone of you, who has all your /ideas, thoughts, and knowledge/, but different /preferences/ --- your evil twin! --- kills you, that's a tragedy for you. You don't want that, and will resist it. They're "replacing" you, but it's not /just/ that --- they're going to go off and shape the world in ways you disagree with.

Meanwhile, if you die, but in your place lives someone who shares /none/ of your ideas+thoughts+knowledge but /all/ of your preferences... well, that's just amnesia. People are usually pretty comfortable with that.

It's also the reason people can be okay with teleportation, or with being temporarily simulated, etc. --- if /their/ conscious experience ends, but the conscious experience of someone /with their same preferences/ goes on, then they can "rest assured" that the world will continue to be optimized in the way they wanted to optimize it. (Or, to go deeper on this, continuous conscious experience is really just a kind of animation/slideshow of a succession of different "yous" who happen to share preferences. You're /always/ being replaced by the next "you" a moment later, but that's okay, because /they're/ going to want what /you/ wanted.)

This is also why people feel that having children obviates mortality, somewhat --- to the degree that you can make a child "carry on your legacy" (i.e. share your preferences, and carry them out in the world as an optimizer in your place), "you" aren't gone.

When you dig into these philosophical edge-cases, most people find that what "you" are, all along, is just the set of things you do and don't want the world to become. The set of possible worlds that drive you to make them real; and the set of possible worlds that drive you to prevent them.

And, in either case, changing the boundaries of those sets, makes for a person that the current you would probably fight to the death to stop.

(If you can get behind the above, then here's a philosophical rabbit-hole of a statement to evaluate: "puberty is a violation of your human rights, since you're being replaced by someone with different preferences. Nobody should have to go through that without the consent of the prior person to be so replaced --- where that consent would imply that they already had preferences that were compatible with the ones they'll get hardwired into them by the change.")
:PROPERTIES:
:Author: derefr
:Score: 5
:DateUnix: 1606233011.0
:END:

***** #+begin_quote
  People are usually pretty comfortable with that.
#+end_quote

I wouldn't be. And this all is born out of the (fictional) conceit that you somehow can draw a sharp line between ideas and acquired knowledge and preferences. As if there wasn't a perpetual feedback loop between the two. My preferences are shaped by my experience. Had I grown into a war-torn country, or as a peasant in 1300, or as a king in Ancient Greece, I would be a different person.

#+begin_quote
  It's also the reason people can be okay with teleportation, or with being temporarily simulated, etc. --- if their conscious experience ends, but the conscious experience of someone with their same preferences goes on, then they can "rest assured" that the world will continue to be optimized in the way they wanted to optimize it.
#+end_quote

I think this is a pretty personal viewpoint. The issue of the continuity of the self isn't this clear cut and in fact the paradox of teleportation lies in that - it's not clear that teleportation does not REALLY kill you and replace you with a copy. Mostly because teleportation doesn't exist and for all we know it might be impossible (and perhaps this impossibility makes the question itself nonsense).

Again, consider this: someone is depressed. They are suicidal. They have a preference for death over life. Then they take antidepressants. Now they are not suicidal any more. Should they not do that because it's erasing who they are as a person? I can be okay with erasing 1% if it allows the remaining 99% to achieve its goals better, no?
:PROPERTIES:
:Author: SimoneNonvelodico
:Score: 2
:DateUnix: 1606233431.0
:END:

****** #+begin_quote
  I think this is a pretty personal viewpoint.
#+end_quote

It's a viewpoint /some/ people have. But, note my original phrasing --- these are reasons that people /can/ be okay with these things. As in, /for the people who are/ okay with these things, these are the most likely justifications that such people would give (I mean, if you give them time to rationalize what are probably emotional visceral reations.)

#+begin_quote
  Should they not do that because it's erasing who they are as a person?
#+end_quote

Well, yes, but actually no.

If you're suicidal, you have /a preference for self-modifying to no longer have preferences/ (or, equivalently, a preference for no longer being able to personally act to optimize for your other preferences.) In other words, you want there to not be a "you" in the world, in the sense of there being someone with exactly your preferences who has to put in the work to make the world match those preferences. A suicidal person who has shadow clones would /presumably/ want to murder their shadow clones "for their own good" before ultimately killing their original body. (And indeed, in reality, sometimes you'll hear of depressed parents killing their own children "for their own good" before killing themselves. See above about children carrying on parents' preferences.)

If you have a preference for "you" not going on, then that usually translates to no longer having any "selfish" preferences, e.g. preferences for the dispensation of your estate in ways that align with your interests. If you cared about these things, you'd want to stay alive in order to optimize the world toward them!

But being suicidal /doesn't/ usually translate to not having any /selfless/ preferences, i.e. preferences about things happening that are "good" in some global-human-utility sense.

And /usually/ these remaining preferences, despite being nominally "selfless", still hew closer to the side of "selfish" than "selfless." Even if you don't want "you" to exist in the world, you'll still tend to care about/worry about /people like you/ having good things happen to them in this world-without-"you", more than /people not like you/ having good things happen to them in said world. E.g. you tend to worry about how your family/friends will go on without you, rather than worrying about what difference you could have made through efficient altruism.

And when you apply that logic to the dispensation of /your own body/ after your [ego-]death --- well, what could be a better possible use for it than for someone /almost, but not quite, exactly like you/ to possess it and make use of it?

And that's basically what you're doing by taking the anti-depressants (or performing any other kind of discontinuous ego self-modification): you're "dying" and donating your body for the incarnation of a person who is almost, but not exactly, "you", to use as they please.

The same instinct that drives people to donate a kidney to save a sibling, means that they'll tend to be okay with passing their body over to the control of a "mental branch-offshoot" of their own mind.

(This presumably means that exactly the sort of sociopathic people who /wouldn't/ donate a kidney to save a sibling, also will tend to be /much less okay/ with the idea of self-modification even as a solution to suicidality. This is a testable hypothesis!)
:PROPERTIES:
:Author: derefr
:Score: 2
:DateUnix: 1606266555.0
:END:


****** #+begin_quote
  it's not clear that teleportation does not REALLY kill you and replace you with a copy.
#+end_quote

It's about as unclear as sleep, in that both clearly kill you
:PROPERTIES:
:Author: RMcD94
:Score: 1
:DateUnix: 1606238483.0
:END:

******* So would going to bed tonight and being shot in the head tonight be precisely equivalent for you? I dare say probably not.
:PROPERTIES:
:Author: SimoneNonvelodico
:Score: 1
:DateUnix: 1606240077.0
:END:

******** At least when I die in bed there is a clone in the morning, at least when I die from teleportation there is clone at the receiving end, where is the clone from gunshot?

If I go to sleep and there is no clone in the morning (maybe I never wake up, mind erased, whatever you like) then yes, it's equivalent to a gunshot.
:PROPERTIES:
:Author: RMcD94
:Score: 2
:DateUnix: 1606240434.0
:END:


**** Legally, we attach different weights to "murder" and "natural death". It makes sense that we'd do the same with self-murder and self-natural-death.
:PROPERTIES:
:Author: ZorbaTHut
:Score: 5
:DateUnix: 1606224141.0
:END:

***** By that standard, self-murder happens all the time too, though. Character development isn't something that just passively comes to people, it's something people actively seek out. Why should soul-magic-based character development be treated as any more murder-y than mundane introspection-and-modification of the sort that I, and I suspect many others on this subreddit, do all the time, and which many people deliberately seek out help with in the form of therapy?
:PROPERTIES:
:Author: LunarTulip
:Score: 6
:DateUnix: 1606226732.0
:END:

****** I think people consider there to be a big difference between "working to change yourself over time" and "explicitly replacing yourself with a different self with a sharp discontinuity".

Like, if you have a girlfriend, and you want her to be better at chess, you could teach your girlfriend chess, or you could break up with your girlfriend and go out with someone who's better at chess. But in one of those cases there's a discontinuity and replacement, while in the other case there isn't.

I'm not sure this /matters/, note. I'm not taking the position that self-modification is inherently wrong. But I am taking the position that it's recognizably different, and that I can understand if people want to then treat it differently.
:PROPERTIES:
:Author: ZorbaTHut
:Score: 10
:DateUnix: 1606227945.0
:END:

******* Ok, but consider something like the Unbreakable Vow at the end of HPMOR. Would placing similar compulsions and restrictions /on yourself/ voluntarily, for the purpose of fostering what you consider positive habits, be something you'd consider evil?

Suppose I was an addict and suffered from it, if I could erase the tendency to addiction from my mind/soul in a snap, why would it be evil for me to do so?
:PROPERTIES:
:Author: SimoneNonvelodico
:Score: 2
:DateUnix: 1606229271.0
:END:

******** I'm not saying it's evil in this case either, note :) But then I also don't think suicide, or even murder, is intrinsically evil in a full consequentialist sense.

But it is /absolutely/ a thing that you should hold at arm's length and regard with the utmost of suspicion.

I said it's not "intrinsically evil in a full consequentialist sense", but I /do/ think it's evil in an immediate sense; that is, you should only do it if you're getting massive gains out of it. It's a deal with the devil, and the devil is oh so very good at getting people to make bad deals.

#+begin_quote
  why would it be evil for me to do so?
#+end_quote

I'm not the only person here to post the Murder-Gandhi thing :) but the basic answer is that I think people are value and diverse opinions and behaviors in people are valuable. Changing a person is generally done to bring them more in line, and that's intrinsically bad; worse, a single change can then be followed by more changes, and it's entirely possible to eliminate all traces of what was.

And even that isn't /necessarily/ wrong, but it's really sketchy and you want to be careful with it, and many many /many/ people wouldn't be that careful. Again; deal with the devil; don't just read the contract, don't just read what the contract implies, but read everything that those implications imply, and everything /those/ implications imply, and so forth on into infinity.

At least for me, that's an almost-instant "nope".
:PROPERTIES:
:Author: ZorbaTHut
:Score: 1
:DateUnix: 1606229760.0
:END:

********* #+begin_quote
  Changing a person is generally done to bring them more in line, and that's intrinsically bad; worse, a single change can then be followed by more changes, and it's entirely possible to eliminate all traces of what was.
#+end_quote

But there is a fundamental difference between me imposing my will on someone else, and me imposing my will on myself. The first is oppression and enslavement, the second is self-actualisation. The reason why the first is regarded as evil is because it leads to deprive another person of one good we consider especially precious - the ability to steer your own life. Conversely, self-modification makes you /more/ effective at steering your own life. The difference is crucial, and the reasoning in one case can not be naively transferred to the other.

As for it being dangerous, in the specific forms of soul magic, sure, it is. But consider this: so is surgery. How many ways are there of cutting someone open, messing with their insides, and then closing them back up? How many of these will leave the person alive, and in fact better off than they were before?

Obviously surgery is a delicate, dangerous affair, whose use is generally avoided unless strictly necessary. Cosmetic surgery is something many people wouldn't even consider, given the relatively high risks compared to the pretty superficial gains (and yet, it IS a thing). But that doesn't mean we don't do surgery, or that surgery is evil. There is a fundamentally very different mindset towards "this thing is evil; it should NEVER be done", and "this thing is extremely dangerous; it can do good, but only if guided and practised by an expert, and for the gravest of reasons". In fact, in this hypothetical scenario, licensed soul magicians helping you with your mental troubles while cooperating with you and your desires, with appropriate safeguards and checks, would probably be the equivalent of our therapists or surgeons.

Here's a very spicy mental experiment: suppose there's a pedophile. They've never hurt any child, they realise it is wrong, but they still experience sexual desire towards children and suffer from it. A soul magician can change this aspect of their mind and remove their paraphilia, making them less dangerous and allowing them to live a healthy, normal life. Right or wrong?
:PROPERTIES:
:Author: SimoneNonvelodico
:Score: 1
:DateUnix: 1606230555.0
:END:

********** #+begin_quote
  But there is a fundamental difference between me imposing my will on someone else, and me imposing my will on myself. The first is oppression and enslavement, the second is self-actualisation.
#+end_quote

On the other hand, suicide is illegal. There's cases where we actively don't want people imposing their will on themselves because (arguably) their will is currently flawed and will result in irrevocable harm.

#+begin_quote
  But that doesn't mean we don't do surgery, or that surgery is evil. There is a fundamentally very different mindset towards "this thing is evil; it should NEVER be done", and "this thing is extremely dangerous; it can do good, but only if guided and practised by an expert, and for the gravest of reasons". In fact, in this hypothetical scenario, licensed soul magicians helping you with your mental troubles while cooperating with you and your desires, with appropriate safeguards and checks, would probably be the equivalent of our therapists or surgeons.
#+end_quote

I absolutely agree, and note that I'm not saying soul magic modifications are /always/ wrong. Just that they're dangerous as hell.

I can imagine a world where people are doing full new-medicide-doubleblind analysis on specific soul magic manipulation practices, to see if they're good treatments without serious side effects. This is a /very/ different world from "let's go eat some mushrooms I found and see what they do", which is the unlicensed-soul-magician-fucking-with-their-own-brain scenario, except in the case where the unlicensed soul magician is also carrying around a WMD and has already shown the bad judgement to use it.

(In fairness, in Aerb, it's also really easy to hide what you're doing; I don't blame them for deciding to just ban the entire concept. But I can imagine a more restricted version of soul magic that's really useful therapeutically.)
:PROPERTIES:
:Author: ZorbaTHut
:Score: 1
:DateUnix: 1606230914.0
:END:

*********** The whole point of the original post was to ask whether it makes sense to consider soul magic evil on principle. I have no problem to agree that something like it would obviously be extremely potentially dangerous and to be used with the utmost care, but that is a world apart for me from something being evil. I can't fathom a world in which rape or genocide are okay as long as they're used with the utmost care. This puts soul magic more in the bin with e.g. pharmacology or genetic engineering or nuclear energy - things that can /absolutely/ hurt or kill people if misused, but also be a great power for good if tamed and used properly. There's still a lot of evaluations to make on a case-by-case basis about what constitutes appropriate use, of course, but it would also be immoral to /not/ consider them when instead they would be essential to protect lives. Evil things can be at best the lesser evil if the alternatives are shitty enough, but never a good in themselves.
:PROPERTIES:
:Author: SimoneNonvelodico
:Score: 1
:DateUnix: 1606233087.0
:END:


****** His point is idiotic in other ways too. We prescribe personality alteration drugs all the time, like hormones, anti depressants, stimulants, drugs for schizofrenia.

It's nonsense.
:PROPERTIES:
:Author: Paxona
:Score: 4
:DateUnix: 1606227946.0
:END:

******* /sips coffee/

"WHY ARE YOU SHARPLY AND SUDDENLY ALTERING YOUR OWN STATE OF MIND?"

/goes to sleep/

"ARE YOU TRYING TO MURDER YOUR OWN CONSCIOUSNESS?!?"
:PROPERTIES:
:Author: SimoneNonvelodico
:Score: 7
:DateUnix: 1606229311.0
:END:

******** 'YOU'RE UNDER ARREST!' 'FOR WHAT?' 'YOU EXERCISED, AND GAVE YOURSELF A HIGH WITH ENDORPHINES, CHANGING YOUR PERSONALITY, AND KILLING YOURSELF!'
:PROPERTIES:
:Author: Paxona
:Score: 1
:DateUnix: 1606229664.0
:END:

********* I /knew/ my lazy potato couch ass was doing something right all this time.
:PROPERTIES:
:Author: SimoneNonvelodico
:Score: 2
:DateUnix: 1606230894.0
:END:

********** Unfortunately, if you become lazier than usual the same applies.
:PROPERTIES:
:Author: Kawoomba
:Score: 2
:DateUnix: 1606235139.0
:END:


***** 'A man was depressed and sought a therapist. Said therapist prescribed him drugs.'

Is this situation murder?
:PROPERTIES:
:Author: Paxona
:Score: 3
:DateUnix: 1606227880.0
:END:

****** I think there's an argument that it's kind of an assisted combination murder/suicide/birth, yes. I wouldn't insist it's morally wrong, but "well, it's arguably suicide but maybe not morally wrong" applies to other forms of more-universally-agreed-upon suicide as well.

If someone gets kidnapped and force-fed permanently addictive drugs that change their entire personality and behavior, then set free, what is this? I think there's an argument that this could be considered murder, in a world where the self is considered more important than the vessel.

(Which, largely, isn't the world we reside in, but is I think defensible.)
:PROPERTIES:
:Author: ZorbaTHut
:Score: 2
:DateUnix: 1606228420.0
:END:

******* But by that metric the self dies and is reborn literally every instant. Can you even murder something that has a lifespan of an infinitesimal?
:PROPERTIES:
:Author: SimoneNonvelodico
:Score: 3
:DateUnix: 1606229377.0
:END:

******** And by that same metric, the body also dies and is reborn literally every instant. Can you murder something that has a lifespan of an infinitesimal?

The legal system says "yes, you can".

So I think that applies here as well; there's a difference between a natural slow change and an artificial discontinuitious change.
:PROPERTIES:
:Author: ZorbaTHut
:Score: 1
:DateUnix: 1606229912.0
:END:

********* Yeah, so obviously the metric doesn't apply. But no, the key issue isn't the speed of the change. I don't get off scot free if I slowly poison you over ten years instead of stabbing you with a knife. The key issue is always whether someone /else/ does something to you against your desires and best interests.
:PROPERTIES:
:Author: SimoneNonvelodico
:Score: 1
:DateUnix: 1606230773.0
:END:

********** I think that's /a/ key issue but not /the/ key issue. Suicide is also illegal, for example.
:PROPERTIES:
:Author: ZorbaTHut
:Score: 1
:DateUnix: 1606231102.0
:END:

*********** I don't know if it is in all countries, also it's kind of a moot point since if it's successful, well... y'know. And if it's not, certainly punishing attempted suicide strikes me as one of the most morally disgusting things you could do.

Regardless, I'm not obligated to agree with the morals of the law. On suicide, like on drugs, I believe if it makes it illegal, the law is simply wrong.
:PROPERTIES:
:Author: SimoneNonvelodico
:Score: 2
:DateUnix: 1606232753.0
:END:


******* I can't speak for other juriscitions, but in here it would be qualified assault, not murder.

People don't usually ascribe murder to personality changes, I'm sorry to say.
:PROPERTIES:
:Author: Paxona
:Score: 1
:DateUnix: 1606228529.0
:END:

******** Yeah, and that's overall reasonable, because those drugs don't exist in this world and neither does soul modification.

But in a world where those /do/ exist I think we might change our mind on what "murder" is.
:PROPERTIES:
:Author: ZorbaTHut
:Score: 1
:DateUnix: 1606229803.0
:END:

********* Says you.

Anything can change your personality, from a traumatic event to medical treatment to trauma.

A blow to the head in this very world can radically change your personality. Isn't murder.
:PROPERTIES:
:Author: Paxona
:Score: 1
:DateUnix: 1606230028.0
:END:

********** It isn't legally murder. Personally, I think there's a good argument that it should be considered murder. It's a rare enough side effect that nobody does it intentionally, so we haven't had to deal with that, but if people could specifically aim for it then we might change our mind.
:PROPERTIES:
:Author: ZorbaTHut
:Score: 2
:DateUnix: 1606230098.0
:END:


***** I mean, self-murder is just suicide and while we can argue to Hell and back whether it makes sense or if anyone can even be considered to be of sound mind while wishing for their own death, I would never call suicide "immoral".
:PROPERTIES:
:Author: SimoneNonvelodico
:Score: 2
:DateUnix: 1606229151.0
:END:

****** Yeah, I'd agree; note that I'm not saying it's intrinsically wrong, I'm just saying it's fundamentally different from natural personality change.
:PROPERTIES:
:Author: ZorbaTHut
:Score: 1
:DateUnix: 1606229830.0
:END:


**** Oh, I'm well aware we are constantly changing naturally, but there is a distinctive difference between a gradual change over time and a sudden alteration. In any case, I was only describing the general idea behind the objection, I'm not saying I'm completely behind it. If I was given the option, there are definitely some aspects of my mind I'd be sorely tempted to change.
:PROPERTIES:
:Author: Fredlage
:Score: 1
:DateUnix: 1606238704.0
:END:


*** Thank you for being succinct.. Sadly it leaves holes overly pedantic people will point at, which is one of the main reasons I avoid commenting on these kind of discussions.

​

Specially in a sub as nerdy as this, either you need to deal with people writing 1500 words to point out one small issue in your succinct comment or you yourself have to write a 1500 word monster to describe a simple thing that could be done in 3-5 lines with +95% accuracy.
:PROPERTIES:
:Author: fassina2
:Score: 1
:DateUnix: 1606339273.0
:END:


*** O...kay, but that applies to changing oneself through other means as well, doesn't it?
:PROPERTIES:
:Author: AlexAlda
:Score: 1
:DateUnix: 1606219584.0
:END:

**** It definitely does. If you were in a world where you sometimes had to kill people, and each time you killed people you felt a little less bad about it, you would be pretty worried about this, yes? And the fear of becoming a person who kills people willy-nilly would be a very good reason to do your best to avoid killing people, suppressing your guilt over having killed people, suppressing empathy, etc.

The difference is that there's only so fast you can become a murderhobo through natural means. There's no real cap on how fast you can become a murderhobo through soul modification.
:PROPERTIES:
:Author: Audere_of_the_Grey
:Score: 5
:DateUnix: 1606221870.0
:END:


** You are killing me! Making a post in /rational about Worth The Candle when we haven't had an updoot in forever? Got my hopes all up!
:PROPERTIES:
:Author: WalterTFD
:Score: 9
:DateUnix: 1606233358.0
:END:


** I didn't read the story, but the qualitative difference is this:

Going to therapy changes us by changing the inputs of our mind, and those different inputs will (might) change our personality/behavior.

With magic, the character changes their mind-software /directly/, without going through the input/output interface of their mind, and it therefore introduces a sort of discontinuity/rule-breaking on the meta level, which is not present when you go to therapy.
:PROPERTIES:
:Author: DuskyDay
:Score: 8
:DateUnix: 1606224227.0
:END:


** Premise: haven't read WTC, just exploring the concept.

I couldn't see a serious argument for why doing something like this would be in itself intrinsically /evil/ - as you said, "I'm going to see a therapist" or "I'm going to learn to play the piano" is effectively self-modification too, and no one sees an issue with it.

I can however see a lot of arguments for why it would be /dangerous as fuck/, if we're talking modifications that are sudden and that affect your judgment - potentially on their very own success. It could also be considered ethically problematic depending on the circumstances: if you undertake a modification that could make you evil, and have no backups, you will not be able to judge yourself as being evil and thus going back afterwards. So you just created an evil being and added it to the world. Good job!
:PROPERTIES:
:Author: SimoneNonvelodico
:Score: 5
:DateUnix: 1606221268.0
:END:


** Because of his bad experience with getting wiped out by Level Up, because of bad associations with Fhallatere or however you spell it doing it to his friends, and because pressing levers which do things that you don't understand is dangerous (although you'd think he'd worry more about int and soc).

Consider that the person in charge of implementing modifications is the DM, who is something of an adversary.
:PROPERTIES:
:Author: GreenSatyr
:Score: 5
:DateUnix: 1606235848.0
:END:


** It's not that the action itself is antiethical, but that it can lead to antiethical actions: The whole group consensus thing is to minimize the risk of self-altering to a state where you genuinely think that certain actions (including further soul modifications) are positive and proceed to do them, when in reality they are contrary to the group's ethics (and your previous self's).
:PROPERTIES:
:Author: Mr-Mister
:Score: 4
:DateUnix: 1606219352.0
:END:


** I don't know if Joon would think this way, but it's similar to the argument against suicide---it's a decision you could change your mind on in the future, but making the decision stops you from being able to do so. With suicide obviously the thing stopping you from changing the decision is death, but with soul modification it's easy enough to continue modifying your soul to prevent it changing back, and changing your values on something will significantly influence your decision to continue doing so. Additionally, it's a drastic change. Obviously there's other forms of self-modification he would be okay with, but they're either not as drastic, not as permanent, or not as self-reinforcing.
:PROPERTIES:
:Author: B_E_H_E_M_O_T_H
:Score: 4
:DateUnix: 1606220928.0
:END:

*** That sort of principle is just as constraining as the states it tries to prevent, though. "I'm in state A, and I can irrevocably move to state B, but I'm not willing to make irrevocable state-changes in myself like that" leaves you /every bit as stuck in state A/ as making the change would leave you in state B, except minus the part where you get to pick /which/ of the two you'd rather be stuck in. It's strictly worse, from a preference-satisfaction standpoint, compared with either "I like it better in state A, so I'm not going to change to state B" or "I'd rather be in state B forever than in state A forever, so I'm going to make the change".

There's plenty of reason to be /cautious/ about any such change, of course---to monitor your preferences over an extended time to make sure it's not just an in-the-moment impulse, to figure out if there are any unanticipated downsides on the other side that'll make it less good than it superficially appears, et cetera---but, after all such caution has been applied, it's often going to be the case that the best thing to do is still to go for it.
:PROPERTIES:
:Author: LunarTulip
:Score: 1
:DateUnix: 1606235846.0
:END:


** I think there's an element of being unsure of how safe the procedures are. Juniper's skill in soul magic is piped into his brain by a not terribly benevolent deity, and at various points it's obvious that he sometimes lacks some crucial knowledge/skill in a magic, magic that he has significant skill in, that regular mages know really well. He would be using this magic to make fundamental changes to who he is as a person, with no good method for undoing those changes should he make a mistake. Soul magic has a relatively convenient interface for making those changes, it seems like it should be a bit harder to make significant mistakes, but it's really not something to approach lightly. And these fears are definitely not unfounded. Raven and presumably other people can give histories of soul mages making exactly these kinds of mistakes.

He could make bodily changes with relatively less risk of a slippery slope, but he doesn't seem to have any special knowledge of biology. Given how fine grained the bodily modifications seem to be, I don't see any reason he couldn't accidentally make changes that don't biologically function.

All of the above goes doubly for spirit. He's the /only/ practitioner for spirit, so no one else would even know what to do if he made a mistake, the interface is much worse, and spirit is a /lot/ better at changing a person than soul magic is. It's a lot more equivalent to doing surgery on your own brain.
:PROPERTIES:
:Author: sicutumbo
:Score: 3
:DateUnix: 1606241790.0
:END:


** Perhaps there are concerns akin to those at play in the Legend of Murder Gandhi. As best I recall it: Gandhi, offered a million dollars to take a pill that would make him a vicious murderer, declined. But he was willing to accept the money to become 1 percent more murderous, this not being particularly murderous. But a 1 percent more murderous Gandhi, being slightly more inclined towards murder, was now willing to enter into a deal where he took another pill, becoming 1 percent more murderous---and so it goes, until Gandhi had become very murderous indeed, far more than original Gandhi would have agreed to for any amount of money.
:PROPERTIES:
:Author: RidesThe7
:Score: 5
:DateUnix: 1606247683.0
:END:


** [deleted]
:PROPERTIES:
:Score: 2
:DateUnix: 1606258191.0
:END:

*** Go stand in the corner & think about what you have done. Just so you know, the correct spelling is [[https://en.wikipedia.org/wiki/Mahatma_Gandhi][Gandhi]].
:PROPERTIES:
:Author: GANDHI-BOT
:Score: 2
:DateUnix: 1606258203.0
:END:


** I never really got this part either. It just seems like an efficient way to improve yourself.

Are you not yourself anymore after changing your priorities? It seems absurd.
:PROPERTIES:
:Author: WildFowl82
:Score: 2
:DateUnix: 1606207889.0
:END:

*** #+begin_quote
  Are you not yourself anymore after changing your priorities
#+end_quote

Take your most precious belief and imagine yourself with your most precious belief being the opposite of what it is. Is this person you?
:PROPERTIES:
:Author: Putnam3145
:Score: 6
:DateUnix: 1606223812.0
:END:

**** To answer your question: no, that person isn't 100% me, but 95% perhaps? Not actually that far off in my optics.

But it's a bit of a weird thought experiment because different values aren't independent. It doesn't make sense to change a single value, it'd revert because of other values supporting it, just as happens in story.

Furthermore, in-story you get to choose which values to change. You'd only change values that you actually prefer to be different.

So take your most precious belief, and then point to a secondary belief that limits you from pursuing the first. Remove the secondary belief. Is this person still you? I think so. All you've done is make your values less contradictory.
:PROPERTIES:
:Author: WildFowl82
:Score: 2
:DateUnix: 1606231080.0
:END:


** Would anybody be interested in talking about practical ways you could mitigate the risk of slippery slopes? Given that values in the universe have numerical values my intuition is to make a shelling fence of allowing X values to be changed with some value Y or perhaps Y%? Or perhaps store the current values and say that any change can at max deviate with X points from the current baseline? Perhaps having scheduled check-ins by a trusted soul mage and store a meme that would pop out if a threshhold of change were reached?
:PROPERTIES:
:Author: Sonderjye
:Score: 1
:DateUnix: 1606236427.0
:END:

*** Ideal situation is that during work hours could change my soul to value productivity and not value sweet dopamine fixes from going on reddit or facebook, and have a way ensured that I would turn myself back once I was done for the day.
:PROPERTIES:
:Author: Sonderjye
:Score: 2
:DateUnix: 1606236738.0
:END:


*** Your first change could be to set this as a high value: "only ever perform value modifications that Pre-Mod Me would not disapprove of".

Your second change could be "prevent the first change I made from getting removed".

Your third change could be "do not let these three changes get overriden by higher values".

Just some ideas. I bet there'd be loopholes in practice. But if you never reach a point where you'd want to exploit them, maybe it'd suffice.
:PROPERTIES:
:Author: WildFowl82
:Score: 2
:DateUnix: 1606257823.0
:END:


** Would be boring if he took away all his flaws
:PROPERTIES:
:Author: RMcD94
:Score: 1
:DateUnix: 1606238036.0
:END:


** The problem with editing one's own mind is that there's no outside perspective to keep that in check. A qualia that edits its own perception cannot perceive that change. It doesn't help that Joon just plain doesn't understand souls to any real extent. He's just playing around with the memory editor GUI he was given. These things compound to make it so a scenario where the characters trap themselves in a destructive loop of soul-surgery becomes very realistic.
:PROPERTIES:
:Author: Revlar
:Score: 1
:DateUnix: 1606264425.0
:END:

*** [deleted]
:PROPERTIES:
:Score: 1
:DateUnix: 1606290075.0
:END:

**** Of course it's not a certainty. Not every soul mage becomes Falletehr. But it is a very real risk that by the time they end up in equilibrium, they're much farther from the initial state than they would have wanted. Which could be very bad, depending on the direction of the changes. It's not that a bad outcome is certain, it just has a non-negligible probability of happening.
:PROPERTIES:
:Author: Audere_of_the_Grey
:Score: 1
:DateUnix: 1606495341.0
:END:


** It's self mutilation, also you could justify anything if you start messing with your soul: second empire style.
:PROPERTIES:
:Author: Wiinounete
:Score: 0
:DateUnix: 1606266650.0
:END:


** Honestly, all Joons moralising in this series became just painfully stupid the moment it became 100% clear that he's in a simulation. There is no such thing as soul modification, he's changing the fucking settings in a game.
:PROPERTIES:
:Author: davorzdralo
:Score: -2
:DateUnix: 1606251481.0
:END:

*** It materially affects how he and others think.
:PROPERTIES:
:Author: sicutumbo
:Score: 4
:DateUnix: 1606252640.0
:END:

**** There are no others, it's a simulation that can be paused by the GM. He is changing the settings on NPCs. As for why it affects him, it's probably because he is not actually Joon, but his digitised mind, uploaded into the game.
:PROPERTIES:
:Author: davorzdralo
:Score: -2
:DateUnix: 1606256626.0
:END:

***** That would definitely be a cool and interesting method of concluding the story: every character except for Joon is actually just a puppet, none of their characterization, struggles, or literally anything else about them matters. Joon grieving for Fenn was utterly pointless because she never actually existed, similarly his romance with Amaryllis and friendship with Grak and Raven doesn't matter at all. This would indeed be the pinnacle of writing, totally and completely, to have 99% of the characters not matter at all. I applaud you for your insight.
:PROPERTIES:
:Author: sicutumbo
:Score: 7
:DateUnix: 1606258094.0
:END:

****** I'm not the one writing the story that way. I already gave up reading it, I might go back once it's finished, but it's turned to utter shit in my opinion.
:PROPERTIES:
:Author: davorzdralo
:Score: 0
:DateUnix: 1606340237.0
:END:


***** Does it matter if the characters in the simulations are intelligences in their own right? Why should non-biological intelligences be treated differently?
:PROPERTIES:
:Author: somerando11
:Score: 6
:DateUnix: 1606268629.0
:END:

****** There is absolutelly nothing in the story that indicates that other characters are anything except unthinking NPCs. There is no reason to believe that the game simulates billions of sapients for no discernable reason.
:PROPERTIES:
:Author: davorzdralo
:Score: 0
:DateUnix: 1606340295.0
:END:
