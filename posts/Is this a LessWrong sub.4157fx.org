#+TITLE: Is this a LessWrong sub?

* Is this a LessWrong sub?
:PROPERTIES:
:Author: portodhamma
:Score: 15
:DateUnix: 1452893308.0
:DateShort: 2016-Jan-16
:END:
I definitely #do not# like the LessWrong worldview, but I enjoy many aspects of "rationalist" literature. I want to know if this subs users always promote atheism and transhumanism or if there's any discussion challenging basic ideas of the LessWrong movement as opposed to arguing within the worldview.

What I'm saying is: will I like the discussion in this sub if I'm not a proponent of immortality, effective altruism, or other new atheist and transhumanist platforms?

Edit: I've decided to stop replying to this thread due to the amount of conversations I had to keep up in. Thank you!

"Whereas some brahmans and contemplatives, living off food given in faith, are addicted to debates such as these --- 'You understand this doctrine and discipline? I'm the one who understands this doctrine and discipline. How could you understand this doctrine and discipline? You're practicing wrongly. I'm practicing rightly. I'm being consistent. You're not. What should be said first you said last. What should be said last you said first. What you took so long to think out has been refuted. Your doctrine has been overthrown. You're defeated. Go and try to salvage your doctrine; extricate yourself if you can!' --- he abstains from debates such as these. This, too, is part of his virtue."


** u/PeridexisErrant:
#+begin_quote
  Is this a LessWrong sub?
#+end_quote

No. Per the sidebar, this subreddit is dedicated to the discussion of works of rational and rationalist fiction.

(There's a fair proportion of [[/r/rational]] readers who are also on LessWrong, but the impact of this should be minimised by our different focusses.)
:PROPERTIES:
:Author: PeridexisErrant
:Score: 1
:DateUnix: 1452907659.0
:DateShort: 2016-Jan-16
:END:

*** That and the way LessWrong folks on reddit seem to really like upvoting people who complain about LessWrong.
:PROPERTIES:
:Author: Putnam3145
:Score: 2
:DateUnix: 1452976514.0
:DateShort: 2016-Jan-17
:END:


** I think you'll be fine with the discussion. I'm not a True Believer and don't write like one, and I think I more or less fit in with the community. I don't necessarily /disagree/ with immortality, atheism, transhumanism, etc. But I'm not about to proselytize or present those views in an unexamined way (speaking as though you are Right is one of those things that I find annoying no matter who's saying it and about what).
:PROPERTIES:
:Author: alexanderwales
:Score: 36
:DateUnix: 1452895634.0
:DateShort: 2016-Jan-16
:END:

*** Dude, until Eliezer starts writing again, you /are/ the community.
:PROPERTIES:
:Author: AmeteurOpinions
:Score: 39
:DateUnix: 1452901751.0
:DateShort: 2016-Jan-16
:END:

**** Other folks try. Intentional or not, /Worm/ counts. [[/u/kibahacker]] is dragging up some very good nBSG fanfic and has just started their own work.
:PROPERTIES:
:Author: mycroftxxx42
:Score: 10
:DateUnix: 1452940613.0
:DateShort: 2016-Jan-16
:END:

***** Almost completely done with Worm. By my beard, this one is monumental. It compels me to write a story of my own.
:PROPERTIES:
:Author: AKhou
:Score: 3
:DateUnix: 1453244753.0
:DateShort: 2016-Jan-20
:END:


**** How about FarmerBob, Kishoto and as the sibling comment says, Wildbow?
:PROPERTIES:
:Author: rhaps0dy4
:Score: 3
:DateUnix: 1452951717.0
:DateShort: 2016-Jan-16
:END:


**** Animorphs tho
:PROPERTIES:
:Author: chaosmosis
:Score: 4
:DateUnix: 1453100694.0
:DateShort: 2016-Jan-18
:END:


**** Idolising someone isn't very rational, in my opinion.
:PROPERTIES:
:Author: Pluvialis
:Score: 1
:DateUnix: 1453146467.0
:DateShort: 2016-Jan-18
:END:


** I had a post here, but I've edited it for the sake of clarity:

A lot of people that read HPMOR also read and absorbed the sequences at LessWrong, as well as a disproportionate number of authors. They not only have evidence for what they believe, but are used to justifying it to people who are disenfranchised. So, no, it's not a LessWrong subreddit, but don't expect to say "I disagree with immortality" on this subreddit and not get dog-piled. It might be a vocal minority, or a vocal majority, but they are vocal and they have incentive to argue.

This isn't a statement of belief, it's just generally how rationalists act; there's no room to "agree to disagree" in the philosophy.
:PROPERTIES:
:Author: rational_rob
:Score: 10
:DateUnix: 1452921163.0
:DateShort: 2016-Jan-16
:END:

*** I think there is room to disagree when it becomes clear that a person's values and end goals are different than yours.

I don't mean when debating concrete facts. I mean when talking about what course of actions should be taken and describing things as "Moral" or "Ethical".

Basically a person can be perfectly rational and believe that it's okay for them to steal from other people as long as they don't get caught becuase their value system only involves improving their own lives and they care little for other human beings.

As long as they're reasonably certain they'll never be caught or held responsible and they're stealing in such a manner that doesn't significantly hurt humanity as whole, you can't rationally say that their reasoning for stealing is wrong based on their intended goals.

You can only say that you disagree with their end goal.
:PROPERTIES:
:Author: Fresh_C
:Score: 3
:DateUnix: 1452968958.0
:DateShort: 2016-Jan-16
:END:

**** I think now would be a good time to mention [[https://wiki.lesswrong.com/wiki/Ethical_injunction][ethical injunction]]. Sure, you can have whatever end goal you want, but if you fall into the trappings of human bias while doing it then you're /not/ an effective rationalist. It's not smart to make the claim that you are effectively selfish or effectively evil because unless you're really careful about messing up, you're not actually effectively anything.

The same goes for positive things, i.e. "I only worship god because believing in him makes me feel happy". See [[http://lesswrong.com/lw/i4/belief_in_belief/][Belief in Belief]].
:PROPERTIES:
:Author: rational_rob
:Score: 1
:DateUnix: 1452970293.0
:DateShort: 2016-Jan-16
:END:

***** Could you break it down for me what point you're specifically trying to make? I can't follow what you're trying to get across with your comment.

Not that your comment is incomprehensible or anything, just that I think I have not read up on all the topics you're referencing and would prefer not to read through everything in those links to understand. I did briefly glance at them (and have read a good chunk of LessWrong in the past). I'll try to summarize what I think your point might be and you can tell me whether I missed the mark or not.

1) You're saying that there's no value in declaring yourself to be "selfish" or "Evil" because broadcasting that fact hinders your goals of being selfish.

2) You're saying that behaving in ways that are typically considered selfish are objectively more likely to cause harm to the individual than if they were not to behave this way. Thus by doing things that are traditionally considered immoral, you are actually hurting your goals of self-betterment

If number 1 is what you're saying, then I completely agree. It's stupid to advertise that your beliefs are contrary to those of society, especially if you're not doing so with the intention of changing society's beliefs to be more in line with yours. It's basically attracting negative attention for no benefit.

If you're saying number 2, then I would say that I mostly agree with the sentiment in practice. But there are many specific situations both hypothetically and in real life where people have committed actions that are traditionally considered unethical where the benefits outweigh the negatives for them personally.

If both of my guesses are wrong... could you explain in more detail what you meant?
:PROPERTIES:
:Author: Fresh_C
:Score: 2
:DateUnix: 1452971363.0
:DateShort: 2016-Jan-16
:END:

****** I kind of mean a bit of both, but it's hard to explain. Basically, there are a lot of things that average, mentally healthy humans value, that aren't entirely selfish. In "Predictably Irrational" the author relates an experiment on human behaviour, in which the students on the MIT campus were offered chocolates for 1Â¢ each, or for free. The students that were offered the free candy took on average 4-5 less candies than the students that were offered the candy for one cent. Even though, predictably, more students capitalized on the free candy (as expected of selfish humans) they showed concerns for scarcity, concerns for the commons, and refrained from taking more than one. (IIRC, the average for the free candies was between 1.5 or 2.5)

Basically, people acting out of self-interest don't /always/ act out of self-interest, so if you use "I act out of self-interest" as an excuse to do something ethically questionable, you aren't being consistent. To clarify, I mean ethically questionable as in something that indisputably has a negative effect on people (like stealing or murder).

The same goes for stealing or murder for a good cause. Another experiment in "Predictably Irrational" showed that when given the opportunity to cheat on a test (without accountability) students cheated by a consistent, if small, amount. When put in a morally compromising position, we often take a little off the top for our own benefit, so long as it has no visible negative effect on the populace. We steal pens at work. The IRS "loses" a ridiculously higher amount of money than all of the burglars combined.

So what do you think will happen when someone steals from the rich and gives to the poor? Who do you think will care, when they skim a little off the top? When you murder somebody for the benefit of society, how to you measure utility? How do you know you are consistent? Where do you stop?

I'm not referring to no-win scenarios, like choosing between a thousand people dying or a million people getting the flu, but I am referring to individual actions.

TL;DR: We consistently underestimate our generosity and consistently overestimate our honesty, and those two things are a deadly combination. When think to yourself "Things would be better if I were in charge" you're making the error of /assuming/ you'll resist temptation, when historically the most infallible people still fall apart. When you /are/ in charge, and you think to yourself "I can take a little bit of the money, I'm a selfish human, after all." you're making a weak justification for breaking what is an entirely sensible ethical code. (an ethical code that most prototypical humans have gained, either innately or through social osmosis)

This goes doubly for anyone who's never read a blog or self-help book on personal bias, because they're unlikely to know they're making an error in the first place.
:PROPERTIES:
:Author: rational_rob
:Score: 2
:DateUnix: 1452972754.0
:DateShort: 2016-Jan-16
:END:

******* Thanks for typing all that out.

I think we mostly agree here. Though I imagine most people who are inherently selfish don't care that they're being inconsistent. Their goal isn't "to be selfish" but rather to do whatever they want to do so long as the consequences aren't too harsh.

Nothing in your response is really saying that such a person shouldn't do illegal things to further their goals (in the hypothetical situation where they're fairly sure they'll never get caught). It's just saying that being selfish is a weak justification. But I don't think selfish people really resort to that sort of justification unless they've already been caught. Internally their actions need no justifications because they're what that person wants to do.

Edit: I would also argue that it's impossible not to act out of self-interest. The people who didn't take more free candy did so because they wanted there to be candy for other people, or because they don't want to be perceived as greedy. That in itself is self interest, just of a different sort.
:PROPERTIES:
:Author: Fresh_C
:Score: 2
:DateUnix: 1452973561.0
:DateShort: 2016-Jan-16
:END:

******** Well, I'm pretty sure the concept of ethical injunction was merely put in place to stop people from doing those things under the assumption that they were rational. Of course, someone who's intent on doing crime will probably do it. We just don't want ordinary people talking themselves into doing something they'd regret.
:PROPERTIES:
:Author: rational_rob
:Score: 2
:DateUnix: 1452974034.0
:DateShort: 2016-Jan-16
:END:


** I'm not a fan of LessWrong, and don't see it as being primarily about atheism or transhumanism. That's a side issue to the set of mental tools and practices that EY pushes.
:PROPERTIES:
:Author: ArgentStonecutter
:Score: 8
:DateUnix: 1452894625.0
:DateShort: 2016-Jan-16
:END:

*** Would you say you don't like the whole bayesian thing, or just lesswrong in particular?

Because I don't hear enough reasonable criticism of the whole bayesian thing.
:PROPERTIES:
:Author: traverseda
:Score: 6
:DateUnix: 1452895424.0
:DateShort: 2016-Jan-16
:END:

**** I think they way overstate the usefulness of Bayes Theorem. They seem to think that it's the best way to evaluate situations even if you pull random numbers out of the air to fill in the gaps.
:PROPERTIES:
:Author: ArgentStonecutter
:Score: 8
:DateUnix: 1452896699.0
:DateShort: 2016-Jan-16
:END:

***** Probabilistic thinking probably doesn't seem like something profound because you're already practicing it, but a lot of people coming from the atheist/skeptic movements got stuck in boolean logic.

It's also very useful for working in groups. Like a mini prediction market.

The trick with lesswrong is that it seems profound at the time, then a few years later you look back and wonder what all the fuss was about. It codified a lot of thoughts that 17 year old traverseda didn't have the words to explain. I would have gotten there eventually, but it certainly sped things up a bit.
:PROPERTIES:
:Author: traverseda
:Score: 22
:DateUnix: 1452897063.0
:DateShort: 2016-Jan-16
:END:

****** That is what I liked about it. It laid out good definitions for things I wouldn't otherwise have had an easy reference concept for.
:PROPERTIES:
:Author: andor3333
:Score: 5
:DateUnix: 1452911181.0
:DateShort: 2016-Jan-16
:END:


***** I'd say that in principle it's the best, but in practice it's generally better to find something resilient than something with a good theoretical basis. You don't want to be wrong forever because you picked bad priors.

But I do think it's important to learn the theoretical basis behind things. And to know /exactly/ what evidence is.
:PROPERTIES:
:Author: DCarrier
:Score: 2
:DateUnix: 1452974098.0
:DateShort: 2016-Jan-16
:END:


**** u/deleted:
#+begin_quote
  Because I don't hear enough reasonable criticism of the whole bayesian thing.
#+end_quote

Coming up with good priors is hard. Even good priors don't really encode information /unless they are from empirical data/, they're regularization methods. Posterior distributions can rarely be actually evaluated numerically, usually just sampled-from.

In short, it's a shining example of taking a normative theory and representing it as applicable to the real world while failing to mention that applying it to the real world is really, really, /really/ hard.
:PROPERTIES:
:Score: 2
:DateUnix: 1453015027.0
:DateShort: 2016-Jan-17
:END:

***** Counterpoint, [[http://www.amazon.ca/How-Measure-Anything-Intangibles-Business/dp/1452654204][Measuring Intangibles in Business]].
:PROPERTIES:
:Author: traverseda
:Score: 1
:DateUnix: 1453019053.0
:DateShort: 2016-Jan-17
:END:

****** I'm not saying the world actually contains immeasurable "intangibles", just that often, even when we know what to measure, the calculations are expensive or intractable.
:PROPERTIES:
:Score: 1
:DateUnix: 1453051115.0
:DateShort: 2016-Jan-17
:END:

******* Fermi estimates are still a big improvement over not doing them.

The correct answer when dealing with uncertainty isn't "throw up your hands" it's "shift your understanding closer towards uncertainty".
:PROPERTIES:
:Author: traverseda
:Score: 2
:DateUnix: 1453070939.0
:DateShort: 2016-Jan-18
:END:


** Welcome!

The reason most people in this community don't question the nonexistence of any gods is probably for the same reason that they don't question the nonexistence of Middle Earth. They've already done the questioning, found the evidence to be fairly conclusive that deities don't exist, and moved on to more interesting topics.

If you have found any evidence that a deity or deities exist, I'm sure many of us would love to hear it and discuss it with you. Just because most of us came to the same conclusions doesn't mean that none of us are open to discussion.

As for transhumanism and immortality, my understanding is that they are more of a value, something to strive for, not necessarily a belief that they are likely to happen. In this respect, google dictionary probably gets it wrong.

What exactly are your objections to effective altruism?

The reason that most people in this community agree on those specific three things: 1. that people should be allowed to live as long as they want, 2. that god(s) don't exist, and 3. that some charities are /significantly/ better at helping people and helping more people than other charities is because:

(1.) We like to be unusually honest and consistent with ourselves (so if one of us ever said that immortality was bad, we wouldn't contradict ourselves by saying that living forever in an afterlife was good.) And (2. and 3.) We each evaluated the evidence and came to our own conclusions.

NOT because of mob mentality.

Also, I just want to make this clear just in case you don't understand and get offended, when we disagree with or contradict other people's opinions, we're NOT claiming any superiority over them nor trying to establish ourselves as dominant over them in any way whatsoever. Many of us are genuinely /glad/ when we are proven wrong about something.

That being said, the rational fiction subreddit specifically is more about rational writing and literature, and not all of it focuses on those particular three subjects. You should be able to find a decent amount of rational fiction to read and enjoy which doesn't focus on atheism, transhumanism or effective altruism.

Some examples I would recommend include:

-Mother of Learning

-Worm

-Hogwarts Battle School

-The Martian (yes the same one that the movie was based on!)

-Forging the Sword

-Shadows of the Limelight

-Dungeon Keeper Ami

-What if Sg-1 Weren't Stupid (it's a lot better and funnier than it sounds. Must read if you're a stargate fan!)

-Stargate Physics 101

-Interview with a System Lord

-Twisted: the Untold Story of a Royal Vizier (okay, this one is kinda transhumanist, but it's a musical retelling of Disney's Aladdin, performed by Starkid, the same people who did a Very Potter Musical! Totally worth it even if you don't agree with transhumanism.

Enjoy!
:PROPERTIES:
:Author: Sailor_Vulcan
:Score: 22
:DateUnix: 1452901584.0
:DateShort: 2016-Jan-16
:END:

*** First of all, thank you for your suggestions! They should be very helpful, as I've already read and liked some of them.

Secondly, I was not trying to question atheism as a position, but on the internet, there's quite a bit of ideological baggage that comes with many atheist communities.

I also don't wish to remove any options for people to extend their lives, that's practically murder. However, I don't think eternal life is a good thing, and striving towards it is an unhealthy choice(clearly I mean spiritually, not physically.)

Also my objections to effective altruism are more along the lines of my inclination to virtue ethics as opposed to utilitarian. I can't save the world but I can act like a good person and gain contentedness from that.
:PROPERTIES:
:Author: portodhamma
:Score: 6
:DateUnix: 1452902776.0
:DateShort: 2016-Jan-16
:END:

**** u/traverseda:
#+begin_quote
  I was not trying to question atheism as a position, but on the internet, there's quite a bit of ideological baggage that comes with many atheist communities.
#+end_quote

You object to the atheist tribe, which is reasonable. A lot of people object to the lesswrong tribe, but they're still the best resources we have for a lot of skills. Some people from the Center for Applied Rationality are dissociating those skills from lesswrong as a tribe.

On the whole, we try to discourage tribalism here, so hopefully you won't have a hard time of it. People might need to be gently reminded occasionally though. Tribalism runs strong in humans.

That's actually one of the bigger complaints about lesswrong, that they encouraged tribalism for the sake of strength and unity, but that that gets in the way of other things we value like discussion and lack of tribe related bias.
:PROPERTIES:
:Author: traverseda
:Score: 13
:DateUnix: 1452905202.0
:DateShort: 2016-Jan-16
:END:

***** Thank you for understanding what I meant and interpreting my words charitably. I had heard that kind of thing about LessWrong and I'm glad I'm not seeing it here.
:PROPERTIES:
:Author: portodhamma
:Score: 7
:DateUnix: 1452905515.0
:DateShort: 2016-Jan-16
:END:

****** I like this community for exactly that reason. There's been a few actual arguments, but this and the general rationalist community are probably the most understanding communities around. Because that's sort of our thing, trying to understand.
:PROPERTIES:
:Author: traverseda
:Score: 3
:DateUnix: 1452907089.0
:DateShort: 2016-Jan-16
:END:


****** [removed]
:PROPERTIES:
:Score: -9
:DateUnix: 1452905522.0
:DateShort: 2016-Jan-16
:END:

******* Wow I'm honored to be selected by this completely inane bot I'd like to thank the Academy
:PROPERTIES:
:Author: portodhamma
:Score: 6
:DateUnix: 1452905789.0
:DateShort: 2016-Jan-16
:END:

******** Sadly, this is probably inspired by [[http://xkcd.com/1627/][this recent xkcd comic]]. That would make it at least the second (spotted another over in [[/r/Python]] )
:PROPERTIES:
:Author: tilkau
:Score: 2
:DateUnix: 1452907289.0
:DateShort: 2016-Jan-16
:END:

********* [[https://www.reddit.com/r/explainlikeimfive/comments/402y34/eli5_i_recently_started_texting_this_girl_who_i/cyr7ua5][Here]] is another one. This sort of thing feels like it /could/ be funny, but they don't have enough of a memetic/cultural presence to pull it off.
:PROPERTIES:
:Author: ulyssessword
:Score: 2
:DateUnix: 1452929816.0
:DateShort: 2016-Jan-16
:END:

********** u/tilkau:
#+begin_quote
  they don't have enough of a memetic/cultural presence to pull it off.
#+end_quote

They should try automatically finding short, controversial comments, applying neural networking to connect them with keywords mentioned in the parent comment.. and generate their actual comment on chosen posts by combining (markov chaining) topical short controversial comments.

I mean, that would be a totally different bot, admittedly.. But it would probably manage to be funny in a Madlibs type of way.
:PROPERTIES:
:Author: tilkau
:Score: 1
:DateUnix: 1452932807.0
:DateShort: 2016-Jan-16
:END:


********* [[http://imgs.xkcd.com/comics/woosh.png][Image]]

*Title:* Woosh

*Title-text:* It also occasionally replies with 'Comment of the year', 'Are you for real', and 'I'm taking a screenshot so I can remember this moment forever'.

[[http://www.explainxkcd.com/wiki/index.php/1627#Explanation][Comic Explanation]]

*Stats:* This comic has been referenced 74 times, representing 0.0771% of referenced xkcds.

--------------

^{[[http://www.xkcd.com][xkcd.com]]} ^{|} ^{[[http://www.reddit.com/r/xkcd/][xkcd sub]]} ^{|} ^{[[http://www.reddit.com/r/xkcd_transcriber/][Problems/Bugs?]]} ^{|} ^{[[http://xkcdref.info/statistics/][Statistics]]} ^{|} ^{[[http://reddit.com/message/compose/?to=xkcd_transcriber&subject=ignore%20me&message=ignore%20me][Stop Replying]]} ^{|} ^{[[http://reddit.com/message/compose/?to=xkcd_transcriber&subject=delete&message=delete%20t1_cyzxc42][Delete]]}
:PROPERTIES:
:Author: xkcd_transcriber
:Score: 1
:DateUnix: 1452907297.0
:DateShort: 2016-Jan-16
:END:

********** ... ... I think I can honestly say "Woosh" to that.

But what can you expect from a bot.
:PROPERTIES:
:Author: tilkau
:Score: 1
:DateUnix: 1452907827.0
:DateShort: 2016-Jan-16
:END:


** Please remember not to downvote based on opinion.
:PROPERTIES:
:Author: traverseda
:Score: 20
:DateUnix: 1452896127.0
:DateShort: 2016-Jan-16
:END:


** Do you like debating immortality, effective altruism, or other new atheist and transhumanist platforms?

If so, I'm sure you'll like the discussion on this board ;p
:PROPERTIES:
:Author: traverseda
:Score: 7
:DateUnix: 1452895307.0
:DateShort: 2016-Jan-16
:END:


** Just curious, what are your reasons for opposing those things?
:PROPERTIES:
:Author: rineSample
:Score: 11
:DateUnix: 1452894523.0
:DateShort: 2016-Jan-16
:END:

*** Well I think that life is primarily a negative experience and people deserve to die and move on to the next life to reap their karma. It's not a scientific perspective, but one I formulated through study of religion and personal experience. And I believe that ethics can only be determined through philosophical insight, I think that the Is/Ought barrier is pretty strong.
:PROPERTIES:
:Author: portodhamma
:Score: 24
:DateUnix: 1452894952.0
:DateShort: 2016-Jan-16
:END:

**** Please do not downvote [[/u/portodhamma]] just because you disagree with the honest answer *she gave to the on-topic question she was asked.
:PROPERTIES:
:Author: Roxolan
:Score: 30
:DateUnix: 1452897357.0
:DateShort: 2016-Jan-16
:END:

***** Thank you, and I go by "she" for future reference.
:PROPERTIES:
:Author: portodhamma
:Score: 7
:DateUnix: 1452899564.0
:DateShort: 2016-Jan-16
:END:


**** Would you make that choice for them?

The general thought around here tends to be preference utilitarianism. That is, if you'd prefer to die you deserve to be given that option. Some would qualify that saying that you should at least make an honest effort to enjoy your life so that others aren't sad about your passing.

But many people do strongly want to live. They should be allowed to, indefinitely if they want.

As for ethics being only determinable through philosophical thought, well most people here and on lesswrong would actually agree with you, more or less.

Rationality is a tool for accomplishing your goals, but your goals themselves can't be decided "rationally". There's no "rational" axioms, no rational reason to want to be happy.

But rationality can help you notice contradictions in your goals, help you figure out what you really want, and when your goals truly do conflict they help you decide which ones to pursue.
:PROPERTIES:
:Author: traverseda
:Score: 27
:DateUnix: 1452895822.0
:DateShort: 2016-Jan-16
:END:

***** I would think that justifying an /obligation/ to refrain from immortality or to never have kids is a far tougher prospect than saying that it isn't virtuous behavior. This is coming from a virtue ethics standpoint, of course. I would regard veganism as virtuous,but I would only extend obligation to refraining from actually hurting animals yourself.
:PROPERTIES:
:Author: portodhamma
:Score: 10
:DateUnix: 1452899532.0
:DateShort: 2016-Jan-16
:END:

****** Ahh, well there's your problem. Virtue ethics.

In all seriousness though, why virtue ethics?

--------------

A rationalist-ish take on the whole veganism thing could look like [[http://slatestarcodex.com/2015/09/23/vegetarianism-for-meat-eaters/][this]].

TL:DR

#+begin_quote
  This argument is so simple I feel dumb for not thinking of it myself; instead, I take it from Julia Galef and Brian Tomasik. Suppose I get about a third of my daily calorie requirement from meat; that adds up to 250,000 calories of meat a year. Further suppose that it's split evenly between 125,000 calories of beef and 125,000 calories of chicken.

  The average cow is very big and makes 405,000 calories of beef; the average chicken is very small and makes 3000 calories worth of chicken. So each year, I kill about 0.3 cows and about 42 chickens, for a total of 42.3 animals killed.

  Suppose that I stop eating chicken and switch entirely to beef. Now I am killing about 0.6 cows and 0 chickens, for a total of 0.6 animals killed. By this step alone, I have decreased the number of animals I am killing from 42.3/year to 0.6/year, a 98% improvement.
#+end_quote

As an example of the general approach. The question then becomes one of whether you value cows more then chickens, and if so how much.
:PROPERTIES:
:Author: traverseda
:Score: 9
:DateUnix: 1452904118.0
:DateShort: 2016-Jan-16
:END:

******* >Why virtue ethics?

Largely because of two things: I believe motive matters in determining the goodness of an action, and deontology and consequentialism were ruled out.

To elaborate: I find it impossible to conceive of a set of maxims that apply to every situation and I find it horrifying to assign ethical culpability when the consequences of an action can be ridiculously, insanely hard to predict with surety.

EDIT: I could really go into things like metaethics and epistemology but I'm on mobile and it's cold so I won't.
:PROPERTIES:
:Author: portodhamma
:Score: 7
:DateUnix: 1452905373.0
:DateShort: 2016-Jan-16
:END:

******** I think motives are important, but they're not at the layer of ethics, they're at the layer of game theory or politics.

The goodness of an action doesn't change based on motive, but how you treat the person doing the action still should, if that makes sense?

Likewise, someone can be a good person, and not have much of an affect on the world. Someone can be a horrible person and do great things.

You're using ethics to judge yourself, but I think you should be using it to judge the world.

Virtue ethics is an alright shim to deal with all the complicated game theory bullshit, because it let's you predict future actions. An evil person who does one great thing isn't "better" (in the sense that you should associate with and reward them) then a good person who doesn't get a lot done. because that evil person is willing to do evil. On the whole, the good person will end up being better.

There's also the layer where we don't want to implement anything like the churches "indulgence" system. There are all kinds of social reasons why we don't want people to be able to buy off their sins.

I'm describing it poorly I know.

The point I'm trying to get at is that something that looks a lot like virtue ethics is that natural result of social structures and preference utilitarianism, but that I see it as just another tool to help us work towards preference utilitarianism. I view it as a social tool in service of good ethics instead of as good ethics itself.

--------------

#+begin_quote
  I find it horrifying to assign ethical culpability when the consequences of an action can be ridiculously, insanely hard to predict with surety
#+end_quote

Lesswrong says is pretty abrasively, but I'm inclined to agree.

#+begin_quote
  You know what? This isn't about your feelings. A human life, with all its joys and all its pains, adding up over the course of decades, is worth far more than your brain's feelings of comfort or discomfort with a plan. Does computing the expected utility feel too cold-blooded for your taste? Well, that feeling isn't even a feather in the scales, when a life is at stake. Just shut up and multiply.
#+end_quote

To put it a bit nicer, I consider preference utilitarianism to be a virtue, and I'm more inclined to help out those that I consider to be virtuous, as a policy. I like virtuous people more then evil people.

If I help out people with that virtue, and they help other people with that particular virtue, more bednets are likely to be distributed to africa, more people get to live happy full lives, etc.

That's what virtue is for, determining what people/corporation you should like and therefore help out.

But how you decide what is a virtue is in the realm of preference utilitarianism and game theory.

Sorry, that was a bit rambly, but hopefully I've got my point across.
:PROPERTIES:
:Author: traverseda
:Score: 11
:DateUnix: 1452907308.0
:DateShort: 2016-Jan-16
:END:

********* I think most of the differences between ethical systems aren't necessarily the conclusions but the reasoning leading to said conclusions. With certain, important, exceptions of course.
:PROPERTIES:
:Author: portodhamma
:Score: 3
:DateUnix: 1452907766.0
:DateShort: 2016-Jan-16
:END:

********** I think that preference utilitarianism results in more bednets getting sent to africa, which is a pretty important difference. Well, to me anyway. It seems like something that's obviously ethical.
:PROPERTIES:
:Author: traverseda
:Score: 5
:DateUnix: 1452908267.0
:DateShort: 2016-Jan-16
:END:

*********** If you count compassion, charity, or benevolence as virtues it leads to bed nets being sent.
:PROPERTIES:
:Author: portodhamma
:Score: 2
:DateUnix: 1452909492.0
:DateShort: 2016-Jan-16
:END:

************ Less of them though. There are plenty of causes to be charitable or compassionate about.

The society for curing rare diseases in cute puppies as an example.

How do you choose what causes are important? The virtues of compassion and charity don't seem to provide any particular guidelines. Is it more compassionate to send your money to the society for cute diseases in rare puppies, or to send bednets in africa?
:PROPERTIES:
:Author: traverseda
:Score: 14
:DateUnix: 1452910862.0
:DateShort: 2016-Jan-16
:END:


************ Yeah, it leads to bed nets being sent, but it also leads to more donations to charities that don't actually use their money and resources to help anyone, or use less money to help someone than they could.
:PROPERTIES:
:Score: 6
:DateUnix: 1452935743.0
:DateShort: 2016-Jan-16
:END:


******** u/deleted:
#+begin_quote
  Largely because of two things: I believe motive matters in determining the goodness of an action, and deontology and consequentialism were ruled out.
#+end_quote

Who says there are only three options in the first place?
:PROPERTIES:
:Score: 1
:DateUnix: 1453012362.0
:DateShort: 2016-Jan-17
:END:

********* I'm considering virtue ethics to be consequentialism that depends on either terminally valuing virtues or virtues acting as a causal factor for other terminal values. I'd also expect some virtues to be convergent instrumental maxima for common human/prosocial/frontier-sharing values.
:PROPERTIES:
:Author: Transfuturist
:Score: 1
:DateUnix: 1453065174.0
:DateShort: 2016-Jan-18
:END:


****** I'm confused. Do you have a justification for why refraining from immortality is virtuous?

(It sounds like you do not have a justification for an obligation from immortality)
:PROPERTIES:
:Author: narfanator
:Score: 3
:DateUnix: 1452906112.0
:DateShort: 2016-Jan-16
:END:

******* Well a virtuous/enlightened person is not attached to their physical form. There's pretty much no obligation in virtue ethics, just traits that a virtuous person has that lead to Eudaimon or Nirvana.
:PROPERTIES:
:Author: portodhamma
:Score: 1
:DateUnix: 1452906289.0
:DateShort: 2016-Jan-16
:END:

******** That is a very strong claim to make, and it presupposes your worldview being correct.

Why would a virtuous person not be attached to their physical existence? Or an enlightened person? For both of these persons, the physical is all they have or can know, and both are obstructed from further good deeds and/or wisdom by the destruction of the carrier of their mind.

You can't be virtuous or wise if you die, mate. Death is a great big off switch. There is no "next life" to move on to.
:PROPERTIES:
:Author: Arizth
:Score: 12
:DateUnix: 1452916392.0
:DateShort: 2016-Jan-16
:END:

********* There is knowledge of non-physical things, just take imaginary numbers and other mathematical concepts
:PROPERTIES:
:Author: portodhamma
:Score: -4
:DateUnix: 1452916732.0
:DateShort: 2016-Jan-16
:END:

********** Neither of which are information states capable of understanding their own existence, nor modifying information states of reality around them, nor capable of deducing the existence of other concepts around them.

Or, in other words, non intelligent mathematical probabilities useful in describing concepts.

Additionally, we have proofs for these concepts, which makes them non-physical but deducable and reproducible in laboratory settings.
:PROPERTIES:
:Author: Arizth
:Score: 12
:DateUnix: 1452917251.0
:DateShort: 2016-Jan-16
:END:

*********** Just because they're deducible doesn't mean you find out things in a laboratory about them. What reproducible experiment shows that the square root of -1 can't be represented as a real number or that the amount of prime numbers is infinite? And moral facts and other non-physical attributes of the universe can be discovered in the same way.

[[http://plato.stanford.edu/entries/moral-realism/]]
:PROPERTIES:
:Author: portodhamma
:Score: -5
:DateUnix: 1452918791.0
:DateShort: 2016-Jan-16
:END:

************ I am not a mathematician, so I will not post layman-understanding level nonsense, but I am given to understand that people had to investigate and compile information to arrive at the theories you posted. These people were, in all likelihood, fairly smart.

They then had to prove said theories beyond reasonable doubt to other, reasonably likely to be fairly smart, people, who then would verify, eventually agree with, and disseminate this information.

By this logic, while I personally cannot give you the proofs, I can posit the position that, were you to study advanced mathematics and take a course that covers imaginary numbers in detail, you would have you fill of proofs, as well as how we arrived at them.
:PROPERTIES:
:Author: Arizth
:Score: 8
:DateUnix: 1452919421.0
:DateShort: 2016-Jan-16
:END:

************* I'm saying they were proved with logic, not experiments.
:PROPERTIES:
:Author: portodhamma
:Score: 0
:DateUnix: 1452919954.0
:DateShort: 2016-Jan-16
:END:

************** Proven, mate. Proved is the current variant to use when discussing something done by a person in the past (Ex: Bob proved Cindy was drinking the last of the coffee by checking the break room camera), while Proven is used for non-direct descriptions (Ex: Bob's theory of Cindy being the coffee finisher was proven after Steve reviewed the break room camera.)

Anyway, on topic, and I'm saying that they were proven experimentally for their field. Mathematical logic is the study of numbers and number theory. Philosophical logic is the study of ideas.

These are two distinct forms of logic, and are very different from one another.
:PROPERTIES:
:Author: Arizth
:Score: 10
:DateUnix: 1452921830.0
:DateShort: 2016-Jan-16
:END:

*************** u/Throne3d:
#+begin_quote
  Proven, mate. Proved is the current variant to use when discussing something done by a person in the past (Ex: Bob proved Cindy was drinking the last of the coffee by checking the break room camera), while Proven is used for non-direct descriptions (Ex: Bob's theory of Cindy being the coffee finisher was proven after Steve reviewed the break room camera.)
#+end_quote

I'm pretty sure the technical terms are "the [[https://en.wikipedia.org/wiki/Preterite#English][preterite]]" (or just the simple past, "I proved") and "the [[https://en.wikipedia.org/wiki/Participle#English][past participle]]" (also used in the [[https://en.wikipedia.org/wiki/Passive_voice#In_English][passive voice]], like "was proven"). According to [[http://grammarist.com/usage/proved-proven/][Grammarist]], "proved" is (at least sometimes, though not that often in my experience) acceptable in British English as a past participle (e.g. "I have proved" or "it is/was proved").
:PROPERTIES:
:Author: Throne3d
:Score: 4
:DateUnix: 1452955048.0
:DateShort: 2016-Jan-16
:END:

**************** Thank you. I tend to forget the technical terms, so I slip back into simple monkey descriptions.

We are speaking American dialect English on an American English forum, so I'd argue that we should preference using American dialect English. As far as I understand it, in American dialect English, it's as my example reads.

Am I incorrect?
:PROPERTIES:
:Author: Arizth
:Score: 4
:DateUnix: 1452955295.0
:DateShort: 2016-Jan-16
:END:

***************** Well, I'd probably typically write in a standard British English way, which is probably along the lines of writing in American English, but spelling some words like "colour" and "mum" as such, and perhaps forgetting a few of the weird 'translations' (like "pants", and "biscuits"), but pointing them out whenever I do write them (which is rarely).

It definitely /is/ an American English forum, though, and if I wrote something dialectal (I don't even know if I could, though? I don't usually use any dialectal wording) I'd include a translation. I'd personally be inclined to write "I proved" and "I've proven", but I'd be inclined to do that while speaking, too.

So, no, you're not incorrect, and I don't know if that person /is/ British, but I was just saying that if they /were/, it's actually, apparently, acceptable. It definitely read weirdly when I first saw it, though, so I'd say you're correct.
:PROPERTIES:
:Author: Throne3d
:Score: 4
:DateUnix: 1452956370.0
:DateShort: 2016-Jan-16
:END:


************** And where do you think logic comes from? What's the causal structure that allows embodied, physical creatures to obtain knowledge of logic?
:PROPERTIES:
:Score: 1
:DateUnix: 1453012663.0
:DateShort: 2016-Jan-17
:END:


************ Only under certain very specific meta-ethical views, which don't encompass the entirety of moral realism. There's a reason that everyone refers to non-naturalist moral realism as metaphysically queer.
:PROPERTIES:
:Score: 2
:DateUnix: 1453012616.0
:DateShort: 2016-Jan-17
:END:


******** u/deleted:
#+begin_quote
  Well a virtuous/enlightened person is not attached to their physical form.
#+end_quote

Maybe. But that's only really talking about a virtuous or enlightened person in conditions of extreme social and technological impoverishment. A person in a healthier, more developed, more grown-up society and ecosystem could well live a "virtuous" life, by whatever definition you imagine it, and also live indefinitely.

One of the troubles with things like deontology and virtue-ethics is that they take the society around them for granted. They can only function in a single historical-material moment.
:PROPERTIES:
:Score: 1
:DateUnix: 1453012544.0
:DateShort: 2016-Jan-17
:END:


******** I'm actually going to specifically disagree. If I take "entropic origins of life", "causaul entropic forcing", and a bit of musing on evolution (I'll go over those), I get that you /should/ be attached to your physical form.

First thing's first, however - the afterlife isn't a thing you should consider. Primarily for two reasons. The first is that it's /after/ this one, and live in the moment and all that. The second is that, if you are being virtuous for the sake of gain down the road, are you being virtuous? I'd definitely say that for the most part, virtue is an in-the-moment thing.

But back to the entropic stuff. There's three principles in play:

- A dead universe with entropy eventually develops life, due to 1) life is "better" at "entropy" (read the source material, these are both well-defined in this context) and 2) dead matter undergoes something resembling evolution that eventually results in live matter.
- An extremely reasonable explanation for the fundemental process of "intelligence" is "maximizing possible future". In more rigourous language, it's "maximize the entropic adjacency of all possible future states". Again, source material is good on this.
- Finally, it seems very reasonable to me that the story of evolution is the story of 1) bringing life to dead things (dead matter, then non-existence imaginary stuff, like ideas) and 2) ever-faster rates of change, currently culminating in an individual's memetics.

When considering all four of these things - "you can't take it with you", "dead matter becomes live matter", "live matter becomes smart matter", "smart means most possible futures"... it seems to me that the push of the universe is for you to have a physical body. If that's the push of the universe, seems like it'd be the virtuous path.

Notably, also implies we should terraform Mars.
:PROPERTIES:
:Author: narfanator
:Score: 1
:DateUnix: 1453229933.0
:DateShort: 2016-Jan-19
:END:


****** So you shouldn't hurt animals, but paying someone to hurt them is okay? That seems pretty arbitrary. If I don't like someone and I punch them in the face, that would be wrong. If I try to get around this by paying someone else to punch them in the face, it would be just as wrong.
:PROPERTIES:
:Author: DCarrier
:Score: 3
:DateUnix: 1452973803.0
:DateShort: 2016-Jan-16
:END:

******* You're basically doing that very thing right now by not living in the woods eating berries in a hut. Where do you think your rare earth minerals for your graphics card comes from? Or your chocolate?
:PROPERTIES:
:Author: portodhamma
:Score: -1
:DateUnix: 1452979859.0
:DateShort: 2016-Jan-17
:END:

******** I'm pretty sure they don't come from animals.

Everything you do will cause something to suffer in some form, but to the extent that it's something you can predict, what matters isn't directness. It's scale. If you eat a pound of meat, that causes quite a lot of suffering. If you drink a pound of milk, it causes less, but it's still significant.
:PROPERTIES:
:Author: DCarrier
:Score: 2
:DateUnix: 1452987127.0
:DateShort: 2016-Jan-17
:END:


******** [[https://en.wikipedia.org/wiki/Tu_quoque]]
:PROPERTIES:
:Author: metalknight
:Score: 1
:DateUnix: 1452981002.0
:DateShort: 2016-Jan-17
:END:

********* There's a very real causal difference. If you buy a chicken burrito from a 7-11 that chicken has already been slaughtered. Your individual demand from not eating meat won't result in there not being chicken in the freezer there. It's a very specific circumstance that isn't very lendable to punch-in-face analogies.
:PROPERTIES:
:Author: portodhamma
:Score: 1
:DateUnix: 1452981315.0
:DateShort: 2016-Jan-17
:END:

********** By purchasing the burrito, you're condoning the actions of the company, and funding them so they may kill more in the future.
:PROPERTIES:
:Author: metalknight
:Score: 1
:DateUnix: 1452982574.0
:DateShort: 2016-Jan-17
:END:

*********** Ah but if by buying things, you're condoning the methods used to acquire that thing, then by owning a computer, or tv, or house, or wood furniture, or chocolate you're condoning slavery and murder.
:PROPERTIES:
:Author: portodhamma
:Score: 1
:DateUnix: 1452982668.0
:DateShort: 2016-Jan-17
:END:

************ Yes, by using a computer you are, more likely than not, condoning the slavery and murder used to create it, proportional to your best estimate of the net good computers do vs. the net bad.

Luddites don't give polio vaccine to 10 million Africans.
:PROPERTIES:
:Author: metalknight
:Score: 1
:DateUnix: 1452982889.0
:DateShort: 2016-Jan-17
:END:

************* I disagree. I believe that since I can't survive without supporting companies that do horrible things, that ethical consumption is a fools errand. Even if I go buy land in the middle of nowhere and subsistence farm I'm still owning land that was stolen and probably murdered for, since I'm in America. The only solution is to be homeless and naked and only eat fruit plucked off of wild trees that you found.
:PROPERTIES:
:Author: portodhamma
:Score: 1
:DateUnix: 1452983186.0
:DateShort: 2016-Jan-17
:END:

************** Every fruit you eat is stolen from the mouth of another. The only solution is to kill yourself. Bad news, you were the next Florence Nightingale, had you survived you would have saved millions. See what's happening here yet?
:PROPERTIES:
:Author: metalknight
:Score: 2
:DateUnix: 1452983325.0
:DateShort: 2016-Jan-17
:END:

*************** Yes, but you're assuming good actions can be weighed against bad actions. That means can be justified by an end. Utilitarianism isn't the only moral system.
:PROPERTIES:
:Author: portodhamma
:Score: 0
:DateUnix: 1452984571.0
:DateShort: 2016-Jan-17
:END:

**************** If you feel compelled to value one moral system over another, you must have had a reason to do so.

a) If this reason involves departure from empiricism, you may as well not have used logic to get this far, if you were just going to scrap it at the last instant.

b) If your reason for choosing one over the other did involve logic, I argue that it is /that logical system itself/ that guides you, since it precludes it.
:PROPERTIES:
:Author: metalknight
:Score: 1
:DateUnix: 1452985751.0
:DateShort: 2016-Jan-17
:END:

***************** I have premises that I extrapolate from. Much like you. You probably accept that your senses are a reliable way of interacting with the world and that because something happened before under certain conditions it will happen again under the same conditions. I have different premises.
:PROPERTIES:
:Author: portodhamma
:Score: 1
:DateUnix: 1452985881.0
:DateShort: 2016-Jan-17
:END:

****************** Could you state your epistemology as a logic problem, with your premises and observations as givens? Perhaps that would help us to understand better.
:PROPERTIES:
:Author: metalknight
:Score: 1
:DateUnix: 1452986307.0
:DateShort: 2016-Jan-17
:END:

******************* I could, but if you look at the comment count, at least half of those are addressed to me and I don't really have the time.
:PROPERTIES:
:Author: portodhamma
:Score: 1
:DateUnix: 1452986575.0
:DateShort: 2016-Jan-17
:END:

******************** Gotcha, I'll hit you up later.
:PROPERTIES:
:Author: metalknight
:Score: 1
:DateUnix: 1452986814.0
:DateShort: 2016-Jan-17
:END:


***** u/deleted:
#+begin_quote
  As for ethics being only determinable through philosophical thought, well most people here and on lesswrong would actually agree with you, more or less.
#+end_quote

[[http://static.tvtropes.org/pmwiki/pub/images/imagesCA5KD61T_2953.jpg][BLAM heresy BLAM]]
:PROPERTIES:
:Score: 2
:DateUnix: 1453012300.0
:DateShort: 2016-Jan-17
:END:


***** Look up something called "Causal Entropic Forcing". It's the closest thing I've seen to math that you can really base a morality upon.
:PROPERTIES:
:Author: narfanator
:Score: 1
:DateUnix: 1452903680.0
:DateShort: 2016-Jan-16
:END:

****** I don't follow.
:PROPERTIES:
:Author: traverseda
:Score: 3
:DateUnix: 1452904267.0
:DateShort: 2016-Jan-16
:END:

******* Did you google and read the thing? I can probably help explain with a more pointed question.
:PROPERTIES:
:Author: narfanator
:Score: 1
:DateUnix: 1453229968.0
:DateShort: 2016-Jan-19
:END:


****** Maximizing the number of still-available potential futures just means forcing the present not to happen.
:PROPERTIES:
:Score: 1
:DateUnix: 1453012711.0
:DateShort: 2016-Jan-17
:END:

******* Hmm. That's true - they didn't put it to a test with a local maxima to get stuck in. I'll think on it some more with this in mind.
:PROPERTIES:
:Author: narfanator
:Score: 1
:DateUnix: 1453230005.0
:DateShort: 2016-Jan-19
:END:


**** [deleted]
:PROPERTIES:
:Score: 10
:DateUnix: 1452915160.0
:DateShort: 2016-Jan-16
:END:

***** I ask myself this a lot. I'm in the most intensive therapy program I can get in all of America. I don't kill myself because I don't think it will end things.
:PROPERTIES:
:Author: portodhamma
:Score: 2
:DateUnix: 1452915364.0
:DateShort: 2016-Jan-16
:END:

****** [deleted]
:PROPERTIES:
:Score: 10
:DateUnix: 1452916148.0
:DateShort: 2016-Jan-16
:END:

******* Thanks for the sentiment.
:PROPERTIES:
:Author: portodhamma
:Score: 2
:DateUnix: 1452916418.0
:DateShort: 2016-Jan-16
:END:


****** Would you think that Buddhism is a religion for those who see more bad experiences in life than good ones. I for instance don't want to kill myself because I believe that all the joy I have here would be irrevocably lost to me with the only thing I would face being utter oblivion. Oblivion being something similar to Nirvana but negative (instead of becoming one with everything you merely become nothing) though I don't see much practical difference between the two.
:PROPERTIES:
:Author: Bowbreaker
:Score: 1
:DateUnix: 1452967006.0
:DateShort: 2016-Jan-16
:END:


**** You do not experience the same reality as I do. That said, I somewhat subscribe to the idea that we can share an experience set and means of interaction but without "sharing" a reality.

If this is life, then, I guess, you'd call the series of reincarnations as meta-life?

With that word-usage - Why do you expect this life to be a primarily negative experience for all people, but (to put words in your mouth) the meta-life to be a primarily positive experience for all people?
:PROPERTIES:
:Author: narfanator
:Score: 3
:DateUnix: 1452904250.0
:DateShort: 2016-Jan-16
:END:

***** Because clinging to form prevents enlightenment. This is largely exhibited as a craving for a beautiful body and an aversion to death.
:PROPERTIES:
:Author: portodhamma
:Score: 1
:DateUnix: 1452904843.0
:DateShort: 2016-Jan-16
:END:

****** Many transhumanists don't actually cling to form or bodies though. They hope for things like body hopping, uploading, and even at some point cybernetically expanding their minds to levels that transcend physical dimensions. In a way they too thrive for reincarnation, just all in the one reality they /know/ to exist and without the loss of memory and personality that goes along with it. Though if I got you correctly you believe that we all already have achieved immortality and that you hope to get rid of it.
:PROPERTIES:
:Author: Bowbreaker
:Score: 5
:DateUnix: 1452967281.0
:DateShort: 2016-Jan-16
:END:

******* Clinging to form doesn't mean they want a particular form, it means they want a form at all.
:PROPERTIES:
:Author: portodhamma
:Score: 1
:DateUnix: 1452979758.0
:DateShort: 2016-Jan-17
:END:

******** The word "form" here being synonymous with "existence as a distinct and continual entity"?

Are you really saying that preference in favor of one's own existence is a bad thing? Do you have any argument in favor of that?
:PROPERTIES:
:Author: Bowbreaker
:Score: 3
:DateUnix: 1453058722.0
:DateShort: 2016-Jan-17
:END:


**** Hmmm, I have a friend who is a nihilist via philosophical insight I'm inclined to want to introduce you too him. But I admit it's mostly out of a desire to watch what fireworks come of it.
:PROPERTIES:
:Author: Nighzmarquls
:Score: 3
:DateUnix: 1452895103.0
:DateShort: 2016-Jan-16
:END:

***** Haha! I'm just a Buddhist anti-natalist. I do have a strong belief in the realism of morality, I just don't think the /continuation of life/ is moral.

EDIT: Moral /in itself/
:PROPERTIES:
:Author: portodhamma
:Score: 7
:DateUnix: 1452895477.0
:DateShort: 2016-Jan-16
:END:

****** That's a really fucked up interpretation of Buddhism, mate.

When the Buddha said that "life is suffering", he specifically referred to "want in life" is suffering, and that you end your suffering by ending you want.

Correct me if I'm wrong, but you comments in this thread have lead me to understand that you see death as the ending of that want and suffering, on the assumption that there is some metaphysical life and karma cycle to wade through posthumously.

This is incorrect for a number of reasons. Firstly, "end of want" is a goal to reach through meditation and study, and is supposed to end you up at "working for more, content with that I've got".

It's the origin of the phrase "Before enlightenment, chop wood and carry water. After enlightenment, carry water and chop wood."

Secondly, you can't enter into a rational discussion of the universe and bring metaphysical anything into it. For the purposes of rational conversation, introducing an inherently irrational element disrupts the whole thing, and invalidates your side. What sort of proof can you present for this karmic cycle and these next lived you mention?
:PROPERTIES:
:Author: Arizth
:Score: 11
:DateUnix: 1452916753.0
:DateShort: 2016-Jan-16
:END:

******* u/MugaSofer:
#+begin_quote
  That's a really fucked up interpretation of Buddhism, mate.
#+end_quote

Considering Buddhism advocates "escaping" the karmic cycle of rebirth as a central tenet, I'm not sure that's true.

#+begin_quote
  Secondly, you can't enter into a rational discussion of the universe and bring metaphysical anything into it. For the purposes of rational conversation, introducing an inherently irrational element disrupts the whole thing, and invalidates your side.
#+end_quote

Nothing is /inherently/ irrational, surely.
:PROPERTIES:
:Author: MugaSofer
:Score: 5
:DateUnix: 1452951200.0
:DateShort: 2016-Jan-16
:END:

******** It depends on the school of Buddhism you study. Like the monotheistic religions, there are a lot of sects.

On the grounds of rational agents, I'm labeling religious beliefs as inherently irrational due to that fact that they claim both dominion over and authority on information states that exist outside of reality. If we want to discuss extra-reality, then we may do. So, but we can't claim that our discussion will be rational within the boundaries of our reality.

An example of inherently irrational agents would be discussing classic fantasy magic. In our universe, rationality dictates that a human may not draw on natural energy unassisted, force it through a huge occult phase or state conversion and then release it as directed energy or matter, but a classic mage can summon a fireball and call up a golem without much issue.

In our universe, this is irrational, because the axioms that govern our existence show it to be impossible. As such, attempting to hold a conversation with someone who posits that such acts are possible in out reality contains an inherently irrational element, and is thus inherently irrational.
:PROPERTIES:
:Author: Arizth
:Score: 3
:DateUnix: 1452952454.0
:DateShort: 2016-Jan-16
:END:


******* Ok first of all, it means that being trapped in Samsara means you will experience dukkha, which /can/ be translated as suffering and is the translation I prefer. I don't think death leads to escape from Samsara, but I do believe death comes for us all and isn't the worst thing possible. The only way to escape Samsara is through he Eightfold Path.

And you should read Kant's /Critique of Pure Reason./ It really goes into metaphysics and its importance.
:PROPERTIES:
:Author: portodhamma
:Score: 2
:DateUnix: 1452917739.0
:DateShort: 2016-Jan-16
:END:

******** You keep using that word, "believe".

Unfortunately, "believe" isn't usually an acceptable scientific proof. Do you have some sort of reproducible evidence that pointed you to this world view?

How are you determining that we are "trapped" in samsara? How are you so certain we aren't living in Midgard, or that this isn't the actual afterlife where we pay for our per-comitted sins, or that we aren't wandering around the river lathe and hallucinating, or any number of other, similarly ridiculous religious hokum?
:PROPERTIES:
:Author: Arizth
:Score: 6
:DateUnix: 1452919590.0
:DateShort: 2016-Jan-16
:END:

********* Well the thing is I don't really need to convince you. I just believe what I need to to get by.
:PROPERTIES:
:Author: portodhamma
:Score: 1
:DateUnix: 1452919802.0
:DateShort: 2016-Jan-16
:END:

********** I'm not asking you to convince me, mate. I'm asking you to defend your worldview using a rational basis.

You're essentially dodging the question by saying "Well, I don't need to justify what I say to you."

Well, then keep your bloody mouth shut. I honestly find it disingenuous to state something as fact, then refuse to defend it when called on it.
:PROPERTIES:
:Author: Arizth
:Score: 7
:DateUnix: 1452921573.0
:DateShort: 2016-Jan-16
:END:

*********** People have asked me my opinions on things and I've told them. I never volunteered my beliefs uninvited.
:PROPERTIES:
:Author: portodhamma
:Score: 5
:DateUnix: 1452922427.0
:DateShort: 2016-Jan-16
:END:

************ Whatever sinks your raft, mate.

I question the sincerity of your opinion if you cannot defend it when questioned, but you are entitled to it.

Enjoy the rest of your life. I hope you find it as free from suffering as your entrapment allows.
:PROPERTIES:
:Author: Arizth
:Score: 5
:DateUnix: 1452923654.0
:DateShort: 2016-Jan-16
:END:


******** u/deleted:
#+begin_quote
  And you should read Kant's Critique of Pure Reason. It really goes into metaphysics and its importance.
#+end_quote

Ironically, it does so using pure reason, rather than empiricism.
:PROPERTIES:
:Score: 1
:DateUnix: 1453012838.0
:DateShort: 2016-Jan-17
:END:


****** I'm not sure if there is a solid word for me so I often just go with I am pragmatic/practical about things. However from my general understanding I'd predict you to view the existence of life to be moral? As per an example that a future with some life in it is better the one without it?
:PROPERTIES:
:Author: Nighzmarquls
:Score: 2
:DateUnix: 1452897918.0
:DateShort: 2016-Jan-16
:END:

******* I would not view any form of existence to be moral, only actions to be. The action of accepting death and impermanence is moral to me, as is the action of refraining from bringing life into the world.
:PROPERTIES:
:Author: portodhamma
:Score: 4
:DateUnix: 1452899662.0
:DateShort: 2016-Jan-16
:END:

******** I actually find this belief system interesting. Though I have a few questions, if you wouldn't mind.

What is your position on life-saving medical treatment? If the point is to accept death and impermanence, should life be fought for at all?

Is the 'next life' in your conception a sort of Dharma wheel of reincarnation into a better life in this world, or a progression to a steadily better world ending in the Buddhist Nirvana? Do your actions effect this at all (does virtuous action lead to virtuous reward?)

Doesn't that kind of belief necessarily remove itself over time from existence?

If you bar both reproduction and continuation of life, and are a non-missionary faith as Buddhism is, the spread of the idea is necessarily limited. Unless it is vastly more persuasive than any other idea, or there is some huge external pressure, its proponents will fade away rapidly as they die and not be replaced by new believers.

It's sort of like the extropian argument against people who are Pro-Death for religious reasons, only it happens much faster, because they aren't reproducing or accepting any life extension.
:PROPERTIES:
:Author: JackStargazer
:Score: 3
:DateUnix: 1452900861.0
:DateShort: 2016-Jan-16
:END:

********* Ok first, life-extending treatment is just that, life-extending. That is a fundamentally different goal than immortality. Accepting death should be on your own terms, though, anything less is murder and a removal of any choice.

And rebirth does not necessarily lead to better conditions. Bad karma is called bad for a reason. Good karma itself will not lead to enlightenment, though, only detachment from craving and aversion will.

And yes it will die out, even though /it is/ a missionary religion. As it said to have died out before. But it will be rediscovered (In the same way,even if civilization is destroyed, people will still rediscover calculus in time,it's a fundamental fact of the universe) and the cycle goes on. Buddhism is about the personal, and doesn't concern itself with effecting all of humanity.
:PROPERTIES:
:Author: portodhamma
:Score: 4
:DateUnix: 1452902063.0
:DateShort: 2016-Jan-16
:END:

********** One of the major points that Yudkowsky uses to argue for here-and-now immortality is that desiring, or expecting, some continued chain of afterlives (or a chain that terminates in a "forever") still /is/ immortality, it's just one that doesn't take place in this subset of reality. Now, generally, the LW writings on this are a little... aggressive, but the question's still valid.

That said, what I'm hearing from you is that it is not the seeking of immortality that dismays you, but the seeking of permanence....?
:PROPERTIES:
:Author: narfanator
:Score: 5
:DateUnix: 1452903967.0
:DateShort: 2016-Jan-16
:END:

*********** Indeed, but Buddhism's very goal is to end immortality. Nirvana is neither existence not non-existence, but it definitely isn't eternal life. Life is suffering, and ending suffering is the reason the Buddha sat under the Bohdi tree.

EDIT: All that arises is subject to its eventual dissolution.
:PROPERTIES:
:Author: portodhamma
:Score: 4
:DateUnix: 1452904113.0
:DateShort: 2016-Jan-16
:END:

************ I was under the impression that Buddhism's ultimate goal is to reach nirvana, a release from suffering and the cycle of death and rebirth. Which can be achieved during life, or death, and does not necessitate the existence of some other realm of being. For example, the Buddha is said to have reached nirvana while still alive, thus he lived without suffering.

Becoming immortal sounds quite like that goal, despite your unexplained and repeated objections.
:PROPERTIES:
:Author: zajhein
:Score: 3
:DateUnix: 1452929216.0
:DateShort: 2016-Jan-16
:END:

************* If I understood it correctly then many Buddhists believe that once you die after achieving Nirvana you lose your "self" in Nirvana like a drop of water in the ocean. In other words finally and actually dying with nothing akin to an afterlife awaiting you is the /goal/. You can say that adherents of the Abrahamic religions believe they are struggling to attain immortality but Buddhists seem to believe that everyone already has that and that we should try to get rid of it.
:PROPERTIES:
:Author: Bowbreaker
:Score: 3
:DateUnix: 1452966799.0
:DateShort: 2016-Jan-16
:END:

************** Reaching nirvana doesn't require you to die first though, unless that's a specific belief of a subset of Buddhism. Also Buddhas (those that reached nirvana) are said to come back and help mankind, not disappear forever, meaning they aren't stuck in the cycle but can supposedly choose.

So if you were to reach nirvana and simply not die, that wouldn't violate any tenant or virtue in Buddhism.
:PROPERTIES:
:Author: zajhein
:Score: 1
:DateUnix: 1453013483.0
:DateShort: 2016-Jan-17
:END:


************ u/metalknight:
#+begin_quote
  Nirvana is neither existence not non-existence, but it definitely isn't eternal life.
#+end_quote

I think what you mean is "some humans defined a word as this, yet I have no evidence for the existence of nirvana itself"
:PROPERTIES:
:Author: metalknight
:Score: 1
:DateUnix: 1452966175.0
:DateShort: 2016-Jan-16
:END:

************* People I trust have stated this to be true. I believe them. I've had experiences that I can't explain scientifically, but were predicted by Buddhism. That's my reason.
:PROPERTIES:
:Author: portodhamma
:Score: -1
:DateUnix: 1452979662.0
:DateShort: 2016-Jan-17
:END:

************** What experiences were these, and why is your reason for believing them stronger than the likelihood of the laws of physics remaining constant, as they evidently have for the last few billion years?
:PROPERTIES:
:Author: metalknight
:Score: 2
:DateUnix: 1452987179.0
:DateShort: 2016-Jan-17
:END:


********** u/Bowbreaker:
#+begin_quote
  Ok first, life-extending treatment is just that, life-extending. That is a fundamentally different goal than immortality.
#+end_quote

So life extension is okay then? Is that regardless of length? If there were a medical procedure to increase the duration of life and health for a hundred years would that still be acceptable in your worldview? What about a thousand or ten thousand years? What about living till the heat death of the universe or beyond it. After all /true/ guaranteed immortality is pretty much impossible anyway. There could always be something out there to finally kill you.

#+begin_quote
  And rebirth does not necessarily lead to better conditions.
#+end_quote

So what about people who are happy and healthy but are aware that they may have accumulated more bad karma than good? They don't necessarily fear death but prefer living a nice life to living a hard one. Wouldn't it be only sensible for them to try to extend their current life for as much as possible?

And I know that any life in any world is suffering due to wanting and craving things but in my own life experience I have more joy and positive emotions than I have pain or negative emotions. So you may understand that even Nirvana itself does not seem like something to strive for to me as it would mean an and to all of these experiences that I rather enjoy experiencing. Why would it be the moral thing to do to give all of that up anyway? Who do I help? What moral good do I advance by doing so?
:PROPERTIES:
:Author: Bowbreaker
:Score: 2
:DateUnix: 1452966527.0
:DateShort: 2016-Jan-16
:END:


**** u/Bowbreaker:
#+begin_quote
  and move on to the next life to reap their karma.
#+end_quote

But what if it turns out that there is no next life? Would everyone still deserve to die?
:PROPERTIES:
:Author: Bowbreaker
:Score: 2
:DateUnix: 1452965427.0
:DateShort: 2016-Jan-16
:END:

***** Yes
:PROPERTIES:
:Author: portodhamma
:Score: -2
:DateUnix: 1452979554.0
:DateShort: 2016-Jan-17
:END:

****** Why?

And to clarify: By deserve to die I didn't mean if everyone should have the right to die once they truly wish to do so. I meant if everyone deserves to have their lifespan limited regardless of their wishes and even though no reward or punishment that would be different from anybody else's reward or punishment awaits them.
:PROPERTIES:
:Author: Bowbreaker
:Score: 2
:DateUnix: 1453058380.0
:DateShort: 2016-Jan-17
:END:


**** What's your empirical basis for the existence of "karma", and subsequently, what's your empirical basis for believing that the concept of "karma" will be visited upon them after death?
:PROPERTIES:
:Author: metalknight
:Score: 2
:DateUnix: 1452967047.0
:DateShort: 2016-Jan-16
:END:


**** u/deleted:
#+begin_quote
  Well I think that life is primarily a negative experience
#+end_quote

Hmmm... I'm not sure about "primarily", but I actually partly agree. Life is /currently/ a /sufficiently/ negative experience that there are great parts of it which I have zero desire to repeat. /That disturbs me immensely/, and makes me feel as if I must be some unusually emotionally damaged individual, especially for having a materially privileged life, but no, the more other people I meet, the more it turns out that /life just sucks like that/, at least right now.

[[http://meaningness.com/kitsch][I just don't consider this a universal or eternal truth.]] I consider it a local trend of my local space-time, and remind myself that "final truths" and "eternal laws", as actually viewed by humans, have actually tended to change about every one to two generations. The things I know as "eternal" will completely cease to be by the time I'm middle-aged. Therefore, I should disregard them and press to make life and the world /better/.

#+begin_quote
  and people deserve to die and move on to the next life to reap their karma
#+end_quote

Aside from [[http://meaningness.com/atheism-first-step][telling you there is no next life or karma]], I fail to understand how this ties in with the first part of your sentence. If existence is mostly negative, why would it be /right/ for people to go on to yet another lifetime of negativity?

#+begin_quote
  And I believe that ethics can only be determined through philosophical insight, I think that the Is/Ought barrier is pretty strong.
#+end_quote

Tell us, what's the causal structure of the "philosophical insight" to which you refer?
:PROPERTIES:
:Score: 2
:DateUnix: 1453012201.0
:DateShort: 2016-Jan-17
:END:


** For what it's worth: immortality and effective altruism are not "new atheist and transhumanist platforms". Immortality and charity are major components of many religions.

Indeed, opposition to them tends to be from either secular or explicitly atheistic grounds (not that this has any epistemic ramifications WRT whether they're good ideas.)

In general, this sub is much more effective-altruist and transhumanist than it is atheist. If you dislike those things, I would probably not /recommend/ the sub (although that doesn't mean you'd necessarily hate hate it.) There /is/ "discussion challenging basic ideas of the LessWrong movement", but it's not a focus, and those ideas /are/ often assumed.
:PROPERTIES:
:Author: MugaSofer
:Score: 6
:DateUnix: 1452950281.0
:DateShort: 2016-Jan-16
:END:


** u/Roxolan:
#+begin_quote
  will I like the discussion in this sub if I'm not a proponent of immortality, effective altruism, or other new atheist and transhumanist platforms?
#+end_quote

Probably not. Most of the stories being shared here, and much of the conversation about them, take the goodness of transhumanism, immortality and effective altruism for granted.
:PROPERTIES:
:Author: Roxolan
:Score: 16
:DateUnix: 1452893802.0
:DateShort: 2016-Jan-16
:END:

*** Basically this. Rationalism is about accomplishing your goals, but many of the stories here accept immortality and altruism as the main goals worth achieving.
:PROPERTIES:
:Author: JackStargazer
:Score: 18
:DateUnix: 1452894465.0
:DateShort: 2016-Jan-16
:END:

**** See, that's why I liked Worm. There was an ensemble cast with different goals largely being pursued rationally. I haven't read the Metropolitan, but I doubt many people here would side with /Lex Luthor/ over Superman unless the characterization is completely changed, but people here seem to love it.

I just want to be able to discuss some of the ideas presented in linked articles without hostility being thrown my way. Tbh, even the people who said I wouldn't like it here have been pretty polite and respectful so I'll probably be just fine.
:PROPERTIES:
:Author: portodhamma
:Score: 5
:DateUnix: 1452895278.0
:DateShort: 2016-Jan-16
:END:

***** Worm isn't widely accepted as a rational story I don't think, at least I've seen a lot of discussion over whether or not it even fits.

#+begin_quote
  I haven't read the Metropolitan, but I doubt many people here would side with Lex Luthor over Superman unless the characterization is completely changed, but people here seem to love it.
#+end_quote

wat, if you haven't read it of course you have no idea why people might side with Lex Luthor in the story... That's like saying you haven't read history but have no idea why people could not like Hitler since he was such a charismatic guy.

#+begin_quote
  will I like the discussion in this sub if I'm not a proponent of immortality, effective altruism, or other new atheist and transhumanist platforms?
#+end_quote

Depends what threads you read, most of the discussion is on the stories posted, and not all of them are immediately about those three things.
:PROPERTIES:
:Author: RMcD94
:Score: 21
:DateUnix: 1452896589.0
:DateShort: 2016-Jan-16
:END:

****** u/Bowbreaker:
#+begin_quote
  Worm isn't widely accepted as a rational story
#+end_quote

I always thought that it was accepted as mostly rational but not as rational/ist/.
:PROPERTIES:
:Author: Bowbreaker
:Score: 3
:DateUnix: 1452965073.0
:DateShort: 2016-Jan-16
:END:


****** I do appreciate moral complexity in stories, regardless of the protagonist's beliefs. To often we see fiction with no examination of why someone thinks they're right and their enemies are wrong. I'm glad /The Metropolitan/ has that more than the usual Superman tale. And you were right about me making assumptions on a work I never read.
:PROPERTIES:
:Author: portodhamma
:Score: 2
:DateUnix: 1452900175.0
:DateShort: 2016-Jan-16
:END:

******* What rationalist stories have you read then? Or did you randomly stumble upon this subreddit without having read any of the fiction that is usually discussed here?
:PROPERTIES:
:Author: Bowbreaker
:Score: 1
:DateUnix: 1452965128.0
:DateShort: 2016-Jan-16
:END:

******** Well I read the first few chapters of HPMOR, most of Alicorn's stuff, Wildbow's stuff, and some other things I don't remember cuz it was a while back.
:PROPERTIES:
:Author: portodhamma
:Score: 1
:DateUnix: 1452979536.0
:DateShort: 2016-Jan-17
:END:

********* So did you like Alicorn's stuff?
:PROPERTIES:
:Author: Bowbreaker
:Score: 1
:DateUnix: 1453058572.0
:DateShort: 2016-Jan-17
:END:


***** Would you feel comfortable if /one/ man had unilateral control over the worlds nuclear arsenal, no matter how sane and reasonable he is?

There is definitely room to be sympathetic to Lex Luthor. I suspect a lot of people here have less tribalism then average. You don't need to side with Lex Luthor to appreciate his competence, and you don't have to be against superman to realize that he's a potential world-ending catastrophe.

We don't tend to side with people. There's plenty of criticism for both Lex Luthor and superman in the discussions around it.
:PROPERTIES:
:Author: traverseda
:Score: 15
:DateUnix: 1452896395.0
:DateShort: 2016-Jan-16
:END:


***** u/Roxolan:
#+begin_quote
  I doubt many people here would side with Lex Luthor over Superman unless the characterization is completely changed
#+end_quote

[[#s][(Broad analysis of The Metropolitan Man, not really a spoiler)]]
:PROPERTIES:
:Author: Roxolan
:Score: 11
:DateUnix: 1452897163.0
:DateShort: 2016-Jan-16
:END:

****** My biggest problem with canon Lex Luthor is that he declared nemesis because Superman accidentally made him go bald.
:PROPERTIES:
:Author: Transfuturist
:Score: 7
:DateUnix: 1452915369.0
:DateShort: 2016-Jan-16
:END:


***** I just want to have a subreddit where I can say "I don't like death" and not be attacked (the way it is in most other subreddits). I want a subreddit where atheism is taken for granted and I can discuss literature. And that is this subreddit.
:PROPERTIES:
:Author: lehyde
:Score: 28
:DateUnix: 1452896232.0
:DateShort: 2016-Jan-16
:END:

****** u/BadGoyWithAGun:
#+begin_quote
  I just want to have a subreddit where I can say "I don't like death" and not be attacked
#+end_quote

I agree with the general sentiment, but I don't think it's worth pursuing. Instrumental rationality overrides virtue signalling, no?

#+begin_quote
  I want a subreddit where atheism is taken for granted
#+end_quote

The epistemic belief, or the accompanying ideological garbage? The former I share, the latter I reject and oppose - as a matter of fact, due to their conflation, I don't like associating with "atheism" at all.
:PROPERTIES:
:Author: BadGoyWithAGun
:Score: 6
:DateUnix: 1452898899.0
:DateShort: 2016-Jan-16
:END:

******* u/FeepingCreature:
#+begin_quote
  I agree with the general sentiment, but I don't think it's worth pursuing. Instrumental rationality overrides virtue signalling, no?
#+end_quote

It's a fuzzy, not a util. Fuzzies are important too, and the market for this one is small.
:PROPERTIES:
:Author: FeepingCreature
:Score: 6
:DateUnix: 1452936890.0
:DateShort: 2016-Jan-16
:END:


****** The funny thing is, I don't believe in any gods either, and I believe my stance on immortality is harder to justify than yours. There's a lot of baggage that comes with many atheists regarding scientism that I don't want to be attacked over not sharing like I would be in [[/r/atheism]].

You guys have been really respectful of my beliefs, so I think I might stick around.
:PROPERTIES:
:Author: portodhamma
:Score: 4
:DateUnix: 1452899948.0
:DateShort: 2016-Jan-16
:END:

******* Don't worry generally this is a place where defensible belief or honest skepticism are not attacked.
:PROPERTIES:
:Author: Empiricist_or_not
:Score: 8
:DateUnix: 1452903365.0
:DateShort: 2016-Jan-16
:END:

******** It would be nice if [[/u/portodhamma]] would actually present either of those two things you mentioned.
:PROPERTIES:
:Author: metalknight
:Score: 2
:DateUnix: 1452987969.0
:DateShort: 2016-Jan-17
:END:


******* Gonna be real here, if you bring up the word "scientism" in here you should probably expect people to call you out on it.

If you don't, though, then we can all pretend there's no problems and talk about stories.
:PROPERTIES:
:Author: Detsuahxe
:Score: 7
:DateUnix: 1452945104.0
:DateShort: 2016-Jan-16
:END:

******** I would defend my beliefs better, but I have over 20 replies in my inbox right now and I really have better things to do. I spend all yesterday commenting on this thread and I don't plan on spending today doing so.
:PROPERTIES:
:Author: portodhamma
:Score: 1
:DateUnix: 1452979188.0
:DateShort: 2016-Jan-17
:END:


******* Holy crap, not here too.

Seriously, scientism isn't a thing. You cannot seriously claim to hold a rational viewpoint and still insist that there exist things outside the sphere of rational definition by the physical sciences.
:PROPERTIES:
:Author: Arizth
:Score: 16
:DateUnix: 1452915998.0
:DateShort: 2016-Jan-16
:END:

******** /hugs/
:PROPERTIES:
:Author: FeepingCreature
:Score: 7
:DateUnix: 1452936936.0
:DateShort: 2016-Jan-16
:END:


******** u/deleted:
#+begin_quote
  Seriously, scientism isn't a thing.
#+end_quote

Let me put this in Bayesian terms. There is a /vast/ difference between stating what the posterior distribution /is/, stating a predictive distribution that marginalizes out the latent variables (ie: the parameters or causal structure being inferred), and just standing there yelling that everyone needs to shut up and accept that maximum a posteriori estimator as The Truth Because Science/Bayes.

That last thing is what sometimes gets called "scientism", and as you can see from the statements above, it's a genuine error.

But unfortunately, the actual word "scientism" is usually just used for "the natural sciences need to stop encroaching on my field's reserved turf."
:PROPERTIES:
:Score: 4
:DateUnix: 1453010861.0
:DateShort: 2016-Jan-17
:END:


******** Homie you are disregarding the consensus of most philosophers.
:PROPERTIES:
:Author: portodhamma
:Score: 1
:DateUnix: 1452916112.0
:DateShort: 2016-Jan-16
:END:

********* And when I say there's no god, I'm disregarding the consensus of most priests.
:PROPERTIES:
:Author: Detsuahxe
:Score: 6
:DateUnix: 1452945151.0
:DateShort: 2016-Jan-16
:END:


********* Most philosophers who aren't trained doctors, scientists, or engineers?

Who argue over things that have definitive answers in the related field of study?

No, mate. I'm going to go ahead and do the thing humanity has been doing so well for millenia: validate claims, assimilate useful knowledge, and prune the bullshit branches.

You do a lot of pruning. Especially in philosophy.
:PROPERTIES:
:Author: Arizth
:Score: 9
:DateUnix: 1452917005.0
:DateShort: 2016-Jan-16
:END:

********** Do engineers learn about the nature of knowledge when they learn how to compress air and ignite it to push a plane through the air or did they just learn how to make a jet?
:PROPERTIES:
:Author: portodhamma
:Score: 3
:DateUnix: 1452918026.0
:DateShort: 2016-Jan-16
:END:

*********** Engineers learn about the nature of the physical universe. In your example, aeronautic engineers will learn about everything from mechanical principles and chemistry to specialized branches of advanced physics.

Information is the universe, and the universe is information. You cannot, in a physical deterministic reality like our own, separate the two. Through the study of information, you gain knowledge.

Yes, MOST engineers don't pursue the study of the study of their fields, they simply study their fields. In such a manner, most people in general do not study the field of investigation and reason, because it is not their primary focus in their existence.

Nevertheless, these people are all dependent on information state analysis for their day-to-day existence, and without the ability to process this information and derive knowledge from it, these people cease to be people, and become lifeless meat. We call this process termination death.

There is no credible evidence for any sort of non-physical intelligence processor running under, over, or in parallel with the purely physical information processor we call our brain. And believe me, people have been looking for one for a long time.
:PROPERTIES:
:Author: Arizth
:Score: 13
:DateUnix: 1452919235.0
:DateShort: 2016-Jan-16
:END:


*********** Well that depends. Did they do experiments in a lab whose outcomes they didn't know ahead of time? Did they account for errors and adjust their experimental apparatus to eliminate known errors? Have they been genuinely surprised?

Having your experiments go wrong on you a few times straight, resulting in shitty data from which no substantial inferences can be drawn at all, will teach you more about the nature of knowledge, and quickly, than most epistemology lectures manage to leave behind in your head after six months away.
:PROPERTIES:
:Score: 3
:DateUnix: 1453010971.0
:DateShort: 2016-Jan-17
:END:


*********** u/Bowbreaker:
#+begin_quote
  Do engineers learn about the nature of knowledge
#+end_quote

That would be neurologists more so than engineers.
:PROPERTIES:
:Author: Bowbreaker
:Score: 2
:DateUnix: 1452964980.0
:DateShort: 2016-Jan-16
:END:


******* I'm hoping that someone can see the argument I'm trying to make for why all existing things are within the sphere of rational definition by the physical sciences and can spell out the point for someone unfamiliar with the jargon:

AIXI (which keeps track of probabilities for all the infinitely many possible scientific theories, and does whatever action has the highest expected value for its utility function) runs purely on science and does well at fulfilling its utility function; therefore we may as well act like we think AIXI would to satisfy our own values.
:PROPERTIES:
:Author: Gurkenglas
:Score: 1
:DateUnix: 1452946511.0
:DateShort: 2016-Jan-16
:END:

******** u/deleted:
#+begin_quote
  AIXI ... does well at fulfilling its utility function
#+end_quote

[[http://jmlr.org/proceedings/papers/v40/Leike15.pdf][That's a very contestable statement]], on several different grounds besides just the one I'm linking.
:PROPERTIES:
:Score: 2
:DateUnix: 1453011074.0
:DateShort: 2016-Jan-17
:END:


***** u/MugaSofer:
#+begin_quote
  I haven't read the Metropolitan, but I doubt many people here would side with Lex Luthor over Superman unless the characterization is completely changed, but people here seem to love it.
#+end_quote

/Metropolitan Man/ does feel quietly critical of many Rationalist beliefs and tropes, although it's very much internal, self-reflective criticism.

#+begin_quote
  I just want to be able to discuss some of the ideas presented in linked articles without hostility being thrown my way. Tbh, even the people who said I wouldn't like it here have been pretty polite and respectful so I'll probably be just fine.
#+end_quote

Hmm. Maybe.

The overwhelming majority should be fine, but I do remember some people jumping down the throats of religious commenters during discussion of a fic with religious themes (/Ginny Weasley an the Sealed Intelligence/).
:PROPERTIES:
:Author: MugaSofer
:Score: 3
:DateUnix: 1452950969.0
:DateShort: 2016-Jan-16
:END:


** I'm not a proponent of immortality, EA, new atheism or transhumanism and I find it fine here. Mostly we discuss works of fiction. In OT threads we typically discuss news, life strategies, personal stuff, and so on.
:PROPERTIES:
:Author: blazinghand
:Score: 5
:DateUnix: 1452924311.0
:DateShort: 2016-Jan-16
:END:


** India isn't really a Hindu nation / America isn't a Christian nation but most of it's citizens are - as in, there's a deeply embedded social norms against attacking non-conformers despite a majority consensus concerning belief. (But certainly no barrier to aggressively criticizing non-conforming ideas without targeting the human behind them)

I'd say it's roughly the same relationship of [[/r/rational]]'s relationship to transhumanist/atheist/effective altruist/ lesswrongish ideologies.
:PROPERTIES:
:Author: glowingfibre
:Score: 3
:DateUnix: 1452911374.0
:DateShort: 2016-Jan-16
:END:


** A few comments for you:

1. This sub is for discussion of fiction. This post is off-topic, despite the fact that one of our mods was polite enough to respond.
2. The answer to your question was in the sidebar -- the sub is about discussing fiction, not the philosophy of any particular group.
3. In programming circles, the response to a question like this would usually be "TIAS", meaning "Try It And See." In other words, instead of posting this question, you would be far better served to just read some of the stories and see if you like them.
4. Your question eseentially boils down to "no matter how good a story is, I do not want to read it if it will expose me to certain ideas." Given that fact, the fact that you did not read the sidebar, and your unwillingness to TIAS, I've got a fairly high prior that no, you will not enjoy this sub. I hope you will try it anyway and then tell me that I'm wrong and you actually do enjoy the fiction and community here, but that's not what I would expect to happen.
:PROPERTIES:
:Author: eaglejarl
:Score: 5
:DateUnix: 1452957316.0
:DateShort: 2016-Jan-16
:END:

*** I'm actually fine with those "certain ideas" but I was wondering if every story took them as an unchallenged good.
:PROPERTIES:
:Author: portodhamma
:Score: 2
:DateUnix: 1452979395.0
:DateShort: 2016-Jan-17
:END:


** I am interested on your take on why I want immortality:

I want immortality because it seems like a pre-requisite for "fork-and-merge". That is, I want to make both choices, experience both outcomes, and then return to being a single individual. Ideally, I would like to do this without regards to time - fork myself sometime in the past, and meet them throughout the resulting "timeline".

For example, if I'd gone with the other choice for college. Or, being pursuing two different careers.
:PROPERTIES:
:Author: narfanator
:Score: 2
:DateUnix: 1452906252.0
:DateShort: 2016-Jan-16
:END:

*** I don't really follow. Wouldn't you need to be able to upload your consciousness also? Or do you think that immortality is the only way you can live long enough to see the aforementioned upload.
:PROPERTIES:
:Author: portodhamma
:Score: 2
:DateUnix: 1452906442.0
:DateShort: 2016-Jan-16
:END:

**** If he ever acquires the ability to fork-and-merge, he'll presumably only ever try suicide during a fork-and-merge, leaving only the selves that didn't attempt it. /s
:PROPERTIES:
:Author: Gurkenglas
:Score: 1
:DateUnix: 1452949042.0
:DateShort: 2016-Jan-16
:END:


*** Sounds like Emily and Control.

I'm not sure the concept of merging without losing either information/knowledge/behavior or similarity of structure has a sensible counterpart.
:PROPERTIES:
:Author: Transfuturist
:Score: 1
:DateUnix: 1453066326.0
:DateShort: 2016-Jan-18
:END:


** I think a lot of the works of fiction presented on this sub has themes of:

- Technological utopianism: the human condition can and should be improved upon with technology.
- Transhumanism: technology can augment and improve human experience and capability.
- Anti-deathism: death is neither necessary nor inevitable.
- High stakes: it's about saving all of humanity's future.

It is not always apparent, but I suspect most stories will have an end-game utopia incorporating those themes.

Anecdotally, I would think that most people come for the litterature first, and the themes second, but this is a sub for the specific genre of fiction --- sure, we have the necessary description in the sidebar, but there is also a âculture' surrounding ratfic.
:PROPERTIES:
:Author: mhd-hbd
:Score: 2
:DateUnix: 1453199785.0
:DateShort: 2016-Jan-19
:END:


** I wouldn't like associating atheism and transhumanism with LW just as much as doing it with rationalism in general for the same reason that I don't like EY's influence too.

That being said, it's hard to make a good story in this genre if the plot\protagonists ignore things like atheism (unless it's [[http://tvtropes.org/pmwiki/pmwiki.php/Main/FlatEarthAtheist][flat earth atheism]] --- which, interestingly enough, was [[http://i.imgur.com/xn4cYl4.png][Hariezer Yudotter's]] reaction to souls) and transhumanism.

Many of the stories I've noticed here so far also frequently deal with munchkining, loophole abuse, deconstruction of classic genres or works, and (sometimes) exploration of paradoxes and philosophical concepts.
:PROPERTIES:
:Author: OutOfNiceUsernames
:Score: 4
:DateUnix: 1452895631.0
:DateShort: 2016-Jan-16
:END:

*** A yudotter just sounds like a cute critter.
:PROPERTIES:
:Author: LiteralHeadCannon
:Score: 1
:DateUnix: 1453000201.0
:DateShort: 2016-Jan-17
:END:


** Having read the rest of your comments in this thread, let me start a new one.

There's a common belief on LessWrong that beliefs require justification. That is, a complicated belief should be supplemented by a correspondingly large amount of evidence.

Do you have evidence for your beliefs commensurate with their complexity? If not, why do you hold them and not others?
:PROPERTIES:
:Author: FeepingCreature
:Score: 5
:DateUnix: 1452937114.0
:DateShort: 2016-Jan-16
:END:

*** um... is posting about a 'common belief on LessWrong' a good way to respond to the original post?
:PROPERTIES:
:Author: ayrvin
:Score: 2
:DateUnix: 1452972909.0
:DateShort: 2016-Jan-16
:END:

**** Well, I'm sort of obliquely inviting the parent to challenge that belief if they want.
:PROPERTIES:
:Author: FeepingCreature
:Score: 2
:DateUnix: 1452976398.0
:DateShort: 2016-Jan-17
:END:


** I think that there are enough people openly associated with LW on this sub that the answer is, "Yes." But it doesn't have to be, that's just the userbase it has right now.
:PROPERTIES:
:Score: 1
:DateUnix: 1453010369.0
:DateShort: 2016-Jan-17
:END:


** [removed]
:PROPERTIES:
:Score: -3
:DateUnix: 1452989947.0
:DateShort: 2016-Jan-17
:END:

*** You're not being very charitable. I'm doing the best I can.
:PROPERTIES:
:Author: portodhamma
:Score: 2
:DateUnix: 1452990021.0
:DateShort: 2016-Jan-17
:END:

**** If you're discussing in good faith, stick around. "I'm bailing because there's too much discussion" sounds, at least in my ears, like an excuse. Few people bail on conversations that they are enjoying, and they generally don't leave long, ambiguous, mystical screeds behind.

I will comment that, had your excuse been something like "I'm really enjoying this, but I have a paper due tomorrow and need to go write it" then I doubt anyone would have said anything.

Speaking of which, I have a quest due tomorrow and need to go write it.
:PROPERTIES:
:Author: eaglejarl
:Score: 3
:DateUnix: 1452998723.0
:DateShort: 2016-Jan-17
:END:


**** Charitable is not the appropriate term here. The statement is, nonetheless, entirely rude and not likely to engage you in productive discussion at all.
:PROPERTIES:
:Score: 1
:DateUnix: 1453015778.0
:DateShort: 2016-Jan-17
:END:

***** Rude, or merely accurate? [[/u/portodhamma]] is obviously not willing to discuss in good faith, [[https://www.reddit.com/r/rational/comments/4157fx/is_this_a_lesswrong_sub/cz0vj4e?context=3][they shroud themselves in mysticism and "I know better than you cuz my friend said so"]]. You will note that I only used such accurate terms [[https://www.reddit.com/r/rational/comments/4157fx/is_this_a_lesswrong_sub/cz0rlj0][after giving them the opportunity to respond with a rational basis for their beliefs]]. I think they may be more comfortable in subreddits like [[/r/occult]], [[/r/alchemy]], or [[/r/astrology]], where claims of knowledge aren't so well scrutinized.
:PROPERTIES:
:Author: metalknight
:Score: 1
:DateUnix: 1453047957.0
:DateShort: 2016-Jan-17
:END:


**** In all honesty, I'd love to hear what you have to say, but if you refuse to say it, you sound like a charlatan.
:PROPERTIES:
:Author: metalknight
:Score: 1
:DateUnix: 1452990140.0
:DateShort: 2016-Jan-17
:END:

***** I didn't start this thread to justify my worldview. I just wanted to know a little about the board culture. This blew up much more than what I was prepared for.
:PROPERTIES:
:Author: portodhamma
:Score: 1
:DateUnix: 1453058799.0
:DateShort: 2016-Jan-17
:END:

****** Don't worry about it. This is likely just a misunderstanding caused by a cultural gap. As I said earlier:

#+begin_quote
  Also, I just want to make this clear just in case you don't understand and get offended, when we disagree with or contradict other people's opinions, we're NOT claiming any superiority over them nor trying to establish ourselves as dominant over them in any way whatsoever. Many of us are genuinely glad when we are proven wrong about something.
#+end_quote

If someone gets defensive about a belief and starts responding to people rather than responding to the things that they're saying, it looks to many of us like that person is shutting the door in our faces on the discussion. People here consider that very rude. To us, communication is information-sharing. If no information is shared, then nothing is communicated. This conversation was started because someone was curious about what you believe and why. They were asking about your beliefs, not about you. When you began answering their questions and engaging in the discussion, they thought you were ONLY talking about beliefs, they didn't see it as an attempt to get to know each other by exchanging cultural ideas.

This kind of cultural misunderstanding happens all the time. This article does an amazing job of explaining it:

[[http://status451.com/2016/01/06/splain-it-to-me/]]

It's really fascinating, I highly recommend reading it. I hope you don't get the wrong impression about this community. We're actually a really thoughtful and friendly bunch, we just have a bit of a...PR problem I guess you could call it because of misunderstandings like this.
:PROPERTIES:
:Author: Sailor_Vulcan
:Score: 1
:DateUnix: 1453165760.0
:DateShort: 2016-Jan-19
:END:
