#+TITLE: [Discussion] /r/rational has a lot of clever people. Let's solve some problems.

* [Discussion] /r/rational has a lot of clever people. Let's solve some problems.
:PROPERTIES:
:Author: traverseda
:Score: 17
:DateUnix: 1405158137.0
:END:
Anyone have any problems they want to discuss?

--------------

I'd like to say discuss the problem space in full before proposing solutions, but in this format that's kind of hard.


** I have a problem with capitalism in general.

It's kind of a stupid optimization processes. But it does work, generally. Just replacing it with something else entirely isn't likely to work, if only because whatever we'd replace it with would need to be /complicated/. And have rules for updating the rules and all that built in. And also generally out-compete capitalism, which is hard if you don't have some way of enforcing cooperation.

My biggest complaint with capitalism is that it's optimizing (poorly, all things considered) towards a damn stupid utility function. That is, profit of a single business entity. Not profit of a society of a whole.

It's captured value vs created value. In capitalism, it doesn't matter how much value you create across your entire society. Just how much value you manage to capture. That leads to a lot of entities choosing, let's say, 2 private utilitons (units of utility) and 1 public utiliton, instead of choosing 1 private and 3 public. Sure, there's more overall utility in situation two, but there are selection pressure's to consider.

The most relevant examples of captured vs created value are probably health care and student loans. An educated populace increases utility across society as a whole, but universities have know way of capturing any of the value they create. We use student loans as a sort of shim, but it still completely decouples value creation from receiving value. Instead favoring schools that can attract large numbers of students and operate cheaply.

So what approaches might we take to solving that? Either changing capitalisms utility function or figuring out alternative ways to run (scale models of) a society?
:PROPERTIES:
:Author: traverseda
:Score: 22
:DateUnix: 1405158586.0
:END:

*** YOU. I /like/ you.

#+begin_quote
  My biggest complaint with capitalism is that it's optimizing (poorly, all things considered) towards a damn stupid utility function. That is, profit of a single business entity. Not profit of a society of a whole.
#+end_quote

Capital/money is optimization power, stored in liquid form. This makes it pretty easy to explain what the hell is actually going on when we say someone is "poor" or "rich", /especially/ when we remember that people can only optimize in limited ways and at limited rates via singular, personal effort. Capitalism just maximizes capital, but... /yeah/. Bloody stupid utility function.

Personally, my favored solutions are [[http://en.wikipedia.org/wiki/Worker_cooperative][syndicalism/cooperatives]], [[http://en.wikipedia.org/wiki/Basic_income][guaranteed basic incomes]], and several forms of [[http://en.wikipedia.org/wiki/Georgism][Georgism]]. I also like the idea for [[https://www.jacobinmag.com/2012/12/the-red-and-the-black/][socialized capital markets]], but think it needs a bunch more work to get it beyond "Just socialize the institutional investors", since you want a system that can direct investment by well-informed individuals to social purposes just as well as it directs mass investment by professional financial managers to such purposes.

What can be said, to those who read the links, is that each of these "reforms": is actually a major change in class relations, can be executed (hypothetically) through ordinary and nonviolent politics, and /has actually been tried and found to succeed in experiments/.

If [[/u/mylittleeconomy]] could come over here, being a market monetarist, I'd also like to propose a kind of "Georgist money", in which currency is issued as a liability/entitlement to some form of positional or ecological (ie: Truly Scarce, cannot be made in a factory) good.

I expect that any and all of these changes, made individually or together, would make the world a much better place, and, notably, a much safer place for other things rationalists like, such as transhumanism. I actually feel that [[http://www.nickbostrom.com/papers/dangerous.html][Bostrom's response]] to [[http://www.foreignpolicy.com/articles/2004/09/01/transhumanism][Fukuyama's critique of transhumanism as inegalitarian]] was inadequate, and failed to address the genuine crisis of stratification that I personally expect to occur should transhumanism be wed to capitalist exploitation (or rather, the capitalist mechanism of exploitation in the absence of AI). Yes, biological-limitation transhumanism + way capitalism makes even the barest survival and barest happiness a positional good = vast human misery. Rather than addressing that problem by attacking transhumanism, we should address it by treating capitalism as a broken, obsolete economic machine and simply building a better one.

(All this assumes that we cannot produce a Friendly AI /Real Soon Now/, as in, soon enough to deal with the problems inflicted by capitalism on most currently-existing humans. There is enough human effort in the world to fix our economic system /and/ build a Friendly AI in the coming decades, at least in my view.)
:PROPERTIES:
:Score: 13
:DateUnix: 1405178584.0
:END:

**** As an aside, I thought [[http://c4ss.org/content/12491][this]] article was an alright overview of the problem space of "power, and how to topple it" in a lot of ways. I don't know where to post it, but it mirrors my general strategy in a lot of ways. Especially

#+begin_quote

  1. Identify the vulnerabilities: Fragility, overconcentration, ignorance, arrogance, lack of diversity, centralization, lack of redundancy, popular disgust, anxiety, dissatisfaction or apprehension, ill-preparedness, lack of agility, overcomplexity (left hand doesn't know what the right is doing), lack of imagination and creativity, etc.

  2. Acquire resources stealthily: Put together what you need without letting your target know you're doing so, or even what you are capable of doing with them.

  3. Develop solutions that exploit the vulnerabilities.

  4. Rigorously assess the likelihood of those solutions working effectively (incapacitating the incumbent power), and deploy only the high-probability solutions, quickly, before the incumbents have time to react and defend themselves.
#+end_quote

Firstly, I'm trying to capture some of the utility of the quickly growing 3D printing market. Then expand the market into just-in-time/decentralized manufacturing. Something everyone is trying to do, just stupidly.

--------------

I'm firmly in the camp of "AI is probably too dangerous, friendly or not. Do it that hard way and uplift existing humans.". But there's some many existential risks coming to a head at once that it may be our best bet, even if the odds aren't good.

Better then that would be a sane organization taking control, and initiating a slow singularity along with measures to deal with radicals and extremists. Mostly good psychiatric care, plenty or opportunities to kill/wire-head yourself, and generally keeping everyone happy.

Basic income was on my list, but I forgot it add it. It's also good for reducing existential risk. People who are content are a lot less likely to be extremist/blow-up-everything.
:PROPERTIES:
:Author: traverseda
:Score: 3
:DateUnix: 1405181271.0
:END:

***** I question why humans are assumed to have a less dangerous utility function than other empowered intelligences. I'm thinking it's probably unwise to meddle with hyper-intelligence of any kind until we have much better models of axiomatic space. Now if we could just invent some kind of AI to help us understand axiomatic space.
:PROPERTIES:
:Author: Earthian
:Score: 2
:DateUnix: 1405230036.0
:END:

****** #+begin_quote
  I question why humans are assumed to have a less dangerous utility function than other empowered intelligences.
#+end_quote

It's not that. It's that you can uplift a bunch at once, and you should be left with an average that isn't too harmful to humans.
:PROPERTIES:
:Author: traverseda
:Score: 2
:DateUnix: 1405232393.0
:END:

******* I guess if it's a smooth transition with lots of peer review, than it would be safer. Though still not safe, but I suppose nothing really is safe, just less dangerous.
:PROPERTIES:
:Author: Earthian
:Score: 1
:DateUnix: 1405233499.0
:END:


****** #+begin_quote
  I question why humans are assumed to have a less dangerous utility function than other empowered intelligences.
#+end_quote

What would "less dangerous" /mean/ without human ethics to ground evaluations?
:PROPERTIES:
:Score: 2
:DateUnix: 1405233568.0
:END:

******* I think the question is mu. But I'm far from certain. Which is ... concerning to me.

With danger being anything that increases the chance of unfavorable outcome, danger (and by extension less danger) would require a utility function on which to be grounded.

But humans seem to have grown, and are in the process of creating our own utility functions, which are completely capable of interfering with one another.
:PROPERTIES:
:Author: Earthian
:Score: 1
:DateUnix: 1405235607.0
:END:

******** I recommend reading Three Worlds Collide to make you less uncertain about the question. It helped for me.
:PROPERTIES:
:Score: 1
:DateUnix: 1405329662.0
:END:


***** #+begin_quote
  As an aside, I thought this[1] article was an alright overview of the problem space of "power, and how to topple it" in a lot of ways. I don't know where to post it, but it mirrors my general strategy in a lot of ways.
#+end_quote

Oh boy, instructions for conspiracy!

#+begin_quote
  Firstly, I'm trying to capture some of the utility of the quickly growing 3D printing market.
#+end_quote

You are? What're you up to?

#+begin_quote
  I'm firmly in the camp of "AI is probably too dangerous, friendly or not. Do it that hard way and uplift existing humans.". But there's some many existential risks coming to a head at once that it may be our best bet, even if the odds aren't good.
#+end_quote

Well-definedly Friendly AIs /do not go wrong/.
:PROPERTIES:
:Score: 1
:DateUnix: 1405187339.0
:END:

****** Friendly is a integer, not a boolean.

There's a lot of hate for thingiverse right now. Thingiverse being the place people go to for their 3D files. Part of that is them [[http://traverseda.wordpress.com/2014/05/23/makerbot-blatently-steals-and-patents-a-community-design/][allegedly stealing a community design]], part of that is them having a bad IP policy. Part of that is them abandoning their open-source roots.

The point is that a lot of designers hate them, and their aren't any good alternatives.

I'm working on an alternative to thingiverse. Take a look at the [[http://alpha.rhombik.com][alpha site]] and our [[https://github.com/Rhombik/rhombik-object-repository][github]].

It's a strategic asset. Mostly just setting me up in a good position to implement things down the line.

There's 3 main factors that potentially go into its success.

- Open-source/community support

- A neutral commons (it doesn't make sense for all the smaller 3D printer companies to make their own)

- I run [[/r/3Dprinting]], which has a large concentration of designers. They can be nudged, although obviously I have to maintain a certain amount of neutrality.

Finally, thingiverses not-us competition generally isn't very good. It's a bitch to overcome their network effect. But it's worth a shot.
:PROPERTIES:
:Author: traverseda
:Score: 2
:DateUnix: 1405227733.0
:END:

******* #+begin_quote
  Friendly is a integer, not a boolean.
#+end_quote

Not if it's done right, it's not. I think Eliezer's "meta-ethics sequence" was dangerously close to being /philosophy/, and I personally would hold that you /do not ever/ build superintelligent AIs based on /philosophy/ (attempting to do so is likely to get you killed, wireheaded, or turned into a pony). I think Eliezer would probably point out that /he invented this view/, and that he didn't actually intend the meta-ethics "sequence" to convey that you should use philosophical methods but rather than this is a hard problem on which we need a lot more /scientific/ evidence to successfully dissolve the problem into a matter of algorithms.

/Given/ a dissolution of AI Friendliness into algorithms, it becomes a matter of formal proof from axioms and the probabilities we assign to the axioms.
:PROPERTIES:
:Score: 3
:DateUnix: 1405233757.0
:END:

******** Formally verifying things is hard. We don't even have any formally verified kernels. By the time we get around to formally verifying an AI, said AI will have existed for a long while. Are we trusting people not to turn it on before it's formally verified?
:PROPERTIES:
:Author: traverseda
:Score: 1
:DateUnix: 1405234233.0
:END:

********* #+begin_quote
  We don't even have any formally verified kernels.
#+end_quote

[[http://www.ertos.nicta.com.au/research/l4.verified/][Yes we do.]] [[http://compcert.inria.fr/compcert-C.html][Also a C compiler.]]

#+begin_quote
  By the time we get around to formally verifying an AI, said AI will have existed for a long while. Are we trusting people not to turn it on before it's formally verified?
#+end_quote

The actual primary problem is figuring out which algorithms constitute both Friendliness /and/ rational AI. Writing a formally verified implementation of those algorithms is actually the smaller ending step, though it could be significantly large since mechanized proofs tend to be rather larger than formal-proofs-for-humans.
:PROPERTIES:
:Score: 4
:DateUnix: 1405234707.0
:END:

********** No source code available for the kernel? That explains why I haven't heard of it. Very interesting though. Thanks for the link.

EDIT:[[http://sel4.systems/][Ooh!]]

You still run into the problem of having functional AI long before you have friendly AI, unless MIRA gets a lot more funding.

That being said, CFAR/MIRA has a good general plan. Help a lot of sane people, and hope a few of them get very rich.
:PROPERTIES:
:Author: traverseda
:Score: 2
:DateUnix: 1405235066.0
:END:

*********** #+begin_quote
  You still run into the problem of having functional AI long before you have friendly AI,
#+end_quote

Not /necessarily/. Current preferences appear to be for putting learning algorithms into wide-scale usage as soon as they're useful, /without/ trying to put together several /different/ algorithms into a human-equivalent, FOOM-capable "AI". The number of people consciously trying to create FOOM-capable AGI with even the remotest competence is very, very small (and it also appears to be a very difficult problem, compared to doing highly general but still strictly Narrow machine-learning).
:PROPERTIES:
:Score: 3
:DateUnix: 1405235722.0
:END:


******* #+begin_quote
  I'm working on an alternative to thingiverse. Take a look at the alpha site[2] and our github[3] .
#+end_quote

This would be very, very cool if I knew more about 3D printing.
:PROPERTIES:
:Score: 1
:DateUnix: 1405239502.0
:END:

******** Yeah. It actually working is pretty reliant on a lot of politics and PR. Which I'm not terrible at, in this sphere anyway.

If it does work, it shouldn't be hard to get a fraction of the utility of what amounts to the next industrial revolution. The beginning of real automated manufacturing.

Still, hard to get accurate estimates. And I'm always plagued by the vague sensation that there's something more I should be doing.

I appreciate people double-checking my reasoning. So let me know if you have any questions.
:PROPERTIES:
:Author: traverseda
:Score: 1
:DateUnix: 1405240563.0
:END:


**** #+begin_quote
  Capitalism just maximizes capital
#+end_quote

What?

#+begin_quote
  major change in class relations
#+end_quote

oh.

#+begin_quote
  If [[/u/mylittleeconomy]] could come over here, being a market monetarist
#+end_quote

no D: it's just the NGDP Targeting Festival. That doesn't mean I /like/ it....

#+begin_quote
  I'd also like to propose a kind of "Georgist money", in which currency is issued as a liability/entitlement to some form of positional or ecological (ie: Truly Scarce, cannot be made in a factory) good.
#+end_quote

Like...gold?
:PROPERTIES:
:Score: 1
:DateUnix: 1405184575.0
:END:

***** #+begin_quote
  no D: it's just the NGDP Targeting Festival. That doesn't mean I like it....
#+end_quote

Well I guesstimated, based on your explicitly mentioning NGDP Targeting and also based on the fact that market monetarism /is/ a current theory in mainstream economics with plenty of evidence and sway behind it.

#+begin_quote
  Like...gold?
#+end_quote

And therein lies the rub. When you tie money purely to something like debt (burdens of optimization placed on individuals or institutions), you get an explosion of toxic financialization (nominal debts grow beyond the real economy's ability to repay). When you tie money purely to something like gold, you become unable to manage the economy, but nominal productivity and real productivity fall into line with each-other.

I think we need some new solutions.
:PROPERTIES:
:Score: 2
:DateUnix: 1405187063.0
:END:

****** #+begin_quote
  When you tie money purely to something like debt (burdens of optimization placed on individuals or institutions), you get an explosion of toxic financialization (nominal debts grow beyond the real economy's ability to repay).
#+end_quote

I have never even heard of that theory. What is this coming from? For that matter, what do you mean when you say money is tied to debt? A fiat currency derives its value from its ability to reduce transaction costs, primarily (also, store of value).
:PROPERTIES:
:Score: 2
:DateUnix: 1405232826.0
:END:

******* #+begin_quote
  For that matter, what do you mean when you say money is tied to debt?
#+end_quote

Our current fiat systems issue money by issuing bonds, correct? That's what's meant. You could have a fiat system that worked some other way, but economists seem to be kinda wary of /just/ issuing money out of nowhere (for reasons I don't entirely understand, which may or may not be particularly good).

#+begin_quote
  I have never even heard of that theory. What is this coming from?
#+end_quote

Michael Hudson, who is heterodox but intelligent, and a few other analyses of financial-sector activity against nonfinancial activity.
:PROPERTIES:
:Score: 2
:DateUnix: 1405233432.0
:END:

******** Well, [[http://www.ncpa.org/pub/ba611][sort of]], but when you said tied to debt it put me in the mind of something akin to a gold standard but with debt. My mistake.

The [[http://www.investopedia.com/terms/h/helicopter-drop.asp][helicopter drop]] is something I find rather tempting myself, but the Fed normally works through banks and the market because it's easier to judge and easier to get the money out there--banks are better than pilots at finding people who want to add to aggregate demand. There may be other reasons. Printing money has something of a bad reputation for [[http://en.wikipedia.org/wiki/Hyperinflation_in_the_Weimar_Republic][some reason]].

There are different definitions of the money supply (M1 and M2 and so forth), and they don't always move together. "Get the money supply right" is easier said than done.

But people like Milton Friedman, Scott Sumner and, uh, me (who doesn't count) think that the Fed should be focused more on the monetary base than the interest rate. Maybe helicopter drops (I prefer roving open vans with cheerleaders armed with those t-shirt cannons myself) will be a tool of monetary policy in the future.
:PROPERTIES:
:Score: 1
:DateUnix: 1405236980.0
:END:

********* #+begin_quote
  banks are better than pilots at finding people who want to add to aggregate demand.
#+end_quote

With respect, I completely disagree. Banks are very good at finding people who want to add to aggregate supply and who want to accumulate capital. That's their job. Thing is, from a bank's perspective (and that of the financial-services sector as a whole, nowadays), "adding to aggregate demand" is called "profligacy".

Of course, they'll /also/ lend you money to be profligate and even downright irresponsible with (see: credit cards), but the whole point is that they do so in order to create liabilities from you to them, adding to their balance sheet, adding to "aggregate supply" and accumulated capital, and /those debts always come due/. You /can't/ add to aggregate demand by loaning money: that just moves aggregate demand from the future to the present.
:PROPERTIES:
:Score: 2
:DateUnix: 1405241667.0
:END:

********** You could argue that at least some of this profligate spending would /never/ happen if not enabled and encouraged by banks, hence creating additional economic activity.

If course, this has some problems if we look at why we care about economics at all - in principle it's to serve the people, and multinational companies and their advertising start to seem abusive.
:PROPERTIES:
:Author: PeridexisErrant
:Score: 1
:DateUnix: 1405258531.0
:END:

*********** #+begin_quote
  You could argue that at least some of this profligate spending would never happen if not enabled and encouraged by banks, hence creating additional economic activity.
#+end_quote

The problem being: it wasn't fucking charity, it has to get paid back later. Credit-stimulus only makes sense when it's rational to move demand from the future to the present (ie: liquidity traps and such), not when there's /actually/ a general glut.
:PROPERTIES:
:Score: 1
:DateUnix: 1405258763.0
:END:

************ While the financial behaviour of large corporations generally makes sense if you treat them as rational agents, I think it's more elegant to admit that individuals are not rational agents (in the classic economic sense) than to construct a utility function for which their behaviour is rational.
:PROPERTIES:
:Author: PeridexisErrant
:Score: 1
:DateUnix: 1405260107.0
:END:

************* Which is exactly what I said elsewhere to [[/u/mylittleeconomy]], but which is apparently kinda heretical in non-behavioral economic theory like GMU does (despite being /absolutely orthodox/ in behavioral economics).
:PROPERTIES:
:Score: 1
:DateUnix: 1405260794.0
:END:


********* ***** 
      :PROPERTIES:
      :CUSTOM_ID: section
      :END:
****** 
       :PROPERTIES:
       :CUSTOM_ID: section-1
       :END:
**** 
     :PROPERTIES:
     :CUSTOM_ID: section-2
     :END:
[[https://en.wikipedia.org/wiki/Hyperinflation%20in%20the%20Weimar%20Republic][*Hyperinflation in the Weimar Republic*]]: [[#sfw][]]

--------------

#+begin_quote
  The *hyperinflation in the Weimar Republic* was a three-year period of [[https://en.wikipedia.org/wiki/Hyperinflation][hyperinflation]] in [[https://en.wikipedia.org/wiki/Germany][Germany]] (the [[https://en.wikipedia.org/wiki/Weimar_Republic][Weimar Republic]]) between June 1921 and January 1924.

  * 
    :PROPERTIES:
    :CUSTOM_ID: section-3
    :END:
  [[https://i.imgur.com/U6V6MXN.jpg][*Image*]] [[https://commons.wikimedia.org/wiki/File:GermanyHyperChart.jpg][^{i}]] - /Weimar Republic hyperinflation from one to one trillion paper Marks per gold Mark; on a logarithmic scale./
#+end_quote

--------------

^{Interesting:} [[https://en.wikipedia.org/wiki/Weimar_Republic][^{Weimar} ^{Republic}]] ^{|} [[https://en.wikipedia.org/wiki/Germany][^{Germany}]] ^{|} [[https://en.wikipedia.org/wiki/Hyperinflation][^{Hyperinflation}]] ^{|} [[https://en.wikipedia.org/wiki/World_War_I_reparations][^{World} ^{War} ^{I} ^{reparations}]]

^{Parent} ^{commenter} ^{can} [[http://www.np.reddit.com/message/compose?to=autowikibot&subject=AutoWikibot%20NSFW%20toggle&message=%2Btoggle-nsfw+ciw2p5s][^{toggle} ^{NSFW}]] ^{or[[#or][]]} [[http://www.np.reddit.com/message/compose?to=autowikibot&subject=AutoWikibot%20Deletion&message=%2Bdelete+ciw2p5s][^{delete}]]^{.} ^{Will} ^{also} ^{delete} ^{on} ^{comment} ^{score} ^{of} ^{-1} ^{or} ^{less.} ^{|} [[http://www.np.reddit.com/r/autowikibot/wiki/index][^{FAQs}]] ^{|} [[http://www.np.reddit.com/r/autowikibot/comments/1x013o/for_moderators_switches_commands_and_css/][^{Mods}]] ^{|} [[http://www.np.reddit.com/r/autowikibot/comments/1ux484/ask_wikibot/][^{Magic} ^{Words}]]
:PROPERTIES:
:Author: autowikibot
:Score: 1
:DateUnix: 1405236994.0
:END:


*** You might want to follow along with [[http://www.fimfiction.net/story/201692/deathonomics][this]].
:PROPERTIES:
:Score: 5
:DateUnix: 1405184382.0
:END:

**** You deserve the karma for posting it, but good job on the Trollestia.
:PROPERTIES:
:Score: 2
:DateUnix: 1405234056.0
:END:


*** #+begin_quote
  That leads to a lot of entities choosing, let's say, 2 private utilitons (units of utility) and 1 public utiliton, instead of choosing 1 private and 3 public. Sure, there's more overall utility in situation two, but there are selection pressure's to consider.
#+end_quote

Ah, externalities. Like when a dragon's smoke drifts over the quiet town of Ponyville....

It is worth noting that in the absence of externalities capitalism achieves exactly what you want it to. In the absence of transaction costs, capitalism is ridiculous at achieving every achievable and present human goal.

Universities capture the value they create with tuition. Students capture the value they create with higher future incomes. And so on.
:PROPERTIES:
:Score: 2
:DateUnix: 1405232664.0
:END:

**** #+begin_quote
  Universities capture the value they create with tuition.
#+end_quote

With respect, no they don't. I mean, there are /really obvious counterexamples/ to this universally-quantified statement of yours: Harvard and MIT. Two of the most prestigious universities on the planet, and they mostly actually run off their endowments and real-estate holdings in Boston-Cambridge. Their tuition is actually artificially low /precisely because/ they're not actually funding themselves through tuition, which means their tuition /isn't/ a rationalized inputs-to-outputs price signal.

And then there's /public/ universities, which are a major thing /everywhere/ but the United States of America... and also sometimes even in the United States of America. These run off state funding, which again, means their tuition is artificially low and not a price signal.

#+begin_quote
  Students capture the value they create with higher future incomes.
#+end_quote

This is circular logic: it assumes value is "that which is captured in market transactions".
:PROPERTIES:
:Score: 3
:DateUnix: 1405234310.0
:END:

***** So Harvard and MIT go after their students' future earnings rather than their current meager finances. But sure, the higher education market is so distorted it practically warps space-time. Of course the argument implies that there is too much education rather than too little. I would bet that "Less education for all!" will never make much of a political slogan.

#+begin_quote
  This is circular logic: it assumes value is "that which is captured in market transactions".
#+end_quote

Eeyup.
:PROPERTIES:
:Score: 1
:DateUnix: 1405237650.0
:END:

****** #+begin_quote
  So Harvard and MIT go after their students' future earnings rather than their current meager finances.
#+end_quote

Quite to the contrary: they actually extensively subsidize their students' tuition. If they go after future earnings, it's by soliciting for donations via alumni associations.

#+begin_quote
  But sure, the higher education market is so distorted it practically warps space-time. Of course the argument implies that there is too much education rather than too little. I would bet that "Less education for all!" will never make much of a political slogan.
#+end_quote

This assumes that you can talk of "more education" or "less education" from an economics perspective without asking the educators to clarify those terms. My personal belief is that we do, of course, have too little education, but that we certainly have too many /degrees/.

Note that unlike other people who believe this, I don't believe we had /more/ education in the past. However, in the past, the amount of knowledge in the average degree was larger /relative/ to the amount of total knowledge academia actually had. Whereas nowadays, starting somewhere around the end of elementary school, we basically teach students tiny fractions of what educated adults /should/ know, we fail to teach them things educated adults should know (ie: basic finances, job training, civics, statistics, a little bit of decision theory), we teach even the academically-bound students very little of what academia knows about their specific fields (instead preferring fake sorta-kinda wannabe-job-training that doesn't train for a job and doesn't give academic foundations /either/)... and then we kick them out with degrees.

We face a weird situation: the degree tracks that aren't targeted at in-demand job fields are overly vague and uninformative because they're focusing on trying to convey General Humane Education, while the tracks that /can/ lead to well-paid work fail to convey rigorous foundations because they're trying too hard to be job training.

The result is that graduate schools have to accept barely-educated beginners (this includes myself when I first got into grad-school) into their PhD programs, because you only really start /actually learning your field/ at a truly rigorous level in PhD school.
:PROPERTIES:
:Score: 2
:DateUnix: 1405238223.0
:END:


**** Ultimately, the universities are capturing the value of the students higher future incomes. But they can't do that, because they don't exist yet.

So we add on yet another layer of complexity. Which increases the cost of good-decision-making/information. In practice, it's a situation that falls apart pretty quickly.

You could have the government take the costs of good decision making. Have them produce research on the best majors and the best schools. There's economics of scale involved. The information is more valuable the more data points you collect.

I don't know how you could, as a private entity, recoup the costs of gathering that kind of data. Incredibly valuable data, but no way to get it to people. Any thoughts?

--------------

#+begin_quote
  It is worth noting that in the absence of externalities capitalism achieves exactly what you want it to.
#+end_quote

Hmm. The internet is a market where I don't think there's too much in the way of externalities. Maybe I'm just not seeing them very well though. Can you give me any examples of externalities on the internet?

The internet isn't really achieving exactly what I want. I think it would be closer to a "pure" idealized market, but it seems like corruption is even worse on it.
:PROPERTIES:
:Author: traverseda
:Score: 1
:DateUnix: 1405233733.0
:END:

***** Well, there is a good deal of uncertainty involved, of course. This is always the [[http://www.econlib.org/library/Knight/knRUP.html][source of profit.]] (What a handsome face....) But this is true of any market to some degree. A man who distributes apples and captures that value by charging money for them will not charge more for someone with supercharged taste buds and a hankering for apples even though that person would be willing to pay far more than the typical price. Our poor apple distributor is not capturing all the value he created, but it is also not clear that this is particularly a problem--the economist's challenge is always, "What are you going to do about it?" It may be that the apple seller's price is never exactly correct, yet I would say that it is correct to say that he is capturing the value he creates.

Externalities on the Internet: comments, pop-ups, denial of service attacks and the like, hacking, viruses, etc.

But it is well-known that the power of an economy with [[http://en.wikipedia.org/wiki/Coase_theorem][zero transaction costs is maximum.]]
:PROPERTIES:
:Score: 1
:DateUnix: 1405237385.0
:END:

****** ***** 
      :PROPERTIES:
      :CUSTOM_ID: section
      :END:
****** 
       :PROPERTIES:
       :CUSTOM_ID: section-1
       :END:
**** 
     :PROPERTIES:
     :CUSTOM_ID: section-2
     :END:
[[https://en.wikipedia.org/wiki/Coase%20theorem][*Coase theorem*]]: [[#sfw][]]

--------------

#+begin_quote
  In [[https://en.wikipedia.org/wiki/Law_and_economics][law and economics]], the *Coase theorem* (pronounced /ˈkoʊs/) describes the [[https://en.wikipedia.org/wiki/Efficiency_(economics)][economic efficiency]] of an economic [[https://en.wikipedia.org/wiki/Economic_system][allocation]] or outcome in the presence of [[https://en.wikipedia.org/wiki/Externality][externalities]]. The theorem states that if trade in an externality is possible and there are sufficiently low [[https://en.wikipedia.org/wiki/Transaction_costs][transaction costs]], bargaining will lead to an efficient outcome regardless of the initial allocation of property. In practice, obstacles to bargaining or poorly defined property rights can prevent Coasian bargaining. This "theorem" is commonly attributed to [[https://en.wikipedia.org/wiki/The_University_of_Chicago][The University of Chicago']]s Nobel Prize laureate [[https://en.wikipedia.org/wiki/Ronald_Coase][Ronald Coase]]. However, Coase himself stated that the theorem was based on perhaps four pages of his 1960 paper "[[https://en.wikipedia.org/wiki/The_Problem_of_Social_Cost][The Problem of Social Cost]]", and that the "Coase theorem" is not about his work at all.

  * 
    :PROPERTIES:
    :CUSTOM_ID: section-3
    :END:
  [[https://i.imgur.com/8we661R.jpg][*Image*]] [[https://commons.wikimedia.org/wiki/File:Jonespeartree_mbsch.JPG][^{i}]]
#+end_quote

--------------

^{Interesting:} [[https://en.wikipedia.org/wiki/Ronald_Coase][^{Ronald} ^{Coase}]] ^{|} [[https://en.wikipedia.org/wiki/Externality][^{Externality}]] ^{|} [[https://en.wikipedia.org/wiki/George_Stigler][^{George} ^{Stigler}]]

^{Parent} ^{commenter} ^{can} [[http://www.np.reddit.com/message/compose?to=autowikibot&subject=AutoWikibot%20NSFW%20toggle&message=%2Btoggle-nsfw+ciw2s7z][^{toggle} ^{NSFW}]] ^{or[[#or][]]} [[http://www.np.reddit.com/message/compose?to=autowikibot&subject=AutoWikibot%20Deletion&message=%2Bdelete+ciw2s7z][^{delete}]]^{.} ^{Will} ^{also} ^{delete} ^{on} ^{comment} ^{score} ^{of} ^{-1} ^{or} ^{less.} ^{|} [[http://www.np.reddit.com/r/autowikibot/wiki/index][^{FAQs}]] ^{|} [[http://www.np.reddit.com/r/autowikibot/comments/1x013o/for_moderators_switches_commands_and_css/][^{Mods}]] ^{|} [[http://www.np.reddit.com/r/autowikibot/comments/1ux484/ask_wikibot/][^{Magic} ^{Words}]]
:PROPERTIES:
:Author: autowikibot
:Score: 1
:DateUnix: 1405237395.0
:END:


*** [[http://liquidfeedback.org/][liquidefeedback]]/Fluid-democracy looks like a good way of letting preferences be known. Admittedly there's a lot of overhead, although I don't know how it would compare to the overhead of a market economy. It presumes that everyone is truly equal, thus making compelling arguments very important. Of course compelling arguments probably aren't the best way to run a society... Truth does matter.

Prediction markets are a thing. They don't seem to generally be used though. They may just be too incompatible with normal society. But they do nicely bolt on to the existing economy. They also encourage secret keeping. They don't need to do better overall, just better then everyone else.
:PROPERTIES:
:Author: traverseda
:Score: 1
:DateUnix: 1405158903.0
:END:

**** #+begin_quote
  Prediction markets are a thing. They don't seem to generally be used though. They may just be too incompatible with normal society. But they do nicely bolt on to the existing economy. They also encourage secret keeping.
#+end_quote

On the contrary, it encourages the spread and sharing of information. That is pretty much the point.
:PROPERTIES:
:Score: 2
:DateUnix: 1405184738.0
:END:

***** How? On a prediction market, you don't need to do better overall to be successful. You just need to do better then your peers. I can see selling information, but not sharing it for free.
:PROPERTIES:
:Author: traverseda
:Score: 1
:DateUnix: 1405227795.0
:END:

****** It is true that prediction markets don't compel every actor to share all the information they have immediately. But they will, [[http://en.wikipedia.org/wiki/Ceteris_paribus][ceteris paribus]], promote the creation and sharing of information as compared to an otherwise identical system that lacks prediction markets. They only encourage secret-keeping in the sense that agents will be discouraged from sharing information on a whim, since there is first money to be made. Nevertheless, a whim-based information-sharing system would be much more inefficient.
:PROPERTIES:
:Score: 1
:DateUnix: 1405232998.0
:END:

******* ***** 
      :PROPERTIES:
      :CUSTOM_ID: section
      :END:
****** 
       :PROPERTIES:
       :CUSTOM_ID: section-1
       :END:
**** 
     :PROPERTIES:
     :CUSTOM_ID: section-2
     :END:
[[https://en.wikipedia.org/wiki/Ceteris%20paribus][*Ceteris paribus*]]: [[#sfw][]]

--------------

#+begin_quote
  */Ceteris paribus/* or */caeteris paribus/* is a [[https://en.wikipedia.org/wiki/Latin][Latin]] phrase meaning "with other things the same" or "all other things being equal or held constant." A prediction or a statement about a [[https://en.wikipedia.org/wiki/Ontic][causal]], [[https://en.wikipedia.org/wiki/Epistemic][empirical]], or [[https://en.wikipedia.org/wiki/Inductive_logic][logical]] relation between two states of affairs is /ceteris paribus/ via acknowledgement that the prediction, although usually accurate in expected conditions, can fail or the relation can be abolished by intervening factors.

  A /__ceteris paribus* assumption/_ is often key to scientific inquiry, as scientists seek to screen out factors that perturb a relation of interest. Thus, [[https://en.wikipedia.org/wiki/Epidemiologist][epidemiologists]] seek to control [[https://en.wikipedia.org/wiki/Independent_variable][independent variables]] as factors that may influence [[https://en.wikipedia.org/wiki/Dependent_variables][dependent variables]]---the outcomes or effects of interest. Likewise, in [[https://en.wikipedia.org/wiki/Scientific_modeling][scientific modeling]], simplifying assumptions permit illustration or elucidation of concepts thought relevant within the sphere of inquiry.

  Whereas [[https://en.wikipedia.org/wiki/Fundamental_interactions][fundamental physics]] tends to state universal laws, other sciences, such as biology, psychology, and economics, tend to state laws that hold true in "normal conditions" but have exceptions, /__ceteris paribus* laws/_ (cp laws). The focus on universal laws is a criterion distinguishing fundamental physics as [[https://en.wikipedia.org/wiki/Fundamental_science][fundamental science]], whereas /ceteris paribus/ laws are predominant in most other sciences as [[https://en.wikipedia.org/wiki/Special_science][special sciences]], whose laws hold in special cases.
#+end_quote

--------------

^{Interesting:} [[https://en.wikipedia.org/wiki/Economics][^{Economics}]] ^{|} [[https://en.wikipedia.org/wiki/Partial_equilibrium][^{Partial} ^{equilibrium}]] ^{|} [[https://en.wikipedia.org/wiki/Marginal_product_of_capital][^{Marginal} ^{product} ^{of} ^{capital}]] ^{|} [[https://en.wikipedia.org/wiki/Technology_dividend][^{Technology} ^{dividend}]]

^{Parent} ^{commenter} ^{can} [[http://www.np.reddit.com/message/compose?to=autowikibot&subject=AutoWikibot%20NSFW%20toggle&message=%2Btoggle-nsfw+ciw1q95][^{toggle} ^{NSFW}]] ^{or[[#or][]]} [[http://www.np.reddit.com/message/compose?to=autowikibot&subject=AutoWikibot%20Deletion&message=%2Bdelete+ciw1q95][^{delete}]]^{.} ^{Will} ^{also} ^{delete} ^{on} ^{comment} ^{score} ^{of} ^{-1} ^{or} ^{less.} ^{|} [[http://www.np.reddit.com/r/autowikibot/wiki/index][^{FAQs}]] ^{|} [[http://www.np.reddit.com/r/autowikibot/comments/1x013o/for_moderators_switches_commands_and_css/][^{Mods}]] ^{|} [[http://www.np.reddit.com/r/autowikibot/comments/1ux484/ask_wikibot/][^{Magic} ^{Words}]]
:PROPERTIES:
:Author: autowikibot
:Score: 1
:DateUnix: 1405233009.0
:END:


****** The very act of buying or selling a share distributes information to the rest of the market that you think this or that prediction is more or less likely to be true. Depending on how detailed the predictions are ("Iran will go to war" vs. "Iran will go to war with Israel" vs. "Iran will go to war with Israel in less than 24 hours over an incident involving U.S. president Obama, a bottle of vodka, and a llama"), that could be quite a bit of information.
:PROPERTIES:
:Author: erwgv3g34
:Score: 1
:DateUnix: 1405233210.0
:END:


**** I like the idea of liquid feedback in theory, but I'm concerned that well marketed but dumb ideas would take over quite quickly, and we'd end up pretty much back where we started.

I agree that truth matters. Defining better models for working with truth would seem useful. I suppose that's what rationality movement is about.

#+begin_quote
  They also encourage secret keeping.
#+end_quote

Perhaps this could be balanced with an information market as well. If useful information is profitable in itself, why hoard it? edit: But the information market would need to be based on making information publicly available, and then profiting based on it's usefulness in predictions.
:PROPERTIES:
:Author: Earthian
:Score: 1
:DateUnix: 1405231626.0
:END:


**** #+begin_quote
  liquidefeedback/Fluid-democracy looks like a good way of letting preferences be known. Admittedly there's a lot of overhead, although I don't know how it would compare to the overhead of a market economy.
#+end_quote

Highly inefficient as compared to the price system would be my extremely confident guess. It would significantly raise transaction costs and most likely also underperform at preference revelation, preference satisfaction, not to mention freeing people from the constraints of politics--the market allows for the flourishing of individualism and diversity in a way that is unlikely to be true of [[http://en.wikipedia.org/wiki/Arrow%27s_impossibility_theorem][democratic decision-making]]. Not to mention how truly democratic such systems are [[http://en.wikipedia.org/wiki/Public_choice][likely to be]]....

I strongly encourage all would-be reformers of society to carefully study the history of [[http://en.wikipedia.org/wiki/Market_socialism][market socialism.]] What was initially highly regarded by many economists to be the scientific yet radical alternative to capitalism was eventually mocked as the universal logic of constrained optimization forced the theory to transform into a carbon copy of capitalism. The [[http://www.fimfiction.net/story/201692/deathonomics][price system]] has been ridiculed, attacked, and even criminalized for centuries, yet it only continues to spread. Call it a foe and attempt to slay it if you want, but do not expect it to be easy....
:PROPERTIES:
:Score: 1
:DateUnix: 1405233691.0
:END:

***** If you actually think market socialism has been, in some sense, defeated, I think you misunderstand socialists. Market socialism is extremely popular on the Left, broadly speaking, for its ability to do /exactly/ what we want it to do: generate an efficient, rationalized economy with reduced or even zero contradictions between Labor and Capital.
:PROPERTIES:
:Score: 1
:DateUnix: 1405255408.0
:END:


*** Centralized AI-managed economy, once we get there. Accelerando! :P
:PROPERTIES:
:Author: Anderkent
:Score: 1
:DateUnix: 1405209933.0
:END:

**** Vile Offspring pls go.
:PROPERTIES:
:Score: 5
:DateUnix: 1405234035.0
:END:


*** #+begin_quote
  The most relevant examples of captured vs created value are probably health care and student loans.
#+end_quote

I think it's worth noting that these particular issues can be pretty much considered "solved" in my home country of Belgium.

While I also have a problem, there are ways in which you can exploit capitalism (as a government) to increase overall wellbeing that seem underutilized. I remember a Slate Star Codex post about how governments could pay private corporations for certain things (like public policy to reduce crime, lowering homelessness) *but* only pay out of that corporation actually reaches its goal. There's more to it than that and I'll see if I can find the post I'm referring to.
:PROPERTIES:
:Score: 1
:DateUnix: 1405330036.0
:END:


*** Hmm, perhaps some kind of semi-socialist economy. Have a large amount of taxes overall but use them to make sure people have the basic staples of living, food, shelter, basic medical care and the like.

Then ever certain period of time (yearly or biyearly or every ten years what have you) give a tax break to companies and individuals who are producing value or research toward a certain goal, like say solar panel efficiency.

The problem with capitalism that there is no natural incentive to drive companies to produce something that is useful as opposed to it having a high marketability. If we can get around that roadblock then there might be hope for the system yet.
:PROPERTIES:
:Author: Threedoge
:Score: 1
:DateUnix: 1405170412.0
:END:

**** #+begin_quote
  Hmm, perhaps some kind of semi-socialist economy. Have a large amount of taxes overall but use them to make sure people have the basic staples of living, food, shelter, basic medical care and the like.
#+end_quote

That is pretty much how most Western countries work. Surely the brilliant radicals of [[/r/rational]] can do better?

#+begin_quote
  The problem with capitalism that there is no natural incentive to drive companies to produce something that is useful as opposed to it having a high marketability.
#+end_quote

Well, insofar as people want to buy things that are useful....
:PROPERTIES:
:Score: 1
:DateUnix: 1405184809.0
:END:

***** #+begin_quote
  people want to buy things that are useful....
#+end_quote

This is an /extremely/ questionable premise.
:PROPERTIES:
:Score: 7
:DateUnix: 1405187546.0
:END:

****** Yeah, people at large know what's marketed, not what's useful.
:PROPERTIES:
:Author: Earthian
:Score: 2
:DateUnix: 1405230457.0
:END:


****** I am pretty sure that most of the things that most people buy are things that they find useful in some way. "Hey, let's spend money on this useless junk!" is not the modal shopping experience. Externalities are another question, but people do spend money to get things that they can use for some end or that are an end in themselves.

It is easy to mock consumers for being hoodwinked and suckered by flashy advertising, and so people often do, but when you reach the point where you are doubting that people even /want/ to buy useful things, unless you mean something very specific by "useful," it is worth taking a step back and asking just what kinds of predictions your theory generates and whether they really seem to match your experiences.

Status competitions, imperfect information, etc., etc., but people are constrained optimizers, if imperfectly so. It is the pony way to look upon people with the utmost dignity and respect and to be charitable in your thoughts and dealings with them.
:PROPERTIES:
:Score: 1
:DateUnix: 1405234231.0
:END:

******* Ok. Let's take a step back... from standard revealed-preferences theory. What can falsify the basic theory of rational shopping (ie: prices at which people bid reveal preference information), and how have the standard irrationality-revealing experiments in behavioral economics failed to meet that standard? Basically, what sort of behavior /can't/ you explain as a preference, but instead only as a failure of rational economic behavior?
:PROPERTIES:
:Score: 1
:DateUnix: 1405255494.0
:END:


** How do we design a game that makes people build transferable information-processing and decision-making skills. Rationality games, basically. Besides Zendo and Fallacy Mania, what's out there already?
:PROPERTIES:
:Author: aintso
:Score: 5
:DateUnix: 1405175316.0
:END:

*** You forgot /EVE Online/. Anyone who's heard of it before knows why I'm putting it here.
:PROPERTIES:
:Author: AmeteurOpinions
:Score: 2
:DateUnix: 1405175882.0
:END:

**** I actually don't see how Eve applies, after playing it for a few years. Could you explain?
:PROPERTIES:
:Author: miningzen
:Score: 2
:DateUnix: 1405178707.0
:END:


*** Well, Fallacy Mania is... obvious, but Zendo provides a bit more instruction as to the principle. Zendo is actually basically [[http://en.wikipedia.org/wiki/Probably_approximately_correct_learning][PAC learning]]. This is what makes it so /hard/ with complicated rules: PAC learning is very inefficient even with an ideal learner.

So if you want a "rationality game", figure out how to make a game that can be won by best approximating an ideal learner from some class of learning algorithms.
:PROPERTIES:
:Score: 1
:DateUnix: 1405176625.0
:END:


*** I tried googling Falacy Mania, do you mean [[http://www.fallacymania.com/][this]] (CAREFUL: LOUD SOUND)? Is that supposed to be some game? I can't seem to make it actually work.
:PROPERTIES:
:Score: 1
:DateUnix: 1405190312.0
:END:

**** Well, this looks like an alpha of a computer-aided version of a pretty simple party game. So, yes. You need a list of fallacies and a bunch of players.
:PROPERTIES:
:Author: aintso
:Score: 1
:DateUnix: 1405208263.0
:END:


** There are a lot of things I think about, but I'm going to post my most selfish (currently, at least) problem that could still benefit a wider community.

I'm currently unemployed and the main thing that I've learned (apart from how not working sucks) is that the skills needed to *get* a job and the skills needed to *do* a job are often completely unrelated. This isn't true for all jobs, but it is true for probably the majority of jobs.

This leads to the problem of perfectly capable human beings (such as me) spending a lot of time and effort applying for jobs they could handle, without any real result (apart from feedback, which becomes useless after the first few times you apply). Not only is this a source of worldsuck, it also seems a highly inefficient way to do things (which is currently only allowed because there are more applicants than jobs).

--------------

Relatedly, figuring out which job actually fits you is also a rather hard problem for quite some people (I notice a lot of people stuck on "good enough" jobs) and it's a problem you're supposed to tackle when you're 14 - 18 years old.
:PROPERTIES:
:Score: 4
:DateUnix: 1405330763.0
:END:

*** Very interested in an answer to this problem.

One option, if you have time and the right skills, is to try and put together a business yourself. It's one of the many things I'm doing.

Maybe something with [[http://www.reddit.com/r/darknetplan/comments/2ankbb/masers_for_long_distance_wifi_links/][masers]]?
:PROPERTIES:
:Author: traverseda
:Score: 1
:DateUnix: 1405331277.0
:END:

**** #+begin_quote
  One option, if you have time and the right skills, is to try and put together a business yourself. It's one of the many things I'm doing.
#+end_quote

This is one of many possible paths, which also requires specific skills. From what I read, it's a path that's significantly easier in the US compared to Europe.
:PROPERTIES:
:Score: 1
:DateUnix: 1405332597.0
:END:

***** I don't know about that. You don't really have a safety net in the US. It might be harder to get venture capital elsewhere though. Venture capital shouldn't be a concern, as only something like 300 out of the 30,000 new businesses in the US actually get it. Plan as if you're not getting it.

If you've got something that can actually make money, and you create it, it will actually make money. The trick is actually creating something that can make money.
:PROPERTIES:
:Author: traverseda
:Score: 1
:DateUnix: 1405332863.0
:END:


***** There's a lot of difference with the EU regarding that. In Germany, it's fairly easy to create a one-person business.
:PROPERTIES:
:Author: Solonarv
:Score: 1
:DateUnix: 1405462015.0
:END:


** How can we convince people to sign up for cryonics?
:PROPERTIES:
:Author: MadScientist14159
:Score: 3
:DateUnix: 1405167623.0
:END:

*** Is that a goal? I'd probably say something like "making cryonics easier to obtain" or "get more people signed up for cryonics". Is this specifically about /convincing/ people? Is it about cryonics' PR? I'm going to presume it's not.

--------------

The reason I'm not signed up for cryonics is that it's too expensive. I imagine that's true of a lot of people.

The first step would be to figure out why people in general aren't signed up for cryonics. Presuming price is as much of a factor as I intuit, figuring out where that cost comes from is important.

So what do cryonics companies spend their money on? Presumably a lot of it is spent on upkeep, and investments ensuring that they can continues to pay for upkeep.

--------------

Significantly decreasing the cost of upkeep hits both of those quite nicely.

Technologies that might make cryonics upkeep cheaper:

- Heat echangers.

They've seen a lot of commercial application recently. It looks like the technology is maturing pretty quickly. Potentially a lot more efficient then whatever cooling methods they're using now. I don't really know, but it might be something other people haven't looked into.

- Aerogels

Very very efficient insulation. Minimize heat creep. Too expensive to implement now, but with a significant initial investment aerogel vessels could be a pretty big game-changer.

--------------

Alternatively, you could make their investments more efficient. I imagine they can afford pretty top tier investment council. That leaves getting the government more involved, or crazy schemes involving crypto-currencies.

Or doing it better then the best investors around. They have to deal in bulk, but some dedicated venture capitalists might get a better ROI, if they're very good at predicting the future.

Riskier, and most cryonics groups are rightfully risk-averse.
:PROPERTIES:
:Author: traverseda
:Score: 5
:DateUnix: 1405168654.0
:END:

**** I agree with all these points, especially getting current organizations to spend more efficiently. (and not on their boardmembers' salaries- yes I am looking at YOU SA...) I highly encourage you to hold cryonics organizations you involve yourself in accountable for their spending.

The most pressing concern to me is getting a process that will receive scientific endorsements as capable of preserving the structures of memory. Then the competent scientists and doctors might start getting on board. I responded in more detail above.
:PROPERTIES:
:Author: andor3333
:Score: 3
:DateUnix: 1405268395.0
:END:


*** Counterpoint: how do we create cryonics/body-preservation methods and providers whose treatments verifiably work, with strong evidence for their working?

Point 1: this is a life-or-death decision. A positive, even highly positive, expected-value based on a low probability of success /is not good enough/: expected values are measurements of average-case utility, which implicitly assumes a repeated set of either possible worlds (Bayesian) or experiments (frequentist). For me to sign up for such a treatment and start pushing it on others, I want it to pass a hypothesis test: "with high probability based on experimental evidence, this thing actually works". Those are the statistical tool you use when you will only get one opportunity to make your bet.

Point 2: Ideally, I would like to see the development of methods that could, for instance, preserve a dead lab-rat (or other experimental mammal) (after its heart was stopped, say) to the degree necessary that it can actually be "resurrected" at a predetermined later time (by restarting its heart, say). ALCOR can't do this, the Brain Preservation Foundation only does brains and has gone quiet, so I don't know whom to turn to.

Yes, this is /mountains of evidence/ I'm talking about demanding, but again, it's a life-or-death decision. You only get life-insurance money once, after all, so if I'm going to spend it on something other than my family (when I have one), I need, at the very least, solid molehills of evidence that I could in fact be brought back /without the use of a Friendly superintelligence/.

Because any plan that hinges on Friendly AI demands putting my money and effort into MIRI stuff, not signing up for medical treatments not known to work.
:PROPERTIES:
:Score: 6
:DateUnix: 1405176540.0
:END:


*** For one thing, you could start by creating a cryonics organization that is actually fiscally responsible. From what I have seen several are extremely shady and pay far too much money tot heir boards, and alcor, which seems legitimate, spends ridiculous amounts inefficiently on do it yourself projects when they could buy their materials much more cheaply and with less chance of problems. Because of their poor finances alcor will go under unless they expand like a pyramid scheme, and this isn't happening.

Also relevant, I have studied molecular biology with a focus on neuroscience. In my opinion, cryonics as it is now is very unlikely to preserve what I believe to be the core structures for memory, and even if it did it would not preserve enough detail for eventual recovery even if every molecule could somehow be mapped in its state at the time of revival. I am EXTREMELY in favor of cryonics if they can get it to work. I will be donating large amounts of my income to get it to work. I do not believe it currently works.

What has been happening is that cryonics has been improving significantly in the last few years, especially since they began vitrification.

The problems are... We haven't determined what structures contain memory, though we are getting close. None of the current prevailing models would be preserved by cryonics in its current state even for magical Drexlerian nanotech which is not feasible under out current understanding of physics.

Most of the money in cryonics is going to organizations run by people with little or no medical knowledge, spending resources inefficiently, and with the majority of the money going to preserving people with the current faulty processes instead of developing new ones.

If you want to convince competent molecular biologists and doctors to help you, these are the problems you solve.
:PROPERTIES:
:Author: andor3333
:Score: 2
:DateUnix: 1405267513.0
:END:

**** Ok, so here's a question: whose efforts should I support? Yours? I generally seem to share your opinions of current organizations and techniques, so I feel like I ought do /something/.
:PROPERTIES:
:Score: 2
:DateUnix: 1405287681.0
:END:

***** I am trying to answer that too. I have been keeping an eye out for organizations doing pure research and admitting it doesn't work now, or even reasonably responsible companies that do claim the freezing could work now as a fundraiser. There was one under development I had high hopes for but it went under before it started. At the moment if there is one out there I don't know where it is.

I wish I could be more help, but for now I am stuck saying there is a problem without being able to offer a solution beyond "someone should make an organization that fixes this." (maybe a little better than doing nothing, but not by much) I will donate money if I ever find one that I think has the right approach but right now I haven't got disposable income because law school and I don't know of any that fit the bill. I don't imagine you'll think of it, but if you somehow run across one in the near future that has these qualities let me know. I could at least spread the word then.
:PROPERTIES:
:Author: andor3333
:Score: 2
:DateUnix: 1405297125.0
:END:


** This seems like a great idea! Wanna hijack [[/r/solvingproblems]] for our rationalist agenda? No one seems to be using it at the moment anyway.
:PROPERTIES:
:Author: Abpraestigio
:Score: 3
:DateUnix: 1405181784.0
:END:

*** The mod over their is active on reddit, so you'd need to convince him to hand it over.

But it does seem like an interesting sort of outreach program.
:PROPERTIES:
:Author: traverseda
:Score: 1
:DateUnix: 1405182203.0
:END:


** I have a writing problem. The premise of the story is that wizards can create robots using a combination of magic and technology. So here's my problem; I need a magic system which allows a wizard to get past the hurdles in modern robotics in order to make humanoid robots. I got about a fourth of the way into the story before really thinking about how the magic system actually worked, and would rather not have a story that runs on handwavium. I guess I'll put my own solution in a comment to this one, but I'd like a better idea than I have now.
:PROPERTIES:
:Author: alexanderwales
:Score: 1
:DateUnix: 1405234450.0
:END:

*** - Wizards can create matter using the spell circles, though they have to specify with precision what it is they want. These spell circles can be written on any surface, and reused as much as desired. This gets past one of the biggest hurdles, which is that machined parts are bloody expensive.
- Spells can take in light and sound as parameters - used traditionally to set up alarms or give simply one-word commands. This takes care of vision and hearing, since magic already handles at least a portion of the control aspects.
- Spells can interact with circuit boards, and with each other, which allows the robots to be programmed.
- Spells can be used to ... uh, make an equivalent of muscles in some way. I guess in theory I could just have the spell circles be capable of producing force in addition to matter.

For example, a simple robot would have a spell circle giving it visual input and set to trigger on the color red. When the trigger condition happened, the spell circle would link up to the circuit board to send input in the form of electrical signals. The circuit board would decide what to do, and send output in the form of electrical signals, which a spell circle would interpret as a command to activate something (probably a muscle).

A full humanoid robot would be composed of a ton of spells and a ton of materials. Every time a new robot needed to be made, all you'd need to do was open up the spellbook that contained all the spell circles, touch each one in turn, and then assemble it.
:PROPERTIES:
:Author: alexanderwales
:Score: 1
:DateUnix: 1405234460.0
:END:

**** It seems to be a cliché or [[/r/rational]] that we always weaponise magic to test the premise... But here's some other ideas too:

- Portable artillery/railguns/whatever. Have one circle create ammunition, and another impart force.

- Energy weapons. Enough said.

- Antimatter. Fissile material. Chemical explosives. Chemical or biological weapons. Supercompressed plasma. Etc. (to many suicide-substances to list)

- On a more positive note, space travel. Fuel, supplies, structural stuff. End the tyranny of the rocket equation, and then create a space elevator out of carbon nanotubes just to show off.

- What does the complexity and density of a spell circle look like? Modern CPU? Victorian clockwork? Hand-drawn calligraphy? To what degree foes this limit the complexity of the output, in shape and composition?
:PROPERTIES:
:Author: PeridexisErrant
:Score: 2
:DateUnix: 1405259562.0
:END:

***** #+begin_quote
  What does the complexity and density of a spell circle look like? Modern CPU? Victorian clockwork? Hand-drawn calligraphy? To what degree foes this limit the complexity of the output, in shape and composition?
#+end_quote

Also, we can assume, since he mentioned circuit-boards, that spell-circles have very limited computational power of their own, right? So we can't try to leverage some conservation-law violating property of magic circles to build hypercomputers?
:PROPERTIES:
:Score: 2
:DateUnix: 1405260916.0
:END:


***** 1. That's totally fine, the spell circles just need to be able to erect a defense against those things.
2. Also totally fine.
3. Antimatter probably gets restricted - robots are meant to be an increase in war-making capacity, and having them be strictly suicide bombers seems like it would go counter to maximizing coolness.
4. Space travel is fine.
5. Complexity and density are on the level of calligraphy, though the simplest of spells can be written in the dirt with the point of your shoe. Magic does most of the heavy lifting, and follows from intent, with a couple caveats.

Thanks for the questions.
:PROPERTIES:
:Author: alexanderwales
:Score: 1
:DateUnix: 1405283957.0
:END:

****** Hmm. The more I think about absurd exploits and their plausibility, the better this sounds. Example cases:

- spell circles that create or modify spell circles

- space travel is basically free, and any mage can plausibly settle other planets or large moons.

- There is a hard upper limit on the price per unit of any (simple) substance, as mages can trivially make more. Platinum catalysed everything, hello!

- Many ways to make one-man WMDs with no materials == security freakout

It sounds pretty similar to /Ra/, actually.
:PROPERTIES:
:Author: PeridexisErrant
:Score: 1
:DateUnix: 1405302897.0
:END:

******* The desired end result is vampires, wizards, and robots fighting in the streets of New York City (which I hope should be sufficiently different from /Ra/) - it's just matter of creating the magic system that leads to that. (Vampires have their own rules that are less abusable.)
:PROPERTIES:
:Author: alexanderwales
:Score: 2
:DateUnix: 1405303374.0
:END:


******* Except magic in /Ra/ is quite a lot more expensive, since you need precisely machined equipment frequently made of rare metals. (Unless [[#s][Ra spoiler]], and creating spells takes months of engineering work. Assembling a staff from its pieces is considered a graduation project impressive enough to get instantly hired by what's arguably the most prominent magic-using corporation.
:PROPERTIES:
:Author: Solonarv
:Score: 1
:DateUnix: 1405462452.0
:END:


*** Random thought: what if magic makes it so that an enchanted object behaves the way that the people looking at it expect it to? Magicians set up optical illusions and such and make them real with magic, etc. A robot servant that does what you expect it to would probably be good enough for most purposes. There would have to be limitations of course. For example, they probably wouldn't work for the person who created them, because they know too much about how it works to expect it to work.

The idea is way too powerful as it is, but properly nerfed it could be interesting.
:PROPERTIES:
:Author: TimTravel
:Score: 1
:DateUnix: 1405672835.0
:END:
