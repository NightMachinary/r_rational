#+TITLE: [D] Friday Off-Topic Thread

* [D] Friday Off-Topic Thread
:PROPERTIES:
:Author: AutoModerator
:Score: 16
:DateUnix: 1533308848.0
:END:
Welcome to the Friday Off-Topic Thread! Is there something that you want to talk about with [[/r/rational]], but which isn't rational fiction, or doesn't otherwise belong as a top-level post? This is the place to post it. The idea is that while reddit is a large place, with lots of special little niches, sometimes you just want to talk with a certain group of people about certain sorts of things that aren't related to why you're all here. It's totally understandable that you might want to talk about Japanese game shows with [[/r/rational]] instead of going over to [[/r/japanesegameshows]], but it's hopefully also understandable that this isn't really the place for that sort of thing.

So do you want to talk about how your life has been going? Non-rational and/or non-fictional stuff you've been reading? The recent album from your favourite German pop singer? The politics of Southern India? The sexual preferences of the chairman of the Ukrainian soccer league? Different ways to plot meteorological data? The cost of living in Portugal? Corner cases for siteswap notation? All these things and more could possibly be found in the comments below!


** I think that /Mission Impossible: Fallout/ was maybe the most anti-utilitarian film I've ever seen.

Mild spoilers for things that were in [[https://www.youtube.com/watch?v=wb49-oV0F78][the trailer]], from what's essentially the prologue section of the film, prior to the first act. Alec Baldwin says "You had a terrible choice to make in Berlin, one life over millions, and now the world is at risk." This is followed by the CIA woman saying "If he had followed the mission, we wouldn't be having this conversation." Baldwin replies, "His team would be dead," to which the CIA woman replies, "Yes, they would, that's the job."

This is entirely sensible, if unheroic (at least in the classical sense of heroism). Most of the plot of the movie follows from Ethan choosing to save a lifelong friend rather than actually doing his job, and, as typical in a Mission Impossible movie, the world comes within a few lucky coincidences and millimeter precise moments of ... well, not necessarily /destruction/, but certainly megadeaths.

Where other movies might choose to make this message implicit, MI:Fallout chooses to hammer it home a number of times through dialog, repeating the refrain that actually, having a severe case of scope insensitivity is a /good/ quality in people who routinely have to deal with wild imbalances of scope.

I thought it was a great movie, but the fact that they kept trying to loudly proclaim that it's virtuous to neglect scope was a little bit jarring, given both my values and to some extent, the plot of the film.
:PROPERTIES:
:Author: alexanderwales
:Score: 20
:DateUnix: 1533322709.0
:END:

*** I think Hollywood, and other forms of entertainment media, have become more and more uncomfortable with the costs of winning at all costs. The simple narrative of a world at hair-trigger risk is an extremely convenient tool for increasing tension, /and/ an extremely convenient tool for political overreach.

Filmmakers and show-runners and comics authors are concerned that heroes who run around killing people today will be unsympathetic in a way that they weren't in the 1980's. So something is added to the text to assure the audience that they're good people: one is kind to animals, another loves his wife or children, another makes hard choices protecting the innocent when there are dangers.

The bleakest example from MI:F wasn't its inciting incident, it was Ethan fatally shooting four gang members in order to save the French police officer who saw the team stashing their prisoner. The movie only introduced, and killed, those characters in order to save the protagonist from a dilemma! They shoot her for him, functionally disarming her, and the fact that he kills in order to save her gains her trust. I'm even sure the movie chose to have her be a woman in order to make her seem especially vulnerable and innocent. Imagine the same scene with a character played by, say, Henry Cavill. It's lazy writing at the expense of potential character development. If you don't let Ethan learn the consequences of this sort of hard decision, he's going to find himself making this same mistakes over and over again.

Good for the movie series, I'm sure, but not so good for the making the sense.

A story could also concentrate on the hard decisions that "bad guys" had to make that put them in a situation where many of their deaths are, so far as this movie is concerned, worth saving one life. How many deaths are Ethan and Friends responsible for compared to any given disposable thug?

So the film is trying /really hard/ not to have us think about that sort of thing. ETHAN IS A GOOD GUY, it shouts over and over. I agree this has rather the opposite of the desired effect.
:PROPERTIES:
:Author: Sparkwitch
:Score: 10
:DateUnix: 1533343667.0
:END:

**** Funny enough, [[https://www.hollywoodreporter.com/heat-vision/mission-impossible-tom-cruise-pushed-a-dark-plot-was-cut-1130744][the original script was much more ambivalent about Hunt being a good guy]]:

#+begin_quote
  Case in point: McQuarrie and Cruise conceived of a plot that would have seen hero Ethan Hunt assume the identity of extremist John Lark for an even longer chunk of the film, a move that would have taken the IMF agent down some dark roads in pursuit of his goal and would have forced him to do some "horrible things," notes McQuarrie. The expanded plot was eventually scrapped, as the director felt it made the film too intellectual and robbed it of the trademarks that people expect from a Mission: Impossible movie.
#+end_quote

(The interview has some discussion from the director about a "dark" Ethan that I found fairly interesting.)
:PROPERTIES:
:Author: alexanderwales
:Score: 9
:DateUnix: 1533344755.0
:END:

***** An overt campaign against subtext, ambiguity, and intellect? Ugh.

Contrast my favorite recent Bond, /Skyfall/ in which /every single thing/ MI:6 tries to do fails because the stakes are high and the challenges are steep and what would happen if the narrative gods weren't on their side Or, more poignantly, [[https://en.wikipedia.org/wiki/Jim_Prideaux][Jim Prideaux]](spoilers!) from /Tinker, Tailor, Soldier, Spy/, an explicit portrayal of what might become of James Bond or Ethan Hunt in a more real world.
:PROPERTIES:
:Author: Sparkwitch
:Score: 3
:DateUnix: 1533346212.0
:END:


*** It would be darkly funny to make a fan edit of the movie that occasionally cuts to all the death and misery caused by the protagonist saving his friends at the expense of everyone else, just to undercut that message. Whenever the protagonist makes a point about how it was right to save his team, play 10 minutes of footage of funerals and the weeping parents/children/spouses for all the people who died when everything turned out "well". Not having seen the movie, I'm guessing a number of the good guys die, even if the day is saved in the end? And that number of preventable deaths was greater than the number of people on the protagonist's team?
:PROPERTIES:
:Author: sicutumbo
:Score: 7
:DateUnix: 1533325575.0
:END:


*** The boss lady was pretty much the only character whose actions weren't powered by kindergarten logic. Though by the end of the movie she got brainwashed as well, I suppose.

#+begin_quote
  I thought it was a great movie
#+end_quote

Nah, too many plot holes and cliches for that.
:PROPERTIES:
:Author: OutOfNiceUsernames
:Score: 3
:DateUnix: 1533436016.0
:END:


*** #+begin_quote
  Where other movies might choose to make this message implicit, MI:Fallout chooses to hammer it home a number of times through dialog, repeating the refrain that actually, having a severe case of scope insensitivity is a good quality in people who routinely have to deal with wild imbalances of scope.

  I thought it was a great movie, but the fact that they kept trying to loudly proclaim that it's virtuous to neglect scope was a little bit jarring, given both my values and to some extent, the plot of the film.
#+end_quote

It sounds to me like you've critically misunderstood. It /is/ moral to care about the individuals as much as the aggregates. If you care more about millions of people you've never met than about the few people you can see with your own eyes, you may have a moral failing. Such "scope sensitivity" opens you up to being manipulated by hearsay and conspiracy.

Here's a puzzle for you: Would you give up your life in exchange for the lives of a million strangers you've never met? This is, presumably, the moral thing to do. The real question is what evidence would you require first?

#+begin_quote
  I thought it was a great movie
#+end_quote

It was sufficiently enjoyable, but I wouldn't recommend spending theater money to see it.
:PROPERTIES:
:Author: ben_oni
:Score: 2
:DateUnix: 1533753875.0
:END:

**** #+begin_quote
  If you care more about millions of people you've never met than about the few people you can see with your own eyes, you may have a moral failing.
#+end_quote

That's just your misguided opinion. If saving humans is good, it's objectively better to save more people (assuming they all have the same worth).

#+begin_quote
  Here's a puzzle for you: Would you give up your life in exchange for the lives of a million strangers you've never met?
#+end_quote

No, because /to me/, my life has infinite more worth than any stranger's.

You're probably on the wrong sub.
:PROPERTIES:
:Author: MaleficentFuel
:Score: 1
:DateUnix: 1533843647.0
:END:

***** #+begin_quote
  No, because to me, my life has infinite more worth than any stranger's.
#+end_quote

As I said: moral failing.

#+begin_quote
  You're probably on the wrong sub.
#+end_quote

Screw you, too.
:PROPERTIES:
:Author: ben_oni
:Score: 2
:DateUnix: 1534139813.0
:END:


** So I finished the first book of the Mars Trilogy by Kim Stanley Robinson, Red Mars, and I think it would fit this sub's tastes even if I wouldn't necessarily call it rational. Hard sci-fi, dealing with the colonization and terraformi g of Mars, and all the ethical concerns raised by those actions. Kind of like the Foundation novels, but I can't put my finger on precisely why. Anyways, it's enjoyable, and I recommend it.

--------------

I still plan on talking about what I've learned about the art of memory, from Moonwalking with Einstein and a few other books, but I was indisposed on Monday for the general rationality thread and didn't want to post a comment that I put effort into if no one was going to see it. I also still need to out some time into practicing the techniques, but that isn't much of a priority right now.
:PROPERTIES:
:Author: sicutumbo
:Score: 10
:DateUnix: 1533315382.0
:END:


** A nice variant on the Shadow Clone: [[https://forum.questionablequesting.com/posts/720578][Kaizou Kage Bunshin (login required)!]] In order to prevent chakra poisons and memetic hazards from being transmitted to the original, the copy /doesn't/ return its chakra and memories to its creator when it's dispelled. Immediately after being created, it knows that it has been doomed to an imminent death. (I get the feeling that it needs a more specific name, though, since =kaizou= apparently ([[https://en.wikipedia.org/wiki/Kaizo_Mario_World][1]] [[https://translate.google.com/#ja/en/%E6%94%B9%E9%80%A0][2]]) means merely =modified=. [[/u/subrosian_smithy][u/subrosian_smithy]])

Fanfiction idea: A ninja who knows a technique that absorbs chakra from other people learns this technique and uses it---or, alternatively, a clone that was created with this technique by a poorly-disciplined ninja and then went rogue stumbles across a chakra-absorption technique. Now, roaming the Elemental Nations is a clan of chakra-vampire clones who must steal chakra from others to avoid dying. The story ends when they learn Sage Mode and become able to absorb chakra from plants and mundane animals rather than having to go after humans and summon animals---or when they've multiplied to such an extent that all human life has been extinguished and the summon animals have retreated to their homes (which are either across the ocean from the Elemental Nations or on a separate plane of existence from Earth, depending on the author).

Optional twist: The original is dead, and only his clones are still around. Maybe clones even are /immortal/ as long as they have enough chakra to continually Henge their malleable pseudo-bodies into younger forms---or, maybe, without specific souls to "remind" them of their proper forms, they gradually lose definition and deform into monstrosities, Glory Girl-style, if they attempt to prolong their lifespans.

See also the traditionally-published book [[https://www.goodreads.com/book/show/40600413][/Kiln People/]]. The book revolves around disposable clones, of varying lifespans and qualities, whose memories are uploaded back to their originals only if the clones return to base before running out of the [[https://en.wikipedia.org/wiki/%C3%89lan_vital]["élan vital"]] that was used to create them. IIRC (I haven't read this book in /many/ years---though [[https://www.goodreads.com/deals/about][Goodreads Deals]] recently facilitated my snagging a copy for $2, so I'll get around to reading it again soon enough) the ultimate villain of the story is a clone whose original discovered the secret of infusing élan vital into /existing/ clones (which normally isn't possible) in order to make those clones immortal. The clone, being high-quality enough to impersonate his original (most clones are cheap and unconvincing), killed the original and made himself immortal.

--------------

It's interesting to note how different authors treat [[http://naruto.wikia.com/wiki/Shadow_Clone_Technique][the Shadow Clone Technique]] differently. The default assumption is that, when a Shadow Clone is dispelled, its memories (along with some of any leftover chakra---or not, because the connection is purely soul-based, not chakra-based*) are transmitted back to its creator. Some authors, however, allow those memories to be transmitted, not only to the original, but also to /all/ the original's /other/ Shadow Clones! This alternative interpretation allows for such overpowered tactics as quickly creating and dispelling a Shadow Clone in order to transmit newly-learned information to your entire network in the blink of an eye, and thereby gets rid of the "the right hand doesn't know what the left hand is doing" situations that independently-operating Shadow Clones otherwise inevitably must confront if left to their own devices for long periods. On the other hand, however, some authors decree that any genjutsu that affects a Shadow Clone can /propagate/ (with some extra effort on the part of the genjutsu user---or not, because of self-amplifying soul-resonance effects---and only after the directly-affected clone has been dispelled---or not, because the genjutsu user can sense the thread of the clone connection and follow it back to its source in the course of casting the technique) to the creator---or, under the alternative interpretation that I just described, to the creator /and/ to his other Shadow Clones, which largely offsets the overpoweredness of that version of the technique (because, the more clones you have out, the more likely it is that an enemy will catch /one/ of those clones in a sleep genjutsu and render you and your one-man army totally defenseless in a single stroke).

I haven't read much /Naruto/ fanfiction in a while,** so the only relevant story that I can add to this pile of (You) bait (other than the one that I already linked) is [[https://www.fanfiction.net/s/5207262][/Indomitable/]].

*If chakra /is/ transmitted, however, enemies may be able to [[https://en.wikipedia.org/wiki/Triangulation_(surveying)][triangulate]] the original's position by dispelling several of his clones and using sensory techniques to watch where the clones' chakra goes.

**/Inter alia/, I was reading [[https://en.wikipedia.org/wiki/The_d%27Artagnan_Romances][the d'Artagnan Romances]]. My fifth reading of [[http://www.gutenberg.org/ebooks/1257][/The Three Musketeers/]] was as good as I remembered, and my second reading of [[http://www.gutenberg.org/ebooks/1259][/Twenty Years After/]] was significantly /better/ than I remembered---but I had to throw in the towel approximately 40 % of the way into my second reading of /The Vicomte de Bragelonne/ (halfway through [[http://www.gutenberg.org/ebooks/2681][Volume 2 of 4]]) because it was just /too/ boring and I wasn't willing to skip as much as I did on my first reading. /Ventre-saint-gris!/ Maybe I'll finally get around to experiencing [[https://www.fanfiction.net/s/5193644][/Time Braid/]] for the seventh time after reading [[https://www.goodreads.com/book/show/35066358][/The First Fifteen Lives of Harry August/]] (thanks, Goodreads Deals!)... but what about [[http://www.gutenberg.org/ebooks/135][/Les Misérables/]]? [[https://www.gwern.net/Culture-is-not-about-Esthetics#lets-ban-new-books][There are /so/ many options!]]
:PROPERTIES:
:Author: ToaKraka
:Score: 6
:DateUnix: 1533311489.0
:END:

*** #+begin_quote
  A nice variant on the Shadow Clone: Kaizou Kage Bunshin (login required)! In order to prevent chakra poisons and memetic hazards from being transmitted to the original, the copy doesn't return its chakra and memories to its creator when it's dispelled. Immediately after being created, it knows that it has been doomed to an imminent death. (I get the feeling that it needs a more specific name, though, since kaizou apparently (1 2) means merely modified. [[/u/subrosian_smithy][u/subrosian_smithy]])
#+end_quote

[[https://78.media.tumblr.com/4e48e1dd1870e9d394ca9079ab2e657e/tumblr_pclndmoCMm1qg0t5co1_1280.jpg][asdfgjsdkhj I wrote that derivative fanfic ages ago]]

If I was writing that today, yeah, I would go out of my way to give it a more specific name -- either getting input from a friend who knows Japanese, or (much more likely) just giving all technique names and such in English. I would also publish it elsewhere, where logins aren't required (and deleting posted fanfiction is actually possible without contacting moderators for support, lol). I anticipated getting much farther in that story than I actually did, but that's what writing is like.

#+begin_quote
  Maybe I'll finally get around to experiencing Time Braid for the seventh time after reading The First Fifteen Lives of Harry August (thanks, Goodreads Deals!)... but what about Les Misérables? There are so many options!
#+end_quote

Les Mis is pretty damn good, IMHO. It's a pain to find a good translation, though -- there's French wordplay flying left and right like Victor Hugo was competing with Aaron Smith-Teller.
:PROPERTIES:
:Author: Subrosian_Smithy
:Score: 2
:DateUnix: 1533316770.0
:END:

**** #+begin_quote
  I would also publish it elsewhere, where[...] deleting posted fanfiction is actually possible without contacting moderators for support[...].
#+end_quote

I am very glad to be able to say that [[https://i.imgur.com/sCZAlZ8.png][I've already downloaded a copy of this story]]. The Internet never forgets.
:PROPERTIES:
:Author: ToaKraka
:Score: 5
:DateUnix: 1533330120.0
:END:

***** You /monster!/
:PROPERTIES:
:Author: Subrosian_Smithy
:Score: 3
:DateUnix: 1533337763.0
:END:


*** Shadow clone-centric Naruto fanfics are usually very fun to read. If you know any stories like this, can you please link them?

#+begin_quote
  /The First Fifteen Lives of Harry August/
#+end_quote

Have you read [[https://www.goodreads.com/book/show/341735.Replay][/Replay?/]] To me, at least, the Harry August story felt rather bland compared to it. So maybe you'll like it too.
:PROPERTIES:
:Author: OutOfNiceUsernames
:Score: 1
:DateUnix: 1533436858.0
:END:

**** #+begin_quote
  Shadow clone-centric Naruto fanfics are usually very fun to read. If you know any stories like this, can you please link them?
#+end_quote

I can't say that I can think of /any/ Shadow Clone-/centric/ stories, beyond a few one-shots ([[https://www.fanfiction.net/s/4778238][/Coping Mechanisms/]], [[https://www.fanfiction.net/s/3118898][/Death of a Kage Bunshin/]], [[https://www.fanfiction.net/s/3882295][/Narcissus/]]).

#+begin_quote
  Have you read /Replay/?
#+end_quote

No, but it's been on my To-Read list on Goodreads for several years.
:PROPERTIES:
:Author: ToaKraka
:Score: 2
:DateUnix: 1533437592.0
:END:


** I finally binged through Attack on Titan season 2 the other day, in preparation for the third season. I'm really glad I did: it's a little more rough around the edges than season one was, but makes up for it in sheer audacity and fun factor. I wouldn't call Attack on Titan as a whole "rational" - the main character is dumb as a sack of potatoes - but I do love how the Isayama writes his mysteries. Everything was written with the intention of having an answer, rather than the answers being filled in after the fact.

--------------

I've gotten better at exercising discretion over what I read. It bugs me how many hundred-thousand-word stories I drop instantly because the author did something unforgivably stupid. Like, there are scenarios where I'll stick it out - generally when there's something else interesting going on - but for the most part a lot of authors have a hard time holding my attention. In Naruto fanfiction it's usually poor characterization or overuse of cliches (Sasuke bashing, "dobe", Kakashi is an irresponsible teacher, any number of fandom specific plots, /unnecessary or indiscriminate japanese/). In Harry Potter fanfiction "independent" or "backbone" is usually the trigger phrase. Keep in mind I'm not even counting the hundreds of fics I skip based on title and summary alone. The problem isn't that the people writing these things are necessarily bad authors. In fact, in many cases, they might actually be pretty decent, or at least technically competent. It's that they weren't able to spare the additional two motes of brain power required to eliminate the most obvious flaws in their work. Half the reason I like rational fiction is because no author who executes rational fiction correctly could possibly be inattentive enough to make something that hideous. (in theory)

(Bashing is another one - if a character is so inexplicably evil that the protagonist wonders out loud how they could have come to be that way, I drop it. I once received a great piece of advice about writing from a teacher of mine, that went something like: "If your writing is so unrealistic that your characters feel the need to /voice aloud/ how unbelievable it is, you should be careful. Make sure your characters never have an opinion about your writing, let alone a correct one.")

--------------

I should save /something/ for the recommendation thread, but I haven't read/watched anything really rational in the last few days, so I might as well post them here. Everything here is not necessarily equal, but they all passed the test of not being awful enough for me to drop them. In order of when I read them, from latest to earliest:

- [[https://forums.spacebattles.com/threads/fate-reach-out-f-sn-smt-p4-crossover-story-thread.245101/][Fate/Reach Out]] is a pretty dumb crossover of Fate/Stay Night and Persona 4. Pretty much submersed in Fate fanon, but it's not poorly written and gets the point of Persona. I really liked the dynamic between Shirou's typical martyrdom complex and Persona's whole "power of friendship" thing coming into conflict, and that was really the only thing I wanted from this crossover.

- [[https://forums.spacebattles.com/threads/man-off-the-moon-fate-extra-x-mass-effect.641011/][Man off the Moon]] is similar, except with Fate/Extra and Mass Effect. It's /alright/. Kind of boring prose-wise, and it doesn't get much of anywhere fast, but the author has a ridiculous update rate, and anything in these two fandoms that isn't shipper garbage is something to be cherished.

- Went through the first two seasons of Overlord the other day, and I wasn't expecting to like it as much as I did from the outset. I think that the main character's "emotional control" thing does wonders to stop the story from becoming yet another "trapped in another world to seduce girls" thing. The focus on the extended cast rather than the Overlord himself makes the story seem much more tense, something I'm really glad for.

- [[https://forums.spacebattles.com/threads/danmachi-percy-jackson-prytaneum.352191/][Prytaneum]], a crossover between Danmachi and Percy Jackson by Ryuugi. When it's not rehashing Danmachi canon, I'm really impressed by its dedication to worldbuilding, and by this weird ontological mystery caused purely by Percy's presence. Has the typical Ryuugi flaw of dropping the main story for a long drawn out series of mostly inconsequential fights for a while, which makes this a softer recommendation. It's not quite as hilariously drawn out as /The Games We Play/, which got fucking inane towards the middle.

I can't remember very much before that, last month. If anyone knows any medium long-fics that are either complete or still updating, along these same lines of quality, I'd love to hear your recommendations as well. This is strictly talking about non-rational fiction - you can trust that I have my eyes glued to the subreddit. Crossovers are fun, but only if they pay out in the end.
:PROPERTIES:
:Author: Tandemmirror
:Score: 5
:DateUnix: 1533316272.0
:END:

*** #+begin_quote
  /unnecessary or indiscriminate japanese/
#+end_quote

Oh that bugs me a lot as well. I've mostly stopped reading new fanfiction, because I feared that my tastes were regressing, but when I was into Naruto fiction the random Japanese was just so jarring. So many of the terms they use Japanese for have perfectly good English translations. I do not need nor want to remember the Japanese names for all the elemental nations, nor the named attacks. It's not like I'm missing some cultural phrase or something by only knowing the English names; it's just confusing. It comes off as the author being an anime snob who gets really heated about subs vs. dubs debates.
:PROPERTIES:
:Author: sicutumbo
:Score: 7
:DateUnix: 1533317101.0
:END:

**** It's not necessarily the villages or titles that I really care about, it's the inconsistency. If you are going to use "sandaime hokage" do not suddenly switch to "third hokage" whenever the hell it suits you, for instance. And with technique names, it's fine so long as the actual description of the technique is accompanied by the name, and it's consistent. It'd be weird if a story about ninjas /didn't/ have a lot of Japanese loan words. The problem is when those words don't really mean anything in Japanese either, or are irrelevant. I don't need to hear "konohagakure no sato" when you're just going to switch to Konoha in a few phrases anyway. I don't need to hear honorifics if you're going to be inconsistent about them, or you are unaware of the distinction between given and family names. Or if the author isn't educated enough to know what the Japanese they're throwing in means. I can't tell you how many stories I've dropped because they say something like "the village of the village hidden in the leaves" or something else that stupid.
:PROPERTIES:
:Author: Tandemmirror
:Score: 8
:DateUnix: 1533317778.0
:END:


** So could the [[https://en.wikipedia.org/wiki/Beauty_and_the_Beast_(2017_film)][2017 Beauty and the Beast remake]] be considered (bad?) "rational fanfiction"? I saw [[https://www.youtube.com/watch?v=vpUx9DnQUkA][this video]] a few days ago and felt that a lot of what its author didn't like about the remake would also hold true for many of the fanfics posted on this sub (e.g. fixing plot holes and inconsistencies at the expense of the original characterization). I also didn't quite agree with a fair bit of what she'd said (e.g. the Beast letting Belle go doesn't condemn the house to death, because keeping her an unwilling prisoner isn't likely to earn her love enough to satisfy the conditions of the curse). But overall have generally found her videos entertaining and thought-provoking.

I also think some of the things the remake "fixed" that she criticizes /were/ improvements to the 1991 Disney film (from what I recall of it, having not seen it in ages), e.g. if Prince Adam's primary failing at 11 was not letting a scary stranger into his house, then a decade-long curse ending in his death seems unjustified, especially since in actuality the powerful enchantress would have been /totally/ unharmed by a bit of foul weather and was totally willing to screw the Prince over with moral entrapment -- talk about stranger danger!). I think that casts the entire plot in a rather different light, and seems less nitpicky than a lot of her criticisms of the remake, as well as less answerable by the MST3K mantra (“If you're wondering how he eats and breathes and other science facts, then repeat to yourself ‘It's just a show, I should really just relax.'”). But I can still imagine stuff like that not bothering others as much.

(edit: to clarify, I did agree with many of her points)
:PROPERTIES:
:Author: phylogenik
:Score: 7
:DateUnix: 1533324480.0
:END:

*** (I love Lindsay Ellis.)

I think a lot of what she talks about in that video applies more generally to [[https://tvtropes.org/pmwiki/pmwiki.php/Main/FixFic]["fix fics"]], of which rational fanfic is commonly a subset. But in the specific example of Beauty and the Beast, a lot of the fixes that they made didn't actually need to be made, and in fact, make the work /less/ like rational fiction. In particular, Belle creating a washing machine that she's mocked for and Belle being chastised for reading when that's mostly ahistoric, the villagers being paid to sing Gaston's praises, Belle's mother having a tragic backstory that her father never explains to her ... a lot of them make the work make /less/ sense, not more, and they're not justifications for what happens in the original plot, they're things added on to answer criticisms of the original.

That said, yes, a lot of "bad" rational fanfic does those things too, and even some of the "good" rational fanfic will -- how to put this -- not necessarily fix things at the expense of the original characterization, but /explore/ things at the expense of that characterization, especially in terms of pointing out ethical or moral problems, knock-on effects of character decisions, etc. I might feel that the Beauty and the Beast remake was a better movie if I thought that it was attempting a deconstruction of the original, but I really don't think that the remake was doing that, it was just trying to put its own spin on things. (My read on Lindsay Ellis is that she wouldn't have a problem with a deconstructionist take on something, but I might be wrong.)
:PROPERTIES:
:Author: alexanderwales
:Score: 11
:DateUnix: 1533325476.0
:END:

**** My perception of "fix fics" was that they typically involved the protagonist (often a self-insert armed with foreknowledge of canon) going around averting and resolving conflicts that developed originally, but it looks like the tvtropes definition is a bit broader than that! TIL! I agree that your (/her) listed changes were unnecessary, and wonder how many of them were a casualty of the script being rewritten? I hear a lot of those sorts of loose ends result from having multiple cooks in the kitchen, so that the final product is a misshapen patchwork of competing visions. Otherwise I think I was able to just treat them as fluff/flavor text, or else think they served at least a /little/ bit to add depth to the characters -- overall I found the movie enjoyable, but maybe only by virtue of going into it with sufficiently low expectations.

I recall Ellis being ok with perspective-flip/subversive/revisionist retellings (I think maleficent was even mentioned in the video on Beauty and the Beast) which seem related to deconstuctive works, so I don't think she'd hate them a priori.
:PROPERTIES:
:Author: phylogenik
:Score: 1
:DateUnix: 1533327399.0
:END:


*** The first link in your post is hiding a lot of your comment's text!
:PROPERTIES:
:Author: rochea
:Score: 1
:DateUnix: 1533366380.0
:END:


** Hey, I'm in the mood for some depressing cynical story (don't ask). Anyone know something good, or should I just re-read /The Moon's Apprentice/?
:PROPERTIES:
:Author: CouteauBleu
:Score: 3
:DateUnix: 1533419093.0
:END:

*** [[http://www.lightspeedmagazine.com/fiction/the-giving-plague/]]
:PROPERTIES:
:Author: SvalbardCaretaker
:Score: 2
:DateUnix: 1533464571.0
:END:


** Have any of you seen or read Genocidal Organ by Project Itoh? I'm curious about what this community thinks of it. I thought it had some interesting ideas about linguistics and the Sapir Whorf theory.
:PROPERTIES:
:Author: babalook
:Score: 2
:DateUnix: 1533333539.0
:END:


** I feel like most Uplift fiction is inherently colonialist in attitude. The notion of one group of people going in and turning another group of people into 'smarter' people is essentially identical to the rationale used to justify colonialism in Africa. It is, in many ways, a textbook case of the white man's burden. When you strictly limit the definition of Uplift to just the introduction of new technological methods, I suppose that is something more generally acceptable. In general, however, most Uplift stories include much more than just new technological methods. They usually introduce new societal modes of being, or a new governance, or things of this nature. In my opinion, these types of stories are inherently flawed. Perhaps I am making too broad statements, but I cannot help but feel tones of colonialism resounding throughout these works.
:PROPERTIES:
:Author: Sampatrick15
:Score: 1
:DateUnix: 1533427107.0
:END:

*** #+begin_quote
  I feel like most Uplift fiction is inherently colonialist in attitude.
#+end_quote

I mostly agree.

#+begin_quote
  In my opinion, these types of stories are inherently flawed.
#+end_quote

Whoa, back up a bit. The /concept/ doesn't constitute an inherent flaw in a story, because the concept itself, as reminiscent of colonialism as it might be, says nothing about how that concept is used in the story.

For example, if the uplifting character or civilization is cast a villain, then doesn't that inherently comment on colonialism in a way that comports with your personal politics? Dr. Moreau isn't portrayed as a good guy, he's portrayed as a villain whose experiments are vile. If the seminal work of uplift fiction is anti-colonial in nature, how can you say that the concept of uplift makes for a flawed story on the basis of its similarity to colonialism? (Not to say that Wells wasn't shockingly racist by today's standards, nor that his anti-colonialist bent was informed by the same social mores that a modern anti-colonialism is.)

Similarly, many books about uplift feature the uplifted characters as second class citizens grappling to form a culture and society of their own. Do you think that's /not/ a comment on modern post-colonial issues of race and identity?

If /you/ can see that there are moral problems with uplift, then authors can too, and a lot of them choose to write about the concept of uplift simply so that they can address those very concerns.

Evaluation of the message of a work which features uplift must be done on a case-by-case basis.
:PROPERTIES:
:Author: alexanderwales
:Score: 12
:DateUnix: 1533431027.0
:END:

**** I think there's a difference between an uplift story and a story criticizing uplift. You could call NGE a Mecha anime, but that's not really accurate. It's a psychological thriller that criticizes Mecha anime. Similarly, a story that critiques a subgenre is by nature not actually a member of that subgenre; if it were, then it could not be a critique. I find it odd for you to bring up Dr. Moreau. Although I will admit that Dr. Moreau is in many ways a symbol of the flaws that Wells saw in educating non-White people (and holy fuck is he racist about it), the story itself isn't particularly anti-colonial. The conclusion is that beasts should be domesticated, not educated. That is certainly a colonial sentiment, even if it is not the same type of colonialism expressed in some other uplift stories. I suppose I can clarify my position; I think that all stories featuring uplift that are not criticizing uplift are inherently colonialist. I think that's a more accurate statement than the more blankety statement that I made before.
:PROPERTIES:
:Author: Sampatrick15
:Score: 1
:DateUnix: 1533434956.0
:END:


*** The themes of modern Uplift fiction feel to me like more of a struggle within progressive philosophy rather than the older kinds which were, as you say, pretty colonialist.

I mean, if you could snap your fingers and make everyone around the world suddenly accepting of other people's sexuality, would you? Maybe you'd say no to that, but I would in a heartbeat. Maybe that makes me a colonialist, or just someone arrogant for assuming that his morals or preferred social norms are better than others people's, but I think after a certain point the desire to reduce suffering and the desire to not interfere with other cultures is going to naturally come into conflict.

It's okay to draw lines in the sand or put up Chesterton fences, but they're going to be different for everyone. If one fantasy country manages to invent anti-aging magic or technology and offers it to another (freely or for a reasonable charge) maybe that would be okay to you, whereas secretly spreading it to the other country would not be okay... but then you have to consider the why. What if there are people in that country who want it, despite the majority of their country not wanting it? It's well and good to say "open borders and let them come," but what if that's just not possible? Most people don't have the money or means to just up and leave their country, even assuming their government or fellow citizens would let them. Yet it would undeniably change their society if some of them started to secretly accept the anti-aging tech and others didn't. There are arguments to be made about making sure the secondary effects of such sweeping societal changes are thought out and protected against, but if you'd call the desire to make those changes at all "bad," then I think there might just be a conflict or confusion of values.
:PROPERTIES:
:Author: DaystarEld
:Score: 5
:DateUnix: 1533538145.0
:END:

**** #+begin_quote
  if you could snap your fingers and make everyone around the world suddenly accepting of other people's sexuality, would you?
#+end_quote

Personally, I'm against brainwashing more than I'm against homophobia, especially seeing as we already know of ways to fight homophobia that don't involve brainwashing.
:PROPERTIES:
:Author: xartab
:Score: 2
:DateUnix: 1533746684.0
:END:

***** On a timescale of hundreds of years, sure. Meanwhile millions of people around the world suffer. From my perspective, being against brainwashing to this degree feels deontological, and I understand why it's a valuable deontology to have, but would argue that it's ultimately a misfire of moral compunction.

Scope insensitivity may also be a thing here. If one of your best friends came out as gay and became subject of abuse from their family, you might be more willing to snap if the snap would only affect the family and the abuse was happening right in front of you.
:PROPERTIES:
:Author: DaystarEld
:Score: 2
:DateUnix: 1533747273.0
:END:

****** #+begin_quote
  From my perspective, being against brainwashing to this degree feels deontological, and I understand why it's a valuable deontology to have, but would argue that it's ultimately a misfire of moral compunction.
#+end_quote

Ok, I'm trying to write a response and the more I write the more stuff comes up. So let's see.

*As a premise, my moral framework is Value Utilitarianism.

Do you think that if you went to all the homophobes in the world, and you told them that you were going to mess with their mind on a fundamental level, and they had absolutely no way of stopping you, you would cause less suffering than they cause by homophobia? It's possible, and if the answer is yes, then you've got an argument in favour of the /Snap/ scenario.

We should also consider that, seeing as a certain share of homophobes don't contribute all that much suffering to homosexuals (today), the odds that the above moral calculation ends in favour of the /Snap/ is even lower. Though I will grant it's arguable.

The fact is, on the face of it, changing the value function of a moral agent (brainwashing) is an a-moral action, because the new value function you get will agree that the new state of affairs is better, whatever you do. That's how value functions work.

But we generally consider brainwashing as immoral. Also, if we were to count that way, then killing someone - by surprise - who has no connection or living relatives and is not paying taxes or otherwise contributing to society, like homeless people, would also be an a-moral action, because at the end of it there's no mind to suffer. Seeing as we don't generally consider either acceptable, you can infer that we use the prior values as the ones to be taken into account in moral considerations. (As I write it occurs to me that forcefully changing someone's value function could be considered a harm with a magnitude equal to the distance from the former values to the newer ones. But then again, is there a way to equate world-state distances to scalar value differences? I don't know).

Now, we should also consider the consequences of that choice. It's no doubt that homosexuals will continue to suffer unduly for decades, possibly centuries, because of the hostility of homophobes. But how should we consider the harm caused by changing the value function? As instantaneous? As continuous from that point forward, every time the brainwashed make a choice they would have made differently if you hadn't messed with them? None of the two seems immediately obvious to me.

If we were to take the first one as true, then Snapping would end up being the least-suffering alternative. If the second one was true, then NonSnapping could be the least-suffering alternative. And it's also likely that you would have to Snap some people again in the future, who would become homophobes for various reasons.

#+begin_quote
  Scope insensitivity may also be a thing here.
#+end_quote

It could be for my position, and also for yours.

#+begin_quote
  If one of your best friends came out as gay and became subject of abuse from their family, you might be more willing to snap if the snap would only affect the family and the abuse was happening right in front of you.
#+end_quote

True, but this is a flawed argument. First of all, we're both against homophobia, so our preference has to be taken into account as to what we choose and whether we should choose that. Second of all, it's an appeal to emotion and proximity. I could also have one or multiple friends and family members who are homophobes, and I would want for them to not be brainwashed.

So at the end of the day, I wouldn't want to snap the Snap because I wouldn't know how much harm I'm causing, or if it's less than the harm I'm preventing, and because there are clearer and less ambiguous paths to fix homophobia.

Of course you could change my mind if you solved those uncertainties.
:PROPERTIES:
:Author: xartab
:Score: 1
:DateUnix: 1533751043.0
:END:

******* Wait, hang on. Why would this:

#+begin_quote
  Do you think that if you went to all the homophobes in the world, and you told them that you were going to mess with their mind on a fundamental level, and they had absolutely no way of stopping you, you would cause less suffering than they cause by homophobia?
#+end_quote

Be a consideration? Maybe you're rejecting the hypothetical and replacing it with a more reasonable approximation of how some kind of mind-altering tech deployment would go in terms of public awareness, but in the hypothetical as it is, there's no reason to tell anyone anything like this. Even if I presume that someone being aware that they're about to undergo a change in values automatically causes notable suffering (which itself needs to be established), I don't really see any reason to believe people not being aware of their impending shift in values toward being more accepting of other people's sexualities would cause suffering.
:PROPERTIES:
:Author: DaystarEld
:Score: 1
:DateUnix: 1533787882.0
:END:

******** There's no need to go to every last homophobe and do that if you decided to snap. As I said before, if you just snapped your fingers and all is done, you wouldn't */get/* how much you're violating the values of those of which you are violating the values. But if you did explain to each one what you're about to do, and the fact that you're about to do it by snapping your fingers, then by gauging their reactions you would get a sense of the amount of harm that you are doing them.

On the other hand, it's also possible that a small number of them would prefer to not be a homophobe anymore.
:PROPERTIES:
:Author: xartab
:Score: 1
:DateUnix: 1533809757.0
:END:

********* This sounds a bit like "you don't understand how potentially important being homophobic is to homophobes, so you don't know how much suffering you'll cause."

Let's replace "homophobia" with something like "non-sexual sadism" now. I would also snap my fingers and change everyone with such violent compulsions too, if we change the hypothetical to being able to alter things on a deeper level. Would you have the same objection? That I should privilege people's potential desire to cause harm as a consideration of harm caused to them by no longer desiring it?
:PROPERTIES:
:Author: DaystarEld
:Score: 1
:DateUnix: 1533831916.0
:END:

********** #+begin_quote
  This sounds a bit like "you don't understand how potentially important being homophobic is to homophobes, so you don't know how much suffering you'll cause."
#+end_quote

Well yes. Not only that, but also the fact that you're modifying their core being without any warning or recourse. Just because homophobia is distasteful and immoral, it doesn't mean snapping it away wouldn't be a form of harm.

#+begin_quote
  Let's replace "homophobia" with something like "non-sexual sadism" now.
#+end_quote

Do you mean "acting sadists"? Because it could also be taken to include "people who would like to behave sadistically but are able to contain their urges". I'll take the first definition.

#+begin_quote
  Would you have the same objection? That I should privilege people's potential desire to cause harm as a consideration of harm caused to them by no longer desiring it?
#+end_quote

Yes/No. Not /privilege/, though that's a possibility (it could be that for humanity as a whole value-function integrity is of greater importance than avoiding violence and hostility), but I would still try to weigh which of the two outcomes causes greater harm.

Interestingly though, I think it's safe to say non-sexual sadists are way less than homophobes, and I also think that there's a chance a relevant slice of sadists would want to have their sadism removed. Obviously you would still need to think about it and draw your conclusions (and the problem about the temporality of the harm in changing a value function would still need an answer).

It's probably correct to eyeball that snapping for sadists would be a net improvement, so, despite taking my time to think about what to do, I would probably have less reservations about snapping acting sadists away.
:PROPERTIES:
:Author: xartab
:Score: 1
:DateUnix: 1533925692.0
:END:

*********** #+begin_quote
  Just because homophobia is distasteful and immoral, it doesn't mean snapping it away wouldn't be a form of harm.
#+end_quote

I think this is our crux. I don't take the transition of values in and of itself to be a form of harm, because values can and do arise without one's choice in the first place, and can change for the same reason. So the results are what matter, ultimately, when calculating if altering someone's values is moral.

If I have reason to believe raising my kids not to be homophobic is good, then I should have reason to believe other people's kids not to be homophobic is good, and then I should also believe that it would have been good if all kids going backward in time had not been raised homophobic, etc. If I can accomplish that with a finger snap instead of a time machine, it seems reasonable to do so.

Part of me wants to say that maybe the snap also makes them okay with their values changing, but I'm guessing you would actually think that worse?
:PROPERTIES:
:Author: DaystarEld
:Score: 1
:DateUnix: 1533932439.0
:END:

************ #+begin_quote
  I don't take the transition of values in and of itself to be a form of harm, because values can and do arise without one's choice in the first place, and can change for the same reason.
#+end_quote

What about this: there's a distinct difference between values changing because of the world and values changing because of your magic. It's approximately the same difference as between having to sell you house because you're out of money and having someone threatening you at gunpoint into selling you house.

Importantly, new values that emerge organically (we're talking terminal values) have a relationship of interdependence with the previous values one holds, which isn't the case for the Snap. If in your life new information and experiences cause your brain chemistry to change and take on a new value, it would be in the context of yourself and what your internal state allows. I'll give you an example.

Let's say we have to homophobic women, Alice and Beth, both homophobic because of religious beliefs.

When Alice's teenage son comes out of the closet, she realises the error of her previous position and stops being homophobic. Beth instead, in that same situation, drives her son out of her house and stops acknowledging their relationship.

Now, I don't think both necessarily changed their terminal values. While Alice is at the beginning still a little distressed while witnessing expressions of homosexuality, in time she learns to accept homosexual love without compunctions and cherish her new worldview. Beth instead never stops holding her relationship with her son valuable. She will suffer for all her days for her lost son, even if the pain will eventually fade to something bearable.

Now, if you snap your fingers, you take away from her something she values more than her own son. Does that seem like not-harm?

#+begin_quote
  If I have reason to believe raising my kids not to be homophobic is good, then I should have reason to believe other people's kids not to be homophobic is good, and then I should also believe that it would have been good if all kids going backward in time had not been raised homophobic, etc. If I can accomplish that with a finger snap instead of a time machine, it seems reasonable to do so.
#+end_quote

Right, but kids have no values that you would be changing. Using a time machine to knock on a specific door at a specific minute would also cause that homeless person to not be born, but morally that's not equivalent to killing them.

#+begin_quote
  Part of me wants to say that maybe the snap also makes them okay with their values changing, but I'm guessing you would actually think that worse?
#+end_quote

I would say that their after-snap state has no bearing on the morality of the decision, because as I said before (and I'm guessing you found that argument sound?) we tend to base our morality on the prior state of the value function.

(EDIT: I have to correct myself. The post-snap state /can/ have a bearing, in that it could determine the amount of harm that you have dealt people.)

Ok, thought experiment. There's a person that has an heriloom that holds sentimental value. You snap them into hating that heirloom, though not the memory it's connected to. Then they destroy the heirloom. Is what you did moral?
:PROPERTIES:
:Author: xartab
:Score: 1
:DateUnix: 1533946783.0
:END:

************* #+begin_quote
  Now, if you snap your fingers, you take away from her something she values more than her own son. Does that seem like not-harm?
#+end_quote

It depends entirely on what those values are, in my view. There's no ur-value of "respecting values" that I think should be divorced from consequences of those values. If the value that's more important to her than her son is one that leads to better outcomes for others in the world, great. If it leads to pain and suffering for herself and others without adding anything positive, then that value is destructive and I don't think it's harmful, even to her, to remove it. Indeed, I'm still not sure where the actual harm comes in, other than potential horror or discomfort with the /concept/ of having your values changed without you knowing it.

#+begin_quote
  Right, but kids have no values that you would be changing. Using a time machine to knock on a specific door at a specific minute would also cause that homeless person to not be born, but morally that's not equivalent to killing them.
#+end_quote

This is confusing the method for the desired outcome. If I want to stop Hitler from starting WWII, I might /prefer/ to use a time machine to prevent him from being born, but if I can't do that I would still accept the ability to snap my fingers and change his values.

#+begin_quote
  I would say that their after-snap state has no bearing on the morality of the decision, because as I said before (and I'm guessing you found that argument sound?) we tend to base our morality on the prior state of the value function.
#+end_quote

No, I don't really think I agree with you that the transition from prior state of the value has as much bearing morally as the consequences of their values.

#+begin_quote
  Ok, thought experiment. There's a person that has an heriloom that holds sentimental value. You snap them into hating that heirloom, though not the memory it's connected to. Then they destroy the heirloom. Is what you did moral?
#+end_quote

No, because consequentially the heirloom was causing no harm, but it was providing some benefit to their life. You can't divorce the harm of homophobia from the concept of the value itself. The whole /reason/ I'm okay with snapping away homophobia or sadism is because they /cause harm,/ in an unarguable and observable way. It might be arguable that they provide some value too, like the sentimentality of an heirloom, but if so I've never encountered a compelling argument for how.
:PROPERTIES:
:Author: DaystarEld
:Score: 1
:DateUnix: 1534491010.0
:END:

************** #+begin_quote
  It depends entirely on what those values are, in my view. There's no ur-value of "respecting values" that I think should be divorced from consequences of those values.
#+end_quote

It's not so much "respecting values" (which is morality), as "not changing value-functions" (which is "no brainwashing").

#+begin_quote
  If the value that's more important to her than her son is one that *leads to better outcomes for others in the world*, great.
#+end_quote

If instead of snapping the homophobes into acceptance you could snap the homosexuals into heterosexaulity, would you deem the outcome equally favourable? Not trying to be snarky, it's an honest question.

#+begin_quote
  This is confusing the method for the desired outcome. If I want to stop Hitler from starting WWII, I might /prefer/ to use a time machine to prevent him from being born, but if I can't do that I would still accept the ability to snap my fingers and change his values.
#+end_quote

I don't think it is, in fact I think that if you ask people how they would choose, between the time-travel option and the killing homeless people option, you wouldn't get an "it's the same". Also I don't think the Hitler analogy works all that well, because there is extremely little moral grey in stopping the holocaust. The "kill Hitler" hypothesis will practically always come on top, even if it comes with "but Hitler will suffer agonising torture for a million years".

#+begin_quote
  No, I don't really think I agree with you that the transition from prior state of the value has as much bearing morally as the consequences of their values.
#+end_quote

Wait a minute. I'll explain myself better. I'm not saying that if I had to choose between one single non-acting homophobe in San Francisco versus a kid about to be stoned to death in Iran I would hold my breath in indecisive panic. I'm not saying that preserving the value function and avoiding persecution and hostility have the same importance. What I'm saying is that the quantities and the measurements, in this particular circumstance, are enough to warrant forsaking the snap out of caution.

#+begin_quote
  No, because consequentially the heirloom was causing no harm, but it was providing some benefit to their life.
#+end_quote

We could add a caveat. You can make them hate their family heirloom and cherish an object reminiscent of a random insignificant moment in history at the same time. Do you think the overall morality of this snap is neutral?

#+begin_quote
  It might be arguable that they provide some value too, like the sentimentality of an heirloom, but if so I've never encountered a compelling argument for how.
#+end_quote

The problem is, you're thinking about the heirloom as an item instrumentally useful to satisfy a deeper value, in this case the sentimentality associated with the object. I'm trying to frame my examples around terminal values, in themselves.

Let's try this: if you asked most people to snap away the love for a dead relative, they wouldn't accept, despite the fact that they are suffering from the loss and nobody gains anything from their continued suffering. The thing that they don't want to loose is not an advantage in how they feel, or a memento of something else. They literally care about keeping caring.

P.s., sorry if this comment is all over the place, I had to write it in instalments.
:PROPERTIES:
:Author: xartab
:Score: 1
:DateUnix: 1534521612.0
:END:

*************** #+begin_quote
  It's not so much "respecting values" (which is morality), as "not changing value-functions" (which is "no brainwashing").
#+end_quote

Right, "no brainwashing" is deontological, not consequentialist. You're saying it's not because the changing of value functions is "harm," and I'm saying "show me the harm inherent to the value change, because I'm not seeing any in cases like this."

#+begin_quote
  If instead of snapping the homophobes into acceptance you could snap the homosexuals into heterosexaulity, would you deem the outcome equally favourable? Not trying to be snarky, it's an honest question.
#+end_quote

No, because now you're changing more than just people's values, you're actually messing with millions of happy homosexual relationships, which is clearly harmful.

#+begin_quote
  I don't think it is, in fact I think that if you ask people how they would choose, between the time-travel option and the killing homeless people option, you wouldn't get an "it's the same". Also I don't think the Hitler analogy works all that well, because there is extremely little moral grey in stopping the holocaust. The "kill Hitler" hypothesis will practically always come on top, even if it comes with "but Hitler will suffer agonising torture for a million years".
#+end_quote

Point taken about the Hitler hate skewing things, but my actual point is that there is extremely little moral grey area in eradicating homophobia. I'd say there's actually none, like the holocaust. Both are unambiguously bad things. The fact that some people disagree does not change that, anymore than some people thinking that starving themselves makes them healthy actually changes what "healthy" means.

#+begin_quote
  What I'm saying is that the quantities and the measurements, in this particular circumstance, are enough to warrant forsaking the snap out of caution.
#+end_quote

Okay, but you're not actually demonstrating any actual harm being caused at all. You're presuming that value-changing is harmful. I'm saying "show me how."

This is like the "what if bugs are sentient" question, come to think of it. I don't think bugs are, personally, so I don't care about bug suffering. If someone wanted to convince me that bug suffering matters, they would need to not only show me that, because there are trillions of bugs on the planet, even tiny amounts of suffering add up to more than humans, they /first have to prove that bugs suffer./

To make me care about the scope of this snap, you /first have to prove that value changing causes suffering./ I don't think you have, yet.

#+begin_quote
  We could add a caveat. You can make them hate their family heirloom and cherish an object reminiscent of a random insignificant moment in history at the same time. Do you think the overall morality of this snap is neutral?
#+end_quote

I'm not sure I understand the example, but if you mean "we can make them hate the literally worthless Object A that they have attachment to, and make them suddenly love another literally worthless Object B that they also own but previously had no attachment to," that WOULD seem neutral to me, except consequentially it means people around them would be confused by this sudden nonsensical change in preferences. If no one else around them would ever know the difference or care, then yes, it's neutral. It may still be harmful or beneficial depending on other factors, but the mere transference of sentiment from one object to another seems harmless to me.

#+begin_quote
  Let's try this: if you asked most people to snap away the love for a dead relative, they wouldn't accept, despite the fact that they are suffering from the loss and nobody gains anything from their continued suffering. The thing that they don't want to loose is not an advantage in how they feel, or a memento of something else. They literally care about keeping caring.
#+end_quote

Sorry but this is a horrible example :P Feeling love for someone who is dead causes suffering, but it doesn't erase the love itself, which has benefits of its own. They care about keeping caring because their caring /is itself valuable./

Homophobia is not. You're saying that people want to keep hating others the same way grieving people want to keep loving the people they grieve. But I don't care about the former. I don't value their value of their mindless, pointless hate. I would not snap away ANY hate or ALL hate, but this kind of hate, yes, there is literally no value in it that I can perceive, and I'm not going to bully my reason into thinking it's a bad idea to get rid of it without someone demonstrating actual harm that comes from snapping it away, even if they say that the actual act of value-changing is itself harmful.

Harmful how? Show me the harm, where is it? What does it look like? What tears does it spill, to wake up one morning and no longer hate someone for such an utterly pointless reason? You keep trying to insist that the "brainwashing" act itself is bad, but "bad" is meaningless if you can't point to the observable harm it causes, empirically.

#+begin_quote
  P.s., sorry if this comment is all over the place, I had to write it in instalments.
#+end_quote

No problem, it was fine to me!
:PROPERTIES:
:Author: DaystarEld
:Score: 1
:DateUnix: 1534571149.0
:END:

**************** #+begin_quote
  Okay, but you're not actually demonstrating any actual harm being caused at all. You're presuming that value-changing is harmful. I'm saying "show me how."
#+end_quote

How do you assess harm? Not by physical pain alone, as sometime we suffer pain in order to gain something we value more. Not by psychological pain alone, as sometime we accept experiences that will cause us anguish in order to gain something we value more. We can propose that harm is equivalent to how much the world moves away from how we would want it to be, not by superficial desires but by deep wants.

Also, we don't value the perception of satisfaction in itself, we value how reality is, despite our perception (mostly).

For example, most people would prefer to suffer by discovering that their partner has cheated on them, rather than live happily all their life without being aware of the betrayal. Another example, we value things that will happen to out bodies after we are dead, despite the fact that we won't be around to perceive them.

This means that if you dissatisfy a value, the individual being aware of it doesn't come into play.

Now, I admit that there are people who don't agree with this, they don't care if their values are infringed when they're not aware of it, or after they become unable to keep caring. Maybe you belong to this category.

It doesn't matter, because harm is not decided by how those people feel, it's decided by how /everyone to which a decision applies/ feel. It's decided by the satisfaction or dissatisfaction of the value function of everyone. And I will point out that physical facts have no influence on what one /should/ (terminally) value, because of Hume's guillotine. Provided, that is, that specific value satisfactions aren't contingent on physical reality.

Oh, by the way, I don't know if you already watch Robert Miles' YT channel, but it's very interesting. In [[https://youtu.be/ZeecOKBus3Q?t=262][this video]], he goes into convergent instrumental values (he calls them goals... which is kinda better than values, I should do it too) and later arrives at /goal preservation/ (6:28). I don't think it will convince you of anything, but you can never know. Maybe his eloquence, which is a world apart from mine, will give you some sort of epiphany. Or maybe not, but it's neat anyway.

#+begin_quote
  Right, "no brainwashing" is deontological, not consequentialist.
#+end_quote

I don't agree. I think it's consequentialist in a way that takes into account previous states as relevant states. Like, if tomorrow a Superintelligent AI had the power to change all the values of humanity, to the very last one, into a value of not-existing, and then destroyed humanity to fulfil that value, by your definition it would have done nothing wrong.

The reason why I bring up brainwashing is that I think it's difficult to visualise the condition of having your values changed, as it happens so rarely in reality, but it's a common trope in fiction. When we see it in fiction, it's usually presented as an evil, meaning that authors of fiction, at the very least, think value-changing is evil... evil means bad, bad means that it decreases value satisfaction, and that means that there must be a value against it.

#+begin_quote
  No, because now you're changing more than just people's values, you're actually messing with millions of happy homosexual relationships, which is clearly harmful.
#+end_quote

You could probably have deduced from context that my question was meant to ask what your opinion would be if the only appreciable change in value satisfaction was changing sexual orientation, while preserving other variables, as the total quantity and happiness of relationships. I'm going to extrapolate that if you'd answered the latter, you would have said that yes, you do find it equally favourable. Please correct me if I'm wrong.

If that's the case, I'll point out again that your system of values is not shared equally by everyone.

(You can then argue that we would take into account the amount of value each to-be-snapped person would put on not having their values changed, and I would agree. I think for large populations a representative sample would do, so we could gather a lot of people chosen at random, interview them, and then determine their average amount of aversion to the thought of having their value function changed)

#+begin_quote
  They care about keeping caring because their caring /is itself valuable./
#+end_quote

This is precisely my point.

#+begin_quote
  But I don't care about the former. I don't value their value of their mindless, pointless hate.
#+end_quote

[[https://lh5.googleusercontent.com/tPvbV4OfLbgcERXPv722tqo9FVQYUwAewJeWW2EoGDMpvg-8TcnGvvHJGWLrrByAa0jxB6753tZHwBDVTpFo7oTyM_6Zcbf9Lnf3RTQeDmdWcltNlf3s1DvGSg6kPSUD3kQFdA89][Relevant.]] By which I don't mean that you're wrong in not valuing it, but that hurt isn't calculated on the basis of what /you/ value.

Nice discussion by the way, I love this subreddit.
:PROPERTIES:
:Author: xartab
:Score: 1
:DateUnix: 1534606050.0
:END:

***************** Hmm. I feel like we're missing each other's cruxes. Particularly because of things like this:

#+begin_quote
  I don't agree. I think it's consequentialist in a way that takes into account previous states as relevant states. Like, if tomorrow a Superintelligent AI had the power to change all the values of humanity, to the very last one, into a value of not-existing, and then destroyed humanity to fulfil that value, by your definition it would have done nothing wrong.
#+end_quote

It seems like you keep bringing up examples of changing people's values that lead to them then objectively losing something in some way that we can from our vantage point obviously determine is negative. If you can't posit a situation in which people's values are changed /without/ it actually being a bad thing, then I think you may, in fact, truly, despite your repeated insistence otherwise, deep-down consider value-changing to be bad deontologically, and not consequentially, especially when you bring up how it's so often bad = evil = harmful in fiction :P

The homo-to-hetero snap that also takes into account all the different changes in life circumstances to equalize happiness seems like it's stretching things beyond the scope of the question in order to come up with a scenario that proves your point, but if it helps, I /would/ say that snapping to make everyone bisexual is another thing I would do and consider an obvious net positive.
:PROPERTIES:
:Author: DaystarEld
:Score: 1
:DateUnix: 1534833267.0
:END:

****************** Values changing is clearly harmful in a preference utilitarianism way.like if you had a papercliper and modified it to not want to tile the universe whith paperclips y the papercliper would not want you to do that .And if someone actually wants to be homophobic then changing them to not be homophobic will rate negatively on their utility functions .And people generally consider that doing things to someone that they wouldn't want you to do to is bad . It just happens that it balances whith the good generated by happy homosexual relationships in your preferences.

I think people's cev probably doesn't include homophobia and if they knew enough they would want to want to be homofobic .But this is not trivially correct and there is room for someone to disagree there .

A papercliper would want to make everyone want to make more paperclips , and for the perspective of the papercliper thats only positive .But you could also have an agent that minimizes the changes the utility functions of humans , and that also seems perfectly consecuentialist so. (though now that I think about it It I'm confused about if there is any kind of deontology that you can't see as some kind of consequentialism if you go meta enough.huh).There is nothing inherently silly about caring about changes in the preferences of other people.

And In any case there are good reasons to have rules against changing people's values like that.Its better if everyone agrees to that norm so our enemies don't brainwash everyone into something we dislike .Even if it would actually be good if you actually did it.
:PROPERTIES:
:Author: crivtox
:Score: 2
:DateUnix: 1534988951.0
:END:

******************* I agree that if we're talking about potential symmetrical weapons, we should avoid using bad ones in realistic scenarios. But I don't think that actually translates to hypotheticals where you get to actually use a weapon your opponent can't. If there's actually a way to remove pedophilia from humans, for example, the people who discover that cure may decide not to spread it around if the actual discovery can also be used to change other fundamental parts of people's drives against their will. But if they happen to find a way to do so that does not risk others misusing what they've invented, they absolutely should use it to remove pedophilic urges from all humans, with or without their consent, and this seems obviously true to me for things like homophobia or sadism too.

To not take such clear utilitarian wins out of fear of some vague "badness" of changing people's values feels like deontology, or just bullying our reason into feeling bad about what it knows is obviously beneficial.
:PROPERTIES:
:Author: DaystarEld
:Score: 1
:DateUnix: 1535094273.0
:END:


****************** #+begin_quote
  If you can't posit a situation in which people's values are changed /without/ it actually being a bad thing, then I think you may, in fact, truly, despite your repeated insistence otherwise, deep-down consider value-changing to be bad deontologically, and not consequentially
#+end_quote

Sure, I can come up with situations in which changing people's values is not a bad thing.

An example that it's not mine but that works well is from Worth the Candle. If you read it, you probably know already what I'm talking about:Amaryllis changing her feelings for Joon, via existentialism, in the HTC. If someone else did it, it would still have been good. Another one, that I've seen here in /rational, was a user that wished they could discard their interest for sexuality. I think if you snapped that value away in them, it wouldn't be a bad thing.

I think it's not impossible to change someone's values and it be a moral action. If they would do it anyway, given the chance, then it's not harm.\\
Now keep in mind that 'til now we've talked as normal human beings in our current world, where there is no tool for uncovering the true value function of someone, and we don't know how terminal, instrumental and convergent values interact in practice. So obviously we must infer what would be right or wrong from context and with limited models.

#+begin_quote
  especially when you bring up how it's so often bad = evil = harmful in fiction :P
#+end_quote

That was for argument's sake, yo!

#+begin_quote
  I /would/ say that snapping to make everyone bisexual is another thing I would do and consider an obvious net positive
#+end_quote

As bonobos teach. That is the point, though, a /net/ positive. Some people would get the sort end of the stick.
:PROPERTIES:
:Author: xartab
:Score: 1
:DateUnix: 1534952785.0
:END:

******************* #+begin_quote
  Sure, I can come up with situations in which changing people's values is not a bad thing.
#+end_quote

Sorry, should have clarified: from an outside agent and without their choice for it to happen. Not someone choosing to alter their own or with their permission.
:PROPERTIES:
:Author: DaystarEld
:Score: 1
:DateUnix: 1535093937.0
:END:

******************** Sorry for the delay, life and stuff.

#+begin_quote
  from an outside agent and without their choice for it to happen. Not someone choosing to alter their own or with their permission.
#+end_quote

Yes, I meant if they /would want it, implicitly/ as well. As long as their value function is not against it, and/or they gain something more than they lose, and/or someone else gains something more than they lose^{1}, then yes, it is moral to do.

1. I say this assuming no other value is being infringed, as it's important to notice that causing harm to someone as an instrumental mean to gain benefit for others, when they have no blame-worthy contextual responsibility, is a very, very big negative value for humanity in general. Nobody wants to suffer just so that some stranger may benefit^{2} - if they didn't choose self-sacrifice independently.
2. This other value is also consequential, you could forsake it for a big enough good, like in the fat man trolley dilemma you would push the fat man if enough children were on the rails, but it's comparatively rather high.
:PROPERTIES:
:Author: xartab
:Score: 1
:DateUnix: 1536143204.0
:END:


*** "Uplift" and "Colonialism" are basically the same thing; the one group of people (or aliens) goes to the other group of people (or aliens) and more or less tells them "This is how you should be doing things, now do it our way". This is often accompanied by an explicit or implicit "or /else/".

But I don't think that means that the /story/ is inherently flawed.
:PROPERTIES:
:Author: CCC_037
:Score: 3
:DateUnix: 1533567238.0
:END:


*** You've looked at examples of colonialism in the past, done by uninformed people, and on that basis you conclude that colonialism is always a bad thing. That's sloppy reasoning.
:PROPERTIES:
:Author: MaleficentFuel
:Score: 3
:DateUnix: 1533840654.0
:END:

**** So is your thesis that colonialism is actually a good thing?
:PROPERTIES:
:Author: Sampatrick15
:Score: 1
:DateUnix: 1533999053.0
:END:


*** Could you give some examples? I've never actually read Brin's Uplift books, so is that what you're talking about?

The example that immediately comes to my mind (though I wasn't a big fan of the book) is Clarke's /Childhood's End/. The paternalism is played to the hilt, but the identification of the reader is with the "normal humans," not with the overlords or the future humans, and the ending certainly doesn't reinforce any themes of colonialism (also the aliens are literally demons). I guess what I'm saying is I can see how there are parts that can be read as "colonialism is justified because it's benevolent," but I don't think that's a necessary reading in this case, and maybe it's not a necessary part of the causal story behind the book.
:PROPERTIES:
:Author: Charlie___
:Score: 1
:DateUnix: 1533516299.0
:END:
