#+TITLE: The Trouble with Transporters

* [[http://youtu.be/nQHBAdShgYI][The Trouble with Transporters]]
:PROPERTIES:
:Author: raymestalez
:Score: 29
:DateUnix: 1457366705.0
:DateShort: 2016-Mar-07
:END:

** Just spent the evening [[https://www.reddit.com/r/videos/comments/49cghv/cgp_grey_the_trouble_with_transporters/d0qpogy][trying to explain this]] to the kind folks over at [[/r/videos]]. Funny how everyone has such a strong intuition about it!

Somebody posted [[http://existentialcomics.com/comic/1][this comic]] which is just awesome.
:PROPERTIES:
:Author: Pluvialis
:Score: 25
:DateUnix: 1457372596.0
:DateShort: 2016-Mar-07
:END:

*** Related to this video: I suspect I'm one of the few people who is actually seriously disturbed by the implication of the continuity theory of consciousness, but doesn't think think that makes it less plausible. That comic /did/ actually bother me when I first read it a while ago, though I had been bothered by that same thought before, and yes it /does actually keep me up at night on occasion/.

The only thing that gives me hope is that I'm not sure just because you don't remember it, that you don't have /any/ sort of experience during deep sleep. I have a certain amount of doubt regarding what counts as experience for the purposes of defining continuous experience "me". For instance I'm not sure whether there's such a thing as subconscious experience and whether that counts or where the line between (if any) is between consciousness and unconsciousness/death.

Altogether I'm probably going to want to shy away from general anesthesia if that sort of medical thing ever comes up, and if i'm ever digitally uploaded (through a gradual process) I don't think I would ever want to include deep sleep in my simulation.
:PROPERTIES:
:Author: vakusdrake
:Score: 4
:DateUnix: 1457397199.0
:DateShort: 2016-Mar-08
:END:

**** I'm sorry to hear about your sleep difficulty. A hope that you dispel it, one or another, for your term as an organism which requires it to be healthy.

If I may ask, purely out of curiosity, what leads you to hold the continuity theory? Is there a particular line of reasoning, or is just a conclusion that you can't seem to shake naturally coming to, or something else I'm failing to imagine?
:PROPERTIES:
:Author: Aabcehmu112358
:Score: 2
:DateUnix: 1457399990.0
:DateShort: 2016-Mar-08
:END:

***** Well continuuity theory just seems to be the most consistent and defendable, as well as it having an intuitive appeal. For one thing there are considerable problems trying to define anything other than one's continuous stream of consciousness as you. For instance there are problems defining oneself based on your personality and memories since even barring bizarre hypotheticals those are easily lost or drastically changed. For another thing I almost can't conceive of a theory of consciousness that makes any sense, which doesn't define you as your constant experience since that just seems obviously what you are when you're observe yourself.

As for you comment on the other thread which explains your position. One problem is that as you said you position allows one to be resurrected by having one's pattern reconstructed later, but if it's not being defined as a continuous process then how rigid does the recreated pattern have to be? I'm not sure you can make any argument for it being a specific percent so it just seems so staggeringly ill-defined I can't really conceive of any of the implications of it. Hell, you could make an argument that for reincarnation with this theoretically if some other life is created at any point it will have similarities to your pattern so why can't that be considered to be you? Unless you choose to define you based on identity but i'm not sure why you would do that given how that can change drastically at any moment, or what that would even mean.

As for the transporter scenario; since the transporter in question has a delay, if it didn't deconstruct you then you would have had experience, in the intervening time and thus any real world transporter that didn't deconstruct you would be making not a perfect copy of you but a copy of you a split second (or longer) in the past.

Another thing that strikes me about your position is that it does seem to imply immortality via Boltzmann Brain's of course that is obviously not evidence of anything but it is a observation.

Ultimately our ideas aren't totally different, as they are both materialist (presumably) and define you as a process of your brain, but since I intuitively draw a distinction between one's identity and one's experience (which I consider to actually be oneself). Then I find problems with allowing one's definition of self to continue past a break in consciousness.

Ultimately I suppose I do actually hold similar views to the person in the comic you linked, with the difference that since I'm not as sure I think I know which processes count as "experience" since you may /just not be able to form memories during deep sleep/, after all even during deep sleep you have some degree of awareness of surroundings, but that's subconscious and like I said it's hard to draw that line. Still this issue is something I think is actually rather important since it has implications for how we should treat true AI and how to deal with mind uploading, things which seem like far more likely technologies than teleporters. As well as making some potential problems for sleep and anesthesia.
:PROPERTIES:
:Author: vakusdrake
:Score: 2
:DateUnix: 1457404249.0
:DateShort: 2016-Mar-08
:END:

****** That certainly seems like a reasonable position, and if it feels comfortable to you, I'm not going to bother bending over backwards just to poke holes in it.

I am having some trouble just parsing your argument, though? Maybe it's because I just sort of agreed with SoundLogic rather than stated my opinion standalone. To clarify, from here on out, I'm just talking about the position that I hold, which may or may not be near to SoundLogic's

One important thing to note, is that I do not consider a hard boundary between 'self' and 'not-self.' This may or may not speak to your point about percentages and divergence and such. In different contexts, different sets of agents in the space of possible agents will be sufficiently similar to my current (and, lamentably, only) instance to satisfy that instance. In some cases, this set is large enough include other people, who don't even have a branch point with my current instance. If that's the case, then I am willing to delegate that task to satisfying people (with the understanding that they may evolve into agents who are insufficiently similar in the future).

The advantages of multiple instantiation, from in my opinion, is that instances that have a branch point in their personal histories seem likely to diverge from one another more slowly, allowing them to remain mutually satisfying for longer (possibly even indefinitely, if memory-integration technology like what I mentioned is available). The random generation of an agent mutually satisfying with my current instance seems mind-mindbogglingly unlikely, but if I were fortunate enough for it to happen, then, well, it's mutually satisfying, by definition. I also prefer to divorce these concepts from words like 'resurrection' or 'reincarnation,' since they seem to paint the right picture, and seem likely to lead to button-pushing rather than communication.

I am fine with my destination instance being marginally divergence from my source instance, since it seems likely to me that they will remain mutually satisfying in that time period.

I don't consider Boltzmann Brains to be plausible at this time, but supposing that they do exist, and they are defined in such a way as to allow some number of them to be mutually satisfying with my current instance, then I would accept them as instances, again by definition.

I simply don't know how to respond to your final point. I honestly just don't understand.

(Also, sorry for possibly flip-flopping between instance-terminology and ordinary pronouns. I avoid using the former for the sake of expediency and not sounding pretentious, so I'm out of practice.)
:PROPERTIES:
:Author: Aabcehmu112358
:Score: 2
:DateUnix: 1457406160.0
:DateShort: 2016-Mar-08
:END:

******* I had actually confused you for with the person who posted the parent comment in this thread my bad. I can see the incentive to not use certain words since they are loaded, however they do kind of work and I generally expect people in this reddit to be mature and not easily offended.

I suppose one thing about you position that seems clear is that you seem to consider memories and personality a integral part of you, since that's what matters when talking about "resurrection". Whereas since the only defining aspect of "you" as I see, is your continuous experience, then that doesn't really make sense.

Of course when dealing with this it is important to note that there are often multiple definitions of "you" which for me at least may include "true" you as I previously was talking about as well as one's experience+personality (identity) and the set of those two.

As for boltzmann brain's: I don't get why you think they're unlikely. I had actually thought about boltzmann brain's before I had heard about them in philosophy, and they always struck me as a inevitability. It just seems that given quantum mechanics should give them a non-zero probability and we may have a arbitrarily large amount of future time to work with they seem inevitable. However there are many unknowns such as how long the heat death of the universe might last for, and brains couldn't happen in a big rip scenario. Of course in a multiverse it seems not only do you have as much time as you need for boltzmann brain's, but since there ought to be infinite (or arbitrarily many) versions of you in most theories, you shouldn't fear death in your concept of consciousness. Basically if you think a multiverse is likely then you ought to think you're probably immortal. Of course since you can't experience those perfectly parallel versions of you's experiences now, I don't think it makes sense to say "you" lived on even after they diverge so they don't die when you do.

Still I wonder what you make of this since there are many different ways through which immortality is made likely for you within your theory, whereas the only theory which would guarantee immortality to me is quantum immortality which is /much/ less likely since it is more specific. Of course depending on whether heat death is conquerable by SI, the singularity may allow immortality to me in the future but of course that's a toss up.

My last point in my prior comment may not make sense since I was mistakenly replying to Pluvialis.
:PROPERTIES:
:Author: vakusdrake
:Score: 2
:DateUnix: 1457409090.0
:DateShort: 2016-Mar-08
:END:

******** I sort of got the feeling that was the case.

That does seems like a major difference in our positions.

Multiple definitions of self was something I was trying to get at as well. A highly divergent instance could be mutually satisfying only in particular respects, and otherwise insufficient.

My understanding of dynamical systems, even quantum mechanical ones, leads me to believe that it is entirely possible that a particular universe is, in fact, unreachable from the one we appear to exist in right now. From my understanding of the universe and of physics, BB-type universe are not reachable, and therefore not plausible.

Immortality remains unlikely in my understanding, since agents that will be mutually satisfying with me /generally/, rather than specifically, is a very small set. I do have some small hope that, as I seemingly approach death, I will suddenly find myself in another time and place (possibly but not preferably with some amount of amnesia or other mental changes), having been recovered from sort of back-up.

Alright.
:PROPERTIES:
:Author: Aabcehmu112358
:Score: 1
:DateUnix: 1457410234.0
:DateShort: 2016-Mar-08
:END:


****** u/Sinity:
#+begin_quote
  For one thing there are considerable problems trying to define anything other than one's continuous stream of consciousness as you.
#+end_quote

But why does it need to be *time* continuity, and not *logical continuity*? It's more intuitive, and makes more sense, I think.

For example, software processes, which are executed on a single CPU, aren't time-continuous. They are executed in slices of time. But they are *logically* continuous.

And are you *really* time continuous when you're awake? Neurons fire at rather slow rate. And discretely. What happens between neuron firings? With time-continuous model, you would die *several times per second*.

#+begin_quote
  Ultimately our ideas aren't totally different, as they are both materialist (presumably)
#+end_quote

I don't see this position as materialist. With transporting, all matter is in exact same informational state. There is *no physical difference*. If you believe that consciousness arises from the interactions in the brain matter, you shouldn't believe that transporting means death.
:PROPERTIES:
:Author: Sinity
:Score: 2
:DateUnix: 1457611312.0
:DateShort: 2016-Mar-10
:END:

******* I suppose the problem with a transporter is that there is a gap in consciousness if no gap actually existed it would be a sort of different thing. As for dying several times a second, because of the gaps in neurons, I used to think that might be the case, however because you have so many neurons i'm not really sure any aren't firing at a given time.
:PROPERTIES:
:Author: vakusdrake
:Score: 1
:DateUnix: 1458076370.0
:DateShort: 2016-Mar-16
:END:


*** Great explanation, I really liked it!
:PROPERTIES:
:Author: raymestalez
:Score: 1
:DateUnix: 1457372996.0
:DateShort: 2016-Mar-07
:END:


** Being honest, I'm perfectly fine with the idea of a teleporter just sending a duplicate of me to the other side. Honestly, I'd rather it be a duplicator, with none of this 'destroy the original' business, as long as there's some sort of memory-integrator (preferably also FTL) that lets my instances stay informed. Even if there isn't, though, having another human being whose branch point from my current state is some time in our shared history rather than null would be really nice.
:PROPERTIES:
:Author: Aabcehmu112358
:Score: 11
:DateUnix: 1457382963.0
:DateShort: 2016-Mar-08
:END:

*** Eh, I want my instance count and my travel plan handled separately. I mean, once I've decided on both it might be convenient to integrate them, but it should be optional. Multiple SoundLogics can cause logistics problems. If I'm at a conference and the room I'm supposed to be at keeps moving this shouldn't mean I suddenly need to get a dozen more beds.
:PROPERTIES:
:Author: SoundLogic2236
:Score: 7
:DateUnix: 1457386581.0
:DateShort: 2016-Mar-08
:END:

**** True, having them bundled does have side-effects, just like most bundled plans.

Thinking about the logistics of having multiple local instances. On a short term scale, it seems like multiple instantiation is net negative, economically, beyond doubling or maybe tripling up (depending on your privacy thresholds between instances). But isn't sharing costs with a housemate generally cost-saving, long term, scaling up to the maximum occupancy of the domicile? I guess for long term, it comes down to whether that is a stable social dynamic between your instances.
:PROPERTIES:
:Author: Aabcehmu112358
:Score: 0
:DateUnix: 1457399372.0
:DateShort: 2016-Mar-08
:END:


** What's hilarious is that Star Trek had an alternate transporter technology that should in theory (at least as far as TNG technology goes) be safer than regular transporters, but it causes cellular degradation.

[[http://memory-alpha.wikia.com/wiki/Folded-space_transport]]

And yet, completely disassembling and reassembling a person does not.
:PROPERTIES:
:Author: ansible
:Score: 10
:DateUnix: 1457393197.0
:DateShort: 2016-Mar-08
:END:


** CGP Grey must be running low on topics. :)

But this does bring me to ask - does The Prestige count as Rationalist fiction? It's basically the story of the first transporter, back when it was still an emerging tech, and the de-constructor part hadn't been implemented yet. Taking an existing SF trope (transporters) and exploring how it (or in this case, it's intermediate steps) would impact a less advanced world is fairly common in Rat Fic. And it fulfills every criteria aside from "The story shows rationalist techniques, which can be applied by readers."

I think it counts.
:PROPERTIES:
:Author: embrodski
:Score: 6
:DateUnix: 1457370944.0
:DateShort: 2016-Mar-07
:END:

*** I'd say it doesn't even qualify as a Rational fic. The characters aren't acting rationally. They're crazy. It's not that the guy using the "transporter" considers both copies himself and thinks of killing one as no different than amnesia. It's that he just doesn't care. I suppose you could say that he's rationally following the goal of publicly embarrassing his enemy and framing him for murder.
:PROPERTIES:
:Author: DCarrier
:Score: 9
:DateUnix: 1457377894.0
:DateShort: 2016-Mar-07
:END:

**** Terminal goals don't require justification. If I desire ice cream, or sex, I just desire those things. They're neither rational, nor crazy, they just are. I guess they could be unfortunate, like if I desired something that is literally impossible to have.

So while a desire to exact revenge might be instrumentally stupid, I don't think you can dismiss a fic as not-rational because the characters' motivations are less noble than "optimize the world." Voldemort may have been crazy, but as Quirrell he acted rationally quite often.
:PROPERTIES:
:Author: embrodski
:Score: 11
:DateUnix: 1457386669.0
:DateShort: 2016-Mar-08
:END:


** Just a perpetual spinner for me. Transcript?
:PROPERTIES:
:Author: ArgentStonecutter
:Score: 3
:DateUnix: 1457377430.0
:DateShort: 2016-Mar-07
:END:

*** "Transporters kill you and then create a new creature that happens to have your memories."
:PROPERTIES:
:Author: eaglejarl
:Score: 5
:DateUnix: 1457381349.0
:DateShort: 2016-Mar-07
:END:

**** Real world: Well, "memories and associated software and customized hardware". I am my memories/connectome/whatever. My consciousness is recreated anew from them multiple times every night.

Trek world: There's some handwavium in the Star Trek canon that there's some kind of "soul" thing that's stored in the pattern buffer and beamed with the rest of the transmission, which is why you can't just beam the pattern to two transporters to duplicate people.

Yes, there's been a few, very few, cases of duplicates coming out of the transporter, but they're always clearly new people and there's all kinds of handwavium about why "this is a special case".
:PROPERTIES:
:Author: ArgentStonecutter
:Score: 9
:DateUnix: 1457381698.0
:DateShort: 2016-Mar-07
:END:


** As I've been reading through the Ender Saga again, I've spent a little time thinking about the transporter dilemma.

Warning, significant Ender Saga spoilers

[[#s][Ender Spoilers]]
:PROPERTIES:
:Author: Covane
:Score: 1
:DateUnix: 1457684709.0
:DateShort: 2016-Mar-11
:END:
