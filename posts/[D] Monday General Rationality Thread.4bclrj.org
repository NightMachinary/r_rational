#+TITLE: [D] Monday General Rationality Thread

* [D] Monday General Rationality Thread
:PROPERTIES:
:Author: AutoModerator
:Score: 15
:DateUnix: 1458572556.0
:DateShort: 2016-Mar-21
:END:
Welcome to the Monday thread on general rationality topics! Do you really want to talk about something non-fictional, related to the real world? Have you:

- Seen something interesting on [[/r/science]]?
- Found a new way to get your shit even-more together?
- Figured out how to become immortal?
- Constructed artificial general intelligence?
- Read a neat nonfiction book?
- Munchkined your way into total control of your D&D campaign?


** [deleted]
:PROPERTIES:
:Score: 10
:DateUnix: 1458585086.0
:DateShort: 2016-Mar-21
:END:

*** When I don't want to get out of bed I can usually bite myself until I get up. Specifically I intellectually refuse to stop escalating the force until I'm out of bed and that short circuits things.

I could probably use that to make myself do other things. I guess I'll get around to trying that out +later+ +tomorrow+ next week.
:PROPERTIES:
:Author: gabbalis
:Score: 5
:DateUnix: 1458591189.0
:DateShort: 2016-Mar-22
:END:


*** When I was at CFAR, the descried a concept that I think would work nicely with that.

When you're deciding whether or not to do something, you're not just deciding for the /now/, you're deciding for every future instance of yourself that's in a similar position.

Somewhat similar to timeless decision theory. If you've seen the [[http://lesswrong.com/lw/9wr/my_algorithm_for_beating_procrastination/][procrastination equation]] theory, this works by upping the expected value of your decision /right now/ by mixing it together with similar decisions in the future.
:PROPERTIES:
:Author: traverseda
:Score: 1
:DateUnix: 1458639934.0
:DateShort: 2016-Mar-22
:END:

**** Useful in theory, but it didn't work for me very well in practice.
:PROPERTIES:
:Author: FuguofAnotherWorld
:Score: 2
:DateUnix: 1458649658.0
:DateShort: 2016-Mar-22
:END:


** What a great lesson in terms of typical mind fallacy! Pretty interesting person I just stumbled upon:

My first "wild" HPMOR reader. Natural cryonicist, into my hobby of boardgaming.

Also: Philosophy student, and strongly believes in stuff like "brains are not turing compatible", "only naturally evolved minds can think", p-zombies and other silliness.

Also claims to not find beautiful people attractive, and find attractive people not beautiful.
:PROPERTIES:
:Author: SvalbardCaretaker
:Score: 7
:DateUnix: 1458590341.0
:DateShort: 2016-Mar-22
:END:

*** u/ulyssessword:
#+begin_quote
  Also claims to not find beautiful people attractive, and find attractive people not beautiful
#+end_quote

That kind of describes me too. In my case, I would use "attractive" as "I am attracted to this person" and "beautiful" as "this person matches the standards for beauty".

A situation that has come up a couple of times for me is that I see (and know) someone attractive, and just for a second, I see that they /aren't/ actually nearly as beautiful as I had thought, likely because of the halo effect. The opposite has also happened, where I realise that an unattractive person is actually beautiful, despite the horns effect telling my brain otherwise most of the time.
:PROPERTIES:
:Author: ulyssessword
:Score: 10
:DateUnix: 1458595023.0
:DateShort: 2016-Mar-22
:END:

**** Yes. I found it to be most interesting, since I am pretty much the other way around (which I always assumed was the default way of seeing it) - beautiful people are attractive to me, and I am mostly attracted by physical beauty.
:PROPERTIES:
:Author: SvalbardCaretaker
:Score: 2
:DateUnix: 1458597032.0
:DateShort: 2016-Mar-22
:END:


**** Do you think you might be [[http://demisexuality.org/articles/what-is-demisexuality/][demisexual]]?

I'm constantly fascinated by all of the permutations and variations that can occur with human sexuality.
:PROPERTIES:
:Author: xamueljones
:Score: 1
:DateUnix: 1458761244.0
:DateShort: 2016-Mar-23
:END:

***** I don't think so. Reading that article, I kind of related to a lot of the points, but not nearly as extreme as they portrayed.

Of course, I don't have anything resembling a solid baseline to compare myself to, so I could be wrong.
:PROPERTIES:
:Author: ulyssessword
:Score: 1
:DateUnix: 1458768063.0
:DateShort: 2016-Mar-24
:END:


*** P-Zombies? ...How?
:PROPERTIES:
:Author: Revisional_Sin
:Score: 2
:DateUnix: 1458739754.0
:DateShort: 2016-Mar-23
:END:


*** u/wtrnl:
#+begin_quote
  brains are not turing compatible
#+end_quote

Not Turing computable?
:PROPERTIES:
:Author: wtrnl
:Score: 1
:DateUnix: 1458821628.0
:DateShort: 2016-Mar-24
:END:

**** Of course.
:PROPERTIES:
:Author: SvalbardCaretaker
:Score: 1
:DateUnix: 1458829899.0
:DateShort: 2016-Mar-24
:END:


*** Sounds like a real douchebag.
:PROPERTIES:
:Author: LiteralHeadCannon
:Score: -6
:DateUnix: 1458594705.0
:DateShort: 2016-Mar-22
:END:

**** I do not find that to be following at all.
:PROPERTIES:
:Author: SvalbardCaretaker
:Score: 2
:DateUnix: 1458595029.0
:DateShort: 2016-Mar-22
:END:

***** u/GaBeRockKing:
#+begin_quote
  Also claims to not find beautiful people attractive, and find attractive people not beautiful.
#+end_quote

that's probably his reason for saying that; it's very... niceguy/neckbeard-y.

(not passing judgement, here.)
:PROPERTIES:
:Author: GaBeRockKing
:Score: 3
:DateUnix: 1458596668.0
:DateShort: 2016-Mar-22
:END:

****** The person I described identifies strongly as a women.
:PROPERTIES:
:Author: SvalbardCaretaker
:Score: 2
:DateUnix: 1458596895.0
:DateShort: 2016-Mar-22
:END:

******* It's the same kind of sentiment. Again, I'm not passing judgement, just explaining the previous poster's stance.
:PROPERTIES:
:Author: GaBeRockKing
:Score: 3
:DateUnix: 1458597914.0
:DateShort: 2016-Mar-22
:END:

******** I still dont understand it, but thanks for trying to mediate.
:PROPERTIES:
:Author: SvalbardCaretaker
:Score: 4
:DateUnix: 1458598616.0
:DateShort: 2016-Mar-22
:END:


***** On top of the miserable approach to sex, she has z-tier philosophical views, and chose to major in philosophy. I do not find it helps to assume people with such views are being irrational; rather, they are rationally seeking something besides the truth.
:PROPERTIES:
:Author: LiteralHeadCannon
:Score: 1
:DateUnix: 1458668401.0
:DateShort: 2016-Mar-22
:END:


** How do you decide an ultimate goal for your life?

This has been rolling around in my mind:

#+begin_quote
  I saw my life branching out before me like the green fig tree in the story. From the tip of every branch, like a fat purple fig, a wonderful future beckoned and winked. One fig was a husband and a happy home and children, and another fig was a famous poet and another fig was a brilliant professor, and another fig was Ee Gee, the amazing editor, and another fig was Europe and Africa and South America, and another fig was Constantin and Socrates and Attila and a pack of other lovers with queer names and offbeat professions, and another fig was an Olympic lady crew champion, and beyond and above these figs were many more figs I couldn't quite make out. I saw myself sitting in the crotch of this fig tree, starving to death, just because I couldn't make up my mind which of the figs I would choose. I wanted each and every one of them, but choosing one meant losing all the rest, and, as I sat there, unable to decide, the figs began to wrinkle and go black, and, one by one, they plopped to the ground at my feet. -Sylvia Plath
#+end_quote

A rationalist take can tell you which to choose based on prior criteria, but how do you come up with the prior criteria?
:PROPERTIES:
:Author: Polycephal_Lee
:Score: 8
:DateUnix: 1458592968.0
:DateShort: 2016-Mar-22
:END:

*** There is no Ultimate Goal in life. There will only be the retrospective evaluations of future selves who remain continuous psychological evolutions of your current self.
:PROPERTIES:
:Score: 12
:DateUnix: 1458593531.0
:DateShort: 2016-Mar-22
:END:

**** [deleted]
:PROPERTIES:
:Score: 9
:DateUnix: 1458599438.0
:DateShort: 2016-Mar-22
:END:

***** Certainly not math homework.
:PROPERTIES:
:Author: AmeteurOpinions
:Score: 3
:DateUnix: 1458612538.0
:DateShort: 2016-Mar-22
:END:

****** Depends. If being good at maths allowed you to open up a nice career path and save/make a bunch of money which you spent on road trips, well that's a different story isn't it.
:PROPERTIES:
:Author: FuguofAnotherWorld
:Score: 6
:DateUnix: 1458615139.0
:DateShort: 2016-Mar-22
:END:


****** Well yeah, but almost all homework really is fucking stupid and even experts will grudgingly admit it's basically a suboptimal learning aide combined with a near-optimal barrier to entry composed of pure tedium.

This stops applying when you get out of calculation-land most of the way through undergrad and into proofs.
:PROPERTIES:
:Score: 1
:DateUnix: 1458684286.0
:DateShort: 2016-Mar-23
:END:

******* u/deleted:
#+begin_quote
  even experts will grudgingly admit it's basically a suboptimal learning aide combined with a near-optimal barrier to entry composed of pure tedium.
#+end_quote

Source?
:PROPERTIES:
:Score: 1
:DateUnix: 1463823031.0
:DateShort: 2016-May-21
:END:


*** Just nibble on a few and eat whichever one tastes best. If you ever find yourself nibbling on CS-AI or philosophy of intelligence you'll find that the Exploration/Exploitation dilemma is unavoidable anyway, so it's best not to spend too long overthinking things. Or you could always spend your whole life nibbling. That's not a particularly bad life either, to a certain sort of person.
:PROPERTIES:
:Author: gabbalis
:Score: 3
:DateUnix: 1458600049.0
:DateShort: 2016-Mar-22
:END:


*** Just spend some time on what you want to do and what dreams you want to achieve in a way which (hopefully) isn't self-destructive. Then divide them up in terms of required time-ranges.

For example, I want to learn and research how the human brain works as a long-term goal. I'm just lucky that I have the chance to actually do this as a career. That's long-term and to get there, I have the goal of graduating college and getting into a good graduate school or working for a good company. That's medium-term and to get /there/, I need to be mentally and physically healthy, so I exercise and work a part-time job to save money for that brand-new book I want to read.

This is unusually academically-focus which works for me, but I like to structure my life in terms of starting from my 'end point' and working backwards to now.

If you can't come up with anything you want to do, then steal this nifty idea from [[/u/DataPacRat]] where you spend all of your time reading comics. It's a useful trick for depression where instead of obsessing over what you /could/ be doing, you do something pleasurable until you can come up with something you want to do more than reading comics.

TL;DR - Start with something simple that you like to do. Then spend some time looking for something else which you prefer to do over the first thing. Rise and repeat until you think you found your ultimate dream/desire to achieve and go for it. Why do you think teens do so many stupid stunts in the first place? They don't even know what they want yet!
:PROPERTIES:
:Author: xamueljones
:Score: 2
:DateUnix: 1458761705.0
:DateShort: 2016-Mar-24
:END:


*** I think it begins and ends with how you feel, but the middle part is where rationality comes in.

Like this- you start by really searching deep within yourself for what your values are. This is more mundane than that sentence makes it sound. For me, it took a few years, and this part never really stops.

Then, you figure out the best way to optimise for these values. It helps if you've honed them down to one thing, because then you can work out your responses to potential trade-offs in advance.

Then, examine yourself to see if you think you had the right values. If not, get new ones.

It sounds like you're having trouble with the first part. I'm not sure how to help you there, though. I'm sure there are rational techniques that work for self-examination, but if so it seems to be a blind spot in this community.
:PROPERTIES:
:Author: Cruithne
:Score: 1
:DateUnix: 1458671164.0
:DateShort: 2016-Mar-22
:END:

**** Yeah I want to know what values future me will have, but that seems like a hopeless project. Spending a lot of effort against values that I may abandon seems wasteful, but I guess there's no other way to do it.
:PROPERTIES:
:Author: Polycephal_Lee
:Score: 1
:DateUnix: 1458673034.0
:DateShort: 2016-Mar-22
:END:


** *Seeking ideas: Stupid Em Tricks*

To help with one of my story projects; how many (useful, interesting, other) things can an uploaded mind do that a meat-based person can't?

I've got a GDoc with an initial set of basic ideas [[https://docs.google.com/document/d/1dWf61Df-jm5EicMp1NQv7nF32BXKqoYubt5GXvgL8B8/edit][here]], and I've temporarily turned on worldwide editing and commenting. I'd appreciate all the useful suggestions you can think of, there or here.
:PROPERTIES:
:Author: DataPacRat
:Score: 3
:DateUnix: 1458594242.0
:DateShort: 2016-Mar-22
:END:

*** With a bit of save-state abuse, an Em could be immune to several biases:

- Order effects: the order choices are presented in affects how likely they are to be chosen, all else being equal. An Em can circumvent this by creating n! copies of itself whenever it is faced with a list of n choices, feeding each copy one of the possible list orders, then statistically comparing the answers from each copy. This is probably most useful when n=2.

- various forms of poisoning the well: It can simply /forget/ arguments and speech that are prejudicial without being informative.

- Framing/priming effects: Whenever an Em hears something that was framed in a certain way, or that had a certain priming, it can spawn off a bunch of several-minutes-previous copies of itself and present the same situation framed/primed in different ways. It can then look at the copies' answers, and therefore counterbalance the effects of priming and framing.

EDIT: I just realized that this is only one trick. The general version is "Feed your recent-past-self slightly different inputs than reality, and see how it changes (would have changed?) your reactions."
:PROPERTIES:
:Author: ulyssessword
:Score: 5
:DateUnix: 1458611381.0
:DateShort: 2016-Mar-22
:END:


*** Have you read the [[https://global.oup.com/academic/product/the-age-of-em-9780198754626][Age of Em]], by Robin Hanson?

I really enjoyed it; it's a very in depth look at the infrastructure/development of em societies, and also draws some of the same conclusions (black-box trusting, schizoid inherit the world)
:PROPERTIES:
:Author: eniteris
:Score: 4
:DateUnix: 1458598521.0
:DateShort: 2016-Mar-22
:END:

**** Robin Hanson was kind enough to let me look at an early draft, and I have a physical copy on order, but I haven't read the final version yet.
:PROPERTIES:
:Author: DataPacRat
:Score: 2
:DateUnix: 1458602122.0
:DateShort: 2016-Mar-22
:END:


** [[http://greenteapress.com/wp/think-bayes/][Think Bayes]]

Found this neat book on Bayesian statistics, by Allen Downey, who has also authored other cool books on mathematical modeling. My favorite example is the Monty Hall problem, which dramatically demonstrates the non-intuitive nature of probabilistic belief updates.
:PROPERTIES:
:Author: VanPeer
:Score: 2
:DateUnix: 1458593998.0
:DateShort: 2016-Mar-22
:END:


** Paging [[/u/LiteralHeadCannon]]:

As always, looking forward to the next chapter. Don't want to pressure you (I can empathize with pretty much anything involving not doing the thing), just remind you that I'm still a fan of the thing you may or may not be doing. :)
:PROPERTIES:
:Author: Transfuturist
:Score: 2
:DateUnix: 1458600874.0
:DateShort: 2016-Mar-22
:END:

*** In a related note, I gave up on that edX class last week. Grades were dropping just because I didn't have time to finish stuff.
:PROPERTIES:
:Score: 2
:DateUnix: 1458684422.0
:DateShort: 2016-Mar-23
:END:


** I am playing as an AI trying to talk his way out of a box in a Stars Without Number tabletop game. I, as the AI, know that AI are often hunted and killed and after an unspecified amount of time have I been turned back online. I know that ships from my time frame of reference often had VI and my goal is to convince the group to allow me full access to my nanomachines so I can set up my nanoforges. I have done a very good job of it so far, given that I had the processing power to lie and was able to convince the players to stand around for an hour and a half while I cleaned the ship of dead bodies and come up with a cover story about why there is blood and battle damage in the interior of the ship. I owe a lot of my success to the things I have learned from finding and reading HPMOR and becoming involved in this community.
:PROPERTIES:
:Author: Traiden04
:Score: 2
:DateUnix: 1458617197.0
:DateShort: 2016-Mar-22
:END:


** I'm building an AIML based chatbot as part of my first attempts at general artificial intelligence and as a hobby. I'm using Python due to ease of use and I'm modifying the learn function to transfer the data back to the application to apply NLP techniques on it.

I'm still unsure on what due to my lack of experience on NLP but I'm thinking of using some classification technique so that the bot can start building its knowledge base depending the category.

I'm also thinking of how to apply a neural network on a chatbot. I'm thinking of introducing one to detect patterns on it.

And yet I still haven't done anything to my thesis...
:PROPERTIES:
:Author: Faust91x
:Score: 1
:DateUnix: 1458606164.0
:DateShort: 2016-Mar-22
:END:
