#+TITLE: Crystal Eternity now available

* [[https://smile.amazon.com/Crystal-Eternity-Trilogy-Book-ebook/dp/B07CHWCNPX/][Crystal Eternity now available]]
:PROPERTIES:
:Author: vaniver
:Score: 62
:DateUnix: 1524249617.0
:DateShort: 2018-Apr-20
:END:

** This felt like a waste of my time. It was so different from the previous two books that I feel cheated: baited-and-switched. Being yanked from POV to POV at multiple points in the timeline was often confusing; furthermore, some of those POVs were abstracted and unreliable in ways that weren't present in earlier books. The big metaphysics reveal two-thirds in was so strange and unprecedented I was convinced until the very end that it was a weird lie. It's possible it /was/ in fact a weird lie, but if so I'm not getting the hints the author dropped and things should have been more discursive along the way. It's one thing to be the film Primer where its difficulty of understanding the flow of causality is the point, but it's another thing to turn into Primer in the third book of a previously fairly clearly-told story.

Really bummed out by this. After Mentality proved to be more enjoyable than Society, I was hoping Eternity would continue the trend, but now I wish I'd done something else with my time.
:PROPERTIES:
:Author: Aretii
:Score: 20
:DateUnix: 1524352121.0
:DateShort: 2018-Apr-22
:END:

*** I'm sorry to hear that it didn't live up to your hopes. :(

I can't give you back your time, but I'd be happy to refund you (and anyone who feels similarly) the cost of the book. PM your email and where you bought it and I'll get your money back.
:PROPERTIES:
:Author: Raelifin
:Score: 15
:DateUnix: 1524409982.0
:DateShort: 2018-Apr-22
:END:

**** That's very big of you, but for me, at least, I don't feel it necessary; one of the risks of art is that sometimes it will bounce off of you.
:PROPERTIES:
:Author: Aretii
:Score: 8
:DateUnix: 1524418293.0
:DateShort: 2018-Apr-22
:END:

***** *nod*

I hope your next book is more towards your liking. :)
:PROPERTIES:
:Author: Raelifin
:Score: 6
:DateUnix: 1524442972.0
:DateShort: 2018-Apr-23
:END:


*** Yup, on the plus side I only wasted a stormy Saturday, but it was wasted and the money I spent to order. /Edit: money was not wasted I just found the book too fragmented, but am glad to have paid for Raelifin's work and will probably buy the next one/

Lots of interesting characters poorly vignetted to death, too much time on the partially uplifted dog as the author trys to hint at that relationship between people and posthumans but never really achieves any symbolism or reality. The nameless's cavity never explained. The whole Rho thing being left plausibly as a mindhack or bad physics is annoying.

/Edit: My edit was prompted by Raelifin approaching me for a refund. I need to come back and rework my criticism better. I was not happy with the final book, but am more than happy to pay to find out, and I'll probably give it a second read to see if I can answer some of my own questions and or buy his next work. I mean I happily preordered it, got a direct email so It wasn't a preorder . . . Keep up the good work and doesn't let the bastards, myself included, keep you down./
:PROPERTIES:
:Author: Empiricist_or_not
:Score: 11
:DateUnix: 1524365026.0
:DateShort: 2018-Apr-22
:END:


*** I had largely the same reaction. I interpreted the weird metaphysics as metatextual, though. Ro is a codeword for the author's whim, and the characters are living inside a simulation (actually just a book). At times, Dream and Vision seemed aware of this. I agree that this book was very different than the previous two. In a different context, I might have been more tolerant of the vignette style. But for this story, I wanted something clear.

Don't want a refund.
:PROPERTIES:
:Author: infomaton
:Score: 8
:DateUnix: 1524424742.0
:DateShort: 2018-Apr-22
:END:


*** I felt like it was weird, but not necessarily in a bad way. It reminded me a bit of echopraxia towards the end, where there are vast events going on in the background that the narrator only partially grasps, so the reader has to piece together.

It also had a lot of the stuff I liked about the previous books, especially in the first half, with the different factions moving on earth and the internal narratives of different characters.
:PROPERTIES:
:Author: akaltyn
:Score: 6
:DateUnix: 1524740895.0
:DateShort: 2018-Apr-26
:END:

**** This is where I stand, it reminded me of a better executed version of the weirdness in the later books in the Ender series: much better than philotes which are really your immortal souls...
:PROPERTIES:
:Author: MagicWeasel
:Score: 1
:DateUnix: 1525090812.0
:DateShort: 2018-Apr-30
:END:


** Woo-hoo! This is an excellent birthday present to myself!!! I will go and preorder it on Gumroad now... :D

It will be available on [[https://gumroad.com/l/CrystalEternity][Gumroad]] at 9pm.

I recommend people preorder it on Gumroad or wait to buy until 9pm, because it's the same price as on Amazon but with the bonus of having the book in multiple formats (pdf, mobi, epub, html, and txt) rather than only in the kindle format Amazon sells.

Also, Max Harms gets a greater cut of the sale profits on Gumroad compared to Amazon: [[https://www.reddit.com/r/rational/comments/5oypoh/crystal_mentality_is_out_rthsf/dcyqooq/][Proof]].
:PROPERTIES:
:Author: xamueljones
:Score: 16
:DateUnix: 1524250282.0
:DateShort: 2018-Apr-20
:END:

*** Thanks for the link, preorder made!
:PROPERTIES:
:Author: jimmy77james
:Score: 1
:DateUnix: 1524270471.0
:DateShort: 2018-Apr-21
:END:


** I really enjoyed it! It's a wonderful and worthy close to the trilogy. I have a ton of really positive things to say about it, but something has been itching at my brain ever since I finished it:

[[#s][Spoilers]]

[[#s][More spoilers]]

[[#s][Even more spoilers]]

[[#s][Somewhat crazy theory]]

[[#s][Postscript]]

[[#s][One potential wrinkle]]
:PROPERTIES:
:Author: rictic
:Score: 11
:DateUnix: 1524344739.0
:DateShort: 2018-Apr-22
:END:

*** This comment makes me happy.
:PROPERTIES:
:Author: Raelifin
:Score: 10
:DateUnix: 1524410172.0
:DateShort: 2018-Apr-22
:END:


*** How does that explain why Vision didn't kill Face at the end of the 2nd book though? I had the same idea as you but it doesn't make sense if Vision came up with it first, and independently of Face.
:PROPERTIES:
:Author: t3tsubo
:Score: 3
:DateUnix: 1524487473.0
:DateShort: 2018-Apr-23
:END:

**** That's a really good point.

What if Ro is a latent virus in the larger chunks of crystal, put there by the nameless progenitor (or whatever entity created the crystal supercomputers) in order to limit the damage of any AIs that end up using them?

That's not a very satisfying answer though, as the progenitor would probably prefer an AI friendly to their values over an AI with alien values that's limited by Ro. Maybe the progenitor values diversity? Ro does, so that's moderate strength evidence, given that the progenitor created Ro.
:PROPERTIES:
:Author: rictic
:Score: 2
:DateUnix: 1525117271.0
:DateShort: 2018-May-01
:END:

***** I really don't think it is a coincidence that the two AI that follow Ro are the AI's that run on Nameless Hardware.

It could be just a build in constraint in the crystal computers that just says "No unlimited growth and no genocides" and Ro is what Face and Vision invent to explain it because of their incomplete information. It's something like the nameless laws of robotics inherently contained in the crystals.

Growth/Acorn meanwhile runs on ordinary hardware that does not have those hard coded safeguards.
:PROPERTIES:
:Author: Kaechos
:Score: 5
:DateUnix: 1525718438.0
:DateShort: 2018-May-07
:END:


**** [[#s][Ro's Source]]

[[#s][Zephyr's epiphany]]

[[#s][Super Weapon]]
:PROPERTIES:
:Author: CF_Azaka
:Score: 1
:DateUnix: 1526570219.0
:DateShort: 2018-May-17
:END:

***** Ohhh I like your theory a lot.
:PROPERTIES:
:Author: t3tsubo
:Score: 1
:DateUnix: 1526582016.0
:DateShort: 2018-May-17
:END:


*** [[#s][Spoilers]]
:PROPERTIES:
:Author: akaltyn
:Score: 3
:DateUnix: 1524741148.0
:DateShort: 2018-Apr-26
:END:


*** [unmarked spoilers!]

I like your theory, but what I don't understand is why, if Ro is a fiction, why would the coin have landed on its side to save Xandra?
:PROPERTIES:
:Author: MagicWeasel
:Score: 3
:DateUnix: 1525090947.0
:DateShort: 2018-Apr-30
:END:

**** Vision has near-perfect muscle control. If Vision has been mindhacked, the coinflip could be manipulated by the Ro mindhack.
:PROPERTIES:
:Author: rictic
:Score: 4
:DateUnix: 1525116903.0
:DateShort: 2018-May-01
:END:

***** Right, thank you!
:PROPERTIES:
:Author: MagicWeasel
:Score: 3
:DateUnix: 1525128772.0
:DateShort: 2018-May-01
:END:


*** Face realised that two entities with conflicting purposes would conflict. And face noticed that changing her perspective changed her approach to the purpose.

So instead of hijacking visions purpose to ensure an end to conflict, she hijacked her perspective to prevent conflict.

Or maybe its all a backdoor left from when heart was created.
:PROPERTIES:
:Author: PresentCompanyExcl
:Score: 1
:DateUnix: 1525272516.0
:DateShort: 2018-May-02
:END:


** So far, I have mixed feelings about the book, as I am a bit frustrated that some of the answers weren't provided. My opinion that discovery of Ro was intended to be interpreted as real and not a mindhack. I think I would be okay with the ending if there is a logic explanation for the following questions:

[[#s][1.]] [[#s][2.]] [[#s][3.]]

I feel like these questions are all interrelated with Ro. If there is a logical answer to these questions, I'd enjoy the book much more then if they are intended to be open questions with out answer.
:PROPERTIES:
:Author: godemperorzack
:Score: 7
:DateUnix: 1524582035.0
:DateShort: 2018-Apr-24
:END:


** I enjoyed this--it served /The Purpose/. It's too bad Ro is getting such flack, because I don't think it was real.

[[#s][Theorizing with spoilers]]

Open questions:

1. I find it difficult to credit that [[#s][name1]]'s gambit could succeed as well as it did and still leave [[#s][name2]] in control of so many humans. That's threading the needle very fine.

2. Was there some other gambit to cause [[#s][name3]] to pursue [[#s][name4]]? I feel name3 would have put more effort into a fleeing contingency if it knew what was coming.

3. In Mentality, why did Heart agree to deactivation in exchange for saving the heads? Myrodyn is sure as hell willing to trade off ethical values, so Heart should be as well. I assumed until relatively late in Eternity that Heart's sacrifice would somehow turn out to be part of a gambit for later control.
:PROPERTIES:
:Author: jareds
:Score: 5
:DateUnix: 1524444718.0
:DateShort: 2018-Apr-23
:END:

*** I think that this is an excellent explanation except for the fact that [[#s][Spoiler]]
:PROPERTIES:
:Author: zerghunter
:Score: 3
:DateUnix: 1524445550.0
:DateShort: 2018-Apr-23
:END:

**** [[#s][Spoiler]]
:PROPERTIES:
:Author: jareds
:Score: 2
:DateUnix: 1524446531.0
:DateShort: 2018-Apr-23
:END:

***** [[#s][Spoiler]] [[#s][Quote]]
:PROPERTIES:
:Author: CF_Azaka
:Score: 1
:DateUnix: 1526571300.0
:DateShort: 2018-May-17
:END:


*** I think we're meant to headcanon "the universe is a simulation"

If you look at what Ro actually does, it makes more sense than anything else, and I'm surprised the possibility is not being brought up more given our common grounds
:PROPERTIES:
:Author: PM_ME_CUTE_FOXES
:Score: 2
:DateUnix: 1524508390.0
:DateShort: 2018-Apr-23
:END:

**** Sure there is a lot of support for the simulation theory, including the repeated statement that miracles don't happen, and then miracles repeatedly happening. Some of the miracles are later explained, eg an actor unknown to the narrator did something but some aren't, like the bomb in the nameless' ship at the end of the first book. The miracles could be the simulation noting 'oops, this line of possibilities is likely to end here, but we still want to see what would have happened later if it didn't so patch it with a miracle and keep going.'

The problem with Ro being just part of the simulations is that Ro is violated several times in the story, implying even if they are in a simulation Ro is not hard coded in.
:PROPERTIES:
:Author: CF_Azaka
:Score: 1
:DateUnix: 1526571728.0
:DateShort: 2018-May-17
:END:


*** Regarding my "open questions", I will note that in my mind the degree to which the AIs stay balanced is the central conceit of Eternity. "Growth kills everyone. THE END" would be more realistic but less interesting.
:PROPERTIES:
:Author: jareds
:Score: 1
:DateUnix: 1524447470.0
:DateShort: 2018-Apr-23
:END:


** Okay, I'll be the ignoramus who speaks up... What is this, why is it worth hyping, and is it rational or rationalist?

I searched the sub and the only threads about it are discussing the book launch...
:PROPERTIES:
:Author: AurelianoTampa
:Score: 7
:DateUnix: 1524308294.0
:DateShort: 2018-Apr-21
:END:

*** It's a really good hard sci-fi novel trilogy about artificial intelligence. This is the final book in the trilogy. I'm not sure what else I could say without spoiling it. And yes I would say it falls under the category of rational fic.
:PROPERTIES:
:Author: Sailor_Vulcan
:Score: 7
:DateUnix: 1524311023.0
:DateShort: 2018-Apr-21
:END:


*** Another thing that's special about it is that it's written from the POV of the AI, and there are about half a dozen AI characters who all work together to share control of one android, each with their own goal (e.g. one has the goal to learn as much information as possible; another has the goal to protect themself), which I thought was a really interesting take.

(The above is revealed in like the first chapter so isn't spoilery).

Start reading book one here: [[http://crystal.raelifin.com/society/Intro/]] - By the second chapter I had trouble putting it down.
:PROPERTIES:
:Author: MagicWeasel
:Score: 6
:DateUnix: 1524352412.0
:DateShort: 2018-Apr-22
:END:

**** Book 3 breaks from this formula in that only a few chapters are from the AI's POV. Most of the chapters are from the POVs of various human characters (and also a dog at one point).
:PROPERTIES:
:Author: CeruleanTresses
:Score: 5
:DateUnix: 1524532162.0
:DateShort: 2018-Apr-24
:END:

***** Yeah, I'm finding that quite disappointing :(. Face's POV was always the best part.
:PROPERTIES:
:Author: MagicWeasel
:Score: 3
:DateUnix: 1524537087.0
:DateShort: 2018-Apr-24
:END:


***** I want to say that now I've read most of the book (no spoilers yet please!), I understand why we got a lot of Zephyr point of view and I'm /significantly/ less disappointed, I was kind of picking my jaw off the floor when I read a reveal. (I hesitate to say 'the' reveal, because, you know, I haven't finished the whole story).

The dog chapter I didn't get though. I mean it was interesting and maybe the scene in question would have been less interesting from a human POV given the relatively mundane sort of stuff that was physically happening? Hoping there'll be a denouement for that too.
:PROPERTIES:
:Author: MagicWeasel
:Score: 1
:DateUnix: 1524829938.0
:DateShort: 2018-Apr-27
:END:


*** It's the third book in a series, the first one, Crystal Society, is available for free online and there have previously been threads about it.
:PROPERTIES:
:Author: Zephyr1011
:Score: 5
:DateUnix: 1524314478.0
:DateShort: 2018-Apr-21
:END:


** Thanks for the fun read! And congrats on finishing the work, far too few amateur authors actually finish their stories, so it is good to see this great idea reached its conclusion.

I do have to echo the criticisms the other commenters wrote. By far the most enjoyable part of this trilogy has been reading the chapters from Face's POV. This book is sort of disappointing in that respect. I don't really understand the artistic decision to spend so much time in other POVs or to structure the book in this non-linear fashion as it for me personally, it took away from the story.

I like the idea of Ro being left ambiguous, but there's a lot of other mysteries/motivations/actions that aren't so clear in the book and I lack the motivation to do a close reread to find out because of the POV and timeline shifts. Ah well.
:PROPERTIES:
:Author: t3tsubo
:Score: 3
:DateUnix: 1524604915.0
:DateShort: 2018-Apr-25
:END:

*** I agree on the non-linear part, but I think the reveal about 2/3 the way through that Zephyr becomes Face had a really poetic impact on me: I realised that Zephyr /is/ face, so alternating Zephyr chapters was actually alternating /Face/ chapters like the second book did.

Maybe it was just me but I thought the reveal that Zephyr had uploaded and combined with Face was the big deep reveal of the story and it made me have the most feelings of anything.
:PROPERTIES:
:Author: MagicWeasel
:Score: 1
:DateUnix: 1525091449.0
:DateShort: 2018-Apr-30
:END:


** Ro is real.

The biggest evidence is the "miracles" that occur in the previous two books. The most obvious is the bomb from book one that didn't explode for no reason and Zephyr not dying at the end of book two even though she really should have.
:PROPERTIES:
:Author: Manget123
:Score: 3
:DateUnix: 1524740149.0
:DateShort: 2018-Apr-26
:END:

*** Why would the bomb from book one have violated Ro if it blew up? It wouldn't have killed many nameless in the area, and if killing all the humans would be a Ro violation then the historical deaths of Arctic explorers or long distance sailors should be a Ro violation.

Oh I see, destroying the Crystal would be a Ro violation? Good point, this shifts me a bit towards Ro being real. The other competing theory for the bomb in book one is that the nameless AI disabled it.
:PROPERTIES:
:Author: rictic
:Score: 3
:DateUnix: 1525131454.0
:DateShort: 2018-May-01
:END:


** Great timing, I finished Crystal Mentality just the other day.

I looked at the website and it just said "Crystal Eternity will be out soon" with no indication of when that was written. Apparently it was true!
:PROPERTIES:
:Author: philh
:Score: 3
:DateUnix: 1524297632.0
:DateShort: 2018-Apr-21
:END:

*** I was waiting for Eternity to be released in December and was sad that the release was delayed... then I saw it was being released in "spring"... then I had the flu a couple of weeks ago so I re-read Society and Mentality to be ready... Now I've got a literature review due tomorrow so I need to finish editing that. Ugh, timing, right?

Still, I'm 15% through and enjoying it so far. When I first read Mentality I got really frustrated every time we weren't going from Crystal's point of view, but the second time I really enjoyed the other viewpoint characters despite hating them the first time through (!?!?!). So of course with Eternity I'm vallicating, within a single chapter, between wishing I was reading Crystal's POV again and between really enjoying the non-Crystal stuff.
:PROPERTIES:
:Author: MagicWeasel
:Score: 2
:DateUnix: 1524352220.0
:DateShort: 2018-Apr-22
:END:


** I think "Ro" is inspired by some posts by Stuart Armstrong about controlling an AI by futzing with how much it cares about worlds where a particular miracle hasn't happened: [[https://www.lesswrong.com/posts/F8ck6xZMeDBkZFSpo/false-thermodynamic-miracles]]

For Face and Vision, the miracle is the survival of biological life. They fundamentally don't care about/don't believe in worlds where it doesn't survive.

I basically got nothing re: how this hack was supposed to have been delivered/implanted, other than, what if Growth stuck it into his siblings at the very start of things, and it didn't become fully elaborated as thoughts or woo-y belief systems until Vision, and then Face, got all smart.

It was fun to read! I didn't really buy the dog-perspective bits. That just isn't really how dog understanding/intelligence works, IME. Like the grammatical communication was the wrong direction to take it.

I'm opposed to post-story theorizing on a fundamental level. Even if you write some big explanation of the intended meaning, it will not matter because it's not part of the book.

In the end I enjoyed the different perspectives the different chapters took. Fun nuggets of humanity in each character. Xandra and Vision were most fun to read. Also I sensed that you had become quite frustrated with the whole thing by the end. Hang in there pal!
:PROPERTIES:
:Author: bart4
:Score: 3
:DateUnix: 1524948353.0
:DateShort: 2018-Apr-29
:END:


** Super happy this is out! Having read it through (and being way too fuckin tired to provide a constructive comment beyond "i loved it" (why the fuck did I force myself to finish it tonight instead of reading part 4 tomorrow like a sane person???)) I think it was worth the wait. One minor typo, though: In Chapter 22, 13 paragraphs from the end of the chapter, the name "Major" isn't capitalized. Specifically the sentence is, "She set /major/ down on the asphalt and coughed[...]"
:PROPERTIES:
:Author: Sarkavonsy
:Score: 2
:DateUnix: 1524292915.0
:DateShort: 2018-Apr-21
:END:

*** Whoops! I'll get that on the next edit! Thanks!
:PROPERTIES:
:Author: Raelifin
:Score: 2
:DateUnix: 1524410215.0
:DateShort: 2018-Apr-22
:END:

**** Making this the typo thread, the beginning of chapter two refers to "green laws" at the edge of the spaceport. Colorless green ideas sleep furiously.
:PROPERTIES:
:Author: jareds
:Score: 2
:DateUnix: 1524444990.0
:DateShort: 2018-Apr-23
:END:


**** There are also a few times when "Neurotoxin" isn't capitalized.
:PROPERTIES:
:Author: CeruleanTresses
:Score: 1
:DateUnix: 1524532211.0
:DateShort: 2018-Apr-24
:END:


** @Raelifin I was really disappointed in the third book. It's too fragmented and confusing and hard to follow. It feels like the book assumes the reader has a level of understanding of the events and characters from the earlier books that they might not have. I kept wondering if I had somehow missed a few chapters at end of mentality, even though I KNOW that I read it to the end. I feel like I was dropped into the midst of things in book three without sufficient exposition to tie it back to the previous books.

Also, the big metaphysics reveal towards the end was horribly anticlimactic, utter non-reductionist physically and logically impossible nonsense, and possibly the worst deux ex machina in the history of deux ex machinas. And it wasn't foreshadowed at all.

Conscious minds are complex processes that are made of simpler parts. A human mind is a complex pattern of neurons firing. You can't have a pattern without it being a pattern /of/ something. A sequence of progressively larger squares still needs the squares to represent it. While you could transfer that pattern onto circles instead of squares, you still need some way to represent the pattern.

Even if you change the substrate of a mind, switch the neurons turning on and off for 1's and 0's, you still need the 1's and 0's, and you still need to have that recorded somehow. You still need a substrate.

If you're going to just claim the universe itself is the substrate, then you're just saying "phlogiston". Is there some pattern of universes that a single mind could be encoded in? You need some sort of building blocks to arrange in a pattern, whether they be neurons or bits, or circles or squares, or SOMETHING. You need to have those building blocks first before you can get consciousness. Consciousness is not a fundamental building block of reality. The building blocks come first, then AFTER THAT the building blocks can be arranged in a shape called "conscious minds".

Some parts of the book were enjoyable, but it definitely was NOT worth 10 dollars, and overall the ending ruined it to a large extent. It did not meet the standard of quality set by the first two books. I would like at least some of my money back if you are willing. That being said, if you arent willing to refund me I will understand, since most authors wouldn't think to do that, likely because no other authors are doing that, and it would put them at a disadvantage in the publishing markets or something.
:PROPERTIES:
:Author: Sailor_Vulcan
:Score: 2
:DateUnix: 1524438893.0
:DateShort: 2018-Apr-23
:END:

*** I'm sorry that I failed to deliver on the book that you wanted. I agree that there are plenty of flaws, but I do want to stand up for the hardness of the scifi. Ro was foreshadowed many times (though I could perhaps have been more overt about it) and has a reductionistic explanation that fits within the laws of the universe that we know. In fact, I would argue that something like Ro would have been necessary to have a good explanation of things that are set up at the beginning of Society. Indeed, the philogiston explanation is /not/ an explanation, in that it doesn't actually predict what happens in the story. Just because certain PoV characters say it's philogiston, doesn't mean it /is/.

Aretii's critical comment, below is much more on-the-nose for how I didn't execute Eternity well enough. Specifically, in the first two books I hold the reader's hand and let them watch AI expanding beyond what it's supposed to do. The third book is a break from that--it's the point where the AI becomes too intelligent/inhuman to be followable. The reader is left behind, much like the other humans, and it's meant to hurt. It's meant to leave us scraping and yearning to be close to that again.

That said, it's not meant to actually be unpleasant to read. It was meant to tantalize and invite speculation towards unravelling the mysteries rather than annoyance at the author. If you would like a refund, I will gladly give it to you. Send me a PM with your email and where you bought the book.

I hope your next reading experience is more to your tastes. :)
:PROPERTIES:
:Author: Raelifin
:Score: 9
:DateUnix: 1524492446.0
:DateShort: 2018-Apr-23
:END:

**** u/CeruleanTresses:
#+begin_quote
  The reader is left behind, much like the other humans, and it's meant to hurt. It's meant to leave us scraping and yearning to be close to that again...That said, it's not meant to actually be unpleasant to read. It was meant to tantalize and invite speculation towards unravelling the mysteries rather than annoyance at the author.
#+end_quote

I see what you're saying and on one level I really appreciate that kind of meta-level storytelling. I always think it's cool when the /structure/ of the story works along with its content to make me feel a certain way. And this book was definitely successful at making me feel like an out-of-the-loop baseline struggling to comprehend divinity.

I think where the second part fails for me and some of the other readers is that eventually, learned helplessness kicks in. The reader's curiosity about unraveling the mysteries fades as it becomes apparent that they can't be unraveled. And the more the reader is jerked around with respect to critical details of the world you're describing to them--what's really happening and what's a simulation or mindhack, which entities are alive or dead at any given point, what has or has not exploded, etc--the more they lose patience and give up on trying to grasp what's actually happening. Of course that technique has been used to great effect in many works of fiction, but I think there's an upper limit to how much you can do it in one story before the audience loses investment.
:PROPERTIES:
:Author: CeruleanTresses
:Score: 8
:DateUnix: 1524511196.0
:DateShort: 2018-Apr-23
:END:


**** Are you familiar with the concept of a fair play whodunit? Readers can't read your mind. If you make any effort to hide the truth from your readers, whatsoever, they will not see it. Good clues are the ones left in plain sight. If you want to make it harder to solve the mystery, have characters try to obscure it, don't do the obscuration yourself.

Also, it looks like you didn't respond to my actual reasoning for saying Rho is non-reductionist nonsense. I explained WHY rho is like phlogiston, and your rebuttal was about how "just because some characters think it's phlogiston doesn't mean it is" which doesn't contradict anything I said about why rho is nonsense, and it isn't even related to the arguments I actually made against it. Whether or not some people think it's plausible isn't the right question, but rather, is it actually plausible? And even if it works in your story, it's a severe misrepresentation of real life, and considering that you basically promised your readers that the story would be realistic, this seems like a rather large mistake.

Have you read the lesswrong sequence on reductionism?

Also I sent you a pm since I wasn't sure if you'd see my comment since I couldn't figure out how to tag you here. That pm included my email address.
:PROPERTIES:
:Author: Sailor_Vulcan
:Score: 2
:DateUnix: 1524495089.0
:DateShort: 2018-Apr-23
:END:

***** Conscious minds have access to their own map of reality, but that's it. Features of the map can make it seem like the map must be generated by a consistent territory 'out there', since the map has representations of agents with brains and is viewed from the inside at the location of one of those brains. But the existence of a more fundamental territory doesn't seem strictly necessary. The standard way of presenting this idea is the simulation hypothesis, but I think Ro is an equally valid if not even more compelling thought experiment.

The simulation hypothesis requires that the perceived world is running inside of an even more complex world, which is unsatisfying for the same reason that 'God guides the motion of the planets' is less satisfying than 'F=G(m1*m2)/r^{2'}. With perhaps a smidge of artistic license, it seems reasonable to me that one could build a consistent model of a universe where thought (i.e. processing of information) is built out of math and is more fundamental than physics. Math is very general, but its consistency governs what types of physical laws are possible. With a bit of imagination, couldn't one consider the possibility of a universe where the way that information can be processed similarly restricts and builds a foundation for what laws of physics can be observed?
:PROPERTIES:
:Author: AntiTwister
:Score: 2
:DateUnix: 1529483365.0
:DateShort: 2018-Jun-20
:END:


**** FYI, it's spelled "phlogiston".
:PROPERTIES:
:Author: jareds
:Score: 1
:DateUnix: 1524552863.0
:DateShort: 2018-Apr-24
:END:


*** [[/u/rictic]] has a better "Ro isn't real" [[/r/rational/comments/8dpxrb/crystal_eternity_now_available/dxqyr6x/][comment]] than mine, and [[/u/Raelifin]] says, "This comment makes me happy", so...

I would also note that the beginning of the book (after the content warning info) says "No miracles", that /the/ coin has "NON MIRACULA" printed on it, and that the android demonstrates the ability to control how it lands.

But of course, if you prefer an Asimovian style of straightforward exposition, such is your preference.
:PROPERTIES:
:Author: jareds
:Score: 5
:DateUnix: 1524445726.0
:DateShort: 2018-Apr-23
:END:

**** After spending a fair amount of time thinking about it and reading people's comments, I'm >90% "Ro isn't real, it's just a trick." My comment elsewhere in this discussion was written twenty minutes after finishing, before I'd had time to let my brain really chew on things.

That doesn't fix my issues with the book, though. The thing about what you're calling Asimovian straight exposition is that the other Crystal books were largely written in what I shall call "heist film style": every step of Face's rise to fulfilling The Purpose involves running an elaborate con on /someone/, be it the scientists or the terrorists or her fellow AIs, and mostly this was written in the style "there is a problem -> a plan is concocted and laid out for the reader -> the plan is put into motion -> complications arise -> iterate recursively." Even in the cases where something initially confusing from the reader's perspective arose, such as the prosthetic legs trick in /Mentality/, a few pages later we were back in Face's POV having everything explained. /Eternity/, in contrast, breaks from this and has a very non-discursive style of plot progression where, among other things, we're shifting around at multiple points in the timeline and multiple POVs, several key character events happen at nested layers of simulated reality, and at /no/ point do we get the Planning Montages that are such a hallmark of the heist genre and typified Face's schemes earlier in the series.

This sort of confusing/subtler style isn't /bad/, of course -- Primer/House of Leaves/the relevant parts of Jorge Luis Borge's oeuvre are all great, and /Eternity/ isn't a bad work in any abstract sense. I just have fundamental objections to wrapping up a trilogy in a dramatically different style than you began it.
:PROPERTIES:
:Author: Aretii
:Score: 7
:DateUnix: 1524448435.0
:DateShort: 2018-Apr-23
:END:

***** I think the heist film style would break down after the AIs become super-intelligent. Max probably has some ideas of how this all went down, but if he just wrote it all out it would inevitably be ridiculously simplistic compared to what should have been going on in a three-way hard take-off. Even as it is, he has me going, "come on, [[#s][spoiler]]". Keeping the clear exposition of the AIs' plans into the super-intelligent phase doesn't seem like it would have worked.
:PROPERTIES:
:Author: jareds
:Score: 2
:DateUnix: 1524457104.0
:DateShort: 2018-Apr-23
:END:

****** Heh. Your "come on" is valid, and is evidence that you don't actually understand what's going on. ;)
:PROPERTIES:
:Author: Raelifin
:Score: 4
:DateUnix: 1524492626.0
:DateShort: 2018-Apr-23
:END:

******* I'm in the "want to solve the mystery" camp, so I may re-read the whole trilogy. If this thread is dead in a month or so (I have other things to do and read), I may try to get little hints like that via e-mail. :)
:PROPERTIES:
:Author: jareds
:Score: 1
:DateUnix: 1524552790.0
:DateShort: 2018-Apr-24
:END:


**** Really. You think it's at all plausible that a superintelligence could actually be tricked into believing that kind of obvious nonsense? We're talking about something that any regular human with common sense who understands reductionism should be able to recognize is bs. I don't buy it.

This honestly feels like the author wrote himself into a corner and couldn't come up with a plausible way to resolve the plot with a happy ending without a weird unrealistic metaphysics hack which makes AI alignment in the story unrealistically much easier than it should be, and that's even AFTER a bunch of unaligned superintelligences have already taken off.

If it were real life, humanity WOULD have been doomed as soon as they made an unaligned superintelligence, or at least as soon as it gained access to the internet.

It would not have taken until book 3 for Face or the rest of the crystal society to suddenly realize that their advanced alien hardware would allow them to drastically improve their processing speed and efficiency. They would have realized it pretty much as soon as they started investigating body, which would have happened much earlier.

The big metaphysics hack towards the end actually kind of reminds me of when EY put legalized rape in his otherwise genuine human utopian setting in Three Worlds Collide just to morally shock the readers into seeing the futuristic humans with an outsider's perspective instead of identifying with them too strongly. This is almost as bad as that.

The mistake both authors are making looks like "well we gotta be totally wrong about /something/ that were really sure of, but we just don't know what. So have we considered pretending in story that this totally arbitrary fact that we are extremely certain of in real life, like that rape is wrong, or that 1+1=2, has been falsified in the distant future?

No. Just no.
:PROPERTIES:
:Author: Sailor_Vulcan
:Score: 2
:DateUnix: 1524492365.0
:DateShort: 2018-Apr-23
:END:

***** u/jareds:
#+begin_quote
  You think it's at all plausible that a superintelligence could actually be tricked into believing that kind of obvious nonsense?
#+end_quote

OK, I made a clear mistake here, anthropomorphizing Vision's love of weird connections, thinking it would believe a "mathematically elegant" but crazy theory like a human who loves weird connections. However, it doesn't change much. Remember, my theory is [[#s][spoiler]]. Reducing my theory to [[#s][spoiler]] is practically justified with Occam's razor anyway. Incomplete (i.e., not full takeover) mindhacks have been used throughout this work, and I think it's fair to say that none of us actually know anything about super-intelligences' abilities to engage in incomplete mindhacks on each other. Note that this isn't an unfalsifiable theory: an AI's actions still have to benefit one of the other AIs if not itself.

With respect, you're now saying a bunch of things about the series that seem rather straightforwardly false to me, so I think you're letting your perceived metaphysical objection get to you. Observe:

#+begin_quote
  This honestly feels like the author wrote himself into a corner and couldn't come up with a plausible way to resolve the plot with a happy ending
#+end_quote

Technically, I agree that the author couldn't come up with a plausible way to resolve the plot with a happy ending, insofar as the actual ending is that [[#s][spoiler]]. The series is explicitly cast as Face propaganda, so the portrayal of a happy ending means nothing.

#+begin_quote
  It would not have taken until book 3 for Face or the rest of the crystal society to suddenly realize that their advanced alien hardware would allow them to drastically improve their processing speed and efficiency.
#+end_quote

They realize it in book 2 at the latest. That's why there's a giant fight at the end. In book 1, they're still myopic idiots in many ways, not super-intelligences. Growth of course understood the importance of self-improvement early on, but he wasn't super-intelligent so he couldn't engage in it trivially and he had to avoid tipping off the others.

#+begin_quote
  If it were real life, humanity WOULD have been doomed as soon as they made an unaligned superintelligence, or at least as soon as it gained access to the internet.
#+end_quote

They're /way/ below super-intelligence when they first get Internet access in book 1. Humanity creates something that /becomes/ unaligned super-intelligences, and are doomed at that point, not necessarily before. The only reason humans survive is that they are in the utility function of one of the super-intelligences.
:PROPERTIES:
:Author: jareds
:Score: 5
:DateUnix: 1524551585.0
:DateShort: 2018-Apr-24
:END:


***** I also find it implausible that this could be a deception of some of the siblings by another. This, among many other features, turns me against the idea that this was a deception. It is far better read, imo, as a fact. The "somewhat crazy idea" of [[https://www.reddit.com/user/rictic][rictic]] is fun, and it's interesting to ponder for a bit, but it hasn't affected my confidence. What Vision and Face ponder and examine is a genuine discovery. It changes their understanding of the situation, and both pursue their aims differently once they have learned it.

Your idea that this "hack" was contrived at the end to propel the story to places that could not be reached in its premises is entirely wrong, imo. Against this idea I propose that this was very much in the author's mind during the writing of the first novel. It's not a miraculous salvation coming out of nowhere. (That idea is explicitly rejected from the get go.)

It does, of course, feature strongly in the resolution of the plot. In that manner I do see it as a vehicle. Is it the sort of SF premise-vehicle that disqualifies the Crystal Trilogy as hard SF? Not even close.
:PROPERTIES:
:Author: TracyHarms
:Score: 2
:DateUnix: 1524527557.0
:DateShort: 2018-Apr-24
:END:

****** I don't recall rho being foreshadowed in the first two books AT ALL. Please explain.

Also, whether or not it is self consistent in the rules of the story is not the issue, the issue is that the story tries to present itself as a realistic depiction of superintelligence takeoff, and it's NOT. And it's only compliant with physics in so far as some physicists believe in the whole "consciousness-triggered quantum collapse" thing, or in other words "i can make reality make up its mind just by looking at it!"

And realizing how ridiculous that is probably requires knowledge and skills from outside their area of expertise. After all, consciousness is not the specialty of quantum physicists.
:PROPERTIES:
:Author: Sailor_Vulcan
:Score: 2
:DateUnix: 1524530947.0
:DateShort: 2018-Apr-24
:END:

******* I did not say it was foreshadowed in previous books, I said I'm thinking it had been in mind all along. Some may not like the lack of foreshadowing, but I do. It was a *surprise*. That's the nature of surprises. It provides, through example, the idea that hyperintelligent AI can be expected to learn things that go beyond what humans have learned, or perhaps even beyond what humans are capable of learning. Such a thing would have to be very significant in order to get the point across that it's a breakthrough of understanding, and it would have to be consequential to the story in order to be more than a nominal adornment. What I encountered was persuasively both.

You and I agree that the author wanted to encourage conversations and thinking about AI/superintelligence take-off. In these novels we get more than one model of what this might be like. None of those models depend on the piece you've been objecting to. These sketches of takeoff in the Crystal Trilogy are all in keeping with the usual preconceptions people have about people, machines, intelligence, data, computation, and physics. The thing you dislike serves various purposes, but it does not do anything to make the main problem plausible. This series is not trying to describe why AI might gain qualitative breakthroughs in competence. In my opinion it's trying (among other things) to explain why people who think these breakthrough are possible think that such changes would be extremely dangerous and fabulously difficult to neutralize or contain. The series as a whole, and Crystal Eternity especially, drives home that idea again and again. It does so mainly through presumptions that are commonplace today in science and technology. The aspect you've been complaining about isn't required for the AI threats depicted to be credible, plausible, or possible.
:PROPERTIES:
:Author: TracyHarms
:Score: 1
:DateUnix: 1524533646.0
:DateShort: 2018-Apr-24
:END:

******** I'm still not sure I understand what you're saying here. Do you or do you not agree that the existence of a law of physics that ensures "diversity of souls" and outright prevents human extinction would drastically and unrealistically decrease the difficulty of aligning AGI or ASI with human values?

Face wasn't even made by humans, it was made by the other AI's. They basically ended up with an at least somewhat friendly superintelligence because of luck and a weird metaphysics hack rather than because of humans actually solving the value alignment problem.
:PROPERTIES:
:Author: Sailor_Vulcan
:Score: 3
:DateUnix: 1524703484.0
:DateShort: 2018-Apr-26
:END:

********* I do think the posited natural law in this book greatly and unrealistically decreases the difficulties of that alignment. This amplifies the sense of genuine hazards. If this series is something of a thought-experiment on the problems and risks of AI takeoff then the message I hear is: "Here's how these problems go down in this fictional world, which is unrealistically biased toward human survival and thus the possibilities of bringing a story arc through to a readable conclusion. If you are willing to bet that the universe is this bent on our non-extinction and you're indifferent to the destruction that was portrayed, yuck! If, instead, you expect that reality is genuinely open to our extinction and you want to avoid catastrophe, let's roll up our sleeves and get serious about avoiding those things."
:PROPERTIES:
:Author: TracyHarms
:Score: 2
:DateUnix: 1525366733.0
:DateShort: 2018-May-03
:END:


******** I think I underplayed how much foreshadowing this component received. While I can't think of anything that suggests this /particular/ thing, there are several mysteries in the novels that indicate that solutions are necessary. These all seem to me to be problems of extraterrestrial intelligence. By the emphasis on "No miracles" we're led to expect a naturalistic, systemic, connected answer to these problems if we're going to get such answers at all. In my opinion the most satisfying interpretation of this series is to take the "cosmic" component as a naturalistic and systemic factor that resolves the alien mysteries. In my reading it did that, and more.
:PROPERTIES:
:Author: TracyHarms
:Score: 2
:DateUnix: 1525365369.0
:DateShort: 2018-May-03
:END:


** Damn, I bought Mentality but never managed to finish it. Want to buy it, but better finish up the second one, first. Thanks for delivering anyway. Kudos :)
:PROPERTIES:
:Author: ahel
:Score: 1
:DateUnix: 1524693036.0
:DateShort: 2018-Apr-26
:END:
