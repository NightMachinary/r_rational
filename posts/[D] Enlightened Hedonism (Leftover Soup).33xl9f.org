#+TITLE: [D] Enlightened Hedonism (Leftover Soup)

* [D] Enlightened Hedonism (Leftover Soup)
:PROPERTIES:
:Author: rthomas2
:Score: 12
:DateUnix: 1430066527.0
:DateShort: 2015-Apr-26
:END:
A while ago, [[/u/MugaSofer][u/MugaSofer]] posted the webcomic Leftover Soup here: [[http://www.reddit.com/r/rational/comments/2czpg9/webcomic_leftover_soup/]]

I've since become quite a fan, and recently discovered (upon re-reading) that the author actually wrote out the life-philosophy of my favorite character. I figured it might be of interest--it strikes me as one of the most cogent, intelligent character philosophies I've seen, not to mention that I personally agree with it entirely. Link is below; what do you guys think?

[[http://leftoversoup.com/enlightenedhedonism.html]]


** Similar though this is to my own philosophy, and much though I love Leftover Soup, I am now going to do a point-by-point rebuttal for my own amusement. I am large, I contain multitudes, etc etc.

#+begin_quote
  It is self-evident that the purpose of life is the pursuit of pleasure and the avoidance of pain.

  Note that "pleasure", here, denotes enjoyable sensations and the fulfillment of desire at any and all levels of the consciousness - the existence of masochism does not invalidate this precept.
#+end_quote

This is either wrong or tautological; either "pleasure" just means a being's utility function, in which case it is tautological, or it means the usual meaning of "pleasure" ... in which case it is self-admittedly wrong. In practise, this is clearly an attempt at what some people call the motte-and-bailey fallacy; definibg your terms one way and then using them another.

#+begin_quote
  It is equally self-evident that the most powerful and effective tool possessed by human beings for the achievement of this purpose is the ability to think.
#+end_quote

How about hands? Or speech? If you find a way to safely wirehead, will /that/ be the new Most Important Thing?

#+begin_quote
  An enlightened person seeks higher-level pleasures over lower-level ones, and long-term pleasurable lifestyles over short-term harmful thrills.
#+end_quote

Long-term pleasurability versus short-term is just basic utilitarianism, obviously; but I think using it this way brushes the possibility of long-term wireheading under the carpet.

The phrase "higher-level metapleasures" is, as far as I can tell, gibberish. It's clearly being used as code for "obviously I /actually/ value lots of things other than pleasure, and when it becomes important enough I will ignore my stated principles".

#+begin_quote
  The definition of "good" behaviour is the practice of empathy - the belief that one's own pleasure and pain are no more and no less important than the pleasure and pain of another.

  Enlightened hedonists attempt to expand their empathy as far as possible - not only to other humans who are physically or psychologically dissimilar, but to any entity capable of experiencing sensations analogous to human pleasure and pain.
#+end_quote

As is, in fact, clear in the strip, this has led Max to value literally every sentient being equally; up to and including insects. The only reason this is tenable is because she apparently can't multiply.

Still, there's not much else I can argue with here.

#+begin_quote
  The enlightened hedonist embraces the alteration of her own consciousness in the pursuit of greater pleasure.

  Enlightened hedonists seek out pleasure in all its forms - they embrace every taste, explore every thrill and test out every sensation available within the bounds of reason and empathy. She utilizes discipline and willpower to surmount any and all instincts, prejudices and limitations that stand between her and pleasure.
#+end_quote

"I will self-modify away anything that prevents me wireheading, including elements of my utility function that make wireheading less valuable to me!"

Nobody must ever tell Max that "wireheading" isn't a metaphor, it's an actual medical procedure we've been able to do for decades :(

#+begin_quote
  Enlightened hedonists accept the validity of choice in other entities in direct proportion to that entity's intelligence.

  It should be noted, here, that "intelligence" means exactly that - the ability to think. It does not in any way refer to an entity's actual thinking, nor to their adherence to enlightened hedonism. Followers of other philosophies should be free to follow their philosophies.

  Enlightened hedonists may advocate the benefits of their worldview, but they should in no way impose these beliefs on anyone capable of dissenting, except in such cases where their beliefs result in the causing of pain to others. While an enlightened hedonist's empathy may twinge in response to another entity's self-inflicted pain, she has no right to force decisions on that party, except in such cases where said self-inflicted pain is the result of ignorance or mental impairment.
#+end_quote

Huh, that's a pretty interesting point. I'd forgotten that was there.

Anyway, since this only permits "self-inflicted pain", you're still trying to force literally everyone into complying with your beliefs. It sounds tolerant and open-minded, but it really, really isn't.
:PROPERTIES:
:Author: MugaSofer
:Score: 11
:DateUnix: 1430070842.0
:DateShort: 2015-Apr-26
:END:

*** WHAT? Wireheading has been possible for decades? I thought it was just a thought experiment. I think that might qualify as an information hazard.
:PROPERTIES:
:Author: RolandsVaria
:Score: 3
:DateUnix: 1430087353.0
:DateShort: 2015-Apr-27
:END:

**** The barrier to entry is literally brain surgery, so I don't think it's a particular hazard for now.
:PROPERTIES:
:Author: Transfuturist
:Score: 5
:DateUnix: 1430090623.0
:DateShort: 2015-Apr-27
:END:

***** Actually, it can be accomplished non-invasively and without any apparent risk using magnets. It's called transcranial magnetic stimulation, which literally means stimulation through the skull with magnets.

There's an article that focuses on TMS here: [[http://www.wireheading.com/brainstim/savant.html]]
:PROPERTIES:
:Author: rthomas2
:Score: 1
:DateUnix: 1430091442.0
:DateShort: 2015-Apr-27
:END:

****** TMS doesn't have the same /impact/ as an electrode directly in the "pleasure center".
:PROPERTIES:
:Author: ArgentStonecutter
:Score: 4
:DateUnix: 1430149503.0
:DateShort: 2015-Apr-27
:END:


****** Um. Do you know for a fact that TCMS can be used to directly stimulate pleasure centers in the same way as an electrode? Because I've never heard that, and I'm on [[/r/tDCS]]. Wireheading of the sort we're actually talking about has only been accomplished so far using [[http://www.wireheading.com/intracran/compulsive-selfstimulation.pdf][direct electrode implants.]]
:PROPERTIES:
:Author: Transfuturist
:Score: 3
:DateUnix: 1430150731.0
:DateShort: 2015-Apr-27
:END:

******* I do not. I'd thought so from my readings, but you'll know better than me.
:PROPERTIES:
:Author: rthomas2
:Score: 1
:DateUnix: 1430151081.0
:DateShort: 2015-Apr-27
:END:


****** Yeah, I really don't think you should spread that around.
:PROPERTIES:
:Author: RolandsVaria
:Score: 1
:DateUnix: 1430095054.0
:DateShort: 2015-Apr-27
:END:

******* Really? I'm honestly surprised you'd think that...can I ask why?
:PROPERTIES:
:Author: rthomas2
:Score: 2
:DateUnix: 1430096673.0
:DateShort: 2015-Apr-27
:END:

******** Well, I'm a fairly content person, so I don't care about such an operation. But for some less fortunate people, perhaps suffering from depression...it seems like a distinct possibility that they might fixate on such a thing if they hear about it.
:PROPERTIES:
:Author: RolandsVaria
:Score: 3
:DateUnix: 1430099655.0
:DateShort: 2015-Apr-27
:END:

********* Hm. I think that's true of a lot of things--off the top of my head, drugs are a good example--but I think the possibility of obsession is an excellent reason to /demystify/ something. If all that's known of weed were "marijuana is prized for its high, and has few if any adverse physiological effects," I think that'd definitely encourage its (ab)use. But add the fact, "this high does not translate to the feeling of fulfillment, and can often impede one from seeking it due to the temporary impairment that coincides with the pleasurable high," and it becomes kinda scary--clearly the sort of thing that, while not as bad as alcohol or cigarettes, can be dangerous and doesn't provide what one really wants.

On the flipside, if TMS actually does provide a shortcut to happiness--complete, fulfilling happiness--and granted, I don't think that's possible; but if it did, it'd be arguably the best possible thing to build enough TMS machines for the whole race, and then find a way to power them and sustain our lives indefinitely.

In short: if it really isn't good, then we should talk about it. If it really is good, we should talk about it.

I mean no disrespect by this, but... I think your downvote and response reflect kind of a scary idea, which is that people shouldn't be trusted with information. And not only that, but that talking about certain things is so negative as to actually detract from a conversation in a way that should be penalized. Absolutely, abuses of knowledge occur. But I don't believe limiting knowledge is actually the solution--rather, I'd argue that only a person's desire to ignore information/to act on only partial knowledge is the problem. And I think saying we shouldn't use TMS might well be accurate, though I actually suspect it's not--it sounds like an excellent treatment for depression, from the research I've read, and not addictive. Still...while not in any way wanting to force my beliefs on you, I do really worry about the implications of encouraging actual censorship.

Please do let me know if I've misunderstood your position, or else if you have a counterargument you think I'm failing to consider, though.
:PROPERTIES:
:Author: rthomas2
:Score: 9
:DateUnix: 1430101065.0
:DateShort: 2015-Apr-27
:END:

********** Knowledge tends to have an inherent value, it's worth attaining for its own sake. And indeed, the best way to move forward is to gain a greater understanding of how to reach our goals. It's worthwhile to try to move forward by promoting further study, even if some people can use knowledge in a bad way.

I wasn't censoring you. I wasn't even saying that you should be censored. I just thought it was a bad idea to spread that particular piece of information around. Kind of like how you don't go out of your way to show your antisocial arachnophobic friend the news article about how in some places it can rain spiders, since you know it might make them ever more reluctant to leave the house. [[http://gawker.com/5982891/meanwhile-in-brazil-its-raining-spiders]]

Only it's far worse than that, since wireheading as it is generally discussed has several hugely negative effects on its participants. Making them withdraw from the world, and stop caring about anything else. Having spent some time around people whom suffer from depression, the type of people who might go in for that sort of thing just to escape, I was hit rather strongly with the feeling that I would not want them to get the chance to consider that option. Much like how, in a hypothetical world where suicide is some obscure facet of reality rather than being widely known about, you wouldn't want to tell your depressed friend about it. You might gather some well learned colleagues and discuss the matter in private, but bringing it up in public seems unlikely to do any good.

I should be clear that that was just my gut reaction. I hadn't taken the time to read the posted article, and once I did it was clear that things weren't remotely so bad as I'd thought. The wireheading you suggest is quite distinct from the nightmarish thought experiments I've read.
:PROPERTIES:
:Author: RolandsVaria
:Score: 4
:DateUnix: 1430104104.0
:DateShort: 2015-Apr-27
:END:

*********** Ahh, ok. Thanks for clarifying!

I do still disagree a bit: while we're agreed that, say, giving an irrationally suicidal person instructions for a homemade painless death machine is indeed bad, I think discussing such machines, and even their instructions is good. Even beyond any inherent value--and actually, I'd argue that knowledge doesn't have any inherent value, but rather that all knowledge has at least a chance of being useful, and thus has at least some degree of extrinsic value. Rather, I'd say that such discussions address the important question, "should life always be lived, and if not, is there a best method for ending it?"

Similarly, while I wouldn't excite anyone's phobia intentionally/directly, I'd disagree that spreading potentially-triggering info is bad, no matter how likely the trigger. Rather, not prefacing it with trigger warnings is bad, as is allowing anyone who is oversensitive to information free access to it. Myself and many of my friends suffer from depression as well--and let me take a sec to extend my sympathies to you and yours. It's a hell of a disease, and you and they have my admiration for your efforts in the face of it, and my sincere sympathy for having to bear with it to any degree.

Still: having been suicidal, I do not think the existence of, say, noose tying tutorials, nor their existence at the other end of an easy internet search, was a bad thing, even for me, even at that time. Though I'm probably quite lucky I didn't find one--or rope, for that matter--the problem as I see it is that I was neglected to the point of having free access to such information while in an emergency-level state. Though my depression is much more manageable now, I still have to avoid certain stories or bits of info, especially the news--and occasionally need to recruit a friend to help keep me away from even Disney movies. (I do /not/ recommend watching the first ten minutes of Up while contemplating the possibility that life is just a prolonged torture concocted by cosmic accidents and bad feedback loops.)

So I do agree that looking after what information people take in, and when, is immensely important. However, I /really/ recommend against doing it on the generation end of things, and believe strongly that censoring the receiving end is key/ideal. That, and paying close attention to our own/each others' sensitive areas.

Most importantly: even in such a small thing as changing your initial position to your reflected-upon one, you do me an honor. This subreddit and my general principles both value earnest discussion quite highly; if I had any to give, you'd be receiving some gold, but as it is I'll just upvote your post and ask that anyone who reads these words do the same.
:PROPERTIES:
:Author: rthomas2
:Score: 7
:DateUnix: 1430106608.0
:DateShort: 2015-Apr-27
:END:

************ u/deleted:
#+begin_quote
  (I do not recommend watching the first ten minutes of Up while contemplating the possibility that life is just a prolonged torture concocted by cosmic accidents and bad feedback loops.)
#+end_quote

But life /isn't/ a prolonged torture concocted by cosmic accidents and bad feedback loops. In fact, it's very non-prolonged, and quite definitively not tortuous (that is, the world isn't /trying hard/ to make you suffer).

So far in history, it sucks being confined to a tiny portion of life-possibility space that is eventually going to be labelled "survivalist shithole full of nutters raving on about how biodecay is good for your moral character." But, well, hey, we're working to break out of that corner, so you can cheer up!
:PROPERTIES:
:Score: 2
:DateUnix: 1430256289.0
:DateShort: 2015-Apr-29
:END:

************* While that is both rational and accurate, my point is more that when one /isn't/ thinking rationally, sad things become far more so. 😖
:PROPERTIES:
:Author: rthomas2
:Score: 1
:DateUnix: 1430256900.0
:DateShort: 2015-Apr-29
:END:

************** I guess I just find it helpful in fighting my depression to remind myself that however dark things seem, that's actually just my brain malfunctioning, and really things are looking at least a little bit up.
:PROPERTIES:
:Score: 2
:DateUnix: 1430278174.0
:DateShort: 2015-Apr-29
:END:

*************** Ho boy yes. Yes yes yes indeed. And thank you for the positivity good sir ^{_^}
:PROPERTIES:
:Author: rthomas2
:Score: 1
:DateUnix: 1430282822.0
:DateShort: 2015-Apr-29
:END:


*********** u/eaglejarl:
#+begin_quote
  I wasn't censoring you. I wasn't even saying that you should be censored. I just thought it was a bad idea to spread that particular piece of information around.
#+end_quote

That's actually pretty much the definition of censorship.
:PROPERTIES:
:Author: eaglejarl
:Score: 3
:DateUnix: 1430117690.0
:DateShort: 2015-Apr-27
:END:

************ I did not threaten or coerce, nor did I say that he should be threatened or coerced (he shouldn't). I simply stated, not even particularly rudely, that I thought it was a bad idea for him to bring that information up at a later point (a statement I'm not currently standing behind). By your logic, it is censorship any time someone expresses a dislike for any idea. Isn't expressing dislike for an idea almost identical to saying that you would prefer that the idea not become more widespread?
:PROPERTIES:
:Author: RolandsVaria
:Score: 2
:DateUnix: 1430129558.0
:DateShort: 2015-Apr-27
:END:


********** u/deleted:
#+begin_quote
  I mean no disrespect by this, but... I think your downvote and response reflect kind of a scary idea, which is that people shouldn't be trusted with information.
#+end_quote

There is a kind of information people shouldn't be trusted with: secrets, which are only valuable while they remain secret.

But yeah, you're much less likely to act in a reflectively-correct manner if someone is deliberately depriving you of useful information. Propaganda, brainwashing, all the old canards.
:PROPERTIES:
:Score: 3
:DateUnix: 1430154137.0
:DateShort: 2015-Apr-27
:END:


********* Person prone to depression here. No, just no. That's really not the kind of thing that sounds appealing.

Besides which, for all the scares about "wireheading" and "orgasmium", last I heard from real neurology, pleasure and happiness are actually separate neurological functions -- Yvain's famous "wanting" and "liking".

Oh, and then there's the Rat Park experiments to consider.
:PROPERTIES:
:Score: 5
:DateUnix: 1430154161.0
:DateShort: 2015-Apr-27
:END:


*** Let me start with my definition of wireheading so we're all on the same page:

"Artificially stimulating the pleasure center of the brain so that the individual continuously experiences the maximum physical pleasure possible for a human."

Further, I have the following assumptions about wireheading:

1. The recipient will resist, to the best of their limited ability, having the wire removed.
2. The recipient is not capable of other actions while wireheading.
3. Because of 1. and 2. the recipient will starve / thirst to death unless bodily maintenance methods have been put in place ahead of time.

Assuming the above is what we're talking about, I've never understood why conversations about wireheading as a dangerous thing happen...or, at least, why they are dangerous for a randomly selected individual.

On [[http://capitalistexploits.at/wp-content/uploads/2014/11/Maslows_Hierarchy_of_Needs.png][Maslow's Hierarchy of Needs]] physical pleasure falls somewhere around level 2.5 -- it's something you look for after security of body etc, but probably before you look for friendship and sexual intimacy (/intimacy/, not just release).

There are three full levels above that! Once you start wireheading you can't seek pleasure from family, friendship, respect of others, creativity, etc. Sure, once you're actually under the wire you won't care about any of that, but before you go under the wire you will. It is my belief that most people will say "I'm sure this would be fun, but I'd rather have these other things." As evidence of this belief I submit that the vast majority of humans are not heroin addicts.
:PROPERTIES:
:Author: eaglejarl
:Score: 2
:DateUnix: 1430099214.0
:DateShort: 2015-Apr-27
:END:

**** I have to say, I am not nearly so worried about the likelihood of my, say, tripping headfirst into a wireheading chair as I am about the possibility of well-meaning hedonist utilitarians deciding that the best thing is to force everybody into those chairs.

Because I may not endorse the fact that my mind reacts in certain ways to pleasure over pain, but that doesn't change the fact that such a machine as you describe would still be incredibly addictive and hard to kick, much as meth and heroin are hard to kick (but less so than the wireheading, I would imagine).
:PROPERTIES:
:Author: callmebrotherg
:Score: 4
:DateUnix: 1430119225.0
:DateShort: 2015-Apr-27
:END:

***** u/eaglejarl:
#+begin_quote
  hard to kick
#+end_quote

That's exactly what I said; once you're in the machine you don't care about anything else and will attempt to keep yourself from being disconnected.

I believe that the vast majority of people will not choose to get into the machine of their own free will.

"well-meaning hedonist utilitarians [forcing everybody] into those chairs" is a different conversation. That's not about the dangers of wireheading, that's about the dangers of people imposing their utility function on others.
:PROPERTIES:
:Author: eaglejarl
:Score: 3
:DateUnix: 1430124655.0
:DateShort: 2015-Apr-27
:END:

****** Right. I'm pretty sure we're in agreement. Sorry for the lack of clarity.
:PROPERTIES:
:Author: callmebrotherg
:Score: 1
:DateUnix: 1430171883.0
:DateShort: 2015-Apr-28
:END:


**** Actually, based on studies of addicts, you /will/ care about all those other things after you go under the wire. You just won't be acting in any kind of reflectively coherent goal-seeking way with regards to any goals other than wireheading: your planning functions will be hijacked to ignore all emotions but the strongest reward signal (ie: the wire).
:PROPERTIES:
:Score: 5
:DateUnix: 1430154379.0
:DateShort: 2015-Apr-27
:END:

***** Okay. I'm not sure it invalidates my point, though -- the practical difference between "I care but won't do anything about" and "I don't care" is pretty small.
:PROPERTIES:
:Author: eaglejarl
:Score: 3
:DateUnix: 1430166123.0
:DateShort: 2015-Apr-28
:END:


**** I'm actually very unsure as to the accuracy of that definition, and especially of the assumptions. IIRC, animals follow the assumptions, but people don't.
:PROPERTIES:
:Author: rthomas2
:Score: 3
:DateUnix: 1430104527.0
:DateShort: 2015-Apr-27
:END:

***** Can you explain your own definition?
:PROPERTIES:
:Author: eaglejarl
:Score: 3
:DateUnix: 1430117092.0
:DateShort: 2015-Apr-27
:END:

****** Yup. And it's only a slight difference: direct stimulation of the brain so as to provide positive/desirable feelings.

However, that difference allows for the possibility of feeling whichever level of Maslow's hierarchy one can feel via such stimulation, thus making wireheading a lot more potentially desirable.

Still, whatever level of wireheading we've achieved so far has produced the following: - Animals basically become immediate addicts - Humans generally report varied levels of enjoyment, mostly very high, but don't seem to show addiction - And in addition, regular wireheading has been shown, when done correctly, to help mitigate depression

Note that I'm using a loose definition of addiction here...extreme compulsion might be a better phrase as pertains to accuracy.
:PROPERTIES:
:Author: rthomas2
:Score: 2
:DateUnix: 1430146332.0
:DateShort: 2015-Apr-27
:END:


****** Going mostly off likely flawed memory here: Standard real life "wire-heading" used things like a button to activate the pleasure (in the possession of the wire-headed person), so it wasn't absolutely on all the time.

Still though, in some animal trials mice were known to press the button instead of eating till they died. I think Tomas is saying, that human ability to manage survival and the pleasure button is better, but I haven't actually seen the studies myself.
:PROPERTIES:
:Author: gabbalis
:Score: 1
:DateUnix: 1430140482.0
:DateShort: 2015-Apr-27
:END:


***** The experiments described [[https://en.wikipedia.org/wiki/Pleasure_center#Human_experiments][in Wikipedia]] seem to be similar to animal models.
:PROPERTIES:
:Author: ArgentStonecutter
:Score: 3
:DateUnix: 1430149576.0
:DateShort: 2015-Apr-27
:END:

****** ***** 
      :PROPERTIES:
      :CUSTOM_ID: section
      :END:
****** 
       :PROPERTIES:
       :CUSTOM_ID: section-1
       :END:
**** 
     :PROPERTIES:
     :CUSTOM_ID: section-2
     :END:
Section 2. [[https://en.wikipedia.org/wiki/Pleasure_center#Human_experiments][*Human experiments*]] of article [[https://en.wikipedia.org/wiki/Pleasure%20center][*Pleasure center*]]: [[#sfw][]]

--------------

#+begin_quote
  Dr. [[https://en.wikipedia.org/wiki/Jos%C3%A9_Manuel_Rodriguez_Delgado][José Manuel Rodriguez Delgado]] implanted electrodes in the brains of 25 people.

  - 1963: [[http://www.scribd.com/doc/6052216/Electrical-selfstimulation-of-the-brain-in-man]["Electrical self-stimulation of the brain in man."]] by [[https://en.wikipedia.org/wiki/Robert_Galbraith_Heath][Dr. Robert Heath]].

  - 1972: A 24-year-old man with temporal lobe epilepsy, identified as patient "B-19". "He was permitted to wear the device for 3 hours at a time: on one occasion he stimulated his septal region 1,200 times, on another occasion 1,500 times, and on a third occasion 900 times. He protested each time the unit was taken from him, pleading to self-stimulate just a few more times... "

  - 1986: A 48-year-old woman with chronic pain. "the patient self-stimulated throughout the day, neglecting personal hygiene and family commitments."
#+end_quote

--------------

^{Interesting:} [[https://en.wikipedia.org/wiki/Pleasure][^{Pleasure}]] ^{|} [[https://en.wikipedia.org/wiki/Death_by_Ecstasy][^{Death} ^{by} ^{Ecstasy}]] ^{|} [[https://en.wikipedia.org/wiki/James_Olds][^{James} ^{Olds}]]

^{Parent} ^{commenter} ^{can} [[/message/compose?to=autowikibot&subject=AutoWikibot%20NSFW%20toggle&message=%2Btoggle-nsfw+cqqblyu][^{toggle} ^{NSFW}]] ^{or[[#or][]]} [[/message/compose?to=autowikibot&subject=AutoWikibot%20Deletion&message=%2Bdelete+cqqblyu][^{delete}]]^{.} ^{Will} ^{also} ^{delete} ^{on} ^{comment} ^{score} ^{of} ^{-1} ^{or} ^{less.} ^{|} [[http://www.np.reddit.com/r/autowikibot/wiki/index][^{FAQs}]] ^{|} [[http://www.np.reddit.com/r/autowikibot/comments/1x013o/for_moderators_switches_commands_and_css/][^{Mods}]] ^{|} [[http://www.np.reddit.com/r/autowikibot/comments/1ux484/ask_wikibot/][^{Magic} ^{Words}]]
:PROPERTIES:
:Author: autowikibot
:Score: 2
:DateUnix: 1430149605.0
:DateShort: 2015-Apr-27
:END:


**** According to Wikipedia, [[https://en.wikipedia.org/wiki/Pleasure%20center]["More recent research has shown that the so-called pleasure electrodes lead only a form of wanting or motivation to obtain the stimulation, rather than pleasure."]] (Berridge, K.C., Kringelbach, M.L. (2008) Affective neuroscience of pleasure: Reward in humans and other animals. Psychopharmacology 199, 457-80.)

At the very least that should make it something to be approached cautiously by would-be hedonists.
:PROPERTIES:
:Author: ArgentStonecutter
:Score: 3
:DateUnix: 1430167242.0
:DateShort: 2015-Apr-28
:END:

***** So it's really more like: wireheading creates a desire to wirehead that doesn't bring any /particular/ pleasure when you wirehead, just a relief from the constant desire to wirehead.

Or as the Buddhists would note: addiction is torture.
:PROPERTIES:
:Score: 3
:DateUnix: 1430256423.0
:DateShort: 2015-Apr-29
:END:


**** It seems to me that either you have some other implicit assumption or something is wrong with what you are describing..

#+begin_quote
  maximum physical pleasure possible for a human
#+end_quote

What other kind of pleasure is there? In the end any kind of positive feeling a creature can experience is physical, be it "simple" fun, such as eating something tasty, or "complex fun, such as the fulfillment of a person seeing their child succeeding and enjoying his life. That is unless one of your assumptions is the existence of "souls" and you decide that they do not fit the the definition of "physical

So why wouldn't such a theoretical machine supply the person with those kind of enjoyment as well?
:PROPERTIES:
:Author: IomKg
:Score: 2
:DateUnix: 1430122201.0
:DateShort: 2015-Apr-27
:END:

***** u/eaglejarl:
#+begin_quote
  What other kind of pleasure is there?
#+end_quote

There is physical pleasure (e.g orgasm) and mental pleasure (e.g. having a great time with your friends, or succeeding at a difficult task).

Wireheading, according to my definition, provides only physical pleasure. It's basically super-heroin.

#+begin_quote
  So why wouldn't such a theoretical machine supply the person with those kind of enjoyment as well?
#+end_quote

I'm discussing machines that could reasonably be created with existing or foreseeable technology. I'm not discussing theoretical machines with computational engines so powerful that they can completely simulate my brain state, determine what brain states correspond to pleasure-at-difficult-job-well-done, pleasure-at-seeing-my-loved-ones-succeed, schadenfreude, etc and then find some way to overlay all of those various brain states on me at the same time without them interfering with one another.
:PROPERTIES:
:Author: eaglejarl
:Score: 2
:DateUnix: 1430124486.0
:DateShort: 2015-Apr-27
:END:

****** I might not have been clear, to my understanding what you feel corresponds to the physical state of your brain. Thus these "complex" types of enjoyment are just the result of different hormones being released in different parts of the brain.

i.e. you don't really need a virtual reality or anything such as that to push the pleasure centers that these actions push.
:PROPERTIES:
:Author: IomKg
:Score: 1
:DateUnix: 1430128833.0
:DateShort: 2015-Apr-27
:END:

******* It looks like we're all agreed that all forms of pleasure are functions of the brain--I'm not making a spiritual argument, nor does anyone else seem to be.

Rather, I think [[/u/eaglejarl]] meant to say that as he understands it, wireheading can at present only effect certain kinds of pleasure, with others not yet being achievable though direct stimulation. Indeed, part of the question here seems to be what extent of the brain's functioning is replicatable via direct stimulation. Does that clear things up?
:PROPERTIES:
:Author: rthomas2
:Score: 2
:DateUnix: 1430146662.0
:DateShort: 2015-Apr-27
:END:

******** Thank you, that's exactly it.
:PROPERTIES:
:Author: eaglejarl
:Score: 3
:DateUnix: 1430166020.0
:DateShort: 2015-Apr-28
:END:


******** I thought we were talking about the theoretical possibility, if that is not the case i cannot really comment as i have no idea what is the state of such technology at the moment..
:PROPERTIES:
:Author: IomKg
:Score: 1
:DateUnix: 1430151612.0
:DateShort: 2015-Apr-27
:END:


***** An optimized reward system? Hopefully it won't be so crude as simply stimulating "pleasure" forever.

From Greg Egan's "Schild's Ladder":

#+begin_quote
  /Tchicaya is a posthuman with a quantum processor for a brain, Yann is a fully software entity currently occupying a similar posthuman body. They have been attempting to have sex, and it's not working out:/

  Yann lay on the floor, watching him. "I think I'm getting all the signals you talked about," he mused. "But they're so crude, even now. And before, it was just a single message, repeating itself endlessly: 'Be happy, be happy, be happy!' Do you think there's something wrong with this body?"

  "I doubt it." Tchicaya sat cross-legged on the floor beside him. "You expected more?"

  "I was already happy, so it was a bit redundant."

  "How happy?"

  "As happy as it's possible to be, for no particular reason."
#+end_quote

Wireheading is meaningless for Yann, because his reward system is already optimized. He's already as happy as it's possible to be for no particular reason. Why not?

#+begin_quote
  "But when you have a malleable mental structure, intensifying pleasure for its own sake is a very uninteresting cul-de-sac. We worked that out a long time ago."
#+end_quote
:PROPERTIES:
:Author: ArgentStonecutter
:Score: 2
:DateUnix: 1430149666.0
:DateShort: 2015-Apr-27
:END:

****** how could something be more "interesting" if interesting is just another form of pleasure, thus if the pleasure center were to be stimulated everything will be the most interesting thing in the universe.
:PROPERTIES:
:Author: IomKg
:Score: 1
:DateUnix: 1430152065.0
:DateShort: 2015-Apr-27
:END:

******* Because pleasure centers, dopaminergic circuits, and the rest are in different parts of the brain with different functions.
:PROPERTIES:
:Score: 1
:DateUnix: 1430154581.0
:DateShort: 2015-Apr-27
:END:

******** ? How is the location or specific ways they operate change anything? I mean unless wireheading is only talking about a specific region of the brain and I missed it there is no reason it will not be stimulating any and all systems and subsystems related to pleasure
:PROPERTIES:
:Author: IomKg
:Score: 1
:DateUnix: 1430165501.0
:DateShort: 2015-Apr-28
:END:

********* Well, for one pleasure and motivation are not directly coupled.
:PROPERTIES:
:Author: FeepingCreature
:Score: 1
:DateUnix: 1430204617.0
:DateShort: 2015-Apr-28
:END:

********** how would that change anything? if you care about how interesting something is then wireheading should be effecting it, and if not then you wont care..
:PROPERTIES:
:Author: IomKg
:Score: 1
:DateUnix: 1430216431.0
:DateShort: 2015-Apr-28
:END:

*********** I'm just saying, not every positive/motivational sensation of the human brain is mediated over pleasure.
:PROPERTIES:
:Author: FeepingCreature
:Score: 1
:DateUnix: 1430219699.0
:DateShort: 2015-Apr-28
:END:

************ that would mostly depend on your definition of pleasure
:PROPERTIES:
:Author: IomKg
:Score: 1
:DateUnix: 1430222969.0
:DateShort: 2015-Apr-28
:END:

************* Well, that would mostly depend on your definition of "definition". :)
:PROPERTIES:
:Author: FeepingCreature
:Score: 1
:DateUnix: 1430234558.0
:DateShort: 2015-Apr-28
:END:

************** 0.0 /throws StackOverflowException/
:PROPERTIES:
:Author: IomKg
:Score: 1
:DateUnix: 1430247531.0
:DateShort: 2015-Apr-28
:END:


************* No, neuroscientists are pretty clear about tracking down what people report as pleasurable and how their brain is functioning at that time.
:PROPERTIES:
:Score: 1
:DateUnix: 1430256467.0
:DateShort: 2015-Apr-29
:END:

************** Could you link to any kind of information regarding that? because i couldn't find anything regarding that separation..

Also i still don't see how that would change anything.. sure you might still have motivation to do this or that, but it wont effect your enjoyment(by definition) so your preference to do things in one way or another will have effectively no impact on your experience(i am assuming here that wireheading is disabling negative feelings and not just pushing the positive, because otherwise motivation could just be negative based, but these negative feelings would be counterproductive to the wireheading purpose so it stands to reason they will be inhibited just the same)..
:PROPERTIES:
:Author: IomKg
:Score: 1
:DateUnix: 1430257503.0
:DateShort: 2015-Apr-29
:END:


******* "Optimized" doesn't necessarily imply reaching the same local maximum as you get from stimulating the "pleasure center". If you want to create a long-term stable mental structure, in fact, you need to find a better one.
:PROPERTIES:
:Author: ArgentStonecutter
:Score: 1
:DateUnix: 1430154834.0
:DateShort: 2015-Apr-27
:END:

******** well that is an extra assumption, that the stimulation is not high enough to cause to make it impractical to continue and function..

which is not what we were talking about
:PROPERTIES:
:Author: IomKg
:Score: 1
:DateUnix: 1430165246.0
:DateShort: 2015-Apr-28
:END:

********* That was implied by the quotes from /Schild's Ladder/. The point is that if you're going to reach a stable mental structure that is also self-consistently hedonic, you need to optimize the reward structure in a different way than simply maximizing a primitive mammalian local maximum.
:PROPERTIES:
:Author: ArgentStonecutter
:Score: 1
:DateUnix: 1430166675.0
:DateShort: 2015-Apr-28
:END:

********** in that case how is that relevant to the discussion?

also, how is the mention of "As happy as it's possible to be, for no particular reason." consistent then? if the system was calibrated for as much default happiness that would still cause the subject to try and achieve more of it it means it would still have plenty more to go? if yann is not as happy as theoretically possible why would wireheading be meaningless for him any more then it is for us?
:PROPERTIES:
:Author: IomKg
:Score: 2
:DateUnix: 1430172964.0
:DateShort: 2015-Apr-28
:END:


** I like Tailsteak's work. His old webcomic 1/0 was also pretty philosophical.
:PROPERTIES:
:Author: The_Insane_Gamer
:Score: 4
:DateUnix: 1430181595.0
:DateShort: 2015-Apr-28
:END:
