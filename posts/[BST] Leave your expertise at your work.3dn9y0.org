#+TITLE: [BST] Leave your expertise at your work

* [BST] Leave your expertise at your work
:PROPERTIES:
:Score: 19
:DateUnix: 1437154382.0
:DateShort: 2015-Jul-17
:END:
[deleted]


** Dystopias are fucking boring and played out. Use this idea in a story with a functional, personal-freedom-filled /Utopia/ and you have the start of one *hell* of a story.

Hint: some scientific knowledge really shouldn't be /public/ knowledge.

--------------

What happens when everyday businesses require the use and knowledge of tech that could be as easily abused as weaponized NBC threats? For example, this off-hours mind wipe could be one way to defend against nanotech misuse. When not in a controlled and heavily monitored environment of an office or factory, you can't be allowed to know how to use and program nano assemblers. Not the pushing the buttons part, but the gritty scientific and engineering details.

Instead of merely having no user serviceable parts, unmonitored minds simply aren't allowed scientific knowledge of this technology. No one can be trusted with that knowledge, nor can any fancy and exploitable expert systems.

AIs working this tech are right out, as that level of freedom of action plus paranoid control systems to try to implement "friendliness" always leads to disasters. In fact, how to make human-level plus AIs is another controlled branch of science. Humans, with moral systems tied into complicated socialization pressures can /barely/ be trusted in secure and self-contained facilities.

Any neighborhood-class nanofab center could be tuned to make weapons of mass destruction by someone determined enough, and with the right knowledge. This is how they work. Safety systems can always be disabled. Physical access is required, and that means any nanofab could be "owned" and turned into a WMD factory. Thus, this technology firewall. And it works, managing to put the genie back in the bottle.

Until our protagonist finds out that someone at their office is cheating the system. The mentally unstable person has already written a manifesto explaining what they've done, and published it where it will be found after millions have died. That our protagonist even knows about this is a massive coincidence, and because they thought something was wrong with their coworker so they went snooping that day. Just barely in time to discover the plot. Turns out, they've been removing their obsessive and insane thoughts /before going to work/, then putting them back again when they get home. Where they currently are, with a brain full of WMD science.

This is going down /now/. Everyone trusts the system and it'll take way too long to make anyone in authority believe this threat exists. If they don't believe the protagonist, the authorities will be in position to slow them (and not the would-be mass murderer) down, so they can't even try warning anyone while not knowing if it will work. From outside, the manifesto looks like it could be a smoke screen, and they certainly won't allow our hero to try to fix this themselves. Only personal daily interactions with someone slowly sliding into insanity is proof that this is really happening. The automated monitoring systems didn't trigger, after all, and the mad-person passed their psych evals as well.

The only sure way to counter the insane actions of this lone maniac is for our protagonist to use the same exploit before it's too late. They reload all their dangerous scientific knowledge outside the office and set out to throw together their own nano-tech counter weapons to protect the innocent victims and take out the nascent gray goo engine. The advantage they have is, they're not crazy, and can think straight about how to go about being the hero of the hour. Shame no one will be able to recognize which of them is the insane terrorist until it's too late, so our hero might be stomped on with the same boot once the utility dust settles.

Of course...our hero is working on really thin data about this threat. And their significant other did just leave them. And their luddite-fundamentalist mom recently died after refusing advanced nano-therapy...which is something our hero is going to do without asking to protect people in the neighborhood, with the side-effect of removing that personal choice from hundreds of thousands of people. And...maybe this whole thing was a security test IT was running. The exploit didn't work /exactly/ the way the manifesto suggested, after all...

Part way through, illegal knowledge able to destroy cities filling their brain and a basement factory full of bushbots, our hero stops to consider that maybe they aren't all that well themselves.

--------------

The end could go a number of ways, few of them good for people within a few hundred miles. Yes, there would be a military/security system response. Yes, our hero thinks it will be too late by the time they show up. And yes, being late, the security force's response will kill tens of thousands of people to save millions.

That's my take on a rational story on the whys of removing knowledge from a brain after working hours, without the dystopia bullshit these sorts of stories always involve.

You could also do something with magic and demon summoning and blah blah blah, but I prefer this set up.
:PROPERTIES:
:Author: TimeLoopedPowerGamer
:Score: 20
:DateUnix: 1437200624.0
:DateShort: 2015-Jul-18
:END:


** Back in the '90s I started to write a story (before I realized that I wasn't actually good at writing stories) with this kind of theme. In this story, the skills belonged to a separate artificial "work persona" that was managed by an implant that basically took over the ego and tied new memories to that persona being present... there was no association chain for the original persona to access them. Lots of handwaving, and it's been 20 years so I forget the details now.

This persona started out being identical to you. It was technically an organically-assisted AI, and was legally part of the implant, and had access to resources in the implant... but it had no continuity of personality or consciousness apart from when it was activated in the brain it was implanted in. It was aware of your life outside, because your regular memories continued to lay down without whatever tags or whatever tied them to the implant.

With the implant off, you really didn't even think about your job, you went into work, you got switched off for 8 hours, and you went home. Theoretically, it's supposed to be like you turn on the implant, the new memories "come back", but you're still the same person. After all, the processing is going on in the same brain. You work for 8 hours, and then the extra memories and skills go away, but you're still you.

But eventually the implant stopped being able to find associations for memories laid down while offline, it's non-work life became dreamlike, and then lost. Now you have a version of you that sees losing the job as an existential crisis...
:PROPERTIES:
:Author: ArgentStonecutter
:Score: 3
:DateUnix: 1437156255.0
:DateShort: 2015-Jul-17
:END:

*** But, the version of yourself that sees losing the job as a self-imperiling proposition is only conscious while on the job; it would be potentially possible to quit while not running the implant. In that case, the job-persona would know, and work out ways to prevent its own destruction...\\
Hey this is neat. It would be fun to have a narrative from either perspective, or both.
:PROPERTIES:
:Author: amplitudeomega
:Score: 5
:DateUnix: 1437188343.0
:DateShort: 2015-Jul-18
:END:


** A somewhat similar idea occurs in the short story (and movie) "Paycheck". That's a more indiscriminate form of memory-wipe, but it's implied that this has taken the place of (or is a more extreme version of) an NDA.
:PROPERTIES:
:Author: alexanderwales
:Score: 2
:DateUnix: 1437156770.0
:DateShort: 2015-Jul-17
:END:


** A funny inversion of reality. A military blog I like follow sums the real state of affairs as: "You can't classify math."

<Semi topical old man kibitzing> It is absolutely disheartening how man science fictionish seeming military technologies copied by competitors can be summed up as; once they knew that we could do it they started doing the math, cribbing the papers our researchers wrote, and the like.

TLDR Oppenheimer knew what he was talking about
:PROPERTIES:
:Author: Empiricist_or_not
:Score: 2
:DateUnix: 1437253594.0
:DateShort: 2015-Jul-19
:END:


** This means human clouds should be a thing. Employees are a commodity, characterized only by processing power, short-term memory capacity, and ability to focus.

Companies store decades-long thought processes that were run on dozens of employees through the history of company. In fact, they run these thought processes 24 hours/day jumping between people in different timezones.
:PROPERTIES:
:Author: ajuc
:Score: 2
:DateUnix: 1437558065.0
:DateShort: 2015-Jul-22
:END:


** You could have a system where people work the time they would normally spend asleep, and have their brains jacked into an AI or have an AI module that feeds info, stimulants, and other hormones to the brain. In this future, we can offload and reload memories, but we cannot yet create a structure as capable of learning and as cheap as a human brain. Perhaps the AI personalities are all long-dead human "uploads" who only live when their hosts are at work, and generally ignore what their original host was like. They might even switch bodies constantly as necessary.
:PROPERTIES:
:Author: darkflagrance
:Score: 1
:DateUnix: 1437169824.0
:DateShort: 2015-Jul-18
:END:


** Well, if this is just a way that companies can be run, then because working at a company which adopts this technology massively stunts an employee's long-term earning potential, such companies have to pay substantially more than other similar companies.

I do not expect this would actually become a mainstream thing to do, given a society which starts out without any such companies; most companies produce a product which can easily be reverse-engineered or obtained through espionage, so the protection of IP wouldn't justify the employee cost.

If, however, this technology is standard:

The skill-data becomes something which is negotiated for in employment contracts. There's no reason to think that the only options are "work normally and keep all your skills" and "we keep everything and you never get it back".

People could steal their own skill-file and either use it at home (onloading it, working, then offloading it to avoid detection) or flee to a country which doesn't honor these laws.

Since a company could sell a skill-file, there's actually a reason for companies to hire complete noobs: after working with them for a couple years, they are now a valuable (and captive) product.

However, academia would have trouble paying for these skills, so I suspect that many of the best instructors and textbook authors don't exist. Industry complains even more than it already does that nobody learns anything from college.

Productivity of people working from home is massively reduced, so a much smaller open-source programming community.

Similarly, the engineers don't remember anything from their work, so there's fewer really awesome things on youtube.

Similarly, public policy debates are even worse than they are now.
:PROPERTIES:
:Author: BoilingLeadBath
:Score: 1
:DateUnix: 1437182252.0
:DateShort: 2015-Jul-18
:END:

*** u/noggin-scratcher:
#+begin_quote
  because working at a company which adopts this technology massively stunts an employee's long-term earning potential, such companies have to pay substantially more than other similar companies
#+end_quote

+I feel like there's another stable equilibrium where everyone does it, anyone that /didn't/ do it would be put at a disadvantage because all their employees would be poached away, and for the employee it means you /really/ don't want to change job, because it means starting to build your experience from scratch.+ You covered that... and I need to read more closely before commenting.

And now I'm picturing a story where someone gets hired at a basic entry-level position only to discover that they've actually been /re-hired/ (let's say they have an implant that stores memories that can only be unlocked with the right employer-provided crypto key, so they aren't deleted when you leave, just rendered inaccessible, and if you return they're re-enabled... and also the memory of having ever worked there is part of the protected set).

So maybe in a former phase of their life they were higher up in the company until they learned /inconvenient secrets/ or got ejected by cut-throat corporate politics, and now they're a janitor with those secrets, using them to take revenge.
:PROPERTIES:
:Author: noggin-scratcher
:Score: 2
:DateUnix: 1437186466.0
:DateShort: 2015-Jul-18
:END:

**** I dislike dystopias, but you should write this

Also I see a small non skill lock company quickly steamrolling competition in this world, because they hire motivated people who think about their work after work.
:PROPERTIES:
:Author: Empiricist_or_not
:Score: 1
:DateUnix: 1437253849.0
:DateShort: 2015-Jul-19
:END:


** This means that every time I'd hire someone, I'd be getting a completely fresh trainee. There'd be no way to staff a team with mid-career professionals.

I think I'd look for 2 things to happen:

1. I'd ask my company to sign a reciprocity agreement with some similar but non-competing companies. Stay in network? Keep your skills.
2. I'd put a lot more research into training to minimize ramp-up time.
:PROPERTIES:
:Author: FishNetwork
:Score: 1
:DateUnix: 1437331129.0
:DateShort: 2015-Jul-19
:END:
