#+TITLE: [D] On the rational use of Superpowers

* [D] On the rational use of Superpowers
:PROPERTIES:
:Author: thirtysevenFG
:Score: 0
:DateUnix: 1414784499.0
:DateShort: 2014-Oct-31
:END:
Hey first time poster, I didn't want to post in an old thread so I'm making a new one but this is related to the question posed in [[http://www.reddit.com/r/rational/comments/2jbfz5/d_q_whats_up_with_superman/][this thread]]. Hope this is on topic for this sub I know mostly this is for fictional stories but I think it might be interesting to discuss this here. I have a detailed explanation below but I'm essentially saying the way people like Superman act in comics IS probably the most rational way to use superpowers.

Essentially if you woke up tomorrow and everything was the exact same, except you suddenly had "god-like" powers, essentially omnipotent for all intents and purposes. What would you do with that power? When I first started thinking on this topic I always figured I would help humanity one way or the other. Build roads, cure diseases, stop war, end world hunger etc. but as I thought more about those things I realized that doing some of those could cause more harm than good.

Curing diseases would probably cripple modern health care systems by making it essentially obsolete, even if you just cured a few of the big ones you would have developed the expectation in the general populace that you CAN magically cure diseases. Long term I'm imagining less money going into healthcare research, less doctors and less patients since people would start looking to you instead of previously established services. I think the world hunger thing is obvious with the majority of the world involved in farming you would cripple countless peoples livelihood. Even if you just redistributed the food you are talking about taking huge chunks of the shipping industry out of action at the very least, again having huge negative impacts in the long term despite the short term benefit of people not dying of hunger temporarily.

I guess to sum it up I would use the fish quote "give a man a fish and you feed him for a day; teach a man to fish and you feed him for a lifetime". Any action you could take as an individual would never be as helpful as actually developing the systematic methods that regular people could use to sustain those actions over the long term. It's way better to have an inefficient but sustainable system then it is to do good things outside the system thus harming the development of that system. Essentially I feel like people don't really think deeply enough about how complicated our world is and how even something simple like building some bridges or the like could have huge unforeseen consequences, like putting bridge builders out of work, or even thinking about who would end up paying to maintain that bridge.

But even further than that how about just teaching people how to do things like cure cancer or build better bridges? Now you are altering the course of human society in a fundamental way. Are we ready for a society like Star Trek or the Culture or would humanity reject that sort of rapid development in its current state? Personally my only conclusion here is that if someone really did gain those powers there is really only one good option... which is to do nothing with that power except in exceptional circumstances like an asteroid or all out nuclear war. In order to really help people you have to let them figure shit out on their own, you can't be holding their hand all the time or as Futurama put it "...You have to use a light touch". Which is essentially how Superman is usually written oddly enough, he saves us from the big external threats but almost never from our internal ones.

That's my take on how to rationally use superpowers, I'm very interested in how people respond to this I would love if someone could think of counter-examples. I've been pondering this for a few years now but I can't seem to figure out a good way to help humanity in any significant way without completely changing what humanity means on a fundamental level essentially destroying it in one way or the other.

TL;DR: Helping humanity only makes us reliant on that help, we have to stand alone or not at all if we want to truly succeed in the long term. Only the impending doom of all of humanity would be a good reason to act decisively in our interests, anything else would just hurt us in the long term.


** Ehh...

It depends on how much power is meant by 'essentially omnipotent'. In any case, thinking about what to do would be the first point on my list, but I strongly doubt my end conclusion would be 'do essentially nothing'. The world we have now is not perfect.

One of the first things to do if the powers allow it to be done safely is to increase my own intelligence, in order to be better able to gauge what else needs doing. But maybe that's not possible safely, that is, without risking accidentally making myself insane or dead.

But, to take a low-end example from you, 'curing diseases' would seem like a good thing to do. Sure, it has some negative consequences. Health care systems are needed less, people lose jobs and so on. But that's nowhere near the magnitude of millions of people dying to diseases. Or you could just cure all diseases that current medicine cannot cure. I hardly expect the losses to medical research funding are worth all the suffering caused by the status quo. Of course, it's better if 'cure diseases' means 'create a formula for a cure that people can easily manufacture and administer' rather than 'touch sick people and they're suddenly healthy', because the latter is much more reliant on me personally and more difficult to study and replicate.

Then there's 'end world hunger'. How do you achieve this? Invent and implement massively more efficient system for producing and transporting food? Seems like a good thing to me overall.

It is difficult to think of things to do that are unquestionably good and have no negative consequences whatsoever, but it seems to me to be much easier to think of things to do that have positive consequences that outweigh the negative ones.
:PROPERTIES:
:Author: Murska1FIN
:Score: 7
:DateUnix: 1414785242.0
:DateShort: 2014-Oct-31
:END:

*** I don't want to put any limits on what I mean by "essentially omnipotent", so if you want to alter reality to make it so hunger doesn't even exist feel free, but know that by doing so you've essentially genocided(apparently not a word?) the current human race by doing so, that sort of thing.

As far as the 'create a formula for a cure that people can easily manufacture and administer' that's the sort of short term stuff that I feel people don't think through. Sure now they can reproduce it, and probably even understand why it works. But say that you keep providing these cures for every new disease that pops up. Pretty soon people will stop bothering to do research and they will rely on you to prevent them from all dying from the next super plague that pops up.

I don't think this would happen immediately or anything, I'm talking on the scale of thousands/millions/billions of years here. I mean eventually even a god would get bored of looking over one planet and suddenly humanity is left completely vulnerable to the next diseases that rolls along.

I guess my problem is exactly why you don't have one... I'm thinking any negative impacts would just snowball as time progressed and eventually without your influence we would fall apart. And at the point that we rely so much on a single person are we really able to call ourselves humanity or are we just a single persons vision of humanity that he has shaped? And what have we lost in that process, I feel like doing things like stopping world hunger are far less valuable than allowing humanity to naturally develop and mitigate those problems on their own... I think I'm just arguing for the Prime Directive at this point only for a superhuman instead of a Star Fleet.
:PROPERTIES:
:Author: thirtysevenFG
:Score: 1
:DateUnix: 1414786205.0
:DateShort: 2014-Oct-31
:END:

**** Well, then I'll simply grant my powers to everyone. /shrug/

I probably wouldn't actually do that without a whole lot of thought first. But it's an option. I can avoid boredom by creating something that doesn't feel boredom that can do my job for me, at least.
:PROPERTIES:
:Author: Murska1FIN
:Score: 1
:DateUnix: 1415154708.0
:DateShort: 2014-Nov-05
:END:


** I don't think the mere fact that something is disruptive to the current order is a reason not to do it. Power looms put hundreds of textile artisans out of business, but I don't think you're too likely to find anyone that says that the invention and production of the power loom was a bad thing.

So yes, the existence of a godlike entity would fundamentally alter human society - I agree with that - but I don't think that the negatives of this would outweigh the positives if done correctly. And in fact, I feel that humanity is fundamentally altering itself with every passing year, and in most ways is becoming fundamentally better (lower crime rates, less war, happier people). Humanity has been radically changed in the last two or three hundred years, and on the whole these changes have not convinced me to be wary of change for the sake of being wary of change.

(I also don't think that you'll get much sympathy in what is largely a community of transhumanists clamoring for brain uploading, artificial intelligence, and eternal life.)
:PROPERTIES:
:Author: alexanderwales
:Score: 7
:DateUnix: 1414787198.0
:DateShort: 2014-Oct-31
:END:

*** I guess this is probably the big point, and I see now that it might be hard to reconcile when it seems to be a point of view problem. I feel like things such as textiles or cars, the internet are all things that have been a paradigm shift in how humans operate day to day. But all these things are still under our control... supposedly. We all collectively decide to adopt or not adopt new technology. But a godlike entity removes that control and now we are essentially puppets dancing to one persons tune, which doesn't sit right with me.

As to the last thing I'm not looking for sympathy here I really would like for someone to come up with an argument I can accept and I hope I can be open minded enough to do so. I've been thinking on and off about what I would do with powers for a long time and I've never been able to come to any conclusion but the one of inaction to preserve humanity. I guess in some ways maybe I'm just afraid of change? But at the same time I feel like I do have a legitimate point here about a single person having that much say over human development.
:PROPERTIES:
:Author: thirtysevenFG
:Score: 1
:DateUnix: 1414787612.0
:DateShort: 2014-Nov-01
:END:

**** When you put it like that, maybe you should make a post in [[/r/changemyview]] instead.
:PROPERTIES:
:Author: AmeteurOpinions
:Score: 2
:DateUnix: 1414788341.0
:DateShort: 2014-Nov-01
:END:

***** I figure posting something like this in CMV wouldn't get as much attention as a smaller sub like this, plus even though my question boils down to natural vs artificial development of human society, I'm really interested in this specific instance of that broader question, namely how would one use great supernatural power in our world in a "rational" way.
:PROPERTIES:
:Author: thirtysevenFG
:Score: 1
:DateUnix: 1414788868.0
:DateShort: 2014-Nov-01
:END:


**** I do think that there are some valid arguments for Superman only using his powers in ways that are very limited - I just think that the arguments on the other side are much, much stronger. It's obviously not ideal for a single man to have the power to utterly destroy humanity, or to otherwise determine its course, but the benefits outweigh the drawbacks. And it's not like Superman would have to make all of his decisions completely alone - he could have a council of advisors and scientists to both help him make use of his powers and ensure that humanity has a say.

(I have, in fact, [[https://www.fanfiction.net/s/10360716/1/The-Metropolitan-Man][written a novel-length fanfic]] about this very subject.)

#+begin_quote
  We all collectively decide to adopt or not adopt new technology.
#+end_quote

I think this is what I most disagree with, because I don't believe that this is the general pattern of change as it happens. To take the ur-example of the power loom, the decision was made by factory owners, had its most major impact on the textile artisans, and the purchasers of those textiles continued to buy what was cheapest. I wouldn't say that anyone really made the decision to use power looms - they were just cheaper at what they did, and consequently killed an industry, without any one person really having that much say in the matter. And if there were people who said "No, the old ways are best, I'm going to keep my artisans" they were pushed aside by the fact that no one really cared about the artisans - they only cared about costs. The same thing gets repeated over and over, especially in the realm of industry where these decisions are made by relatively few people and affect a relatively large number of workers. If tomorrow McDonalds replaces all of its fast food workers with automated systems, it won't be because of a conscious desire to adopt new technology, it will merely be a result of market forces - something that no one really decided on but ended up happening anyway. People lose their jobs, they rally against the change, but efficiency wins out.
:PROPERTIES:
:Author: alexanderwales
:Score: 2
:DateUnix: 1414789402.0
:DateShort: 2014-Nov-01
:END:

***** I'm glad you brought up the advisor thing because that's probably the best/only solution to this problem. I feel like you still run into the problem of which collective subset of people could be trusted to make decisions like that... but that's the case in modern day anyway so probably not much can be done to mitigate that.

Also when I saw "we all collectively..." I was actually trying to say exactly what you just did. That "we" decide to adopt things based on their perceived value, and what "we" as humanity value, instead of basing decisions on one person's values. Having a single person make those decisions is bad even if the effects are "good"... I guess I value the sort of unconscious collective direction we have as a whole rather than a guided plan, since once you've planned something you remove the possibilities to grow beyond that plan in a way. The last thing I want is for humanity to seal off potential futures just because someone came from on high and decided we all needed to be space faring robots or what not. Not that I have a problem with it if humanity naturally takes that path, just like I don't have a problem with McDonalds replacing all their workers with robots, because thats a consequence of human development as a whole even if it is kind of shitty for some people.
:PROPERTIES:
:Author: thirtysevenFG
:Score: 1
:DateUnix: 1414790544.0
:DateShort: 2014-Nov-01
:END:


**** u/deleted:
#+begin_quote
  But a godlike entity removes that control
#+end_quote

You could, I dunno, /ask/ people if you should feed them or let them starve to death. Same for curing malaria and cancer and ebola and sleeping sickness, and getting rid of debilitating prenatal conditions, and so forth.

There are some problems where it's so important to solve them, we don't care who solves them. When people are dying, I want the problem solved. I don't care whether anyone gets the pleasure of coming up with the answer themselves. I don't care if space aliens or the left ventricle of God provides the fix.

For everything else, I rather agree -- keep powerful non-human beings out of our lives.
:PROPERTIES:
:Score: 2
:DateUnix: 1414797782.0
:DateShort: 2014-Nov-01
:END:


** u/deleted:
#+begin_quote
  Curing diseases would probably cripple modern health care systems by making it essentially obsolete
#+end_quote

How is this a problem? Use your godlike powers to become immortal and just keep on curing diseases. Or if you worry that you'd get bored, create a race of ethereal, non-sentient (to avoid moral complications) guardian angels that will attach to each human and protect them from disease and trauma.

#+begin_quote
  I think the world hunger thing is obvious with the majority of the world involved in farming you would cripple countless peoples livelihood.
#+end_quote

If I solve hunger, farmers won't be able to get jobs. They won't starve, either. They might have to sell their farms and find new jobs in order to stay clothed and so forth. I'm sobbing indeed.

Or here's a thought: take over /all/ production. Give everyone a desktop nano-assembler, restricted (with your godlike powers) from creating anything terribly dangerous. Now tons of people are out of jobs. You replace all governments with your godlike powers and restrict capitalism to a safe sandbox. People earn money for living, and they can earn more for serving others and for creative output. Personally, I'd adjust it so that a typical person has to work no more than ten years of 30-hour weeks to retire at a normal standard of living.

If you want a more moderate solution, everyone has access to piles of soylent or some other not-very-flavorful nutrient source. (Again, you create a race of soylent angels to create and distribute it.) Farmed food is a luxury good, as are spices.

#+begin_quote
  Any action you could take as an individual would never be as helpful as actually developing the systematic methods that regular people could use to sustain those actions over the long term.
#+end_quote

Because you're focused on keeping all the power in yourself rather than spreading it out into self-sustaining systems that will go on independent of your existence.

#+begin_quote
  Only the impending doom of all of humanity would be a good reason to act decisively in our interests, anything else would just hurt us in the long term.
#+end_quote

Scale that down to an individual level. How well does that work? Terribly. I refuse to engage in any charity unless it saves people's lives from their deathbeds. Preventative measures? Pah. Improving standards of living from kill-me-now to I-can-actually-tolerate-this? Weak-minded liberal nonsense. There's a disease going around that makes people's limbs drop off? Not worth bothering me about. A cure for HIV if I just donate my pocket change? Forget about it; HIV doesn't kill you, it just weakens you so much that the sniffles would kill you. Lead paint in the milk? Sure, feed it to the children.

Yeah, no.
:PROPERTIES:
:Score: 4
:DateUnix: 1414786220.0
:DateShort: 2014-Oct-31
:END:

*** I guess I'm viewing this superpowered person as an external influence, separate from humanity, even if they are technically human. So instead of humanity growing based on the collective everyone, you've suddenly put all of humanity in the hands of one person, even with "robots", and by doing so completely changed how we would develop.

I actually like your idea about tasteless food I never thought about something like that and I could see that working, although I still think you run into some issues with that line of thinking as I talk about below.

The problem I see with the "guardian" solution, I always imagined AI's or something but same idea I think, is that now instead of having the negative consequences be physically based, you are now fundamentally changing human culture/nature, or what it means to be human. Is it worth it to save something if by saving it you've essentially destroyed what defines that thing? Again I feel like I'm pretty much just arguing for the Prime Directive here. If you had all that power you would have a heavy responsibility to use it in a way that wouldn't have disastrous consequences, whatever form they might take. Essentially if the action you take is so small as to not really affect human development then it probably is going to have such a small effect that you would be better off leaving us to figure it out. And if the effect is big then suddenly you've forced humanity to change course and now you are back to Prime Directive territory.
:PROPERTIES:
:Author: thirtysevenFG
:Score: 1
:DateUnix: 1414787193.0
:DateShort: 2014-Oct-31
:END:

**** The Prime Directive is a conclusion. What's the reasoning behind it?

In Star Trek, it seems to have been a response to colonialism. Better to let planetfuls of people die than to force them into our mold, erase their cultural identity, et cetera. And better not to give them the option of taking some of our technological artifacts to improve their lives on their own terms, rather than treating them like adults.

Your reasoning seems to be that some amount of egregious death and suffering is required for human existence to be worthwhile, and you don't want to cross that line. Instead of trying to narrow down where that line might be, carefully trimming away at the worst parts of our lives, you'd rather let everyone suffer and die.

It's better to do nothing than to do something if you have no confidence that that something is a good idea. However, that's the worst non-terrible thing you can do. In this case, it seems like you're doing nothing so you can avoid thinking about the problem, gathering some information, and considering the effects of possible actions.
:PROPERTIES:
:Score: 6
:DateUnix: 1414796477.0
:DateShort: 2014-Nov-01
:END:


**** u/Detsuahxe:
#+begin_quote
  you are now fundamentally changing human culture/nature, or what it means to be human. Is it worth it to save something if by saving it you've essentially destroyed what defines that thing?
#+end_quote

My feeble human body does not define me. The fact that scarcity forces me to work for a living does not define me. Improving these things will not "destroy me."

In fact, why are you equating change with destruction? Curing someone of cancer CHANGES THEM IRREVERSIBLY but it doesn't DESTROY THEIR FUNDAMENTAL NATURE. Changes are just that- changes. Which is a different thing from destruction.

As others have already pointed out, 'human nature' is ALREADY a constantly changing thing. The status quo of human society is the same way. Except right now, they're being changed by arbitrary market forces and sociological pressures. I find it very difficult to see an active hand of a sympathetic god to be a step down from that.

So my answer goes more like this: Give all humans complete immunity to injury and illness, deactivate aging past physical prime unless they want to keep aging. Make all sleep and eating completely optional, recreational activities. Create a simple way of signaling for my attention to wish for things- a universal prayer- and a list of prayers I will and won't grant. Automate this process by creating AIs based around my own mind that are built to enjoy the task of granting prayers without ever getting bored or discontented and granting those AIs sufficient shards of my own power.

Then terraform Mars, tell humanity to "fetch the garden world" and go traveling through the galaxy for fun.
:PROPERTIES:
:Author: Detsuahxe
:Score: 1
:DateUnix: 1415264966.0
:DateShort: 2014-Nov-06
:END:


** First, as other already said, improve intelligence. Since I can't predict what I'll think one that's done (which is the whole point of doing it), I can't really predict what I'd do afterward. My current 'plan' is something along the lines of:

- Figure out how to make a post-scarcity society of immortals work
- End scarcity
- End death
- ???
:PROPERTIES:
:Author: Solonarv
:Score: 2
:DateUnix: 1414853902.0
:DateShort: 2014-Nov-01
:END:


** u/deleted:
#+begin_quote
  Essentially if you woke up tomorrow and everything was the exact same, except you suddenly had "god-like" powers, essentially omnipotent for all intents and purposes. What would you do with that power?
#+end_quote

The instant I realize I have such a power, I stop time.

I'll get back to you in an objective instant several million subjective years later when I finish thinking this through.
:PROPERTIES:
:Score: 2
:DateUnix: 1415132992.0
:DateShort: 2014-Nov-04
:END:


** Take a look at How to succeed in evil. It has a few points on what a rational agents would do with and finally to superpowers.
:PROPERTIES:
:Author: Empiricist_or_not
:Score: 1
:DateUnix: 1414850256.0
:DateShort: 2014-Nov-01
:END:


** In no particular order: Clean the earth, make everything abundant, fix humanity.

Examples:

Farm soil is a valuable resource. I would turn deserts into lush plains, I would deepen the humus layers, I would put mechanisms in place to make such a change sustain itself.

Now modern farming can comfortably feed the entire human race.

Then, I could make every useful metal and mineral available in huge quantities in the upper layers of earth's crust. No more difficult prospecting, no more "rare" earths. Even hydrocarbon fuels and helium could be made abundant.

We could clean the entire ecosphere of every ecologically propagating toxin ever. And the athmosphere of green house emissions, smog, etc.

Every human could be made biologically immortal, disease free, able bodied, and with voluntary control of reproductive functions.

I would clear terrestrial space of kessler debris, and maybe erect a space elevator.

I would terraform the moon, mars, venus, the moons of jupiter, congeal the asteroid belt into a planet and terraform that too.

Now we have functionally infinite
:PROPERTIES:
:Author: mhd-hbd
:Score: 1
:DateUnix: 1415056238.0
:DateShort: 2014-Nov-04
:END:


** u/Roxolan:
#+begin_quote
  even something simple like building some bridges or the like could have huge unforeseen consequences, like putting bridge builders out of work
#+end_quote

Following that line of thought, Superman should go [[http://en.wikipedia.org/wiki/Parable_of_the_broken_window#The_parable][break windows]] all over the world. That way, many people will find employment as glaziers and the economy will surely prosper.

In fact, wipe out enough of civilization that everyone has to resort to subsistence farming, and you will see unemployment drop all the way down to zero. You'll also kill quite a lot of people, but who cares about /people/?
:PROPERTIES:
:Author: Roxolan
:Score: 1
:DateUnix: 1415060154.0
:DateShort: 2014-Nov-04
:END:


** Yes, it's true that our actions have long-term consequences that we can't foresee. We're living in a time of extremely rapid change, world-changing inventions are appearing literally every year. It is already impossible for me to say what the world will be like in fifty years. I cannot attempt to make decisions based only on the long-term consequences, because things will have changed so much by the time the long-term arrives that my motivations will be obsolete.

You wish to keep the world as it is, to avoid decisions that will have unplanned long-term consequences. Now, maintaining the status quo is a valid philosophy. The way we're doing things at the moment has its problems, but we haven't actually destroyed the world yet. Any other way of doing things does not have this guarantee, its consequences have not been seen in the real world. Resist all change, avoid all conflict, because that change might eventually result in the extinction of humanity? I have my objections to that, but it would work.

The problem is that "don't change the world" and "don't let the world change" aren't the same. As I said, the world is already changing. In order to keep the world as it is, you need to halt that change. Suppress new technologies and new ideologies, that sort of thing. Because if you did do essentially nothing, if you let human history take its course... how do you know that "history's course" doesn't end in 2017 with a nuclear war?

Everything we do has long-term consequences. Everything everyone else does also has long-term consequences. It's all too much to keep track of, too much to predict. All we can do is do what we think is best right now, and deal with the crises if and when they come.

(... then again, you might not be getting an unbiased view, coming to a subreddit full of transhumanists and singularity-lovers and arguing that humanity is fine as it is.)

Edit: In response to your question, I'd like to terraform a few planets and spread humanity out a bit. More natural resources to go around, and nations that hate their neighbours can just move out.
:PROPERTIES:
:Author: Chronophilia
:Score: 1
:DateUnix: 1415075276.0
:DateShort: 2014-Nov-04
:END:
