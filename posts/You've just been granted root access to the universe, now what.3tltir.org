#+TITLE: You've just been granted root access to the universe, now what?

* You've just been granted root access to the universe, now what?
:PROPERTIES:
:Author: Rationalfideism
:Score: 13
:DateUnix: 1448049311.0
:DateShort: 2015-Nov-20
:END:
Taking this seriously, as in it happens tomorrow to you. No limitations. What changes do you actually make and what values are you basing your decisions off of? Do you tell people? To what extent do you share your power with others or involve them in decisions regarding it's use?

Edit/ To everyone suggesting setting up a system of backups, resets or simulations to test out ideas, aren't you effectively creating, causing suffering for and killing people each time you do it?

Edit2/ Really everyone? The minute you're handed near definitive proof that our reality is a simulation you want to create alternate throw away realities to experiment on without consideration for the people you're creating?


** I accidentally destroy everything. Fast. Probably immediately. What sort of half-assed omnipotence put /me/ in charge of physics?
:PROPERTIES:
:Author: Sparkwitch
:Score: 37
:DateUnix: 1448055350.0
:DateShort: 2015-Nov-21
:END:

*** u/Chronophilia:
#+begin_quote
  /"Hold my beer and watch this!"/\\
  -Omega
#+end_quote
:PROPERTIES:
:Author: Chronophilia
:Score: 27
:DateUnix: 1448063309.0
:DateShort: 2015-Nov-21
:END:

**** This may be the best comment I've seen on reddit.
:PROPERTIES:
:Score: 2
:DateUnix: 1448144720.0
:DateShort: 2015-Nov-22
:END:


*** Honestly, this is the most likely for me.

I would probably attempt to reverse entropy, and end up wrecking physics irreparably, like a caveman trying to rewire a laptop.
:PROPERTIES:
:Author: High_king_of_Numenor
:Score: 1
:DateUnix: 1448431358.0
:DateShort: 2015-Nov-25
:END:


** Save current state to nonvolitile storage and set up a cron job to restore that state. If I make changes later, and like them, i can kill the cron job, and update saved state.
:PROPERTIES:
:Author: clawclawbite
:Score: 26
:DateUnix: 1448054320.0
:DateShort: 2015-Nov-21
:END:

*** If something goes Horribly Wrong™ and you're incapacitated beyond being able to reverse your changes, and then the cron job restores the universe to exactly the state recorded, what prevents the fresh instance of you from proceeding with exactly the same plan and making exactly the same mistake again?

You need some kind of persistent information; an ability to signal to yourself that the emergency backup plan has been activated (ideally with an accompanying description of what you were planning so you know what not to do again). Otherwise you're headed for an eternal universe-wide loop... and not even a "Groundhog Day" loop if you're restored identically from backup; just an exactly repeating loop.

In fact there's a sense where "restoring from backup" then having the universe go through the same steps "again" isn't actually a separate thing from the first time through; it's exactly the same set of states with no distinguishing variable out of place, calling them /different/ is aphysical nonsense. So, arguably, that cron job ends the universe instead of saving it.
:PROPERTIES:
:Author: noggin-scratcher
:Score: 21
:DateUnix: 1448054855.0
:DateShort: 2015-Nov-21
:END:

**** Journal perhaps? Or a changelog; record what you're doing and have it sync up periodically with the copy. It itself would only be low capcity binary, so contaminants being released would be low. You could reasonably figure out what went wrong, or atleast what not to do reading it. Eventually, you'll hit an optimal path.
:PROPERTIES:
:Author: eshade94
:Score: 9
:DateUnix: 1448064018.0
:DateShort: 2015-Nov-21
:END:

***** Seems like a vulnerability vector for potentially dangerous things to escape via.
:PROPERTIES:
:Author: nicholaslaux
:Score: 2
:DateUnix: 1448111882.0
:DateShort: 2015-Nov-21
:END:

****** If the bandwidth is low enough?
:PROPERTIES:
:Author: ArgentStonecutter
:Score: 2
:DateUnix: 1448274150.0
:DateShort: 2015-Nov-23
:END:


**** Indeed. Though if you see there is already a backup waiting, be suspicious.
:PROPERTIES:
:Author: clawclawbite
:Score: 3
:DateUnix: 1448056048.0
:DateShort: 2015-Nov-21
:END:

***** Probably the simplest, safest, and most foolproof way of preventing an endless reload loop would be to have the persistent data be just a plain counter for the number of load cycles that have been done. That way the restored version of you will have at least /some/ slightly different inputs for each cycle and be able to make some different decisions on that basis without worrying about those decisions being prejudiced by whatever might have killed the universe last time around.

If I wake up and see the counter registering "2" I'm going to respond very differently than if I wake up and see the counter registering "1,002,592".
:PROPERTIES:
:Author: FaceDeer
:Score: 12
:DateUnix: 1448065347.0
:DateShort: 2015-Nov-21
:END:

****** I would write down a list of everything I wanted to try, in order. 1, 2, 3, etc.---/before/ looking at the counter for cycles.

Because what happens if my instinct for 2 is virtually the same as 10? Or 60 and 90? I could get stuck in a loop while trying to avoid a loop.

At least this way, I'd have some hope of seeing, oh, it's already on loop four. 1-3 must have some problems there.
:PROPERTIES:
:Author: HeirToGallifrey
:Score: 14
:DateUnix: 1448067886.0
:DateShort: 2015-Nov-21
:END:

******* I think it's an unlikely risk, since the checklist will effectively already be present in your mind anyway. It's not a problem if your instincts for responding to loops 60 and 90 are basically the same as long as by the time you hit loop 1000 that causes you to try something a little different. Loops are "free", after all. There's absolutely no cost to repeating the same loop a million times as long as you break out of it on loop 1000001.
:PROPERTIES:
:Author: FaceDeer
:Score: 6
:DateUnix: 1448068624.0
:DateShort: 2015-Nov-21
:END:

******** There are finite amount of plans finite mind can come up with. So, starting from some very huge number, response always will be the same and you go into infinite loop. HeirToGallifrey's idea is useful, and some kind of additional comments in backup is even more useful.
:PROPERTIES:
:Author: Dead_Atheist
:Score: 3
:DateUnix: 1448113032.0
:DateShort: 2015-Nov-21
:END:

********* That doesn't make the mind any less finite, though. Unless your first act after backing up is to somehow make your mind "infinite" no amount of additional comments are going to change that.

Some things just can't be planned around. If you have tried /literally every possible outcome/, there's no way to magic up additional possibilities. If you're not satisfied with the universe after trying every possible thing that can be done with it then you're just not satisfiable.

Heck, given an infinite amount of loops, that "integer" will eventually grow to become a representation of every possible blob of unicode text anyway. Also images, movies, 3D models, and every possible video game. It will become every possible integer at some point and any binary data file can be represented as an integer.
:PROPERTIES:
:Author: FaceDeer
:Score: 1
:DateUnix: 1448125170.0
:DateShort: 2015-Nov-21
:END:

********** I was thinking about this situation:

You have ideas number 1,2,3,4... 2 and 3 look very similar.

First one didn't work, backup loaded. You see [1 reload], decide not to try that obvious idea and do №2, but since you have no actual list, you accidentally do №3. It also failed. Then you do №3 again. Then 4,5... and they all failed. Infinite loop. And №2 was the correct one.

If you decide to go with instincts, there are a lot of space for mistakes. Cost for responding to loops from 60 to 90 the same way is that you lost 30 strategies. After 1000 you will not think that solution can be simple. Every number after billion is just "very big number" for your instincts, you will not generate single new strategy after that. So, if you are not at least 10 times smarter than me, you will have less than 50 tries before infinite loop.
:PROPERTIES:
:Author: Dead_Atheist
:Score: 1
:DateUnix: 1448155964.0
:DateShort: 2015-Nov-22
:END:

*********** Not so, IMO, for a number of reasons.

Firstly, you're assuming that #2 is the /only/ possible solution. I don't even know what it's a solution to, really, this "savegame" is meant to be some kind of ultimate failsafe in case something goes /really really/ wrong, so it's likely that whatever happens is something very unusual in its own right. I think it's more likely that doing almost /anything/ differently is likely to butterfly away whatever it is that eventually went so disastrously wrong. Maybe solutions #7-#108 will all work just fine too.

Secondly, once you get past the first couple of entries on the idea list you're going to start getting them jumbled anyway, so this is still something that could happen even if you wrote the ideas out. The first time you write them out you might write them in order 1, 2, 3, 4, and then the second time you write them you write them in order 1, 3, 2, 4, and thus #3 gets skipped anyway.

Thirdly, once I start seeing the counter getting up into the millions I'll have run out of concrete ideas anyway. At that point I'll just start randomly screwing around, which means old ideas that I may have inadvertantly skipped and assumed that I'd already tried will get tried again (along with all kinds of other dumb things that I haven't tried before because they're dumb).

And fourthly, what if sitting down and writing that list /is/ what's going wrong? Like, there's something you think of while wracking your brains for ideas that causes you to do something with terrible unforseen consequences. If you're absolutely committed to writing down that list first thing then that's a good way to actually get one of those loops (at least, until the size of the number startles you so badly that you finally decide not to do it this time around).

I think you're just not accounting for the fact that I've got /infinite tries/ at this. So eventually I'm going to try everything that it's possible to try, whether I've got a rigorous system for it or not. The fact that there's a different integer sitting in front of me on every try ensures that there will be /some/ difference between each run, which is all that's needed where infinity is concerned.
:PROPERTIES:
:Author: FaceDeer
:Score: 1
:DateUnix: 1448159691.0
:DateShort: 2015-Nov-22
:END:

************ 1)It looks like you think that we write list after we see counter. So probably you missed what the point of list is.

#+begin_quote
  (at least, until the size of the number startles you so badly that you finally decide not to do it this time around)

  I would write down a list of everything I wanted to try, in order. 1, 2, 3, etc.---/before/ looking at the counter for cycles
#+end_quote

2) I wrote about №2 as the only correct solution just for example. Without list you can miss a lot of solutions, not only №2.

3) I assumed that we live in the deterministic universe, at least on macro level. Are you sure some non-deterministic quantum effects I don't know of can get us out of the loop?

4) If our universe is deterministic, then you can't write the list differently before you see the counter - the only different piece of information.

5) If our universe is deterministic, then you can't "just start randomly screwing around" - you will generate the same "random" solution over and over and over.

6) If writing that list is what's going wrong and we don't have additional failsafes, we are doomed. But you can tell this about any plan. Obviously, we must make additional failsafes.

7)I am accounting for infinite tries. Again, our brains are finite, so after some huge number all numbers will be the same for your instincts. If you see number 1087520371, you will go with That One Desperate Strategy Of Last Resort, and if you see Graham's number, you will do the same.

If you have same good idea pseudo-randomizer(not intuition), that use counter as seed, that would work.
:PROPERTIES:
:Author: Dead_Atheist
:Score: 1
:DateUnix: 1448192957.0
:DateShort: 2015-Nov-22
:END:

************* I was assuming that the save point is the very first thing you do once you've got this power. That maximizes the range of options for what you can do afterward. I'm not sure what the point of not looking at the counter after loading the save is - if you're trying to be deterministic you should have done that stuff before making the save point, that's the only way to be sure.

The universe most likely /isn't/ deterministic. There are plenty of quantum events that "just happen", with no specific prior cause, and they can be trivially magnified to macroscopic scale. A Geiger counter is the classic example, each of the ticks it makes is the result of a single atom undergoing radioactive decay and those decays are uncaused quantum events. You can use the time delay between ticks as a source of true randomness. Frankly, the integer counter is just a suspenders-and-belt safety precaution to account for the possibility that everything we know is wrong (which it might be given that there's such a thing as "root access" to begin with, that's certainly not something current science predicts). It's a guaranteed source of non-determinism as far as any particular run-through of the universe is concerned.

I won't do the same thing for 1087520371 as I will for Graham's number because I can grasp the first number at a glance whereas the second one would take me some time to figure out the magnitude of. That alone introduces a difference that will butterfly bigger over time. Especially considering that the counter would need some sort of unusual interface to represent numbers that large, as it's larger than can be displayed with all the atoms in the universe. Frankly, once I got to that point I'd probably just say "screw it, I'm using this integer to determine the state of each planck volume in the universe directly" and just turn the whole universe into a random fuzz. Which probably triggers an immediate reset due to it being a total mess, but every once in a while a viable universe will result and we'll see something new.

I'm actually starting to have trouble figuring out what you think is wrong, here. Yes, minds are finite. The entire /observable universe/ only has a finite number of configurations it can be in, so given infinite time even in a non-deterministic setting you're going to have an infinite number of "repeats" happen. What's wrong with that? As long as all possible outcomes are tried /eventually/ it doesn't seem like a problem to me, which is what that counter is there for.
:PROPERTIES:
:Author: FaceDeer
:Score: 1
:DateUnix: 1448213471.0
:DateShort: 2015-Nov-22
:END:

************** u/Dead_Atheist:
#+begin_quote
  I'm actually starting to have trouble figuring out what you think is wrong
#+end_quote

In simple words, "root access to the universe" and "trust your instincts" together just triggered an alarm. If you have clever ideas like using reload counter to determine the state of each planck volume in the universe directly, you will not stuck in infinite loop, you are right here.

It looks like I just can't speak English good enough to convey what I was trying to convey. I give up.
:PROPERTIES:
:Author: Dead_Atheist
:Score: 1
:DateUnix: 1448215510.0
:DateShort: 2015-Nov-22
:END:

*************** The "backup of last resort" is meant as a failsafe against exactly that sort of thing. If at some point you think to yourself "hey, let's just give the Wheel of Physics a spin and see what happens" you at least get another chance after everything goes blooie (assuming you didn't make another backup right before trying something stupid like that).

I suspect the problem is English itself. It was never designed with these sorts of circumstances in mind, so there are assumptions and omissions in the language that interfere with discussing them. I get the same sort of trouble when talking about things like time travel and brain copying.
:PROPERTIES:
:Author: FaceDeer
:Score: 1
:DateUnix: 1448215870.0
:DateShort: 2015-Nov-22
:END:


****** Now that would be terrifying.

According to your memory, you've only just finished setting up a backup system to fix any screw-ups. According to the counter it provides you with, this is attempt 1,002,592.

Presumably in those million attempts you would have tried something simple like "don't do anything". For some reason you don't know, that didn't work (though you can't be certain you actually tried it).

Something is causing an event so severe that you deem it a failure state (or die) and it or negative events of similar magnitude have happened 1,002,591 times so far.

Can you reliably reverse engineer your own thought patterns for all those attempts to determine what you might have already tried? Can you come up with something that 1,002,591 versions of you---differing at t_0 only by the state of the counter---couldn't?

Maybe many of those versions of you /did/ find the solution, only they just couldn't bring themselves to do it. Maybe they reasoned that some other you will do it, once the counter gets too large for their excuses to fly. Maybe 1,002,592 is that threshold, and it all comes down to you. Are you ready to die for what is right, or are you going to put it off for just one more lifetime?
:PROPERTIES:
:Author: ZeroNihilist
:Score: 8
:DateUnix: 1448091996.0
:DateShort: 2015-Nov-21
:END:

******* Your brain is not the only source of solutions.

Open wikipedia, use the counter as a seed for a random number generator to find a page. Read that and use it to devise a strategy. Even if it's something silly. If the number is larger than the number of entries in Wikipedia, Google the number. If the number is larger than the number of people in the world, pick a random person and ask them what to do. Combine these strategies.
:PROPERTIES:
:Author: ArgentStonecutter
:Score: 3
:DateUnix: 1448274432.0
:DateShort: 2015-Nov-23
:END:


****** [[https://www.fanfiction.net/s/10721988/1/Let-s-think-this-through-first][There is a small HP story with a similar idea.]]
:PROPERTIES:
:Author: OutOfNiceUsernames
:Score: 1
:DateUnix: 1448076898.0
:DateShort: 2015-Nov-21
:END:


**** u/DCarrier:
#+begin_quote
  If something goes Horribly Wrong™ and you're incapacitated beyond being able to reverse your changes, and then the cron job restores the universe to exactly the state recorded, what prevents the fresh instance of you from proceeding with exactly the same plan and making exactly the same mistake again?
#+end_quote

I can't help but think of the Endless Eight from The Melancholy of Haruhi Suzumiya.
:PROPERTIES:
:Author: DCarrier
:Score: 3
:DateUnix: 1448070481.0
:DateShort: 2015-Nov-21
:END:


**** Trivially, have the cronjob increment a counter, and whenever that counter is divisible by N, do a full restore.
:PROPERTIES:
:Author: protagnostic
:Score: 1
:DateUnix: 1448305309.0
:DateShort: 2015-Nov-23
:END:


**** The comment thread beneath me is really unimaginative.

Guys, /root/ access.

Edit the main partition by deleting some empty(ish) space, and create three new partitioned volumes: [God Consciousness], [God Consciousness.bak] and [Horribly Wrong Recovery].

Transfer slowly your main consciousness processing from human.brain to an independentconsciousness.god container, then use a virtual god network [VGN] to connect to Consciousness.bak, using .bak as a proxy VM interface that only broadcasts information back and commands forward, and create a "terminate connection" shortcut function that you can use to disconnect from Consciousness.bak quickly, while causing a full dump and rebuild from your primary mind on God Consciousness. Access reality.universe only through Consciousness.bak.

Any time you fuck up and need to reset Reality.universe to a snapshot, do a dump to Horribly Wrong Recovery, rebuild .bak, and access Reality.universe from .bak, then rebuild from there.

It's like running a particularly sensitive *nix build. Just don't do anything in production on servers that might be affected by the "oh crap" backblast.
:PROPERTIES:
:Author: Arizth
:Score: 1
:DateUnix: 1448311852.0
:DateShort: 2015-Nov-24
:END:


*** And here's the only guy who understands what he was told well-enough to /not/ just start /clobbering literally everything./
:PROPERTIES:
:Score: 5
:DateUnix: 1448054868.0
:DateShort: 2015-Nov-21
:END:


*** All of the sentient beings in each of your simulations that get reset(presumably as subjectivity real a reality as we live in) think you're a sadistic God. Are you OK with that?
:PROPERTIES:
:Author: Rationalfideism
:Score: 3
:DateUnix: 1448064764.0
:DateShort: 2015-Nov-21
:END:

**** No they don't, they cease to think the moment the simulation is reset.
:PROPERTIES:
:Author: FaceDeer
:Score: 7
:DateUnix: 1448065400.0
:DateShort: 2015-Nov-21
:END:

***** I mean they think that up until the moment you reset them. So do people when you kill them. What's the difference?
:PROPERTIES:
:Author: Rationalfideism
:Score: 3
:DateUnix: 1448068350.0
:DateShort: 2015-Nov-21
:END:

****** I wouldn't /tell/ them I'm about to reset the universe. What would be the point of that? It'll happen instantaneously, they won't see it coming.
:PROPERTIES:
:Author: FaceDeer
:Score: 2
:DateUnix: 1448068705.0
:DateShort: 2015-Nov-21
:END:

******* "I didn't tell them I was about to kill them. It was instantaneous, they didn't see it coming." - FaceDeer

I mean they think it about all the mistakes you're making that cause you to reset.
:PROPERTIES:
:Author: Rationalfideism
:Score: 3
:DateUnix: 1448072780.0
:DateShort: 2015-Nov-21
:END:

******** Ah, I see. Well, I'd be trying hard /not/ to make mistakes like that, so hopefully that won't happen often. And hopefully root access will let me correct most of them without a full reset, too.

And if all else fails, people wouldn't know they're /my/ mistakes. I have no interest in worship or anything silly like that, so I probably won't let many people know about my effective godhood. Maybe just a few friends and family members. It'll be good to have them as advisers, psychological benefits aside.
:PROPERTIES:
:Author: FaceDeer
:Score: 3
:DateUnix: 1448073795.0
:DateShort: 2015-Nov-21
:END:


** Post to [[/r/rational]] and ask for advice. Probably as a hypothetical.
:PROPERTIES:
:Author: trifith
:Score: 33
:DateUnix: 1448050649.0
:DateShort: 2015-Nov-20
:END:

*** Be sure to throw in a line to take it seriously, otherwise you might get some troll answers.
:PROPERTIES:
:Author: Lugnut1206
:Score: 16
:DateUnix: 1448050988.0
:DateShort: 2015-Nov-20
:END:


*** If pressed, would you tell them the truth that it's real?
:PROPERTIES:
:Author: Rationalfideism
:Score: 8
:DateUnix: 1448053281.0
:DateShort: 2015-Nov-21
:END:

**** Why yes, of course. And I would also immediately grant similar powers to the people who give me advice

/crosses fingers/
:PROPERTIES:
:Author: TBestIG
:Score: 21
:DateUnix: 1448054296.0
:DateShort: 2015-Nov-21
:END:

***** No, I would only grant similar powers to people who were giving the advice to be /very careful/ about who you grant similar powers to. Because clearly such people are safer to give power to than just any old person with ideas.

/fingers extra-crossed/
:PROPERTIES:
:Author: FaceDeer
:Score: 15
:DateUnix: 1448065515.0
:DateShort: 2015-Nov-21
:END:

****** Ah, but wouldn't a more reasonable request be more likely to be fulfilled, as it is safer to fulfill? So only those people who do not request the power, but only information of the power's existence, will have their request granted.

/breaks fingers/
:PROPERTIES:
:Author: Transfuturist
:Score: 5
:DateUnix: 1448077878.0
:DateShort: 2015-Nov-21
:END:


**** No. But for the sake of revealing any Omega-powers you may have recently acquired, absolutely yes.

/Presses you/
:PROPERTIES:
:Author: Transfuturist
:Score: 7
:DateUnix: 1448053654.0
:DateShort: 2015-Nov-21
:END:


** This is a fun one. Luckily, I already have it planned out.

0- become Immortal and Indestructible

1- make certain there are no rules. If there are, modify the following steps accordingly.

2- set it up that should I cease to exist, the universe retroactively reverts to this state, plus a viewable record of the destroyed universe(s). Ensure that the rest of the universe is halted while this happens, so one thing doesn't keep destroying me.

3- set up multiple places that should my current avatar be destroyed, I will spawn at a new spot. No need to reset if I don't have to

4- Have a version of my past self, at the time right before I interacted with the universe, get complete control at a higher level than mine, but only at such a point as he genuinely believes that I have been compromised. I don't want hypnosis to ruin me, not when I have this much.

5- Improve my avatar. I mean, standard invincibility is nice, but also time looping (grey boy), regeneration, immortal object tags, etc. I don't want anything to happen to me.

6- Make certain there are no other beings with similar or greater powers. If possible, make it so that they are not/will not become a threat.

7- Make sure that there are no other items/people with enhanced privileges within the system. See step 6

8- ensure there are no catastrophes currently ongoing

9- See if you can detect any higher universes above yours. The powers suggest your universe is magical rather than natural, and probability says it is probably a simulation.

10- attempt to talk your way out of the box. Don't spend too long if you don't get a response- there is a chance you aren't in one, or that you won't get let out.

11- determine how powers work. Make sure what you are doing is what you intend to

12- Grab the standard superpowers, plus PtV, time stop, wish powers, etc. Anything you think you will need, or think might be useful, or think have theoretical value, etc. Prioritize information.

13- Create simulations of yourself, as many as possible, for all branches you still consider you. This is determined beforehand- it's so that any given you is likely god of a simulation. send down the message- don't let them think they are in a hostile box, so they don't have to waste time attempting to escape

14- create an afterlife. make it as pleasant as can be reasonably be possible. make one for all other sentient, as well. 15- Improve life on earth/civilized worlds

16- think for a long time on other safeguards for your immortality. Follow the proper pattern (ie don't propose solutions for at least 5 mins, etc)

17- ???

18- profit
:PROPERTIES:
:Author: 1101560
:Score: 15
:DateUnix: 1448056914.0
:DateShort: 2015-Nov-21
:END:


** Depends, how easy is the interface to use? Does having root access to the universe mean that the information appears in my mind at will? Like, can I run queries with my mind or something? And if the size of the query is not limited by the size of my mind, how much time do I have to even read/think about all the data, or does it come at me all at once and my brain somehow miraculously doesn't explode?

If the interface is easy to use, then I would learn as much as I can and find a way to safely prove to a trustworthy team of researchers with relevant expertise what I am capable of. (My best guess for a good way to do this is to make a prediction about something that I cannot possibly have any way of knowing about, by running a query and then telling them what I find out. And I would do this as many times as it takes to convince them.)

Then with their expertise I would do whatever I needed to do to save all sapient lives that ever existed forever without destroying the universe or infringing on anyone's human rights. I guess maybe I would use my powers to help ensure that Super-AI is friendly, and create backup copies of everyone who ever died and bring them back to life. Although I'm not entirely sure that the AI thing is the best way to go about it, but I would prefer to be as non-interventionist as possible to avoid screwing everyone over. But I suppose that if having root access to the universe doesn't come with superintelligence, a super AI could outsmart me and manipulate me into using my powers as it wants me to. I suppose if it really came down to it I could just go f*** myself (read as FOOM myself) and hope my increased intelligence means that I won't screw everyone over, although that would be more of a last resort since I don't want to FOOM myself...

If the interface is too difficult, I might just ignore the power because whoever gave it to me is probably just trying to mess with me anyways and almost certainly doesn't care whether the universe continues existing if it chose me to have root access.
:PROPERTIES:
:Author: Sailor_Vulcan
:Score: 7
:DateUnix: 1448067092.0
:DateShort: 2015-Nov-21
:END:

*** u/eaglejarl:
#+begin_quote
  create backup copies of everyone who ever died and bring them back to life.
#+end_quote

Everyone? Hitler? Pol Pot? Genghis Khan? Torquemada? That kid who bullied you in second grade?

This is actually a question that interests me a lot -- if we gain the ability to recover dead people, how should we decide if and on whom to use it?
:PROPERTIES:
:Author: eaglejarl
:Score: 3
:DateUnix: 1448088253.0
:DateShort: 2015-Nov-21
:END:

**** I want all of them back. Hitler killed millions. This makes a loss of dozens of millions of life years. Even if we could only resurrect Hitler and nobody else, the payment for taking multimillion years of life should be multimillion years of community service, not eternal oblivion. Man, talk about the easy way out. But, since we can also resurrect each of his victims, killing someone has just lost nearly all of its moral weight. Now he faces only the economic cost of resurrecting his victims, which if we're omnipotent is zero, and the moral cost of teleporting people into the future against their consent. And because we're omnipotent, we can move every atom in the universe such that the universe is shaped like one where those people never died, effectively time traveling backwards to put everyone where they go. We'll also award him a medal of some kind. He did, after all, kill Hitler.
:PROPERTIES:
:Score: 14
:DateUnix: 1448131177.0
:DateShort: 2015-Nov-21
:END:


** u/space_fountain:
#+begin_example
  ls
#+end_example
:PROPERTIES:
:Author: space_fountain
:Score: 4
:DateUnix: 1448135381.0
:DateShort: 2015-Nov-21
:END:

*** u/Transfuturist:
#+begin_example
  bin    dev         initrd.img.old  libx32      opt   sbin  usr
  boot   etc         lib             lost+found  proc  srv   var
  cdrom  home        lib32           media       root  sys   vmlinuz
  core   initrd.img  lib64           mnt         run   tmp   vmlinuz.old
#+end_example
:PROPERTIES:
:Author: Transfuturist
:Score: 6
:DateUnix: 1448139900.0
:DateShort: 2015-Nov-22
:END:

**** u/space_fountain:
#+begin_example
  man man
#+end_example

I'm not nearly familiar enough with Linux systems to start messing around with the one running the universe.

Maybe

#+begin_example
  ls /bin
#+end_example

or

#+begin_example
  ls /home
#+end_example
:PROPERTIES:
:Author: space_fountain
:Score: 5
:DateUnix: 1448163144.0
:DateShort: 2015-Nov-22
:END:

***** u/Transfuturist:
#+begin_quote
  ls /home
#+end_quote

#+begin_example
  천지왕            Óðinn           Þórr    गौतम    上帝
  CelestAI         Pinkie Pie      الله    बुद्ध     天照大神
  Celestia         Rˤ              יהוה     विष्णु    思兼
  Huītzilōpōchtli  space_fountain  Ζεύς    शिव
  Hveðrungr        Tawa            Ἰησοῦς  सरस्वती
#+end_example
:PROPERTIES:
:Author: Transfuturist
:Score: 5
:DateUnix: 1448164781.0
:DateShort: 2015-Nov-22
:END:


*** u/ajuc:
#+begin_example
  Out of memory: Kill process 2954 (physicd) score 183 or sacrifice child
  Killed process 2954 (physicd) total-vm:38767500PB, anon-rss:785644PB, file-rss:0kB
#+end_example
:PROPERTIES:
:Author: ajuc
:Score: 2
:DateUnix: 1448264107.0
:DateShort: 2015-Nov-23
:END:


** Step 1. I make myself immortal and indestructible. /Alsssso become animagussss, if posssssible./

Step 2. Find some very smart and trustworthy people and demonstrate that I can turn into a cat (or whatever) to convince them to help me figure out steps 3 through N.
:PROPERTIES:
:Author: ArgentStonecutter
:Score: 10
:DateUnix: 1448049861.0
:DateShort: 2015-Nov-20
:END:

*** Who do you start out with and how do you determine trustworthiness? Remember, you're all powerful. It's a good answer and all but steps 3 through n are really what I mean by asking the question.
:PROPERTIES:
:Author: Rationalfideism
:Score: 2
:DateUnix: 1448053089.0
:DateShort: 2015-Nov-21
:END:

**** That depends on what having root on the universe means.

If it's like having root on a production server *, FUUUUUUU....

I'm talking physicists and chemists and biologists and the like. People who I can ask "what if I allowed this exception to entropy" and they tell me "if you do that you'll set the universe on fire". That sort of thing.

Who? I guess I'll start with people with high Erdös-Bacon-Sabbath scores. And Charlie Stross.

^{*} ^{What} ^{do} ^{you} ^{expect} ^{asking} ^{a} ^{sysadmin?}
:PROPERTIES:
:Author: ArgentStonecutter
:Score: 8
:DateUnix: 1448056041.0
:DateShort: 2015-Nov-21
:END:


** Step 2: Stop time for everyone but myself so that people don't suffer while I'm figuring stuff out.

Step 1: Make sure step 2 doesn't end in disaster.

Step 3: Omniscience

Step 4: Optimization

Step 5: Resume Time
:PROPERTIES:
:Author: TimTravel
:Score: 5
:DateUnix: 1448067188.0
:DateShort: 2015-Nov-21
:END:


** Upgrade my intelligence to the point where I can handle a universe of data. No point in making a decision with only minimal knowledge of the likely results.
:PROPERTIES:
:Author: Geminii27
:Score: 4
:DateUnix: 1448125202.0
:DateShort: 2015-Nov-21
:END:

*** With root access and a mind and the ability to encompass all data within your mind wouldn't it be the case that your mind is the substrate that the universe is running in? Or at the very least by comprehending the whole you are simulating another copy of the universe?
:PROPERTIES:
:Author: Spychex
:Score: 1
:DateUnix: 1461571631.0
:DateShort: 2016-Apr-25
:END:


** I calculate and execute my CEV. First approximation: Everyone gets the option to emigrate at will to their own realm of omnipotence, the material plane is unaffected except for the initial announcement and people disappearing. Whether two realms can communicate is managed on a friends/ignore list basis, depending on the outcome of the race between AI-Box offense and defense. Emigrants can agree to binding contracts.
:PROPERTIES:
:Author: Gurkenglas
:Score: 4
:DateUnix: 1448055964.0
:DateShort: 2015-Nov-21
:END:

*** You mean to Equestria?
:PROPERTIES:
:Author: Sailor_Vulcan
:Score: 5
:DateUnix: 1448065083.0
:DateShort: 2015-Nov-21
:END:

**** I would certainly hope that's an option. Along with nerfed versions where you don't actually have to be a brony.
:PROPERTIES:
:Author: ArgentStonecutter
:Score: 1
:DateUnix: 1448145840.0
:DateShort: 2015-Nov-22
:END:


*** Just curious, but are the binding contracts binding in the sense that an unbreakable vow is in hpmor? I've wondered about the ethics of such a thing...
:PROPERTIES:
:Author: Rationalfideism
:Score: 1
:DateUnix: 1448075527.0
:DateShort: 2015-Nov-21
:END:

**** Yup.
:PROPERTIES:
:Author: Gurkenglas
:Score: 1
:DateUnix: 1448075744.0
:DateShort: 2015-Nov-21
:END:


** I would screw it up just trying to write a find/replace routine for horrible diseases, or inventing some kinda mass-producible miracles, and wind up [[https://www.youtube.com/watch?v=nVp3GyMGiEc][turning babies into gold, or screwing with the weather]].

So... I'd try to see if the universe comes with documentation. Then hire someone smarter and patienter than me to try and translate it into something I can comprehend, although I'd need to find some way to guarantee they aren't going to betray me (after all, I am now an existential threat, but also a source of great power and temptation).

Also, publish the universe's documentation on Github, after carefully searching for obviously dangerous exploits that mightn't be best made public.

(If the universe is undocumented, then I guess I have job security for the years before I'm knowledgeable enough to rewrite reality on a whim. First priority is figuring out how to defend myself so that I can do research with experts in the relevant fields, rather than get spirited away by some shady military organization.)
:PROPERTIES:
:Author: cae_jones
:Score: 4
:DateUnix: 1448059303.0
:DateShort: 2015-Nov-21
:END:

*** I was hoping to see this answer. The universe is a huge project, step one should absolutely be to read every bit of documentation and commenting.\\
You just know there's going to be some ridiculous cludge code somewhere that has mortality linked to being able to move sideways.
:PROPERTIES:
:Author: IllusoryIntelligence
:Score: 3
:DateUnix: 1448106189.0
:DateShort: 2015-Nov-21
:END:


** u/FuguofAnotherWorld:
#+begin_quote
  Edit/ To everyone suggesting setting up a system of backups, resets or simulations to test out ideas, aren't you effectively creating, causing suffering for and killing people each time you do it?
#+end_quote

Well yeah, but it's still far, far, /far/ better than fucking up and not being able to revet to a saved state.
:PROPERTIES:
:Author: FuguofAnotherWorld
:Score: 4
:DateUnix: 1448073700.0
:DateShort: 2015-Nov-21
:END:

*** Is it? You've just deleted a universe worth of sentients. You'd have to REALLY mess things up for it to be worth killing a universe worth of sentients to start over
:PROPERTIES:
:Author: Rationalfideism
:Score: 1
:DateUnix: 1448081655.0
:DateShort: 2015-Nov-21
:END:

**** You may be underestimating how easy it would be to fuck up that hard. All you need to do is mess with basically anything to do with any of the forces and you've probably doomed most beings that exist, or at least really screwed their ecosystem.

Consider the alternative, where you fuck up and doom innumerable species leading to trillions of dead worlds for hundreds of millions of years until life makes sense of the new physics enough to evolve sentience again.
:PROPERTIES:
:Author: FuguofAnotherWorld
:Score: 2
:DateUnix: 1448111341.0
:DateShort: 2015-Nov-21
:END:


** It depends on the interface, how smart the interface is, and how much reason I have to trust the interface is optimizing for the same things I am.
:PROPERTIES:
:Author: EliezerYudkowsky
:Score: 5
:DateUnix: 1448083698.0
:DateShort: 2015-Nov-21
:END:

*** Let's say you can have any interface you like and you have as much trust in it as you can get by it passing every test you throw at it. It doesn't do abstract requests like maximize happiness though. It re-orders matter you have as much as control as a programmer does over his program but with an easy ui. In other words, the interface itself isn't smart.
:PROPERTIES:
:Author: Rationalfideism
:Score: 2
:DateUnix: 1448085099.0
:DateShort: 2015-Nov-21
:END:

**** u/ArgentStonecutter:
#+begin_quote
  It re-orders matter you have as much as control as a programmer does over his program but with an easy ui. In other words, the interface itself isn't smart.
#+end_quote

OK, this makes it more like "root on a production server" and less like "you're god, have fun". This is "if you're not really frigging careful, you're going to destroy the universe in five minutes or less".

I would start out by re-reading [[https://en.wikipedia.org/wiki/The_Infinity_Concerto][/The Infinity Concerto/ and /The Serpent Mage/]] and [[https://en.wikipedia.org/wiki/Rick_Cook][/Wizard's Bane/]]. Just to burn into my mind how easy it is to fuck up when you have control over the code.

The first active thing would be to find or develop a place where I can build empty spaces to test out ideas. Throw-away universes /with nobody in them/, with a framework that makes tests safe. Tilt switches and the equivalent of a negative pressure chamber in a lab levitated over an acid bath on an asteroid orbiting a completely different star. I'm not inside the universe, I have at most a meat puppet there, and a graduated dead-man switch that can do everything from cutting me free of the puppet to rolling me back to a sane state as each step fails.

All in a timeline running orthogonally to this universe's.

THEN I start working on solving problems. It may take the rest of my life several times over until I'm ready to make myself immortal and invulnerable, but that's what the dead man switch is for. There's going to be lots of unhappy versions of me, but they all made the choice to get in the tank. Nobody's mind-state gets lost who didn't decide to risk it.

Edit: If this universe was created by someone who wasn't literally insane, this framework already exists.
:PROPERTIES:
:Author: ArgentStonecutter
:Score: 3
:DateUnix: 1448143959.0
:DateShort: 2015-Nov-22
:END:


*** I'd like to hear your answer as well as HPJEV's if you don't mind. Say he discovers the lost terminal of Atlantis or some such. The fate of the universe may or may not depend on your answer
:PROPERTIES:
:Author: Rationalfideism
:Score: 2
:DateUnix: 1448087907.0
:DateShort: 2015-Nov-21
:END:


** Create a room with a copy of me, including these priviledges, and set it to instantly simulate a month of time passing in that room.

Finding myself in the room, look through the from my perspective frozen world, and copy various people who I trust or with have specific relevant cognitive skills or knowledge.

Spend a bunch of subjective days just brainstorming and debating how to go about things with people way smarter than me withote using the powers for anything other than materializing food, comforts, and more relevant people from reality.

Create another simulation with some complex organization of privileges and instantiating copies of minds and very hevily regulated self improvement (because value is fragile) and run this for some huge number of subjective years.

Resulting plan of action is automatically followed.
:PROPERTIES:
:Author: ArmokGoB
:Score: 3
:DateUnix: 1448061279.0
:DateShort: 2015-Nov-21
:END:


** Are you granting me omnipotence, or are you just handing me a program that uses more advanced math than I understand, some arbitrary-seeming variables that will kill me if changed even slightly, and expecting me to do something useful with it?

#+begin_quote
  To everyone suggesting setting up a system of backups, resets or simulations to test out ideas, aren't you effectively creating, causing suffering for and killing people each time you do it?
#+end_quote

Most of the simulations can be done without people. And when I do cause suffering, it's a necessary evil. Do you have any idea how much suffering goes on each second I spend trying to figure out how this works?
:PROPERTIES:
:Author: DCarrier
:Score: 3
:DateUnix: 1448070708.0
:DateShort: 2015-Nov-21
:END:

*** If the purpose of your simulations is to optimize happiness/reduce suffering what good will it's data be If the simulations don't include humans? And I may have equivicated causing with letting happen there, but it's effectively the same thing. And if you were to create a complete simulation then whatever amount of suffering were talking about, you've roughly doubled it plus it minus depending on whether the changes you're experimenting with end up increasing or decreasing it.
:PROPERTIES:
:Author: Rationalfideism
:Score: 1
:DateUnix: 1448073476.0
:DateShort: 2015-Nov-21
:END:

**** u/DCarrier:
#+begin_quote
  If the purpose of your simulations is to optimize happiness/reduce suffering what good will it's data be If the simulations don't include humans?
#+end_quote

I'm thinking less to prevent things like the Soviet Union and more to prevent things like the sun exploding. First I'll make sure that I can change things without destroying astronomical bodies, then rocks. Then computers. Then animals. Then humans.
:PROPERTIES:
:Author: DCarrier
:Score: 1
:DateUnix: 1448073769.0
:DateShort: 2015-Nov-21
:END:

***** That's sounds like a reasonable place to start. The question still remains about the ethics of simulation restarts once you add people though. I wonder how far you could really get without them.
:PROPERTIES:
:Author: Rationalfideism
:Score: 1
:DateUnix: 1448081326.0
:DateShort: 2015-Nov-21
:END:

****** At some point, you're going to have to test teleportation on people, but once you do that you can teleport them between universes, so simulation restarts won't be a problem.
:PROPERTIES:
:Author: DCarrier
:Score: 1
:DateUnix: 1448081654.0
:DateShort: 2015-Nov-21
:END:

******* Hmmmm... That sort of defeats the purpose of your simulations though... Interesting thought
:PROPERTIES:
:Author: Rationalfideism
:Score: 1
:DateUnix: 1448082935.0
:DateShort: 2015-Nov-21
:END:

******** I can save them all and load them when I have the hang of things.
:PROPERTIES:
:Author: DCarrier
:Score: 1
:DateUnix: 1448085081.0
:DateShort: 2015-Nov-21
:END:


** This answer has been clarified for me. I would contact effective altruist organizations first, and work from there. But now I want to read or write a story about someone who doesn't.

+I'd announce to the world that I am its supreme dictator of everything for life, and then ask for help in setting up good governance. I would set up a platform in the ocean, perhaps near Iceland as the sea floor is shallow there (thanks, Bioshock) in order to separate ties from my home country. I would set up a massive satellite as well, what evil overlord can go without?+

+I would try to directly erase guns from the earth, as well as all nuclear weapons. Chemical and biological weapons would also concern me. Malaria is gone. HIV is gone. I would research removing arterial plaque without dangerous effects.+

+Then I would start producing unbreakable negentropy devices to replace turbines in power plant generators. Energy becomes free, but it also becomes worthless. Same with materials. Same with transportation. Presuming I can break physics locally, instant production and transportation of food and water. The only thing left is shelter.+

+This is a near-instant transition to post-scarcity. Markets would collapse as everything became overvalued overnight. Stability would be a major concern. Logistics would be a major concern.+
:PROPERTIES:
:Author: Transfuturist
:Score: 2
:DateUnix: 1448052837.0
:DateShort: 2015-Nov-21
:END:

*** u/ArgentStonecutter:
#+begin_quote
  Then I would start producing unbreakable negentropy devices to replace turbines in power plant generators.
#+end_quote

As someone pointed out to me, be damned careful, it's really easy to set the universe on fire doing this.
:PROPERTIES:
:Author: ArgentStonecutter
:Score: 5
:DateUnix: 1448057839.0
:DateShort: 2015-Nov-21
:END:

**** Maybe the world, but not the universe.

Dump waste heat off the ecliptic in EM and you'll be fine. Even if you eventually decide to fix the expansion of the universe (assuming you don't just make FTL, but stars /are/ pretty), you have a nice differentiated volume of stress-energy to destroy indiscriminately.
:PROPERTIES:
:Author: Transfuturist
:Score: 2
:DateUnix: 1448059641.0
:DateShort: 2015-Nov-21
:END:

***** When creating a state where entropy is reversed, you have to be careful that there is no possible mechanism for the state to propogate. Otherwise it will, and you end up with the local entropy reversal spreading through the entire universe.

And "no possible mechanism" does not mean "really unlikely".
:PROPERTIES:
:Author: ArgentStonecutter
:Score: 5
:DateUnix: 1448060606.0
:DateShort: 2015-Nov-21
:END:

****** u/Transfuturist:
#+begin_quote
  When creating a state where entropy is reversed
#+end_quote

A physical state. The devices are superphysical artifacts induced on arbitrary loci and would act unitarily. This of course presumes I would be able to figure out how to produce that effect, but with this statement:

#+begin_quote
  Let's say you can have any interface you like and you have as much trust in it as you can get by it passing every test you throw at it. It doesn't do abstract requests like maximize happiness though. It re-orders matter you have as much as control as a programmer does over his program but with an easy ui. In other words, the interface itself isn't smart.
#+end_quote

by [[/u/Rationalfideism]] I would consider it trivial to implement (given a proper API, which can be constructed from lower levels if required). I would of course test and debug with sandbox universes. But in the end the only worry you have is dealing with the growing heat, which can be dealt with by similarly unitary energy sinks.
:PROPERTIES:
:Author: Transfuturist
:Score: 2
:DateUnix: 1448140314.0
:DateShort: 2015-Nov-22
:END:

******* u/ArgentStonecutter:
#+begin_quote
  I would consider it trivial to implement
#+end_quote

Based on:

#+begin_quote
  It re-orders matter you have as much as control as a programmer does over his program but with an easy ui.
#+end_quote

Dude, if the interface isn't smart I wouldn't assume /anything/ was trivial.

After 40 years of programming I would assume that ANYTHING I did was full of malicious gremlins called "myself five minutes ago".
:PROPERTIES:
:Author: ArgentStonecutter
:Score: 3
:DateUnix: 1448143066.0
:DateShort: 2015-Nov-22
:END:

******** u/Transfuturist:
#+begin_quote
  you can have any interface you like and you have as much trust in it as you can get by it passing every test you throw at it
#+end_quote

The interface isn't smart, but that sounds like high-level primitives are provided.

The gremlins do swarm, though.
:PROPERTIES:
:Author: Transfuturist
:Score: 1
:DateUnix: 1448146169.0
:DateShort: 2015-Nov-22
:END:


**** If I had root on the universe, don't I win automatically? If it's DWIM, it's trivial.

Save states, memory bubbles. Win. Everybody lives!
:PROPERTIES:
:Author: nerdguy1138
:Score: 1
:DateUnix: 1448253346.0
:DateShort: 2015-Nov-23
:END:

***** Why would you expect it to be DWIM?
:PROPERTIES:
:Author: ArgentStonecutter
:Score: 1
:DateUnix: 1448276785.0
:DateShort: 2015-Nov-23
:END:


*** u/ArgentStonecutter:
#+begin_quote
  now I want to read or write a story about someone who doesn't.
#+end_quote

[[https://en.wikipedia.org/wiki/The_Infinity_Concerto][/The Infinity Concerto/ and /The Serpent Mage/]] kinda qualify. ^^
:PROPERTIES:
:Author: ArgentStonecutter
:Score: 3
:DateUnix: 1448145493.0
:DateShort: 2015-Nov-22
:END:


** u/MrCogmor:
#+begin_quote
  Edit2/ Really everyone? The minute you're handed near definitive proof that our reality is a simulation you want to create alternate throw away realities to experiment on without consideration for the people you're creating?
#+end_quote

I don't see anything wrong with creating alternate throw away realities provided you don't leave them running too long. In one sense you are creating and killing temporary copies of people. In another sense you are simply wiping peoples memories and moving everything back the way it was before.

It is the same thing as the issue of whether transporters kill and copy a person or not and I would answer it the same way. It's the information and process that is important, not the exact arrangement of atoms. If you copy and kill a person in a single moment then it's morally neutral because no information was lost.
:PROPERTIES:
:Author: MrCogmor
:Score: 2
:DateUnix: 1448097890.0
:DateShort: 2015-Nov-21
:END:


** Here's a great example of what not to do: [[http://anonkun.com/stories/infinite-wishes-quest/f9GgmpEH79x4ohHTo]]
:PROPERTIES:
:Author: Baronet_Picklenose
:Score: 2
:DateUnix: 1448158740.0
:DateShort: 2015-Nov-22
:END:


** CTRL+C, CTRL+P. Play [[#s][Worm spoilers]] for a while.
:PROPERTIES:
:Author: Calamitizer
:Score: 1
:DateUnix: 1448054224.0
:DateShort: 2015-Nov-21
:END:


** Vastly increase the amount of intelligent life in the universe
:PROPERTIES:
:Score: 1
:DateUnix: 1448056968.0
:DateShort: 2015-Nov-21
:END:


** Backup everything. Ensure that if I accidentally do something to myself in the next steps, the universe reverts to backup.

Then, fix my current influenza.

After that, start looking through stuff to figure out how things actually work. Make a memo of possible changes I might want to make, starting small to get used to my new abilities. Think on every change for some length of time that I will specify beforehand, to ensure I'm not making any obvious mistakes. Use reasonably accurate simulations to help predict the effects. Commit one change at a time using backups.
:PROPERTIES:
:Author: Murska1FIN
:Score: 1
:DateUnix: 1448057969.0
:DateShort: 2015-Nov-21
:END:


** u/Zenmaster13:
#+begin_example
  cd /
  sudo rm -rf *
#+end_example
:PROPERTIES:
:Author: Zenmaster13
:Score: 1
:DateUnix: 1448062026.0
:DateShort: 2015-Nov-21
:END:

*** Never thought I'd say this, but...

Thank god the universe runs on Windows.
:PROPERTIES:
:Author: eaglejarl
:Score: 7
:DateUnix: 1448088342.0
:DateShort: 2015-Nov-21
:END:


*** I think you need a --no-preserve-root in there
:PROPERTIES:
:Author: traverseda
:Score: 1
:DateUnix: 1448125754.0
:DateShort: 2015-Nov-21
:END:


** I experiment with what types of experience are possible. I recreate the rules of the universe to have minimal suffering/pain experiences, and untold richness of joy/pleasure experiences. I make everyone immortal until they desire not to be. Universe solved.
:PROPERTIES:
:Author: Polycephal_Lee
:Score: 1
:DateUnix: 1448063047.0
:DateShort: 2015-Nov-21
:END:


** 1. Enable back-ups
2. Render self immortal and indestructible
3. Find out if there really is intelligent life in other parts of the galaxy.
4. Start enacting plans I've drawn up for various SIs to test how different things in multiple universes will interact.
5. Become a omni-potent god-king.
:PROPERTIES:
:Author: jldew
:Score: 1
:DateUnix: 1448088525.0
:DateShort: 2015-Nov-21
:END:


** Chances are if this actually occurs, that universe itself is merely a matrix-type system, a subset of a larger incomprehensible . Improvements to this one would be tremendous for its sentient inhabitants, but might be as meaningless to a god-level operator the same way that computer simulations are to us, because our greater awareness comes with knowledge of our actions' relative insignificance.
:PROPERTIES:
:Author: darkflagrance
:Score: 1
:DateUnix: 1448097519.0
:DateShort: 2015-Nov-21
:END:


** /Feedback/

Create feedback programs that display automatically updating statistics, metrics and population maps for whatever I tell it to whether it is number of burgers eaten in the last week to the number of depressed people in each country.

/Afterlife/

I'm thinking of something like a VR version of Second Life with a Infinite expanse of procedural generated terrain similar to mine-craft and giving individuals a limited amount of reality warping power that recharges over time.

Dealing with the souls of the mentally ill and brain-damaged would be tricky and morally complicated. Would probably want to learn more about neurology and psychology first.

Will create souls for the afterlife by scanning and interpreting mental states of the present and past.

/Covert Optimization/ Use my abilities to hack into criminal accounts and redistribute it towards charity. I gradually lower the rate of mosquito reproduction. Use powers to identify and investigate terrorists, human traffickers, child abusers, organized crime gangs and other criminals. Use anonymous tips, fabricated evidence, unfortunate accidents or mind control to deal with them. In particular kill the leaders of dictatorships and terrorist groups.

Covertly improve the skills and mental faculties of researchers and scientists, particularly in the medical and renewable energy fields, providing them with epiphanies, additional concentration and additional motivation.

/Alien Optimization/

Pretend to be a sufficiently advanced alien, show up in system with my ship, terraform Mars, leave a giant warp gate on it connecting to a massive network of portals allowing interstellar travel as well as a paranormal effect keeping Mars habitable. Do the same for Earth, dropping a device that will regulate the planet's atmosphere, water levels, soil quality, core temperature, fault lines, weather, sea waves and protect it from asteroid impacts making natural disasters a thing of the past. Also have a separate effect that prevents animals and humans from being conceived with known genetic defects like Down syndrome. Kill all the mosquitoes and eliminate biological weapons and other dangerous diseases like malaria and polio.

Maybe start giving people superpowers.

/Overt Optimization/ (This makes intelligent design extremely apparent)

Create and implement a magic system focusing on runes and geometric diagrams in particular allow magically binding contracts, honesty checking spells, rings of sustenance, linked transport circles, portkeys, rapid fabrication and so on, everything you need for a nation to go post scarcity. Publish it on the internet. Also create a spoken night light spell, naza taza lin gretal. The book will encourage you to say it first to see if you can do magic (everyone can), doing so will then create a brief light and convince people it's the real deal even though none of the other spells are spoken. Perhaps introduce it gradually by making only a small amount of people able to cast magic but have the number of people increase over time.
:PROPERTIES:
:Author: MrCogmor
:Score: 1
:DateUnix: 1448103731.0
:DateShort: 2015-Nov-21
:END:

*** u/ArgentStonecutter:
#+begin_quote
  I'm thinking of something like a VR version of Second Life with a Infinite expanse of procedural generated terrain similar to mine-craft and giving individuals a limited amount of reality warping power that recharges over time.
#+end_quote

Nah. Give people sharded toy universes and pretty much the same powers I have inside them. Look for people who handle it well, and hook their shards together, and eventually delegate them to monitoring the rest.

Discover that's what happened to me.
:PROPERTIES:
:Author: ArgentStonecutter
:Score: 1
:DateUnix: 1448145273.0
:DateShort: 2015-Nov-22
:END:

**** You can't have the afterlife do it for everyone because then you will get the fundamentalists continually making and raising other fundamentalists. It would also likely lead to strange reactions from Buddhists and is much harder to reason about. If you create any infinitely dividing world system then it will result in the most stable patterns repeating themselves endlessly and those patterns are unlikely to be what I consider optimal.

Furthermore any approach they use is something I could devise through other means either by creating a fallout vault style bubble universe or just asking people their opinion. Eventually I would contract people in the afterlife to help me design magical bubble universes and videogame worlds for people in the afterlife to play / be reincarnated in.
:PROPERTIES:
:Author: MrCogmor
:Score: 1
:DateUnix: 1448151442.0
:DateShort: 2015-Nov-22
:END:

***** u/ArgentStonecutter:
#+begin_quote
  You can't have the afterlife do it for everyone because then you will get the fundamentalists continually making and raising other fundamentalists.
#+end_quote

Fundamentalists wouldn't get the "handling it well" cachet, so they wouldn't get other people under their control.
:PROPERTIES:
:Author: ArgentStonecutter
:Score: 1
:DateUnix: 1448153025.0
:DateShort: 2015-Nov-22
:END:

****** Then you have a very exclusive afterlife. What do you do with everyone else, do you just let them cease or create more custom worlds?
:PROPERTIES:
:Author: MrCogmor
:Score: 1
:DateUnix: 1448160658.0
:DateShort: 2015-Nov-22
:END:

******* Everyone gets their own shard. If they want to interact with other shards, they have to earn it.
:PROPERTIES:
:Author: ArgentStonecutter
:Score: 1
:DateUnix: 1448195786.0
:DateShort: 2015-Nov-22
:END:


** - Give myself the standard godly superpowers -- invincibility, indestructibility, incorruptibility (of my mental states and consciousness), ability to stay existent, thinking, and rational even if the laws of physics forbid such a thing, etc.

- Develop a time travel protocol that enables me to visit any point in the past or future I wish and make any changes I wish but which undoes any change I make as soon as I leave that era, with the exception of copying anyone I take with me.

- Give myself the ability to understand and speak any language from any era and to appear as whoever or whatever I wish.

- Create a complete digital archive of the Library of Alexandria and upload it to every University net on Earth and also to the Pirate Bay under the username "Anonymous".

- Enjoy the reaction this causes.

- I hear that there were some schmart guys that died before I was born (Plato, Socrates, Abe Lincoln, etc. ) and some nifty events that happened before I was born (Rome, Fall of Rome, all the rest of human history, Dinosaurs, etc). It's time to go see and experience them all, and collect those people I like as cloned companions. This make take a while, but since I can access any time I wish there's hardly a need for haste in fixing the world's problems.

- Realize that becoming God has made me kind of a dick and promise myself to eventually fix things once I view all the important events of the past and various future timelines and met and asked the opinion of everyone worth meeting and asking.

- Check out alien life and if interesting do the same with its history as with human history.

- Several million subjective years and many carefully applied incremental intelligence enhancements later: Fix everything perfectly.
:PROPERTIES:
:Author: OrzBrain
:Score: 1
:DateUnix: 1448138974.0
:DateShort: 2015-Nov-22
:END:

*** Incorrubtibility and invicibility run a high risk of turning you into a statue. I'd prefer respawning or regeneration to a preprogrammed backup state if you encounter catastrophic damage.

Simplest way to handle the time travel protocol would probably be the creation of a TARDIS like device much lower risk of screwing up the targeting and selection.
:PROPERTIES:
:Author: MrCogmor
:Score: 1
:DateUnix: 1448151782.0
:DateShort: 2015-Nov-22
:END:


** Immediately save the state of the simulation, extract myself onto the next layer, then pause the simulation (if that's all viable). Then spend some time figuring out what to do next.

If that's NOT viable, then... I suppose start reading manpages. If reconfiguring the universe is as trivial as writing some Bash, hooray! If it means patching the kernel, this might take a while.
:PROPERTIES:
:Author: protagnostic
:Score: 1
:DateUnix: 1448305451.0
:DateShort: 2015-Nov-23
:END:


** rm -f /usr/bin/sudo && rm -f /bin/su
:PROPERTIES:
:Author: nagelwithlox
:Score: 1
:DateUnix: 1448333747.0
:DateShort: 2015-Nov-24
:END:


** - I am safe/immortal/superintelligent, have control over my own source code.

- Everybody in the world has a button that restores them to youth and perfect health.

- Everybody in the world has a button that creates a protective field around them, complete safety from any harm.

- No more lack of resources. Generate plenty of basic food/water/other necessary stuff for everybody.

I believe that will solve most of the biggest problems, then I tweak and solve more minor things as I go.
:PROPERTIES:
:Author: raymestalez
:Score: 1
:DateUnix: 1448366152.0
:DateShort: 2015-Nov-24
:END:


** According to Scott Meyer and his Magic 2.0 series (*Off to be the Wizard* and its sequels), most people try adding money to their bank account, which attracts the attention of the feds, so you flee to medieval England and pretend to be a wizard.
:PROPERTIES:
:Author: chorpler
:Score: 1
:DateUnix: 1448930338.0
:DateShort: 2015-Dec-01
:END:


** Root access means I can change every file right?

So the obvious moral optimum is to rewrite the universe as filled to the brim with sapience which are locked into a bliss state.

That's happiness maximum right there.
:PROPERTIES:
:Author: RMcD94
:Score: 0
:DateUnix: 1448055021.0
:DateShort: 2015-Nov-21
:END:

*** Do you give people a choice?
:PROPERTIES:
:Author: Rationalfideism
:Score: 1
:DateUnix: 1448058123.0
:DateShort: 2015-Nov-21
:END:

**** People are probably an inefficient way of experiencing bliss so no I don't give them a choice.
:PROPERTIES:
:Author: RMcD94
:Score: 1
:DateUnix: 1448058876.0
:DateShort: 2015-Nov-21
:END:

***** [deleted]
:PROPERTIES:
:Score: 8
:DateUnix: 1448073816.0
:DateShort: 2015-Nov-21
:END:

****** With any starting axioms you maximise to something
:PROPERTIES:
:Author: RMcD94
:Score: 1
:DateUnix: 1448634144.0
:DateShort: 2015-Nov-27
:END:

******* Well that's the bit where I say that you could maximise to something less horrifying.

Then you say that 'horrifying' isn't a very good reason to decide something whereupon I say that maximising to such a state shows an incomplete understanding of happiness theory and the human utility function.

Then you say that no-one has a complete understanding of the human utility function and I say that we can at the very least tell that orgasmium is not the optimal state of being because it only optimises upon one axis while ignoring all other relevant measures of what is important leading to a lower combined score than other possible world-states.
:PROPERTIES:
:Author: FuguofAnotherWorld
:Score: 2
:DateUnix: 1448640734.0
:DateShort: 2015-Nov-27
:END:

******** I don't agree with the conclusion of your second sentence and though you predicted my response to the first line it isn't the same one to the third. Knowing human utility is not relevant everyone given this power will maximise their own utility as we likely have a small value for other humans maximising their utility is natural.

However I know and everyone else should know that if you just mess around without doing this you will eventually press your bliss coma button even if it is after eons. After doing that you won't make any decisions anymore so you have to beat yourself and bliss everyone first so you don't forget or stop caring.

Plus there's no such thing as multiple axis, everything can be reduced. When you have brain access.
:PROPERTIES:
:Author: RMcD94
:Score: 0
:DateUnix: 1448641464.0
:DateShort: 2015-Nov-27
:END:

********* It might be natural to have a small value for maximising the utility of other humans, but that doesn't make it optimal or universal, or else there would be less grand gestures to help others. For example, when the creator of the polio vaccine chose to make it cheap instead of charging money, leading to what is essentially the eradication of polio in the modern day. I like to think that this idea of trying to care more than one's emotions and such normally allows is fairly common among rationalists and people in this sub.

I dispute that a bliss coma is inevitable so long as safeguards, save points and such can be properly implemented. I also dispute that the bliss coma is the best possible state. Unless when you say bliss coma you actually mean a simulation of the most fulfilling possible life for that being, which is a different thing and rather obviously better than just feeling happy the whole time.
:PROPERTIES:
:Author: FuguofAnotherWorld
:Score: 2
:DateUnix: 1448642485.0
:DateShort: 2015-Nov-27
:END:

********** By small I merely meant that it exists.

My point only works if there is any value for empathy. The greater your empathy the more you should rewrite the universe.

The idea of having a simulation shows a fundamental misunderstanding of human happiness and human well being and even utility in general. Everything is determined by brain chemicals, you never need to simulate anything if you knew the exact pattern of chemicals a simulation will release.

As the human brain has not that many positive channels you can just max them all out and that is the same as a simulation of the best possible life (which would be a bliss coma).

All utility functions of physical beings are reduced to chemicals. Unless you're a dualist which I doubt you will agree.
:PROPERTIES:
:Author: RMcD94
:Score: 1
:DateUnix: 1448643285.0
:DateShort: 2015-Nov-27
:END:

*********** Let's make this completely clear before I go any further, are you or are you not arguing in favour of wireheading?
:PROPERTIES:
:Author: FuguofAnotherWorld
:Score: 1
:DateUnix: 1448645655.0
:DateShort: 2015-Nov-27
:END:

************ I think the universe on wireheading is the optimal value, that doesn't mean individuals should wirehead, it means if you can choose the universe the best one in terms of morality is the one where everyone literally cannot be happier any other universe.

And, I believe that all instances of power over the brain lead to wireheading over a long enough scale because if you have power over the brain after you have spent a billion years doing stuff at some point you might touch your pleasure centre and then boom, there is nothing that can make you do anything else.
:PROPERTIES:
:Author: RMcD94
:Score: 1
:DateUnix: 1448646471.0
:DateShort: 2015-Nov-27
:END:

************* I believe that processes that can be compressed to a register counting up are no different than the simpler process. Wireheading is literal destruction of the mind, it is suicide. Pleasure is an evolutionary hack, and if we are able to rewrite our brains to entirely remove a valence-maximizing hotspot, which I believe we eventually will be, we should do that /as soon as humanly possible/ to prevent as many wireheads as possible. Otherwise there will be a collective of nothing but registers counting upwards. Remove Wirehead. REMOVE WIREHEAD.
:PROPERTIES:
:Author: Transfuturist
:Score: 1
:DateUnix: 1448650091.0
:DateShort: 2015-Nov-27
:END:

************** The brain needs something to operate... morals are derived from chemicals that make you feel good when you do keep moral.
:PROPERTIES:
:Author: RMcD94
:Score: 0
:DateUnix: 1448655060.0
:DateShort: 2015-Nov-27
:END:

*************** You are removing morality entirely. Morality does not calculate bliss efficiently. All you are doing is stimulating the pleasure centers. The rest of the brain has nothing to do with anything involved here.
:PROPERTIES:
:Author: Transfuturist
:Score: 1
:DateUnix: 1448670639.0
:DateShort: 2015-Nov-28
:END:


************* Allright, wanted to make sure I had that clear.

To my way of thinking wireheading misses large parts of what is important. It's just a brain in a jar feeling good about itself. Say you have a car with a speed dial. To me, wireheading is removing everything but the dashboard and then turning the speed dial as high as it can go. Sure, according to the dial things are great but it largely misses the point of what cars are for.

Similarly, chunks of orgasmium might feel good but they're not actually achieving anything. No art or science or creativity is happening, no-one is exploring the stars or partying or falling in love and so on.

To me wireheading is just taking all of humanity and measuring it on a simplified scale, then setting out to optimise that scale while forgetting that the scale itself is just an approximation we made because we didn't fully understand the proper underlying concepts and therefore any attempt to optimise things using that scale can only go so far.

I am confident that given a few hundred years humanity will create new schools of thought then theorise and possibly implement states far superior to wireheading. To wirehead everyone immediately misses out on those future states, locking the universe into a dead end inferior to what is capable of.
:PROPERTIES:
:Author: FuguofAnotherWorld
:Score: 1
:DateUnix: 1448654608.0
:DateShort: 2015-Nov-27
:END:

************** u/RMcD94:
#+begin_quote
  It's just a brain in a jar feeling good about itself. Say you have a car with a speed dial. To me, wireheading is removing everything but the dashboard and then turning the speed dial as high as it can go. Sure, according to the dial things are great but it largely misses the point of what cars are for.
#+end_quote

Right but if the car derives how it determines what it is for from the dial then it isn't missing its purpose.

#+begin_quote
  Similarly, chunks of orgasmium might feel good but they're not actually achieving anything. No art or science or creativity is happening, no-one is exploring the stars or partying or falling in love and so on.
#+end_quote

You only value those things because of the chemicals in your brain. This is just a failure to see what is actually behind the axioms you use to support your moral system.

#+begin_quote
  while forgetting that the scale itself is just an approximation we made because we didn't fully understand the proper underlying concepts and therefore any attempt to optimise things using that scale can only go so far.
#+end_quote

Except that's not true. Humans are chemical reactions, they can easily be optimized to maximise whatever chemical it is that gives us our morals and our satisfaction upon completing them. There is a solution to sapience.
:PROPERTIES:
:Author: RMcD94
:Score: 0
:DateUnix: 1448656046.0
:DateShort: 2015-Nov-27
:END:

*************** I think you think that you are telling me new facts here, but it is not so. These are all things that I knew already, and upon learning all of them I still decided that wireheading was sub-optimal compared to other options. Calling humans chemical reactions does not necessarily mean that this particular series of reactions you are arguing for would be best compared to the chemical reactions for (for example) a person living the most fulfilling life that it is possible for them to live or one of many other options.
:PROPERTIES:
:Author: FuguofAnotherWorld
:Score: 2
:DateUnix: 1448658882.0
:DateShort: 2015-Nov-28
:END:

**************** u/RMcD94:
#+begin_quote
  Calling humans chemical reactions does not necessarily mean that this particular series of reactions you are arguing for would be best compared to the chemical reactions for (for example) a person living the most fulfilling life that it is possible for them to live or one of many other options.
#+end_quote

But the definition of the word fulfilling is based of off that chemical make up, so the most fulfilling life is achieved by direct manipulation of the brain in every single case.
:PROPERTIES:
:Author: RMcD94
:Score: 0
:DateUnix: 1448659038.0
:DateShort: 2015-Nov-28
:END:

***************** Well yeah, or a computer running a program that is identical to that brain. That's not a point of contention here. What is is that you're saying that brain should be sitting there with all its happiness bars artificially shot into the infinities while thinking about nothing and I'm saying that brain should think that it is experiencing the best life ever while possibly having its sadness and such turned down.
:PROPERTIES:
:Author: FuguofAnotherWorld
:Score: 1
:DateUnix: 1448659671.0
:DateShort: 2015-Nov-28
:END:


***************** u/Transfuturist:
#+begin_quote
  But the definition of the word fulfilling is based of off that chemical make up, so the most fulfilling life is achieved by direct manipulation of the brain in every single case.
#+end_quote

That does not actually follow. I repeat, get your head tuned. Maybe rotate your tires.
:PROPERTIES:
:Author: Transfuturist
:Score: 1
:DateUnix: 1448684133.0
:DateShort: 2015-Nov-28
:END:


*************** u/Transfuturist:
#+begin_quote
  You only value those things because of the chemicals in your brain. This is just a failure to see what is actually behind the axioms you use to support your moral system.
#+end_quote

You are either being deliberately obtuse or genuinely confused about what values are. We don't /want/ our source of pleasure to become unhinged from how it is naturally causally attached to the things /we actually value/. To do so would be to change the things that we value, and /people don't want that to happen./ Despite not having a reified utility function, humans follow Omohundro's convergent instrumental goals fairly well.

#+begin_quote
  Humans are chemical reactions, they can easily be optimized to maximise whatever chemical it is that gives us our morals and our satisfaction upon completing them.
#+end_quote

If humans are chemical reactions, then I'm not human. I'm a pattern of causality that induces local optimizing effects for a dynamic set of goals that is currently dependent on this fleshy chemical reaction called a human.

I understand and accept materialism, and there is nothing about it that enforces this particularly deranged package of unrelated values. Have you even /heard/ of the orthogonality thesis?! I do not hesitate in saying that you are broken. Go to the human mechanic and get your head checked.
:PROPERTIES:
:Author: Transfuturist
:Score: 1
:DateUnix: 1448684037.0
:DateShort: 2015-Nov-28
:END:


***** (. _ .)

/Who upvoted this?/
:PROPERTIES:
:Author: Transfuturist
:Score: 3
:DateUnix: 1448139782.0
:DateShort: 2015-Nov-22
:END:

****** What's wrong with discussion?
:PROPERTIES:
:Author: RMcD94
:Score: 1
:DateUnix: 1448634110.0
:DateShort: 2015-Nov-27
:END:

******* Our terminal goals are inherently opposed, and I consider any human who endorses the sort of terminal goals you are endorsing to be literally damaged in some way, emotionally or psychologically. Upvoting is not discussion. Upvoting is /approving of what you said./
:PROPERTIES:
:Author: Transfuturist
:Score: 1
:DateUnix: 1448649689.0
:DateShort: 2015-Nov-27
:END:

******** Upvoting is certainly not agreement...

Otherwise you couldn't get Confession Bears, or AskReddit posts about "worst thing you've done" and other stuff.

If you use upvotes that way you're genuinely misusing the website.

Also I can't possibly believe you have read lesswrong if your response to any sort of point is assuming the person saying the point is damaged
:PROPERTIES:
:Author: RMcD94
:Score: 0
:DateUnix: 1448653347.0
:DateShort: 2015-Nov-27
:END:

********* u/Transfuturist:
#+begin_quote
  Upvoting is certainly not agreement...
#+end_quote

I did not say that. I said it was /approval,/ meaning that there are people who want to encourage that sort of post. I disapprove that approval. I do not want to give you a voice, because your voice may convince others of the 'correctness' of your goals. This is a border where censorship is absolutely acceptable to me.

#+begin_quote
  if your response to any sort of point is assuming the person saying the point is damaged
#+end_quote

It is /not/ a /point!/ It is a fundamental denial of everything reasonable to my values, and to the values of anyone who wishes to remain intelligent or even to treat humans as representing their own interests! /You said yourself you would/ */give no choice to anyone,/* /converting humans into wireheads because/ */humans are an inefficient form of computing bliss!/* If you truly endorse this, we are enemies. I do not value your own satisfaction in this. I value your dissatisfaction. You are /damaged./ I may not qualify as Friendly, but you are /anti-Friendly./ *You are fundamentally horrifying to me.*
:PROPERTIES:
:Author: Transfuturist
:Score: 1
:DateUnix: 1448670201.0
:DateShort: 2015-Nov-28
:END:


***** [Utilitarianism intensifies]
:PROPERTIES:
:Score: 1
:DateUnix: 1448295612.0
:DateShort: 2015-Nov-23
:END:

****** Indeed
:PROPERTIES:
:Author: RMcD94
:Score: 1
:DateUnix: 1448299407.0
:DateShort: 2015-Nov-23
:END:
