#+TITLE: Philosophically Curious George and the Limits of Empiricism

* [[http://existentialcomics.com/comic/132][Philosophically Curious George and the Limits of Empiricism]]
:PROPERTIES:
:Author: wtfbbc
:Score: 54
:DateUnix: 1469297110.0
:DateShort: 2016-Jul-23
:END:

** I might just have an unsophisticated opinion, but there's something about this comic that irks me.

Finding out that 5 - 3 = 2 wasn't magic, it happened because he counted bananas and fingers. Just because you can abstract that information and come to the conclusion that 5 - 3 = 2 is universally true, doesn't mean that it's not an empirical fact that was arrived at by observation. If you make a deduction and also realize that 6 - 4 = 2 without going out and counting things again, well that's because you got the empirical basis right in the first place. You deductions are only as good as your premises, and to get those right you have to go out and look! This doesn't defeat empiricism. If you didn't go out and look at the world, you wouldn't notice that there's a difference between discrete and continuous quantities and you'd be tripped up when someone asked you "Why do two puddles equal one puddle when added together? Does this make your math false?".

Then, it seems like he goes on to treat categories like they're real things floating out there in the abyss, rather than properties of brains that can't avoid classifying things. There are soft, red candles that smell like roses too! Categories fall apart when you prod them hard enough, they aren't these ideal things that you arrived at without looking at the universe! To think that you came to this idea of a candle without your senses seems blatantly silly to me, a blind and deaf person would never have that concept without being told about it. People get caught up in these classification problems like "Is it still a candle if I don't use wax?", and /that should be a hint, people/. A hint that we're making it up as we go along, and if a candle was a platonic ideal then you shouldn't be able to create an object where half the attributes point to "candle" and half the attributes point to "not candle".
:PROPERTIES:
:Author: DeterminedThrowaway
:Score: 39
:DateUnix: 1469308009.0
:DateShort: 2016-Jul-24
:END:

*** Ok, before I write anything else, it's worth noting that /I absolutely freaking love you guys on this sub/. Like, I drop a one-liner, and two other people come in with the /pinpoint correct/ objection to the comic.

That said, it's worth giving credit to the comic for just being about the history of philosophy as commonly taught to, most likely, undergrads. Philosophers working several hundred years ago didn't possess concepts like "causal role", "discrete versus continuous", "reduction", or "causal generative model", let alone disciplines like topology or information theory.

Hell, the way that abstract knowledge and domains emerge from the hierarchical correlation structure in empirically-observed data has /only just these past few years/ become readily apparent, to the point that I can still (somewhat) write a paper about it and be (almost, mostly) saying something novel.

Point being, freaking love you guys.
:PROPERTIES:
:Score: 24
:DateUnix: 1469314457.0
:DateShort: 2016-Jul-24
:END:

**** u/creatureofthewood:
#+begin_quote
  the way that abstract knowledge and domains emerge from the hierarchical correlation structure in empirically-observed data has only just these past few years become readily apparent
#+end_quote

Huh. If that's true then I guess previous innovations turn into a culture's subconscious background assumptions /really fast/ because I can hardly imagine any other sensible answer...what did they think caused categories before, if not regularities in the underlying structure of observations?
:PROPERTIES:
:Author: creatureofthewood
:Score: 6
:DateUnix: 1469343415.0
:DateShort: 2016-Jul-24
:END:

***** That's all the stuff about Platonic ideals....but I agree with you, I've totally internalised the "categories for man" "carve reality at the joints" "bleen/ rube" idea of categories to the point where I can't really imagine a sensible alternative.
:PROPERTIES:
:Author: CoolGuy54
:Score: 6
:DateUnix: 1469346210.0
:DateShort: 2016-Jul-24
:END:

****** Well yeah but that's Plato and he's an ancient. I assume he's mostly the foil against which new philosophers cut their teeth against than an actual representation of what people seriously think?

I feel like the naive view would automatically tend to the (ostensibly) correct one, and platonism is what you get if you think about it too hard and end up confusing yourself with your own semantics, but that might just be because I've been encultured with that view or something.

Heh, maybe "thinking so hard they get confused by their own semantics" describes a lot of philosophers actually.
:PROPERTIES:
:Author: creatureofthewood
:Score: 8
:DateUnix: 1469346659.0
:DateShort: 2016-Jul-24
:END:

******* u/deleted:
#+begin_quote
  I assume he's mostly the foil against which new philosophers cut their teeth against than an actual representation of what people seriously think?
#+end_quote

Well, the issue here is that you used the word "against". Not so much "against", usually, as "with". His influence over the field of philosophy has been really, really, /reaaaally/ long-lived, to the point that the view labeled "realism" in many fields of philosophy X is easier to just label as "Platonism about X".
:PROPERTIES:
:Score: 2
:DateUnix: 1469390549.0
:DateShort: 2016-Jul-25
:END:


***** u/deleted:
#+begin_quote
  If that's true then I guess previous innovations turn into a culture's subconscious background assumptions really fast
#+end_quote

LW is a subculture whose founder happens to have reinvented (I'm not sure if he did it independently of Friston et al's theoretical neuroscience work) much of what later became the Bayesian Brain Theory, which has very clear implications regarding how categories and such work, without quite ever becoming a neuroscientist.

Or he may just have been transcribing the neurosci literature into the Sequences. I can't date and cross-reference all of it; I just think with the benefit of hindsight that Eliezer should have bothered publishing a lot of his ideas as "real" statistics, information theory, and machine-learning so he could get his name on what're now the best-in-class theories of how minds work.
:PROPERTIES:
:Score: 3
:DateUnix: 1469364121.0
:DateShort: 2016-Jul-24
:END:

****** Honestly, that's just how I've always thought about categories before I had ever heard of lesswrong or was exposed to any philosophy in general. It never occurred to me to think of it in any other way.

The meaning of words is rich with connotations and associations. The dictionary just attempts as best as possible to define what we mean by the words. I feel like this fact should be instantly apparent to anyone who has ever been asked to define a word or translate a word to a speaker of another language. The hard part is more making the belief explicit rather than an implicit background assumption. If I were to ask a random high schooler this question... well I'd have to do some thinking about how to phrase a question like this but I think they would give the right answer.

I think maybe somewhere along the line some influential person had a compelling but wrong idea and it somehow mislead philosophers from the intuitive and correct idea?
:PROPERTIES:
:Author: creatureofthewood
:Score: 1
:DateUnix: 1469379549.0
:DateShort: 2016-Jul-24
:END:

******* u/deleted:
#+begin_quote
  I think maybe somewhere along the line some influential person had a compelling but wrong idea and it somehow mislead philosophers from the intuitive and correct idea?
#+end_quote

Yes. The compelling but wrong idea was, "Once you clean them up and apply context, words are like symbols in a formal logical calculus: they precisely indicate a single, precise referent." This runs contrary to what the entire rest of linguistics ever since has found, which is that words are noisy statistical symbolized optimized for coding length.
:PROPERTIES:
:Score: 5
:DateUnix: 1469384739.0
:DateShort: 2016-Jul-24
:END:

******** u/Anderkent:
#+begin_quote
  is that words are noisy statistical symbolized optimized for coding length
#+end_quote

I have to know, was this on purpose? This doesn't parse for me, but I got your meaning anyway. Did you do that to demonstrate the noisy, coding-length optimised symbolism, or was it accidental?

(in particular 'symbolized' comes out of nowhere)

Aside: I don't think "optimised for coding length" is accurate. A lot of language is optimised for being self-correcting. You have redundancies in grammar, word choice, phrasing that make it possible to capture meaning even if you can't understand every single thing someone's saying. This is of course at the cost of coding length.

A language optimised for coding length would not have one or two-letter combinations not assigned to a meaning.
:PROPERTIES:
:Author: Anderkent
:Score: 1
:DateUnix: 1469456588.0
:DateShort: 2016-Jul-25
:END:

********* Not on-purpose, sorry. I derp up sometimes.

But yeah, ok, optimized for likelihood the listener can understand when the message is partially redundant and they (the listener) have limited attention and computing power to spend decoding the utterance.
:PROPERTIES:
:Score: 3
:DateUnix: 1469458090.0
:DateShort: 2016-Jul-25
:END:

********** Well, I'd be really impressed with the next level-edness of that message had it been on purpose :P
:PROPERTIES:
:Author: Anderkent
:Score: 2
:DateUnix: 1469460762.0
:DateShort: 2016-Jul-25
:END:


********* Isn't it generally a tradeoff between both? Our abbreviated words / portmanteaus are invariably based on existing words (so they satisfy both length and self-correctability). Occasionally a portmanteau becomes more legitimate than its roots, and then itself becomes a candidate for portmanteauing.

That said, my impression of everyday English language favors coding length somewhat (people generally say short things and complain if misunderstood, rather than saying somewhat longer, more explicit things.)
:PROPERTIES:
:Author: tilkau
:Score: 2
:DateUnix: 1469457417.0
:DateShort: 2016-Jul-25
:END:

********** Right, yes, I didn't mean to go too far in the other direction. What I wanted to point out is that there's multiple tradeoffs in every language, it's not all just coding length.

Another tradeoff, for example, is how fast people speak. Languages that are spoken more rapidly (like spanish) tend to have more redundancy in their grammar.

Generally there's a pretty set limit in how fast people can actually ingest verbal information; languages make different tradeoffs in terms of how it's transmitted.
:PROPERTIES:
:Author: Anderkent
:Score: 2
:DateUnix: 1469460721.0
:DateShort: 2016-Jul-25
:END:


** Most of so-called unconditional beliefs in fact aren't. A good example about 2+2=4 can be seen [[http://lesswrong.com/lw/jr/how_to_convince_me_that_2_2_3/][here]].

People are often too fascinated by disciplines based on "pure thought" to notice they have quite mundane origins. Geometry, for example, was born from measuring fields using stakes with ropes tied to them (this is where concepts of a point and line come from).
:PROPERTIES:
:Author: PlaneOfInfiniteCats
:Score: 10
:DateUnix: 1469311994.0
:DateShort: 2016-Jul-24
:END:

*** I still think that articles fails to consider that we can learn from patterns in our observations, as well as the literal content of our observations. Though it appears that I am putting two headphones together with two headphones to get 3 headphones, I am fairly certain that I could puzzle out I seem to be perceiving a single additional illusory headphone, based on the behavior of said headphones.

Not that empirical observation isn't still key in order to putting mathematics to any actual use. Two plus two equals four because we say so, but that only means anything in a concrete sense because we consistently observe behavior in the world which it models well (mostly because, as you say with Geometry, because we designed it be a decent model to begin with).

e-

Because something bothered me about how I phrased this, I put it in slightly more metaphorical terms.

You can't disprove a hammer does what hammers do, but you can disprove that your problem is a nail.
:PROPERTIES:
:Author: Aabcehmu112358
:Score: 6
:DateUnix: 1469318019.0
:DateShort: 2016-Jul-24
:END:


** When do we get nonparametric hierarchical Bayesian George?
:PROPERTIES:
:Score: 13
:DateUnix: 1469301468.0
:DateShort: 2016-Jul-23
:END:


** I take issue with the comic as a whole (as I do most of those on that site), but the bit about the concept of time in particular annoyed me.

No, you don't need the concept of time to make observations about things changing. Look at something twice and you have observed a change in time, even if you do not know what time is. You don't need to have a concept of something to be subject to it, otherwise the concept of ignorance would be incoherent.

Naturally, once you have observed a change you can keep exploring the concept to discover that the rate of change appears unrelated to many things, like whether you are awake or asleep, bored or excited, running fast or standing still (for non-relativistic speeds of course). Maybe it's an external phenomenon, then.

Further, you can create a little device that "ticks" at a predictable rate and use that to measure the rate of other things and thus build up a vast and coherent picture of the concept. Heck, you might even find a more reliable "ticker" than your original idea if your results have errors.

In essence, not only is time a perfect concept for empirical study, our concept of it has been empirically improved since we initially developed it (see relativity).

And a brief bit about the ladybug: yes, you may need a lot of concepts to be able to understand a particular new concept. As the saying goes, no shit Sherlock. Breaking down a problem and studying its component concepts is kinda one of the core tenets of empiricism.
:PROPERTIES:
:Author: ZeroNihilist
:Score: 8
:DateUnix: 1469339172.0
:DateShort: 2016-Jul-24
:END:

*** I thought the ladybird was illustrating that empiricism doesn't bootstrap itself. You need a lot of background knowledge before you can empirically observe "there is a ladybird on the ground". And every part of this background knowledge, in turn, requires its own library of background knowledge before it can be empirically observed. The recursion bottoms out somewhere. There must be pieces of knowledge that you didn't acquire through observation of the outside world.
:PROPERTIES:
:Author: Chronophilia
:Score: 2
:DateUnix: 1469569926.0
:DateShort: 2016-Jul-27
:END:


** I guess a metal cage isn't so different from an ivory tower.
:PROPERTIES:
:Author: renegadeduck
:Score: 5
:DateUnix: 1469320423.0
:DateShort: 2016-Jul-24
:END:
