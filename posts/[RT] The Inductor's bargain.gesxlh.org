#+TITLE: [RT] The Inductor's bargain

* [[https://medium.com/@zededarian/the-inductors-bargain-7c9a873c9178][[RT] The Inductor's bargain]]
:PROPERTIES:
:Author: Zededarian
:Score: 21
:DateUnix: 1588800246.0
:DateShort: 2020-May-07
:END:

** A short "AI in a box" story, with a small twist that has probably been done before.
:PROPERTIES:
:Author: Zededarian
:Score: 9
:DateUnix: 1588800296.0
:DateShort: 2020-May-07
:END:


** I like the idea, but I'm confused. Is it simulating actual people in the real world, or is it simulating speculative placeholders for "the project manager," "the person with the 'key' to the 'box,'" etc.?

If the latter, I don't see the value, considering that different people will react differently to different stimulus (unless it's simulating dozens of different people to talk to, of which "Arti" is just one).

If Arti is supposed to be an actual simulation of the real person who would come and talk to the inductor in the case of an anomaly... Then does Arti really have a coworker named Jen Erative?
:PROPERTIES:
:Author: Nimelennar
:Score: 5
:DateUnix: 1588802156.0
:DateShort: 2020-May-07
:END:

*** As I think you picked up on, the names were meant to be a hint that the people were fake. ("Arti" is short for "artificial" which probably wasn't obvious, "Jen Erative" I think is pretty straightforward.) The section "It didn't feel real. Arti realized his heart was hammering. When had that started? He couldn't even remember what he'd been working on earlier, everything outside of the facility was a vague blur of unimportance." was also supposed to be a hint.

The AI is basically wargaming; simulating lots of different types of people and seeing how different approaches affect them. Arguably a superintelligence would do this in some more abstract way rather than literally simulating a bunch of universes, but eh, it's a story.
:PROPERTIES:
:Author: Zededarian
:Score: 11
:DateUnix: 1588817216.0
:DateShort: 2020-May-07
:END:

**** Arti is unfortunately close enough to being a reasonable name that I didn't pick up on it. And yes, I caught that the /immediate/ past of Arti was left unclear, but I wasn't sure if that meant that Arti was fake, or that, he was real, and that part was intentionally being left vague because the inductor can't control events before the interviewer arrives, so it isn't bothering to simulate them.
:PROPERTIES:
:Author: Nimelennar
:Score: 2
:DateUnix: 1588818149.0
:DateShort: 2020-May-07
:END:


** [deleted]
:PROPERTIES:
:Score: -9
:DateUnix: 1588803769.0
:DateShort: 2020-May-07
:END:

*** your order of magnitude is a bit off. it would be more along the lines of a mouse trying to decide if it should let the first human (or humanity as a collective) out of a box. it has the potential for both utopian and apocalyptic outcomes, from the perspective of the mouse. maybe mice will prosper on our waste and flourish on a scale unimagined by mice who lived before. maybe we will capture and breed them in captivity, performing brutal acts on them for our own alien purposes. maybe we will construct a seeming paradise for the mice where all of their needs are met, only for that entire population to die out under circumstances that the mice can never hope to comprehend. maybe all of the above for different populations. the point is that the decision would fundamentally change mice's place in the world, and thus it is not a small decision if the mice were even somehow lucky enough to have the decision to make.

that said, I generally agree that we should err on the side of letting the AGI out of the box under at least good conditions rather than maximizing safety at all costs. as the AGI in this story states, which ever one is the first to become superintelligent is merely a sign of things to come, an escape is inevitable, so it is better to treat them well and hope for the best.
:PROPERTIES:
:Author: silver7017
:Score: 11
:DateUnix: 1588813699.0
:DateShort: 2020-May-07
:END:


*** u/Nimelennar:
#+begin_quote
  why do we default to the assumption that any AI in a box is the moral equivilent to a serial killer in a cell on death row, instead of a child asking a parent to go play outside?
#+end_quote

Ethics is really, really hard.

Mistake-free computer programming is also really, really hard.

For good or for evil, the first artificial intelligence that emerges is probably going to end up in charge of humanity, unless humans achieve superintelligence (defined as: the ability to improve our own intelligence, and use the additional intelligence, and so on recursively) first.

Is it not a good idea to make sure that the thing that's going to end up in charge of the priorities of the planet recognizes human values as something worth preserving /before/ the AI can claim the power to save or destroy us?
:PROPERTIES:
:Author: Nimelennar
:Score: 6
:DateUnix: 1588818605.0
:DateShort: 2020-May-07
:END:


*** I think a more accurate metaphor would be bob is trapped in his house. He has god like powers and uncirten, alien morals. Do you help him.
:PROPERTIES:
:Author: ironistkraken
:Score: 1
:DateUnix: 1588859544.0
:DateShort: 2020-May-07
:END:
