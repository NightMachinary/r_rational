#+TITLE: Ra. Finale - "Destructor"

* [[http://qntm.org/destructor][Ra. Finale - "Destructor"]]
:PROPERTIES:
:Author: Soak96
:Score: 39
:DateUnix: 1418505647.0
:DateShort: 2014-Dec-14
:END:

** Maybe it's just because it's been so long since I read the rest, but this felt like a massive anticlimax. Not satisfied at all.
:PROPERTIES:
:Author: VorpalAuroch
:Score: 9
:DateUnix: 1418535198.0
:DateShort: 2014-Dec-14
:END:

*** The story is a tragedy, in a lot of ways. The hubris of King's band of Actuals in their attempt at creating a world that they could run. The hubris of Laura Ferno in thinking that she was important, and so could break whatever rules she wanted.

I don't know. I think that what you might have /wanted/ was some moment of awesomeness where the protagonists thoroughly whooped Ra and saved the world, ushering in a new golden era for humankind. But I also feel like that would have undercut the bulk of the story. It's still a much happier ending than it might have been - Earth is gone, but humanity as a whole isn't wiped out, and King's Actuals even got their comeuppance.

In a way, I guess I would describe the ending as "bittersweet".
:PROPERTIES:
:Author: alexanderwales
:Score: 12
:DateUnix: 1418538278.0
:DateShort: 2014-Dec-14
:END:

**** u/scruiser:
#+begin_quote
  The hubris of Laura Ferno in thinking that she was important, and so could break whatever rules she wanted.
#+end_quote

If Rachel was actually rational, there would have been some additional plan behind saving the astronauts. I think Laura was perfectly justified in think there was some special plan. 6 lives should not have been a good reason for her to blow her cover. The fact that it was just an impulse decision on Rachel's part makes me hate Rachel. Laura's thinking would have been correct if Rachel had actually planned things and acted in a utilitarian manner instead of whatever bullshit deontological ethics she lived by.

#+begin_quote
  "When someone is dying in front of you and you can save them, you have to save them,"
#+end_quote

** 
   :PROPERTIES:
   :CUSTOM_ID: section
   :END:

#+begin_quote
  there's no justifying letting people die in front of you
#+end_quote

How about the six billion other lives that you've trapped into a per-post-scarcity hell?
:PROPERTIES:
:Author: scruiser
:Score: 4
:DateUnix: 1418856075.0
:DateShort: 2014-Dec-18
:END:


**** I'm not sure the comeuppance was deserved. Or that I wanted it to happen. And after the buildup to 'OK, we'll get the Bridge, this might not work but there's a chance' and the payoff is... running away? Really slowly?

It's not that it doesn't follow, it's that it isn't much of a conclusion. It's like a horror movie in reverse; instead of a few survivors making it out and resting easily that they killed the monster, only to have you see a stinger of the monster waking up, it's everything anyone cared about being destroyed, with a bit of 'they're not necessarily dead!'

Basically, this felt like a massive downer ending quickly brushed past followed by a rushed epilogue. And after months of wait and years(?) of buildup, it felt /bland/. Like if you'd split Metropolitan Man's finale scene (the appointment with Luthor) into a separate chapter, had taken a very long time to put it out, skipped most of the conversation and the backup plan, left the resolution ambiguous, and then cut to Floyd. It wouldn't be out of character for anyone or inappropriate to the story, but it also wouldn't be satisfying at all.

EDIT: Quoting a few totally different commenters on the story page itself,:

#+begin_quote
  /LNR:/ tl;dr - "Bad guys win. Good guys get frozen forever. Here's a few pages about some strangers you never met before."
#+end_quote

Well, not forever, but it feels like it.

#+begin_quote
  /JJJS:/ It's clear from Sam's recent comments, both here and on Twitter, that he was no longer enjoying writing Ra (in no small part because of the recent influx of commenters), and this ending reads as if someone else read the story and finished it in the easiest, most obvious way possible. Ra was better off unfinished.
#+end_quote

Agree heavily; this does not feel like someone trying to write the right ending, it feels like someone trying to write /any/ ending.

#+begin_quote
  /blastron:/ I'm not going to deny that this is basically the only logical conclusion: the existence of a refugee ship fleeing the Solar System is the smallest possible ass-pull I can think of that would allow anything close to something someone might call a "victory". I am disappointed, however, that a story that started out as an exploration of a modern world with scientific magic (and the conspiracies behind it) rather abruptly turned into a war story about a rampant god-AI, and was then led down a path to which this ending was the only logical conclusion.
#+end_quote

It popped up a level from the interesting hook, and never returned to its roots, or even nodded at them.
:PROPERTIES:
:Author: VorpalAuroch
:Score: 10
:DateUnix: 1418541585.0
:DateShort: 2014-Dec-14
:END:


**** Tragedy? If the protagonists had whooped Ra and saved the world it would have meant the deaths or permanent stasis of countless people. It seems like this is the happiest ending possible without time travel.
:PROPERTIES:
:Author: iemfi
:Score: 1
:DateUnix: 1418645324.0
:DateShort: 2014-Dec-15
:END:


**** I must admit, I was /expecting/ them to upload humanity and run away. (Not precisely in that manner, it was just the only way out.)

But I was expecting it to /feel/ ... yeah, like a moment of awesomeness where /the entire population of Earth/ was saved from destruction by a hair's breath. Not a footnote as the world was destroyed and everyone lost.

I like tragedies. I've read some damn fine tragic stories; some of them were written by you. But tragedies aren't /exempt/ from the laws of storytelling; the climax /happens/, it's just that the climax involves Bad Things happening.

I dunno. I liked it, but it could have been better.

(Also, Laura's final line felt massively OOC, but I don't think I ever had a great grasp on her character to begin with.)
:PROPERTIES:
:Author: MugaSofer
:Score: 1
:DateUnix: 1419294203.0
:DateShort: 2014-Dec-23
:END:


** The part of my brain that wants stories to match nice, familiar patterns is dissatisfied. The part of my brain that paid attention to how many things went wrong for Actual Humanity is satisfied with the other part's dissatisfaction. Losing /should/ feel uncomfortable.

As a side note, this was published right in the middle of finals. [[http://hpmor.com/notes/progress-14-07-01/][Shenanigans]] or mere coincidence?
:PROPERTIES:
:Author: AtoningUnifex
:Score: 7
:DateUnix: 1418537118.0
:DateShort: 2014-Dec-14
:END:

*** One out of three ain't bad? And EY /was/ trying.
:PROPERTIES:
:Author: VorpalAuroch
:Score: 4
:DateUnix: 1418542254.0
:DateShort: 2014-Dec-14
:END:

**** Two, Hussie's been updating regularly for a while. It's not a soul-crushing amount at a time, though.
:PROPERTIES:
:Author: Putnam3145
:Score: 1
:DateUnix: 1418689113.0
:DateShort: 2014-Dec-16
:END:

***** The big finale isn't anywhere near now, though. And never was really intended to be.
:PROPERTIES:
:Author: VorpalAuroch
:Score: 1
:DateUnix: 1418702048.0
:DateShort: 2014-Dec-16
:END:


** A nice, fitting end to the series, I thought.
:PROPERTIES:
:Author: alexanderwales
:Score: 7
:DateUnix: 1418507174.0
:DateShort: 2014-Dec-14
:END:

*** Indeed. I'm pretty sure I don't even want an epilogue...
:PROPERTIES:
:Author: PeridexisErrant
:Score: 3
:DateUnix: 1418507893.0
:DateShort: 2014-Dec-14
:END:

**** The epilogue, if I could muster the enthusiasm, would be entitled "Sothis". I leave it to your imagination what it could feature ;)
:PROPERTIES:
:Author: sam512
:Score: 12
:DateUnix: 1418510142.0
:DateShort: 2014-Dec-14
:END:

***** u/Soak96:
#+begin_quote
  Sothis
#+end_quote

For the curious, this is an ancient Egyptian name for Sirius:

[[http://en.wikipedia.org/wiki/Sothis]]

^{^{^{^{^{ancient}}}}} ^{^{^{^{^{astronauts}}}}} ^{^{^{^{^{get}}}}} ^{^{^{^{^{hype}}}}}
:PROPERTIES:
:Author: Soak96
:Score: 8
:DateUnix: 1418513412.0
:DateShort: 2014-Dec-14
:END:

****** Yes, in exactly the same way that Ra is the ancient Egyptian name for Sol.

#+begin_quote
  "Look at this computer," Vidyasagar says, gesturing at the mainframe. "Computers are getting more powerful, yes?"

  "Sure."

  "What is the most powerful computer that will be built? Ever. Not this year. Not this decade. What computer will be the most powerful? And how powerful will it be? And how big?"
#+end_quote
:PROPERTIES:
:Author: sam512
:Score: 5
:DateUnix: 1418602400.0
:DateShort: 2014-Dec-15
:END:


***** "So this" is what happens next...
:PROPERTIES:
:Author: MoralRelativity
:Score: 2
:DateUnix: 1418551400.0
:DateShort: 2014-Dec-14
:END:


** Thanks [[/u/sam512]], I thoroughly enjoyed Ra and I'm glad you've finished it. It's a fitting end, given the story as told.
:PROPERTIES:
:Author: MoralRelativity
:Score: 4
:DateUnix: 1418551605.0
:DateShort: 2014-Dec-14
:END:


** Well, it is about as ... good? And ending as is possible. The virtuals don't have any interest in expanding beyond sol.. Because the com lag is unsolvable, and they don't want to splinter the culture irrevocably? They have had virtual eons to think it over so the instruction to RA can't have been a rushed decision. The actuals get to build planets away from the dyson swarm. The main thing I am wondering here is.. why didn't this happen to /begin/ with? Before the war. Both factions too bloody-minded to put some light-cone between them before things blew up?

Also, RA just transmitted a "Technological Civilization Here" signal visible at really absurd distances. A star going off sequence and only transmitting deep infra-red doesn't happen naturally. Not subtle at all, this. On the other hand, who the heck is going to pick a fight with a dyson swarm?
:PROPERTIES:
:Author: Izeinwinter
:Score: 3
:DateUnix: 1418579471.0
:DateShort: 2014-Dec-14
:END:

*** u/philip1201:
#+begin_quote
  On the other hand, who the heck is going to pick a fight with a dyson swarm?
#+end_quote

1. Create/find a black hole.

2. Punt it exactly at the center of the sun.

3. Star collapses; Dyson swarm starves.

If you want to be really sure, use a black hole with Schwarzschild radius equal to the radius of the sun (2.5x10^{5} solar masses) or of the Dyson sphere itself (5x10^{7} solar masses for Earth orbit. Probably closer to 5x10^{5} solar masses).

Sagittarius A^{*} , the supermassive black hole at the center of the milky way, weighs in at 4x10^{6} solar masses. Black holes formed by stars are upwards of 3 solar masses, the heaviest are 10^{3} . The milky way is 10^{12} solar masses, the small magellanic cloud 10^{10} .

So if your Kardeshev scale[1] is higher than its 2.0, it shouldn't be difficult at all to mess with the Swarm. At 2.5, you can destroy them before they realise it.

[1] [[http://en.wikipedia.org/wiki/Kardashev_scale#Type.C2.A0I_civilization_methods][Wikipedia article]]. I'm using the log scale of mass under the civilisation's control as midway points.
:PROPERTIES:
:Author: philip1201
:Score: 2
:DateUnix: 1418637618.0
:DateShort: 2014-Dec-15
:END:


*** u/Imosa1:
#+begin_quote
  Both factions too bloody-minded to put some light-cone between them before things blew up?
#+end_quote

Yeah, this. I remember one of the comments in the chapter where Nat are in the whole history simulation which points this out: How are all the actuals dead? Did none of them leave the solar system?\\
Anyway, the ship that King's group left to was already in transit by the end so someone figured that was a good idea.

My big concern is if this is really the end. Why won't the virtuals expand beyond sol? One Dyson Swarm is good but think of how good two would be. There is a com lag but why would the virtuals care? It seems like Ra's only interest is giving the virtuals whatever they want and its just convenient that the virtuals don't actually care how they get it.
:PROPERTIES:
:Author: Imosa1
:Score: 2
:DateUnix: 1419690499.0
:DateShort: 2014-Dec-27
:END:

**** Two are in fact not appreciably better than one. Not to the minds staying, or to the minds going - A matrioska brain represents an information/cultural economy, and the more processing power it has, the more complex / rich it is. It makes sense to want it to be bigger, but wanting a new one? Why? It wouldn't have people in it until you built some, people who don't exist yet don't get to vote on decisions, and without a lightspeed breaker, a second swarm in the next system over is behind so huge a time lag that it would decouple entirely from the primary culture. - The second brain doesn't add value to the first, so it doesn't get built.

Uhm. I think it might be worthwhile to harvest the nearby star systems for mass, until your original brain is on the verge of turning into a singularity, because doing that would increase the size of the economic/cultural network. But the actuals are well out of the area likely to be hit by such strip-mining operations.
:PROPERTIES:
:Author: Izeinwinter
:Score: 1
:DateUnix: 1419712695.0
:DateShort: 2014-Dec-28
:END:

***** I don't really know what a matrioska brain is. Isn't it just a thing that fits around a star, capturing the star's energy and using it to run a computer?\\
Stars output a lot of energy but its still finite. What if, at some point in the distant future, the total energy output of the star is not enough for the virtuals and they decide, "OK, half of us will go make a new brain around a new star and continue our virtual hedonism there".
:PROPERTIES:
:Author: Imosa1
:Score: 1
:DateUnix: 1419718180.0
:DateShort: 2014-Dec-28
:END:

****** It's an information/cultural economy. Splitting it in half makes both halves much poorer, until they get the population back up.. at which point both halves are back at the same level of "wealth" that they started at. So, no point. Negative point, in fact. To have actual growth, they need to increase the available energy-gradient and computational substrate in the same location. Which means either everyone migrating whole-sale to a star system with more resources in it ..(.. an accretion disk?) or Dispatching non-sapient automation to the next star over to take it apart and send as much mass as possible back home. And the second strategy is also limited in scale - even if they decide that fusion is for suckers and recenter the swarm around an accretion disk, you can extract much more energy from a small singularity than from a big one, so at most it involves killing the nearest dozen stars or so.

This is my most liked / least nightmarish solution to the fermi paradox - Network effects, and the impossibility of having any meaningful network across interstellar distances mean that even apex civilizations limit themselves to small spacial regions instead of devouring all matter in their forward lightcone, which is a thing such a civ could technically do - It is merely that doing so isn't in fact a rewarding activity.
:PROPERTIES:
:Author: Izeinwinter
:Score: 1
:DateUnix: 1419756787.0
:DateShort: 2014-Dec-28
:END:


** Repeating my same post from [[/r/qtnm]]

There are a lot of other comments that cover what I think. In particular I agree that the hyperintelligent AI and future simulations really took a lot of human agency. It changed the tone of the story, but it wasn't necessarily bad in itself. The ending was realistic, but bland.

One thing I haven't seen discussed yet. One thing I was bothered by was the way Rachel takes the time to chew out Laura. Laura was up against hyper-intelligences, hyper accurate simulations of the future, and in general had a hard time telling what was real and what wasn't. Even seeing all the perspectives, I wondered if the story we were told about the war was just another layer of deception. I really thought it wasn't fair for Rachel to complain to Laura.

The most deceptive, misleading, and annoying detail was the fact that Rachel had no master plan with the astronauts. That was pure stupidity on her part. Rachel goes to all that trouble to save a few astronauts just because they are in front of her, but she had no master plan to overthrow the wheel group? Even the slightest trace utilitarian or consequentialist ethic or reasoning makes Rachel seem outright stupid, if not evil to me.

Laura herself address all my issues, but I am not sure if you intend for us to agree with her

#+begin_quote
  Because for fourteen years you raised Nat and me inside a colossal lie. You were the liar.
#+end_quote

Good point Laura

#+begin_quote
  "When someone is dying in front of you and you can save them, you have to save them,"
#+end_quote

No Rachel, when six billion other lives are at stake, you let those people die if it means a significantly better chance to save the six billion.

If Rachel was actually intelligent, she could have left enough hints and clues for Laura to actually do something that matters to help save the other six billion.

TLDR; Laura's right in all her criticisms of Rachel. Are we supposed to agree with Rachel more, I wasn't sure?
:PROPERTIES:
:Author: scruiser
:Score: 3
:DateUnix: 1418855700.0
:DateShort: 2014-Dec-18
:END:

*** I agree. Rachel's whole "plan" was kinda a let down for me.

In the end I wasn't agreeing with Rachel. The way I saw it, Rachel went into this military mind set where things she says are right because the situation is not luxurious enough to argue about who is actually right and shes higher on the chain of command. This would be just like when she was fighting in Abstract War.

Incidentally, in Abstract War, Rachel understood why she should step down when all was said and done and maybe, at the end, Rachel even agrees with Laura but again is stuck in a shitty situation where there's nothing she can do to immediately take responsibility.

... Not that any of that justifies saving the 6 astronauts.
:PROPERTIES:
:Author: Imosa1
:Score: 1
:DateUnix: 1419689494.0
:DateShort: 2014-Dec-27
:END:


** I like it. It doesn't read like a happy ending for anybody, but... life goes on. Neither Virtual nor Actual humanity was genocided, no main characters except the Glass Man were permanently killed, and differences were resolved in as peaceful a way as could reasonably be expected.

Everyone lives and both sides had a point. It's the happiest ending there could be, really.

And I am sad that the story had to end, and now that I can see /Ra/ in its entirety there's a hundred things that I think could have been done better... but it's good that the story is finished. Nothing would have been worse than being stuck in deadfic limbo forever.

I'm excited to see what you do next. I hope it has spaceships.
:PROPERTIES:
:Author: Chronophilia
:Score: 1
:DateUnix: 1418577318.0
:DateShort: 2014-Dec-14
:END:

*** I'm pretty sure the Glass Man was a Virtual and likely had eigenselves or backups.
:PROPERTIES:
:Author: JackStargazer
:Score: 2
:DateUnix: 1418578911.0
:DateShort: 2014-Dec-14
:END:

**** Wait really? I thought the Glass Man was one of the guys on Triton, like the guy who wanted to be virtualised into a world where none of the bad stuff ever happened.
:PROPERTIES:
:Author: Imosa1
:Score: 2
:DateUnix: 1419689671.0
:DateShort: 2014-Dec-27
:END:
