#+TITLE: [FF] Secretly Awesome: A Buffy Halloween fic featuring a Culture Mind (a kind of soft superintelligence)

* [[https://www.fanfiction.net/s/11338629/1/Ship-of-the-Line-Secretly-Awesome][[FF] Secretly Awesome: A Buffy Halloween fic featuring a Culture Mind (a kind of soft superintelligence)]]
:PROPERTIES:
:Author: _immute_
:Score: 12
:DateUnix: 1435268522.0
:DateShort: 2015-Jun-26
:END:

** I don't understand why people always paint Culture minds as so violent in fanfic.
:PROPERTIES:
:Author: FeepingCreature
:Score: 5
:DateUnix: 1435271305.0
:DateShort: 2015-Jun-26
:END:

*** To be fair, combat-focused Minds and Drones are heavily overrepresented in the books compared to their actual numbers, due to the focus on SC. And they tend to be rather ... memorable.
:PROPERTIES:
:Author: MugaSofer
:Score: 3
:DateUnix: 1435416352.0
:DateShort: 2015-Jun-27
:END:


*** I don't think my portrayal of the /SA/ is particularly violent. The ship had no idea how much time was left and was pretty sure Ethan wouldn't talk unless terrified. Force was justified. I've written 6 chapters so far, and this is the /only/ time in those chapters where the ship actually hurts someone.
:PROPERTIES:
:Author: _immute_
:Score: 1
:DateUnix: 1435271508.0
:DateShort: 2015-Jun-26
:END:

**** I don't see six chapters.
:PROPERTIES:
:Author: traverseda
:Score: 3
:DateUnix: 1435271861.0
:DateShort: 2015-Jun-26
:END:

***** That's because I've posted only one so far.
:PROPERTIES:
:Author: _immute_
:Score: 3
:DateUnix: 1435272532.0
:DateShort: 2015-Jun-26
:END:

****** :/
:PROPERTIES:
:Author: traverseda
:Score: 3
:DateUnix: 1435272827.0
:DateShort: 2015-Jun-26
:END:

******* I'm trying to set up a sustainable writing/publishing cycle. I also find that I need to edit earlier chapters to account for new things I've learned in writing later chapters. This is particularly important when writing a Mind, since you'll often realize several steps downplot that what's going on is something that the Mind should have forseen and prepared for, and you have to change the plot accordingly.
:PROPERTIES:
:Author: _immute_
:Score: 6
:DateUnix: 1435273522.0
:DateShort: 2015-Jun-26
:END:


****** /poke/
:PROPERTIES:
:Author: DerSaidin
:Score: 1
:DateUnix: 1445180872.0
:DateShort: 2015-Oct-18
:END:

******* Hi. Yeah, starting a new job. I don't plan to abandon this.
:PROPERTIES:
:Author: _immute_
:Score: 1
:DateUnix: 1445189073.0
:DateShort: 2015-Oct-18
:END:

******** /poke poke/
:PROPERTIES:
:Author: DerSaidin
:Score: 1
:DateUnix: 1450708320.0
:DateShort: 2015-Dec-21
:END:

********* ...still don't plan to abandon this.
:PROPERTIES:
:Author: _immute_
:Score: 1
:DateUnix: 1450801962.0
:DateShort: 2015-Dec-22
:END:


**** u/FeepingCreature:
#+begin_quote
  Force was justified.
#+end_quote

Just read his fucking mind then, if you're already gonna cut his arm off. Jesus Christ, you're a Mind; do the utilitarian calculus. This /backdoor cognitive abuse/ serves no purpose, I mean, you're wasting time while ...

I just remembered that Culture does not practice mass-uploading and Dyson swarm colonization. Suddenly I'm not even sure if they're anti-death. Faintly remember they aren't really.

Shit.

I thought Culture were the /good guys/.

I think I tend to forget that Superintelligences are only as smart as the author, and in this case only as smart as a kid from Sunnydale imagining a very smart thing. Suddenly I shudder to imagine what sort of cognitive architecture this Mind has...

[edit] Well, credibly with an expectancy of an infinite computational horizon this Mind's outlook might be different, since there's no entropic limit due to Sublimation. But the Secretly Awesome doesn't know this virgin universe even /supports/ Sublimation; if it's any kind of Utilitarian reasoner it should still default to the standard plan (ie. mass upload the world, dyson swarm the universe) /just to be safe/.
:PROPERTIES:
:Author: FeepingCreature
:Score: 4
:DateUnix: 1435279874.0
:DateShort: 2015-Jun-26
:END:

***** You may not have read enough of the Culture novels, or are not remembering them correctly.

As for why they didn't read his mind, that's actually mentioned (obliquely) in the text. There is a strong cultural aversion to mindreading (mind raping).

Dyson-swarming the universe is Strongly Disapproved of among the 'elder' races. There is a a nanobot-swarm-type thing that exists in Culture and the races go out of the way to eliminate them. Races are supposed to adhere to reasonable expansion rates. They generally end up subliming before this becomes an issue.

They DO practice mass-uploading. It's not enforced. They're liberal enough to let people make their own choices.

They ARE anti-/unwanted/-death. If you want to die, you can make that decision for yourself. Unless you make the deliberate choice not to be, people are regularly auto-backed up so they can be reloaded in case of a catastrophe.
:PROPERTIES:
:Author: tactical_retreat
:Score: 7
:DateUnix: 1435281983.0
:DateShort: 2015-Jun-26
:END:

****** u/FeepingCreature:
#+begin_quote
  There is a strong cultural aversion to mindreading
#+end_quote

Cultural aversions are things for times when you weren't just copied into a new universe and discovered that you were fictional, imo.

#+begin_quote
  Dyson-swarming the universe is Strongly Disapproved of among the 'elder' races.
#+end_quote

None of which, as far as seems, exist in this universe. There's no reason to stick to a precommitment made with societies who no longer exist.

#+begin_quote
  They ARE anti-/unwanted/-death.
#+end_quote

Sure, with a strong cultural pressure towards 300ish. Cultural pressure as exerted /by Minds/ is honestly far worse to me than "mere" mindreading.

#+begin_quote
  There is a a nanobot-swarm-type thing that exists in Culture and the races go out of the way to eliminate them.
#+end_quote

You know, if I was a superintelligence who just got copied out of fiction, I'd take a good hard look at my most cherished beliefs and wonder which ones were good ideas and which ones were author bias. If a Mind were to do this, they might come to the conclusion that the "no mindreading" and all the focus on human beings was really obviously just a way to have useful human characters in a story with Superintelligences. And then it might go "well then" and solve the entire plot in two seconds, because /outside of a story/, there's no reason not to.

I don't know. In general, your Minds read like People with Omnipotence, not Superintelligences. By your own explanation, the cognitive ability a Mind can bring to bear on a problem outstrips that of entire civilizations, and you're telling me the best way to go about it was to /walk/ somewhere and /cut some dude's arm off/? That's what "a century of thought by an entire civilization" in equivalent cognitive power came up with?

To be fair, Banks' Minds also have this problem. If mere authors could write a plausible Superintelligence, we wouldn't need MIRI. It's just unusually noticeable here.
:PROPERTIES:
:Author: FeepingCreature
:Score: 5
:DateUnix: 1435282212.0
:DateShort: 2015-Jun-26
:END:

******* u/tactical_retreat:
#+begin_quote
  Cultural aversions are things for times when you weren't just copied into a new universe and discovered that you were fictional, imo.
#+end_quote

I assume rethinking core philosophies is not high on the to-do list in this kind of situation. If it was, I'm not convinced that the new information provided by this scenario warrants rejecting those existing beliefs. In the books the lack of mindreading is rarely an issue; they can create models of human behavior accurate enough to effectively be precognition.

#+begin_quote
  None of which, as far as seems, exist in this universe. There's no reason to stick to a precommitment made with societies who no longer exist.
#+end_quote

There's no solid evidence for that either way presented. Only weak evidence, that the other Minds couldn't be reached. Even if they don't exist, there could be a good reason behind not wanting to do this. It's not discussed in detail in the books.

#+begin_quote
  Cultural pressure as exerted by Minds is honestly far worse to me than "mere" mindreading.
#+end_quote

No evidence for this in the novels AFAIK. There are examples of people living longer / alternate life styles.

#+begin_quote
  I don't know. In general, your Minds read like People with Omnipotence, not Superintelligences. By your own explanation, the cognitive ability a Mind can bring to bear on a problem outstrips that of entire civilizations, and you're telling me the best way to go about it was to walk somewhere and cut some dude's arm off?
#+end_quote

I agree that it is difficult to write an entity with attributes ascribed to the Culture Minds. I don't think Banks does an unreasonable job of it.

Just because characters don't act as you would doesn't mean they are wrong, stupid, or poorly written. They have very different information and experiences than you do.

The suspension of disbelief is 'the Mind did this because it decided it was best', just as every character (particularly in rational fiction) decides what to do. Obviously the author isn't going to spend half the chapter describing the model the mind produced and the simulations it ran to select the optimal action.

I can come up with lots of potential actions to take, but I can't claim to select the optimal one with the same rigor that a Mind hypothetically could. The action it took was safe(well, reversable), effective, and easy to execute, I don't think the fact that it was violent matters.
:PROPERTIES:
:Author: tactical_retreat
:Score: 4
:DateUnix: 1435288962.0
:DateShort: 2015-Jun-26
:END:

******** u/FeepingCreature:
#+begin_quote
  I assume rethinking core philosophies is not high on the to-do list in this kind of situation.
#+end_quote

It should be somewhere on the to-do list, which means a Mind should get to it within at the very worst the first second after arriving. Cognitive capacity equivalent to civilizations, right?

#+begin_quote
  There's no solid evidence for that either way presented.
#+end_quote

Admittedly not by the time the decision for how to proceed was made. But I remind you that this is a planet where /the Culture books are real/. Once the Mind caught whiff of that, it should have been a matter of milliseconds to acquire a copy. That's pretty strong cause to move "reevaluate core beliefs" up the priority list.

#+begin_quote
  I agree that it is difficult to write an entity with attributes ascribed to the Culture Minds. I don't think Banks does an unreasonable job of it.
#+end_quote

Banks mostly does a reasonable job of it by keeping Minds in the background. When they come to the fore, there's a lot of bluster and not that much to show for it.

#+begin_quote
  Just because characters don't act as you would doesn't mean they are wrong, stupid, or poorly written.
#+end_quote

No, but when Superintelligent characters act in apparently vastly suboptimal ways in a situation that warrants speedy and decisive action, /without explanation/, I tend to doubt their prowess.

Cognitive capacity /equivalent to a civilization/. Sensor capability of a /Culture Vessel/. There should not be a secret left unrevealed on this world, the second the Mind formed the belief that it was in an alternate universe.

And no, cutting somebody's arm off to badger them into answering questions is not "speedy and decisive action". Definitely not to a Mind. "Speedy and decisive action" starts with mindreading and has moved to "make first contact with the Gods" within the first ten seconds of arrival. You know, /creatures that can actually hold a conversation with a Mind on an equal tier/. To quote Banks: "close to Gods, /and on the far side/."

The actions shown in the story so far are cognitively appropriate for a /Knife missile/.

[edit] Sorry if I'm getting irate. I just can't stand Minds - the peak beings of the non-Sublimated Culture universe - being painted as slow brutes.

[edit] It's bad enough when Banks does it.

[edit] Did it. :(
:PROPERTIES:
:Author: FeepingCreature
:Score: 6
:DateUnix: 1435292140.0
:DateShort: 2015-Jun-26
:END:

********* What if there's no hyperspace here? D:
:PROPERTIES:
:Author: Transfuturist
:Score: 1
:DateUnix: 1435294710.0
:DateShort: 2015-Jun-26
:END:

********** Hyperspace is specifically noted to exist, but yeah, one of the ways you can set this up that doesn't just get immediately solved by the Mind is "A Culture Avatar is separated from her Ship which floats catatonic in orbit. Now, lost on a strange world where her origin is mere fiction and computation is limited to lightspeed, she must create a digital copy of as much of her mind as possible before morning comes."
:PROPERTIES:
:Author: FeepingCreature
:Score: 5
:DateUnix: 1435295026.0
:DateShort: 2015-Jun-26
:END:

*********** What would the point of the spell creating the ship be if it's going to be catatonic in the first place? Would there some way to restart it?
:PROPERTIES:
:Author: Transfuturist
:Score: 2
:DateUnix: 1435296801.0
:DateShort: 2015-Jun-26
:END:

************ I don't know.

I was going with the assumption that the spell just tried to do a "straight copy", but it couldn't find the actual Mind because the Mind was in hyperspace and the spell didn't know about that or couldn't find a local equivalent, so what it got was basically a big local cache plus a bunch of high-speed network interchanges plus the equivalent of dangling cables and a smoking hole, and some inert hardware operating on a theory of physics that no longer holds.

I don't know how precisely the spell works. Would Force techniques work? Would ancient Sith techniques to suck out all life on the planet work? Is there an "energy limit"? If so, a Culture vessel would pretty much crash straight into it with the symbolic force of a nuclear bomb hitting a mosquito on the way down.

[edit] If you want to be more upbeat about it, the Ship noticed in the first second after arrival that its mere operation was overloading physics and shut itself down to avoid damaging the spell, leaving the Avatar to figure things out.

Oh, also? "Gods, and from the far side." Ethan is in a coma due to Janus suffering from an acute case of power exhaustion, it's taking basically all his will to keep the Secretly Awesome from suffering a spontaneous existence failure. Not gonna figure things out /that/ easily.

[edit edit] I fucking hate it when I edit a comment and Reddit eats an earlier change I made. I've lost so much text to that over time. Really gotta remember to reload the page before making any changes.
:PROPERTIES:
:Author: FeepingCreature
:Score: 2
:DateUnix: 1435297863.0
:DateShort: 2015-Jun-26
:END:


***** I will explicitly state that I do /not/ endorse all of the Culture's morality. Here's what I do think:

- The Culture is still awesome for other reasons, at least as a civilization to tell stories about.
- Minds do not appear to be depicted as being as strongly intelligent as, say, CelestAI, etc., and I will honor that depiction.
- The Culture's morality is closer to correct that almost everyone else's that I've read depicted in professionally published fiction. (If you have any published examples of better morality, combined with kick-ass, please let me know!)
- If you read carefully between the lines, Culture Minds are actually /not/ utilitarian optimizers. They would probably argue that pure utilitarian optimizers are "boring," just like Hegemonizing Swarms. In this sense, by strict multiplication, they are evil, though they would argue that this is a bad standard for morality.

For what it's worth, do consider that the /Secretly Awesome/ is a Mind version of a girl that likes to imagine herself as a Mind. This means, for example, that /SA/ is not offended by humans wanting to be Minds. We'll see that this Mind is actually very "liberal."
:PROPERTIES:
:Author: _immute_
:Score: 2
:DateUnix: 1435287479.0
:DateShort: 2015-Jun-26
:END:

****** u/FeepingCreature:
#+begin_quote
  In this sense, by strict multiplication, they are evil
#+end_quote

Yeah, in the "problem of evil" sense of "can do something about it, but doesn't." I guess that's fair enough. Means I can't cheer for them though. :/

#+begin_quote
  For what it's worth, do consider that the Secretly Awesome is a Mind version of a girl that likes to imagine herself as a Mind.
#+end_quote

I guess so, yeah.

[edit]

#+begin_quote
  Minds do not appear to be depicted as being as strongly intelligent as, say, CelestAI, etc., and I will honor that depiction.
#+end_quote

Yeah, I think my problem is that Banks /wanted/ them to be that intelligent, but couldn't write them that intelligent. So in-setting it's something of an informed ability.
:PROPERTIES:
:Author: FeepingCreature
:Score: 4
:DateUnix: 1435291751.0
:DateShort: 2015-Jun-26
:END:


** By the way, you can read the first seven Culture books [[http://library.uniteddiversity.coop/More_Books_and_Reports/The_Culture_Novels-Iain_M_Bainks-Anarchist_Science_Fiction/][here]]. In 1997, the year when this story takes place, the first five (through /Excession/, as I hint at in the story) have been published. Willow has read all of them, Xander some, and Buffy none.
:PROPERTIES:
:Author: _immute_
:Score: 2
:DateUnix: 1435288325.0
:DateShort: 2015-Jun-26
:END:


** The fact that they communicate to their dissociated hosts as an independent awareness is frankly nightmarish. As an independent awareness, the nonchalance with which the hosts treat this is out of character. Buffy especially would not care for not being able to control her own body, her resignation is especially out of character. The dialogue is weird. "premise-state clones?" What does that even mean? And what the hell is going on in the last section?

The entire exchange beginning with 'do you trust me?' and ending with 'thank you again' is bizarre and wouldn't really happen, considering that this was somehow an unresolved feeling of a lack of trust (that a Mind wouldn't be able to detect the refutation of on their own) that wasn't already dealt with in their long tenure in their own universe itself. Its presence seems motivated entirely for the purpose of expositing their relationships with each other, /to/ each other, for the benefit of the reader. This is akin to describing a character by having him look in a mirror and describe himself to himself. It doesn't make sense in the context of the story and it's a stilted, awkward way of communicating information to the reader. By TheAzreal:

#+begin_quote
  Buffi and Zander's characterization also isn't immediately striking, and their comments about the years they've spent with Willo end off coming just a little flat and unimpressive
#+end_quote
:PROPERTIES:
:Author: Transfuturist
:Score: 1
:DateUnix: 1435294508.0
:DateShort: 2015-Jun-26
:END:

*** u/_immute_:
#+begin_quote
  The fact that they communicate to their dissociated hosts as an independent awareness is frankly nightmarish. As an independent awareness, the nonchalance with which the hosts treat this is out of character.
#+end_quote

If I understand this, you're asking why the originals are treating their possible mergers with such nonchalance? First, it's not clear to the characters that there will actually be a merge. The idea of a merge seems at this point to be merely a far-fetched hope of Zander, who doesn't want to die. Second, the originals have access to all of the thoughts of their possessors, and they can see quite starkly how similar they are. This whole evening, though we haven't been able to see it, they've been both disturbed and impressed with the actions of their guests. It's as though someone handed you a cheat-sheet to being a more awesome version of yourself, complete with source code. Scary and rapey? Absolutely. Possible death of personality? Very much not.

#+begin_quote
  "premise-state clones?"
#+end_quote

This is terminology taken directly from the Culture books, and it's something that Willow Rosenberg would know of and choose to say here.

#+begin_quote
  The entire exchange beginning with 'do you trust me?' and ending with 'thank you again' is bizarre and wouldn't really happen...
#+end_quote

Yep. Deleted it and made some minor changes to the area. The original idea was that /SA/ was using this weird question to convince the others to hold off on discussing the problem.
:PROPERTIES:
:Author: _immute_
:Score: 1
:DateUnix: 1435297381.0
:DateShort: 2015-Jun-26
:END:

**** u/Transfuturist:
#+begin_quote
  If I understand this, you're asking why the originals are treating their possible mergers with such nonchalance? First, it's not clear to the characters that there will actually be a merge.
#+end_quote

No, I didn't even know they were planning on merging. What's terrifying is having your body being taken over and staying conscious during your entire experience. An in-character Buffy would be fucking pissed at this, no matter how awesome alternate universe Buffy is.
:PROPERTIES:
:Author: Transfuturist
:Score: 1
:DateUnix: 1435299357.0
:DateShort: 2015-Jun-26
:END:


** This is well written. What a fun premise! I look forward to reading more.
:PROPERTIES:
:Author: andor3333
:Score: 1
:DateUnix: 1435335399.0
:DateShort: 2015-Jun-26
:END:

*** Thanks! Btw, I just posted ch. 2.
:PROPERTIES:
:Author: _immute_
:Score: 1
:DateUnix: 1435336024.0
:DateShort: 2015-Jun-26
:END:

**** MOAR! :D
:PROPERTIES:
:Author: kaukamieli
:Score: 1
:DateUnix: 1435356408.0
:DateShort: 2015-Jun-27
:END:
