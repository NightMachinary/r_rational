#+TITLE: How to know if you're right, when everyone around you thinks you're wrong? [D]

* How to know if you're right, when everyone around you thinks you're wrong? [D]
:PROPERTIES:
:Author: Kishoto
:Score: 25
:DateUnix: 1430264972.0
:END:
Ok, we can agree that public opinion is often wrong. It's debatebly easy to sway crowds. As they say, a person is smart, people are stupid. Mob mentality. Etc.

That being said, it's also not rational to hold onto an opinion if the rest of the world thinks it's wrong. Now, reality is reality. The sky's blue (usually). You drop a ball, it will fall to the ground. But it gets harder to identify fact from fiction when the issues get more complex, and I just want to know, is there any good, general techniques to ensure that, even if everyone in the room is telling you that you're wrong, you can be assured you're right? Simply having an unpopular opinion doesn't make it incorrect.

Sorry if I'm not very clear with my question! Also, I ask this here, because I find there seems to be a lot of intelligent people on this subreddit. :)


** No. If everyone in the room is telling you that you're wrong, you can occasionally be /fairly confident/ that you're right, but you certainly shouldn't be 'assured'.

Maintain the belief that you /could be wrong/. More importantly, learn to hold beliefs with varying levels of confidence - if everyone in the room thinks you're wrong, and you logically 'proven' to yourself that you are not.. you should have some significant doubt, especially if you can't point out a clear reason /why/ everyone would believe that untruth.

Now, to address what I think you're really after.. if you for some reason need to determine your correctness /suddenly/ - immediate consequences, basis for a time-limited decision, etc - then you should find someone willing and able to have a rational discussion about /why/ they hold the opinion they do, and /truly attempt to understand/. This is not an exercise in figuring out 'how they were wrong', you need to be able to imagine circumstances in which you would also believe that thing. If you can't easily/safely discuss the topic.. you're stuck. Treat your belief as non-confident to some degree.

In reality, that doesn't come up much. More often, you are asked to commit socially to an opinion, but there is no real fallout from /not committing/, or from expressing a lack of certainty. Express and maintain that lack of certainty, until you can consult someone who /ought to know better than you/ on the topic (not somebody from your community, or someone who will just agree with you, someone who has specific experience or expertise in the topic in question).

Edit: above all, be aware that humans (even ones who really should know better) are /terrible/ about updating their beliefs. Do /not/ commit to one and pretend you're going to come back and reassess later.

Edit: clarified leading sentence slightly.
:PROPERTIES:
:Author: nevinera
:Score: 38
:DateUnix: 1430266487.0
:END:

*** #+begin_quote
  Maintain the belief that you could be wrong. More importantly, learn to hold beliefs with varying levels of confidence - if everyone in the room thinks you're wrong, and you logically 'proven' to yourself that you are not.. you should have some significant doubt, especially if you can't point out a clear reason why everyone would believe that untruth.
#+end_quote

Also, formal logic is a very leaky abstraction for dealing with things that aren't ontologically basic (ie: most things), so you should trust apparent empirical evidence over "logical" argumentation. Look at the way the world seems to be, rather than what it sounds like in your head.
:PROPERTIES:
:Score: 11
:DateUnix: 1430267036.0
:END:

**** One of my favorite techniques: figure out a way for their 'incorrect' belief to allow someone to generate profit. Then determine if anyone actually is generating a profit in that way.
:PROPERTIES:
:Author: nevinera
:Score: 25
:DateUnix: 1430269423.0
:END:

***** [[https://xkcd.com/808/][Relevant XKCD]]
:PROPERTIES:
:Author: ulyssessword
:Score: 17
:DateUnix: 1430273781.0
:END:

****** [[http://imgs.xkcd.com/comics/the_economic_argument.png][Image]]

*Title:* The Economic Argument

*Title-text:* Not to be confused with 'making money selling this stuff to OTHER people who think it works', which corporate accountants and actuaries have zero problems with.

[[http://www.explainxkcd.com/wiki/index.php/808#Explanation][Comic Explanation]]

*Stats:* This comic has been referenced 100 times, representing 0.1624% of referenced xkcds.

--------------

^{[[http://www.xkcd.com][xkcd.com]]} ^{|} ^{[[http://www.reddit.com/r/xkcd/][xkcd sub]]} ^{|} ^{[[http://www.reddit.com/r/xkcd_transcriber/][Problems/Bugs?]]} ^{|} ^{[[http://xkcdref.info/statistics/][Statistics]]} ^{|} ^{[[http://reddit.com/message/compose/?to=xkcd_transcriber&subject=ignore%20me&message=ignore%20me][Stop Replying]]} ^{|} ^{[[http://reddit.com/message/compose/?to=xkcd_transcriber&subject=delete&message=delete%20t1_cqs6tpe][Delete]]}
:PROPERTIES:
:Author: xkcd_transcriber
:Score: 9
:DateUnix: 1430273794.0
:END:

******* ..wait, 100 exactly?
:PROPERTIES:
:Author: appliedphilosophy
:Score: 1
:DateUnix: 1437871597.0
:END:


***** This. Took me a while to realize that myself.
:PROPERTIES:
:Author: recursiveAI
:Score: 1
:DateUnix: 1430345194.0
:END:


***** What if they actually are, but they keep technology in secret being afraid of competition?
:PROPERTIES:
:Author: rakov
:Score: 1
:DateUnix: 1438516880.0
:END:

****** The conditions required for that to be relevant are pretty narrow, but it's a valid concern. The profit-generating techniques are usually not complicated enough for technical feasibility to play a role - this approach is not as appropriate for evaluating assertions about physics or engineering with non-obvious impacts.
:PROPERTIES:
:Author: nevinera
:Score: 1
:DateUnix: 1438618328.0
:END:


*** In addition, you should avoid having strong beliefs about very complicated systems: social systems, real economies, individual human minds, 'the future of AI', and political policy are all excellent examples.

No matter how much of an expert you are on any of those topics, you do not /grok/ them, and you cannot make dependably accurate predictions about them. If someone else seems to be offering a high degree of confidence about anything like that, they are exaggerating - look for a motive (conscious or unconscious).
:PROPERTIES:
:Author: nevinera
:Score: 5
:DateUnix: 1430306837.0
:END:


*** In some sense /logic/ is a tool specifically for that - try to express your assumptions and definitions clearly to yourself.
:PROPERTIES:
:Author: nevinera
:Score: 2
:DateUnix: 1430266716.0
:END:

**** You have to be careful, since logic is also very good at letting people reinforce incorrect beliefs.
:PROPERTIES:
:Author: Uncaffeinated
:Score: 2
:DateUnix: 1430280402.0
:END:

***** Yes, but if anything can help you determine your own correctness in a vacuum, it'll have to be the process of defining your belief and assumptions and then examining your own logic a link at a time.
:PROPERTIES:
:Author: nevinera
:Score: 3
:DateUnix: 1430305503.0
:END:


***** This. To my ears, in common parlance "logic" seems more synonymous with "the application of /modus ponens/" than with any form of formal logic.

Who needs to be explicit with assumptions when they're obvious a any rational person would automatically know them??
:PROPERTIES:
:Author: xelxebar
:Score: 1
:DateUnix: 1430848389.0
:END:


*** #+begin_quote
  No. If everyone in the room is telling you that you're wrong, you can be fairly confident that you're right, but you certainly shouldn't be 'assured'.
#+end_quote

No, you can be fairly (60+%) confident that you are wrong, not right assuming a reasonably homogenous group. Scrutinize and question your beliefs very carefully.
:PROPERTIES:
:Author: distributed
:Score: 1
:DateUnix: 1430306103.0
:END:

**** Sorry, my wording was ambiguous. I meant that you /can occasionally/ be fairly confident under certain circumstances, not that you generally should be confident.

If you can find a clear profit-motive or a social-motive for /asserting/ the believe you are encountering, then it should barely affect your confidence. Standing in a church with an opinion about the presence of a deity would be an obvious example. The polarization of politics in the US makes it actually /hard/ to find a sizable homogenous group without strong social motives for having a huge variety of specific beliefs about social structure and economics.
:PROPERTIES:
:Author: nevinera
:Score: 7
:DateUnix: 1430307299.0
:END:

***** Point well made.
:PROPERTIES:
:Author: distributed
:Score: 2
:DateUnix: 1430309077.0
:END:


**** #+begin_quote
  No, you can be fairly (60+%) confident that you are wrong, not right assuming a reasonably homogenous group. Scrutinize and question your beliefs very carefully.
#+end_quote

No, because you are assuming a reasonable level of rational introspection and extrospection on the part of the group.

For example, there is no logical proof of the modernly popular abrahamic deity, but if I walk into a church and say "There is no god", the churchgoers will tell me I am wrong and that there is a god, despite an overwhelming lack of evidence to base their opinion about.

A more correct response would be "No, you can be >50% confident that you yourself are wrong, assuming a reasonable homogenous group".
:PROPERTIES:
:Author: Arizth
:Score: 2
:DateUnix: 1430419678.0
:END:


** This sounds worthy and thoughtful, and I wish you the best of luck. There are many places to turn to learn and to find resources about how to disagree and what it means to know you're right when others thing you're wrong. It might be worth checking out [[/r/lesswrong]] (or [[/r/lesswronglounge]] ?), which is a subreddit related to the Less Wrong rationalist community. Other places to check out include the comments section of the blog [[http://slatestarcodex.com/][Slate Star Codex]] which is full of people who are trying to become well-versed in all manner of things.

What you're describing is interesting, and I guess the underlying question here is how much other people's opinions should matter. The problem isn't people disagreeing with you, the problem is being wrong, and there are many correct facts that people agree on. It's also annoying and difficult to have an opinion many people disagree with. Having an unpopular opinion has negative consequences that I'll address later. For now let's focus on being right when people are wrong without losing your ability to adopt people's correct opinions.

*** Being right when people are wrong
    :PROPERTIES:
    :CUSTOM_ID: being-right-when-people-are-wrong
    :END:
So, my usual strategy is to only trust people to be right about certain things. There's a large class of subjects that I expect almost everyone in my life to agree on and be mostly correct about. Examples include basic arithmetic, common-use definitions of American English words, and everyday skill knowledge like cooking, operating consumer electronics and machines at a basic level, writing, reading, and so on. On these things, if I have confusion, I usually bring it up but don't cling to it if most people disagree with me.

In domains where knowledge is specialised or difficult to acquire in an unbiased fashion (politics, automobile repair, organic chemistry, religion, laws of a specific country or city, microelectronics, local geography of suburban town, martial arts or combat training, etc), I do not automatically defer to those around me. Instead, I defer to them on subjects that I judge them to be likely to know about. If I'm in a room full of lawyers from India, and there's a lively discussion happening about the best way to travel between two cities in India, and I have an opinion they disagree with, I'll generally assume I'm wrong and they're right. On the other hand, if we get into a discussion of microelectronics and I have an opinion and they all disagree with it, I see no reason to thing they are right while I am wrong.

My father is a domain expert in real estate, european literature, German, Farsi, and French. If I'm hanging out with him and his real estate agent friends and I have a certain opinion about whether or not it's possible to legally sell a home in a certain way, and they all disagree, I'm almost certainly wrong. We run into an interesting case though if I express an opinion about real estate politics ("we should have more high density housing in SF!") and they disagree. When we run into issues where people have a motivation to have a certain belief, we have to counterbalance expertise with motive. If I'm hanging out with my dad's Persian friends and try to talk about Iran, things get even worse. They may not have motivation about a particular answer, but there will be all kinds of identity politics gumming up the works of discussion. If they all think Rouhani is a swell dude and the clerics need to butt out, and that would help Iran's economy, that's fine. Still, I have to think about the fact that that might be an expression of their distaste for Islamism and not an expression of their thoughts on the best policies for the management of the Iranian state. If I express some disbelief in Rouhani's economic policies, their subsequent attack won't be an expression of their thoughts on the price controls placed on staple goods, but rather a way of defying the theocracy that plagues the Iranian government.

So, if people are disagreeing with you, and you want to factor this into your decision about whether or not to change your opinion, you need to think about why they're disagreeing with you, and how much they know about a subject matter, and whether they have other thoughts on their mind. My roommate hates techy culture, despite being a techy person, because of past experiences with the dark side of Silicon Valley tech norms. An expression of distaste for a hackathon isn't necessarily a swipe against pizza, beer, and crappy code, but could be a swipe against negative past experiences. When the rightist branch of my family expresses distaste for my leftism, that doesn't tell me anything about the truth. My family would be annoyed by leftist thoughts whether or not these thoughts are correct.

Choose which groups you discuss things with carefully. The opposite problem is actually much more common. It's really really easy to notice when you disagree with most people. They'll let you know. If you're wrong, and you disagree with everyone, I am absolutely certain that people will let you know you're wrong. The much more dangerous scenario is being wrong when everyone else is wrong. This isn't something that is easily noticed.

Being right when everyone else (in the room with you) is wrong is unsettling. I don't really know that I've been in a situation where I've felt seriously threatened by disagreeing with people, though. This is probably the largest amount of thought I've put down about what it's like to disagree with people, because for me it's fairly natural. I'm extraordinarily stubborn (and nobody will tell me otherwise! hueheuhue) when it comes to people, but not when it comes to facts. Take your time and learn what you want to learn

*** Dealing with consequences of disagreemnt
    :PROPERTIES:
    :CUSTOM_ID: dealing-with-consequences-of-disagreemnt
    :END:
So, I've been rambling a lot and probably have gotten off message here. My usual strat is to not tell people I disagree with them! :D
:PROPERTIES:
:Author: blazinghand
:Score: 11
:DateUnix: 1430269891.0
:END:

*** Very well put. Other than the nebulous "how smart/rational is person X," the two most important factors in determining how seriously I take their views is their expertise on the topic and their motives.

Sometimes it comes off to others as an ad hominem to dismiss arguments for these reasons. While most reasonably intelligent people accept that if they have not studied biology or computers their beliefs on the topics are ill informed, when it comes to political or social or economic issues, everyone has an opinion and few appreciate having their lack of credibility pointed out.

In the ideal world, arguments are judged on their own merits, and who says them is completely immaterial. But when an argument literally /can't/ be judged on its own merits, because we don't possess the necessary, hard to acquire information related to it, or if the ultimate truth of the statement is impossible to verify, or if the justification for the argument relies on a difference of values, then focusing on the person is a useful shortcut for determining how much stock to put in what they say.

Also,

#+begin_quote
  If I'm hanging out with my dad's Persian friends and try to talk about Iran, things get even worse... their subsequent attack won't be an expression of their thoughts on the price controls placed on staple goods, but rather a way of defying the theocracy that plagues the Iranian government.
#+end_quote

Son of another Iranian immigrant here. Can confirm.
:PROPERTIES:
:Author: DaystarEld
:Score: 4
:DateUnix: 1430283441.0
:END:


** That's basically, like, the entire task of rationality. The first step is to be unsure, and the second is to let yourself be moved by external facts about the world that /aren't/ generated by people.
:PROPERTIES:
:Score: 10
:DateUnix: 1430267091.0
:END:


** Reality can't be bought, it cant be bullied, it cant be reasoned with and it cant be negotiated with. Reality just wants the world to turn.

So find a way for reality to point out the right of way. A test to see if proposition X, yields result Y.

Also get some sort of area of effect weapons like a flame thrower, to keep away mobs of people who want to ignore your arguments and argue pointlessly.
:PROPERTIES:
:Author: rationalidurr
:Score: 6
:DateUnix: 1430286414.0
:END:


** You know whether you're right or wrong by the evidence.

So, if someone advances an opinion or several people advance an opinion it doesn't mean much. Whenever you hold a piece of knowledge you should ask yourself "How do I know what I know" (i.e. what evidence is there for it) and "What is the majority consenus of actual experts who have studied the matter?"

The two questions normally go together because experts tend to know things based on evidence.

You don't have to agree with the experts, but you have to agree with the evidence. What studies do they have to support their view, what analysis, what experiences? You should know these about whatever issue so you know how strong the evidence is in favor of whatever view.

A lot of popular culture views aren't amendable to evidence. We should ban gay/ interracial marriage because it will destroy traditional marriage? How do we know it will destroy traditional marriage? How quickly will it destroy traditional marriage? What countries has it successfully destroyed gay marriage in, how unhappy are relationships in that country? Those who advance views like the above don't tend to have a good answer to such questions and so it being a popular view doesn't mean much.

Or for a previous question you asked, how successful is x diet plan. How large was the study used to test its success? How much weight was lost on average? How well did people adhere to the diet? Did they prove their point metabolically?

Stuff like that. If you want to know you're right you have to have numerical answers to questions like that which can reliably predict the future.
:PROPERTIES:
:Author: Nepene
:Score: 4
:DateUnix: 1430305786.0
:END:


** I think "How to know /whether/ you are right, without resorting to popular consensus" is a better way to put this. (Because we want to actually /be/ right, not prove that our opinion /was/ right)

#+begin_quote
  Now, reality is reality.
#+end_quote

Not really. If you're thinking in a philosophical sense, you can't ever know. Your methods of calculating truth are just a result of your brain's hardware, and at bottom there's no final justification for any of it other than that's what /you think/. It is analogous to morality in that way.

Practically speaking, it depends. If the question is not philosophical but a complex empirical issue, you go to places like this [[http://scholar.google.com/]] and this [[http://www.ncbi.nlm.nih.gov/pubmed]] and so on and take stock of the evidence.
:PROPERTIES:
:Author: ishaan123
:Score: 3
:DateUnix: 1430323956.0
:END:


** Find cases where you will find out in the foreseeable future if you were right. Set numerical probabilities. Bet, if they'll let you. That is how you practice and calibrate any abilities you think you have to update well on other people or disagree with them well.
:PROPERTIES:
:Author: EliezerYudkowsky
:Score: 3
:DateUnix: 1430417382.0
:END:

*** How would you suggest doing this with complex issues? I can't say if the Baltimore riots will help with any racism issues in America, and I'm fairly certain that, if they do, the effects will be subtle, and over a prolonged period of time, with a number of other mitigating factors. Not something I can really predict.
:PROPERTIES:
:Author: Kishoto
:Score: 2
:DateUnix: 1430436845.0
:END:

**** #+begin_quote
  in the foreseeable future
#+end_quote

As you said yourself, yours is a bad example because a "prolonged period of time" is longer than the "foreseeable future."
:PROPERTIES:
:Author: what_deleted_said
:Score: 1
:DateUnix: 1435337032.0
:END:


** Great question. I'd also recommend posting questions like this on [[http://lesswrong.com/][lesswrong]]'s discussion broads.
:PROPERTIES:
:Author: Igigigif
:Score: 3
:DateUnix: 1430266082.0
:END:


** I'd say that you have to understand the arguments of others before you can judge the relative strength of your own position. I have a personal example.

I was a jury boss at one point, for a court case where there were about twenty charges. I (and everyone else on the jury) were convinced that the defendant, who had not even shown up to court, was guilty of all charges, except one.

I was the only jury member who was unconvinced of the most serious charge, the one which had the potential for significant jail time.

There was a bit of irritation towards me, but I short-circuited it by simply asking everyone else to explain to me why they thought like they did. Most of them couldn't articulate reasons. Two could. Between the two of them, they helped me bridge some things together and see things from a perspective that I hadn't considered.

The rest of the group had been right. I had missed a couple critical connections, but only two of the others were able to actually explain their position.
:PROPERTIES:
:Author: Farmerbob1
:Score: 1
:DateUnix: 1430331049.0
:END:


** You know you're right if your method works. You know you're wrong if your method doesn't work. If I predict an eclipse tomorrow based on my knowledge, and that eclipse doesn't happen, I'm wrong. If I predict no eclipse tomorrow, and there is one, I'm wrong. If everyone everywhere predicts and eclipse tomorrow and there isn't one, everyone everywhere is wrong.
:PROPERTIES:
:Score: 1
:DateUnix: 1430341077.0
:END:

*** I get that, but when the issue gets complex, it's hard to say. It's not always that simple, especially when there's a lot of data involved.

For example, the riots in Baltimore. I got into a charged argument with my three friends (for reference sake, we're all black people) about it, and its effectiveness. My argument is that I feel this sort of violent outburst only makes those responsible for the injustice (be they the justice system, the police, the government itself) feel justified if there is a racist element to this sort of thing. In addition, I think the number of unarmed black male shootings that have become sensationalized recently are just that; sensational. I'm not saying that it's right, or just, or anything like that. I'm saying when you have a country with over half a million cops, and 300 million people, screw ups are BOUND to occur. And we shouldn't use that as an excuse to go "Fuck the system!!". Does the American justice system have flaws? Hell yes. But I feel like these shootings aren't as systemic as these incidents would have you believe. I think it's an error in judging scope. We know humans have trouble with scale once we surpass a certain number.

In this case, my three friends feel that the shootings are a tragedy, a result of a system steeped in racism. While I'm not arguing to the system being racist/non-racist, I'm arguing to the fact that 5-6 (?) unarmed black male shootings out of the 650 odd people killed in police altercations in 2014, seems to be an acceptable number when you note that there are over ten million arrests made by police every year.

I know that sounds callous, but that's my viewpoint. Needless to say , my friends disagree. And while I feel I have a rational view, I also feel my friends are fairly intelligent (easily on my level, although they don't partake in rationalism) so the 3 on 1 odds made me wonder.

TL;DR: Complex topics make it hard to rationally decipher facts. I feel the Baltimore riots are a result of the recent over-sensationalization of unarmed black male shootings. Said sensationalization occurs due to the anecdotal logical fallacy, in my opinion, vs. there being a real issue. Opinions?
:PROPERTIES:
:Author: Kishoto
:Score: 2
:DateUnix: 1430361275.0
:END:

**** Oh, I never said it was simple. Here's some of the problems:

- Police forces are being militarized. They are given weapons and taught to defend themselves with lethal force in a reactionary fashion to perceived threats, rather than trying to de-escalate. Some lady is disagreeing with them in public loudly but non-violently? Pepper spray. Someone walking down the street asserting their right to leave if not being detained? Tasered. Someone checks their cell phone? Shot. Somewhere along the way the police started being taught their lives were more important than ours, rather than they were the few noble volunteers who took the risks the public shouldn't have to. Now instead it's the public on the chopping block of a police force that protects and serves itself.
- Police forces are being immunized. They are exempt from most on-duty crimes and the consequences of their actions, and a large portion of their off-duty crimes too. This is done in the name of team unity, since police have to work together, but it's being done too strongly and there is no longer an adversarial incentive to stay straight and honest and clean. The blue shield insulates everyone on its side of the line.
- Police forces are being privatized. The mayor gets campaign donations from corporations telling him how they would like laws enforced. The mayor passes this down to the police chief, who is has power over because he assigns him. The chief makes this a quota, or a priority, because it's an election season and it looks good for the mayor if they can cut a particular kind of crime. Regardless of if that coincides with the will of the people.
- Police forces are being vilified. There's a deliberate effort to make police forces seem more racist than they are. If 70% of violent crime is committed by blacks (Warning: Hypothetical Premise!) then it is not racist that when cops investigate crimes, they find a 7:3 ratio of black to non-black and end up arresting more blacks than other races.

Combining ALL of these factors makes for one hell of a mess, one that feeds back into itself as police get more accused, more scared, more vilified, more reactionary, stick together tighter, care less about their actual duty, as the "race problem" appears to grow worse, as the top men decide something must be done... and so on around the multidimensional vortex of failure.

We need to hold cops to higher standards than citizens. If a cop can shoot someone they think was reaching for a gun, kill them, be wrong, and not even lose their job, much less go to jail, then a civilian should have more right than that to perform self defense, without facing charges. Now it seems clear that this level of permissiveness in self-defense killings among civilians is unjustified and absurd. So it should be doubly absurd for police, who in addition to being held to higher standards and charged with protecting the lives of even criminals with their own lives, also wear body armor and have advanced training! Cops need to be held accountable, and taught to de-escalate rather than shoot first and get a pat on the back for offing another black guy probably up to no good.

Similarly certain demographics who have issues and attitudes with the police need to understand that those very attitudes, deserved or not, are part of the problem. I understand their concern. If you literally can't trust the police to not shoot you while you walk down your block at night, then you really should be shooting cops to kill or disable. Going to jail is a fair measure better than being killed outright. But that action would require you to actually believe and be justified in believing that the cops are out to kill you. And in some places, they might be able to make that case, but I won't deign to judge what places that might be.

Money has to be kicked out of politics. Corporations have to stop being treated like people. Stockholders should be liable for the actions of companies they own stock in, and when a corporation is found guilty of something, they should feel the sting. Owning stock in a corporation is just like having a share ownership of a poorly socialized pit bull. You're responsible for the people it bites. Bribes to government officials under the guise of campaign donations need to be penalized and prosecuted.

So yes, the issue is complicated, and there's plenty of blame to go around in many directions. Cops want to not die on the job nor be prosecuted for their mistakes in the same way a civilian would be. People in high-crime demographic profiles want to believe they're more than safe from, but protected by the police, innocent until proven guilty, and not guilty until shot dead. Corporations want the high-crime demographic eliminated and legal authority in their hands. And the general public wants accountability and transparency.
:PROPERTIES:
:Score: 2
:DateUnix: 1430363337.0
:END:


** This thread has been linked to from another place on reddit.

- [[[/r/lesswrong]]] [[https://np.reddit.com/r/LessWrong/comments/34crbb/how_to_know_if_youre_right_when_everyone_around/][How to know if you're right, when everyone around you thinks you're wrong? (Crosspost from r/rational)]]

[[#footer][]]/^{If you follow any of the above links, respect the rules of reddit and don't vote.} ^{([[/r/TotesMessenger/wiki/][Info]]} ^{/} ^{[[/message/compose/?to=/r/TotesMessenger][Contact]])}/

[[#bot][]]
:PROPERTIES:
:Author: TotesMessenger
:Score: 1
:DateUnix: 1430361704.0
:END:


** Best existing essay on the topic I know of is the [[http://lesswrong.com/lw/1kh/the_correct_contrarian_cluster/][Correct Contrarian Cluster]]
:PROPERTIES:
:Author: khafra
:Score: 1
:DateUnix: 1430503068.0
:END:


** You have to have blind faith in your position and just instinctively know tht everyone else is wrong. /s
:PROPERTIES:
:Author: libertarian_reddit
:Score: 0
:DateUnix: 1430328340.0
:END:


** When people disagree with me on subjects that actually matter to them (i.e. there are more incentives for them to be correct than not) then they're probably correct and I'm probably wrong.

If there are no such incentives then the disagreement is only weak evidence of me being wrong.
:PROPERTIES:
:Author: Predictablicious
:Score: 0
:DateUnix: 1430334723.0
:END:

*** Given this logic, all the religions in the world are correct at the same time.
:PROPERTIES:
:Author: what_deleted_said
:Score: 0
:DateUnix: 1435585975.0
:END:
