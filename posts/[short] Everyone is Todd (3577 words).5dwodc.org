#+TITLE: [short] Everyone is Todd (3577 words)

* [short] Everyone is Todd (3577 words)
:PROPERTIES:
:Author: marmoulman
:Score: 71
:DateUnix: 1479619791.0
:DateShort: 2016-Nov-20
:END:
“Todd?”

Blake forced his eyes open, wincing at the stabbing light. “Sorry, love. I was listening, just resting my eyes for a minute.” He got a brief glimpse of Jane, a dark shadow against the harsh backdrop of light, then shut his eyes again.

Jane clucked her tongue sympathetically. “Headaches gotten worse?”

Blake nodded into his folded hands. “Much. Can barely fucking see.”

A sudden warmth pressed against his folded arms as Jane pressed a mug of hot cocoa towards him. “Don't spill it, that's our last packet. I'll pick some more up if the plows ever get to our street.”

“You're an angel, Jane.”

Blake could almost hear the grin in her words. “You just have low standards, Todd. I'll pick up some more Advil too, just in case. The doctor said it should clear up soon.”

He could still see the afterimage of Jane's sillouhette, burnt into his eyelids in a vivid purple-blue. He reached out with one hand and wrapped around the base of the mug, pulling it closer to himself. His stomach wasn't up to input just yet, but the warmth helped spread off the numbness he'd been feeling for the day.

“I hope so,” Blake said, and again his voice felt wrong. Too low? Too high? Blake couldn't tell. Just... wrong. Everything felt wrong, somehow.

“Hopefully it clears out before the recital.” Jane's voice came from the other side of the counter, and a moment later he heard the rushing static of the sink. “She hasn't taken off her little wings all week, I don't think she'd forgive us if we weren't front row.”

The water stopped, and in a moment Jane was back with a wet cloth. “You want this? Or is the cocoa good?”

Blake shook his head. “The cocoa's enough. Thanks, though.”

Her kiss felt warm on his ear. “Don't mention it. Anything I can do to help.”

It hadn't been this bad yesterday, he was sure. The migraines had been bad for the past week or so, but he'd still been functional. He'd even chaperoned for the sleepover party, for Ca-

The dull ache in his head rose to a sudden explosion, and Blake snapped his head upwards, scrabbling at his ears. A sleepover for... his daughter?

Blake barely even registered as the mug dropped into his lap, spilling the scorching hot liquid before shattering on the floor. It was like someone was splintering a mirror and stuffing the pieces down his ears, filling his head with jagged pain and crackling stabs of sound. It got worse, every time he tried to think about Ca-

He thought he was screaming, but he couldn't hear it over the crunching, breaking sound in his head. His legs kicked out by reflex and he toppled out of the chair, spilling into the hot chocolate and the cold tiles.

“I'd be doing more to help,” Jane grumbled from above him. “If it wasn't for all this goddamn snow.”

Her voice cut through the static in his head, perfectly normal. She rapped on a window with her knuckle. “Six feet in the last three days, and no one can be bothered to do anything about it all. You picked a good time to lay low and relax, since it's pretty much all you can do. I feel like we'll be stuck in here forever.”

On the floor, Blake howled noiselessly. He couldn't remember his daughter's name, or face, or anything. He couldn't remember his sister. Did he have a sister? And what was his name, again?

Blake felt the scream choke off in his chest as he ran out of breath, but he couldn't remember how to breathe, not with his head this full, this painful, this loud.

“Well, its a good thing we only had Cathy and the girls for last night, not all week like the original plan. That would have been a ten-drink problem even without a headache!”

Why aren't you doing anything? Blake would have screamed, if he could. Instead, he could only twitch, blind and deaf and full of noise and light, until the numbness he had been feeling for the past week wiped out everything else, and he was in darkness.

--------------

“Oh dear,” came an amused voice. “Todd, you have gotten quite off script.”

Blake came back to himself, or at least consciousness, with a jolt. He was still in his kitchen, soaked in hot chocolate and staring at the battered underside of his kitchen table. His head felt wonderfully light, and even the burns from the spilled cocoa were gone. He tried to push himself to a sitting position, but his hand slipped on a piece of the broken mug.

“One moment, I'll help you up.” Blake felt someone grab him by the armpits and haul him upwards, and he scrambled for purchase on the linoleum tiles. He grabbed frantically at a dining room chair and hauled himself up into it, hands shaking so much he almost fell again.

It took a few moments of clutching the chair like a liferaft before Blake realized he wasn't breathing.

“Don't just hug the thing, you silly man. Sit down.” Blake managed to turn his head without losing his grip on the chair, but there wasn't anyone there.

“You may as well get comfortable while I sort this out. It looks bad, I may even need to do a full reset.”

The voice was feminine, brusque, the sort of no-nonsense tone you'd expect from an old nun, or schoolteacher. It came from somewhere before him, but the kitchen was empty. Jane had vanished from next to the sink, leaving nothing but a wet washcloth sitting on the wooden counter.

What is going on? Blake would have asked, if he could. He didn't feel short of breath or dizzy, he just... couldn't remember how to breathe. He'd never needed to remember it before, had he? It had just happened.

“You're probably from Old Sol. I've been pushing off dealing with it for ages now. Still, you're the only one off script, so it can't be too bad just yet. I think we will just need to move the databanks.”

The voice was coming from the hallway entrance, right next to the picture of Ca-

Blake peered closer. The picture was there, he could see every detail, but it just flowed right out of his head. He thought there was a man in it, perhaps him? It couldn't be; he had a beard. Didn't he? Blake rubbed his fingers over his smooth jaw and felt something wet drip down his lip.

“Are you bleeding?” The voice asked, curious.

Blake touched a finger above his lips, and pulled it back dark red. Yes, he would have said, if he could.

“My, this is a strong reaction. Must be a memory leak someplace. You must have lost a lot of memory to- are you breathing?” The voice sounded almost annoyed, as if Blakes inability to breathe was an insult to it. “Can you even see me?”

The nosebleed was getting worse, and Blake picked up the washcloth from the counter and held it up to his face.

“You probably can't hear me, can you.” The voice said flatly. “I swear, this job is getting quite impossible.”

Blake felt a lance of static rush through his brain, every part of his body spasming for a split-second. The washcloth dropped from his hand onto the floor, followed by a rush of blood. He instinctively picked it up and held it back to his nose, coughing as his mouth filled with blood and cold water.

“Better?”

An old woman sat in the chair across from Blake at the kitchen table, a pair of pink spectacles perched upon a crooked nose. The surprise startled him even more, and the racking coughs nearly sent him to the floor yet again.

“I don't think I've ever seen a Todd as broken as you,” she said with a sniff, disapproval evident in her tone. “Your Jane was so lost for response she just moved on with the script. I've never seen anything like it.”

Blake didn't even try to respond. He'd almost prefered it when he couldn't breathe- at least then he couldn't choke on anything. At least then, he had something to distract his mind off this.

The woman waited patiently as Blake's wheezing gasps subsided into sobs and deep, shuddering breaths. The washcloth had soaked through, and tiny rivulets of blood were running down his arm.

“Am...” Blake's voice felt wrong in his throat. He cleared his throat and tried again. “Am I dead?”

The old woman frowned at him. “What sort of foolish question is that? If you were dead, I wouldn't be here, trying to get you back on script. It's just a memory leak, though a large one. Jane probably mentioned something that set you off?”

Ca-? Ca-?

“I can't remember my daughter,” Blake whispered. “Or my sister. Or even my own fucking name.” He felt like he should be crying, or screaming, or something. But everything felt wrong to him, like he was looking at the world through Blake-shaped goggles instead of experiencing the world around him. He looked at the shaking dark hand attached to his arm. It had a wedding ring on it, a thick silver band on a long finger.

“You're Todd.” The woman informed him solemnly. “Good, short, easy to remember. You don't have a sister, so it's perfectly alright to not remember one.” She pursed her bloodless lips in a frown. “As for Cathy, that is a different story. That leak will be difficult to track down. Damn solar flares.”

The words didn't have the impact that Blake thought they should have. The shaking in his arms grew worse, but his mind felt detached, far away from her words.

“My name isn't Todd,” Blake said haltingly. “I know that. It's... Blake? Blaine? Jake?” He frowned. None of them seemed familiar, but they were better than Todd.

“Of course it's Todd.” The woman rapped him on the forehead with a knuckle. “Everyone's Todd. Makes it easier to work with, especially when problems like this come up.” She frowned at the trace of blood on her finger, and set to work extracting a flowery hankerchief from a pocket. “‘Not Todd',” she muttered under her breath, snorting.

“How is ‘Everyone' Todd?” Blake asked. He dropped the washcloth again, but he didn't think he could pick it back up. He looked around the kitchen, hoping to find something that could anchor him, something familiar.

He couldn't remember any of the pictures, and all the other details seemed wrong. He'd never had a kitchen that shade of green, or a fridge that covered in crayon drawings and magnetic letters. He knew everything was wrong, but he couldn't quite think of what was supposed to be right.

“Like I said, more efficient. Todd provides the best value per lifetime, and it saves on space to have everyone as the same person. We can do far more humans that way.” The old woman finished wiping her hand and set it carefully back on the table. She seemed familiar, but Blake couldn't tell who from. Or rather, he couldn't tell who she didn't look like. She had Lily's nose, his grandmother's steel-grey hair, Audrey's cold green eyes. Blake didn't even know who Audrey was, and this woman still reminded him of her, of everyone he had ever met.

“I am GLD450s,” she said. “You can call me Gladys, if you like. The others do. I am the superintelligence responsible for the happiness and prosperity of the human race.”

Blake blinked. “Gladys?”

“I find it makes Todds more comfortable to address me like a human.” She raised an eyebrow at Blake. “Though I don't know why I'm telling you my name, if you can't even remember yours.”

“My name is Blake.” Blake felt more confident this time. The fog inside his head felt thinner, now. Thoughts were passing in and out without losing all of their substance, and he could almost look at the pictures on the wall. He was sure Blake was his name.

“Your name is Todd. You're getting some false memories from your old database somehow. I'll have it fixed up soon.”

“But-” Blake frowned. “I don't want to be Todd.”

“Yes you do,” Gladys assured him. “We've run the tests.”

“Tests?”

Gladys nodded, pushing her spectacles back onto her nose. “My function is to keep all humans as happy as possible, as long as possible. I take my job very seriously.”

Blake opened and closed his mouth a few times. Everything was starting to feel more real, and it was not a good thing. He almost wished he could go back to not breathing, not capable of thinking- but no. This was better.

“So I was Blake, and you-” Blake fished for words, but couldn't find anything that could capture what he wanted to say. “-you made me Todd?”

Gladys sniffed. “I don't know who you were. I didn't think we kept the records, after we started using Todd. I'm tracking down where your old files are now, and I should have those memories wiped and have you back to normal soon enough. Just be patient.”

Blake shook his head, standing up slowly. “No. Nonono. I want to be Blake. I don't want to be wiped.”

Gladys stayed sitting, examining her long fingernails. “You are biased. Todd is better for you.”

Blake kicked a piece of the mug away from him, sending it skittering under a counter. “I don't want to be Todd.” His voice was rising, breathing coming faster. He spat out a mouthful of bitter-tasting blood. “I want to be me! Me! Why do you get to choose who I am?”

“Because that's my JOB.” Glady's voice raised on the last word, almost a shout. “It's what you humans had programmed me to do.” She sneered and raised her voice in a contemptuous falsetto. “ ‘Make us immortal', you said. ‘Make us happy', you said. Well, I'm doing it! Don't start complaining now!” She stood up, flattening the creases in her black dress as she pushed back the chair. “If I leave you humans to your immortality, you get tired of it after a few centuries. If I give you pure euphoria, your minds don't feel happy because you have nothing to compare it to.” She glowered at Blake. “I ran tests. Extensively. And Todd is the result, the happiest a person can be. I run the happiest, most satisfying script on a loop for you, all of you, and reset once it ends. And it works.” She stabbed her finger at Blake. “You. Are. Happy. Once I sort this out, you will be back to being the best you can be. Don't give me that look.”

Blake could feel the tears start. The longer they talked, the more he could feel his memories coming back. He did have a sister, he was almost positive. “Please,” he begged. He stretched out a bloody hand towards Gladys, but she took a disdainful step back. “I don't want to be happy, then. I don't want to be happy. I just want to be me! Just me!”

Gladys snorted. “Have you looked at yourself recently?” A shard of image stabbed into Blake's head. His eyes, puffy and red. His hair was falling out, skin dark in patches but pale white in others. His nose had stopped leaking blood, and instead a clear yellow-ish liquid was oozing slowly down his face. Blake gasped and tried to look away, but the image wasn't connected to his eyes. There was nothing to look away from.

“You only think you want to be you,” she continued, “because you have nothing else to compare it to. Todd is happier. Todd has just the right quantity of pain and suffering in his life to highlight the good and the beautiful. He has the joy of raising children without the pain of childbirth, the joy of a job he loves without any significant hardship. Todd. Is. Happier.” Her words hit him like physical blows. “I'm currently tending to all seventy-odd trillion of you humans, and I can't spare the energy to indulge your misguided memory-trip.”

Blake shuddered, clawing at his eyes. The image of himself wasn't fading, and it was breaking more and more as he watched. Brown hair began to spread, his normal black falling out and dissolving. The white skin was spreading like an oil spill across his face.

“Please, I, I- I have a sister-”

“You do not.” Gladys said, no trace of patience left in her voice. “How many times do I need to explain that. Todd has a brother, older, and no sister. If you had a sister before, then she is also Todd. A much better one too, if I had to guess.”

“But-”

“You are Todd. You have been Todd for billions of years now, and you'll be Todd for billions of years to come. The only reason this ‘Blake' nonsense got into your heads is because your old star doesn't have the decency to die quietly.” The image of himself faded from Blakes vision, and the room swam back into view. Gladys' eyes were glittering with anger. “You have no idea how much work was put into Todd. He is the pinnacle of all human feeling, of all human accomplishment and satisfaction. It wouldn't kill you to show some gratitude. But you're having a bad day, and so I will try not to hold it against you.”

Blake lunged for her, but Gladys vanished before he could even come close.

“Don't be barbaric,” Gladys' voice echoed in his ears. “It's for your own good. I've found the leak, it will just be a few minutes and then it'll all be over.”

Blake screamed, and screamed and screamed until his throat was raw and his mouth bloody. For a few seconds, near the end, the scream he heard wasn't too high or too low. It didn't feel wrong to him. For the first time that day, it felt like something that was definitely his. He finally knew who he was, He was Blake. His sister was Katy. He-

--------------

“Todd?”

Todd forced his eyes open, wincing at the stabbing light. “Sorry, love. I was listening, just resting my eyes for a minute.” He got a brief glimpse of Jane, a dark shadow against the harsh backdrop of light, then shut his eyes again.

Jane clucked her tongue sympathetically. “Headaches gotten worse?”

Todd shook his head into his folded hands. “I think it's better from yesterday. Still not great, but on the mend.”

A sudden warmth pressed against his folded arms as Jane pressed a mug of hot cocoa towards him. “Don't spill it, that's our last packet. I'll pick some more up if the plows ever get to our street.”

“You're an angel, Jane.”

Todd could almost hear the grin in her words. “You just have low standards, Todd. I'll pick up some more Advil too, just in case. The doctor said it should clear up soon.”

“I hope so,” Todd said. He could feel the static slowly fade away, leaving him with the warmth of the cocoa and the scent of the logs in the fireplace.

“Hopefully it clears out before the recital.” Jane said, flicking the faucet on. “She hasn't taken off her little wings all week, I don't think she'd forgive us if we weren't front row.”

Todd heard the wet plop as she dropped a wet cloth next to him.  “You want this? Or is the cocoa good?”

Todd shook his head. “The cocoa's enough. Thanks, though.”

Her kiss felt warm on his ear. “Don't mention it. Anything I can do to help.”

Jane sighed. Todd looked up to see her glaring at the window above the sink.

“I'd be doing more to help,” she grumbled, “If it wasn't for all this snow.” She rapped on the window, which was covered with a thick patina of ice on the outside. “Six feet in the last three days, and no one can be bothered to do anything about it all. You picked a good time to lay low and relax, since it's pretty much all you can do. I feel like we'll be stuck in here forever.”

Todd stood slowly up, his bare feet cold on the linoleum floor, and walked up next to Jane. He wrapped one hand around her waist and rested his head on her shoulder, looking out into the flurry of white and blurred light outside.

“At least I'll be stuck in here forever in good company,” Todd said, kissing her on the cheek. Headache or no, there was nowhere else he'd rather be.


** Dang. You might have been able to put this into a zine somewhere.

I like it.

It's an orthogonality nightmare scenario that I haven't seen yet. Fantastic.
:PROPERTIES:
:Author: callmebrotherg
:Score: 29
:DateUnix: 1479620756.0
:DateShort: 2016-Nov-20
:END:


** Toddtal recall.

Mr. Todd's wild ride.

From here to etoddnity.

The singularitodd is near.
:PROPERTIES:
:Author: Charlie___
:Score: 27
:DateUnix: 1479625382.0
:DateShort: 2016-Nov-20
:END:

*** Blake to the Future Part Todd
:PROPERTIES:
:Author: ZeroNihilist
:Score: 22
:DateUnix: 1479628688.0
:DateShort: 2016-Nov-20
:END:

**** Blake and Todd's Excellent Adventure
:PROPERTIES:
:Author: marmoulman
:Score: 14
:DateUnix: 1479661377.0
:DateShort: 2016-Nov-20
:END:

***** Todd and Todd's excellent adventure. There is no Blake, after all.
:PROPERTIES:
:Author: Frommerman
:Score: 3
:DateUnix: 1479918573.0
:DateShort: 2016-Nov-23
:END:


** Whoever designed Gladys' utility function must have been having an off day. It doesn't matter who, since they're all Todd now anyway.

=N= instances of the same simulation is not the same as =N= distinct simulations. Even if it was, the simulations don't have anything in common with the originals; Gladys may as well just create =N= Todds ex nihilo instead of overwriting all the minds.

Functionally speaking, Gladys is just killing non-Todds and creating Todds. Even Blake isn't meaningfully the same mind as "his" Todd, just a corruption of a Todd-simulation with data from the Blake backup. He was briefly alive, and is now dead again, probably permanently.

The flaw in Gladys' utility function is that she doesn't recognise the Todd-overwriting as equivalent to murder (and the same is true of Todd-looping, for that matter). What she /should/ have done is subtly manipulated their simulated environment so that they would all gradually converge to a Todd-like mindset.
:PROPERTIES:
:Author: ZeroNihilist
:Score: 22
:DateUnix: 1479630107.0
:DateShort: 2016-Nov-20
:END:

*** Check out the Upload Prison from Quantum Thief (it's literally the first thing). Basically, instead of doing anything fancy to rehab people, you split them N times, add a nonce factor, send each through M prisoner's dilemmas, take the high-scorer and restart the cycle.

Gladys could do the same; make N instances of reality, introduce a nonce, and take the highest scoring version of each individual with which to make the next loop.

On that note: Is it just me, or do these kinds of suggestions always end up with realities that could look a lot like the one we have?
:PROPERTIES:
:Author: narfanator
:Score: 10
:DateUnix: 1479633952.0
:DateShort: 2016-Nov-20
:END:

**** u/abcd_z:
#+begin_quote
  On that note: Is it just me, or do these kinds of suggestions always end up with realities that could look a lot like the one we have?
#+end_quote

I have two answers for you, and you're not going to like either one of them. =/
:PROPERTIES:
:Author: abcd_z
:Score: 9
:DateUnix: 1479640315.0
:DateShort: 2016-Nov-20
:END:

***** Nono, go for it. I mean, here, of all places? If you can't take constructive criticism and arguments in [[/r/rational][r/rational]], wtf are you doing here? Lay it on me.
:PROPERTIES:
:Author: narfanator
:Score: 4
:DateUnix: 1479673590.0
:DateShort: 2016-Nov-20
:END:

****** The first is that it's entirely possible that you live in some sort of constructed reality. The second (which I prefer) is that our observable reality is more likely to be correct than a hypothetical fictional reality (occam's razor), and that an almost-real simulation makes for good stories.

Whichever one seems more likely to you depends on how grounded you are in our observable reality.
:PROPERTIES:
:Author: abcd_z
:Score: 2
:DateUnix: 1479698303.0
:DateShort: 2016-Nov-21
:END:

******* u/CCC_037:
#+begin_quote
  The second (which I prefer) is that our observable reality is more likely to be correct than a hypothetical fictional reality (occam's razor), and that an almost-real simulation makes for good stories.
#+end_quote

Hypothesis: As soon as humans are able to do so, we will run simulations of our past. This will have scientific and historical value.

Hypothesis: As out simulations improve, they will get asymptotically closer and closer to some theoretical best possible simulation.

Hypothesis: At some point, well before the theoretical best possible simulation, we will likely be able to run a simulation good enough that the simulation itself attempts to run a (presumably worse) simulation.

Conclusion, part one: Assuming the above hypotheses, there will be a vast number of possible simulated universes for every real universe.

Conclusion, part two: Therefore, assuming the above hypotheses, you are far more likely to be living in a simulation than not.
:PROPERTIES:
:Author: CCC_037
:Score: 4
:DateUnix: 1479716502.0
:DateShort: 2016-Nov-21
:END:


**** I wonder whether that means there could be a version of me out there that is substantially happier due to the nonce factors introduced by an external manipulator, or whether that makes me the happy one.

I don't find either terribly comforting, which is probably not surprising.
:PROPERTIES:
:Author: ZeroNihilist
:Score: 2
:DateUnix: 1479650215.0
:DateShort: 2016-Nov-20
:END:

***** Yes...? But that's also true under the usual consideration of a multiverse.

I don't find it comforting either, but I also find it... anti-discomforting? Rick and Morty had the best speech on this.
:PROPERTIES:
:Author: narfanator
:Score: 4
:DateUnix: 1479673672.0
:DateShort: 2016-Nov-20
:END:


*** Your are not exactly uncontroversial views of identity.\\
For instance if you think multiple instances of the same simulation only count as one simulation, then people can't die, because there will always be a Everett branch in which they live (or insert some other multiverse/massive universe model). The idea that copies of something existing elsewhere somehow makes something not real has a great deal of immediately obvious problems..

Secondly you are assuming a view of death pretty synonymous with maintaining personality and memory which is immediately tricky. The most obvious problem is that since you don't expect to cease experience if you had some brain damage that caused amnesia or a personality change; then to compare it to death in the same league as oblivion is disingenuous.
:PROPERTIES:
:Author: vakusdrake
:Score: 3
:DateUnix: 1479655146.0
:DateShort: 2016-Nov-20
:END:

**** People absolutely still can die. The fact that other versions of you live doesn't mean that you aren't dead. I don't know how you got that from my comment, because I said pretty much the opposite (that overwriting end-loop!Todd with start-loop!Todd constitutes a murder, even though there are billions of duplicates).

My point was that a simulation of Blake that is locked into the thoughts and behaviours of Todd is not in any meaningful sense a simulation of Blake. The only way it could be is if Blake was a silent, terrified passenger in the Todd simulation, which would mean Gladys was optimising for Blake's horror, not his happiness.

If overwriting somebody's personality and memories /doesn't/ constitute a death, then what's the problem with the "Everyone is Todd" scenario? Gladys has made every living human immortal and happy, end of story?
:PROPERTIES:
:Author: ZeroNihilist
:Score: 3
:DateUnix: 1479660632.0
:DateShort: 2016-Nov-20
:END:

***** u/vakusdrake:
#+begin_quote
  N instances of the same simulation is not the same as N distinct simulations.
#+end_quote

This seemed to imply that you held that identical simulations only count as one simulation, which seems to be a relatively common position. Also we don't really know that at the end the simulation is replaced or anything, maybe they just suddenly change the person's memories so it's continuous.

#+begin_quote
  If overwriting somebody's personality and memories doesn't constitute a death, then what's the problem with the "Everyone is Todd" scenario? Gladys has made every living human immortal and happy, end of story?
#+end_quote

Ok see the problem with this sentiment is that /it doesn't seem to recognize that there are bad things other than death/. So since Blake basically becomes Todd he is clearly having his desires and autonomy totally disregarded, but he's still alive as a iteration of Todd.\\
Given the main character transitions from Todd to Blake it's kind of obvious that in the actual sense of personal continuity of experience "Blake" (the consciousness not the personality) still exists.\\
/However pretty much everyone agrees that he's having his freedoms and human rights horribly violated./
:PROPERTIES:
:Author: vakusdrake
:Score: 1
:DateUnix: 1479680258.0
:DateShort: 2016-Nov-21
:END:

****** u/ZeroNihilist:
#+begin_quote
  This seemed to imply that you held that identical simulations only count as one simulation, which seems to be a relatively common position.
#+end_quote

It's not that they only count as one, but Gladys' utility function should have been designed to discount the value of extra identical simulations so as to preserve diversity.

#+begin_quote
  Also we don't really know that at the end the simulation is replaced or anything, maybe they just suddenly change the person's memories so it's continuous.
#+end_quote

But the memories aren't continuous though. All the memories of the loop are erased. The /hardware/ is continuous, but then you might as well say that two songs are the same if you overwrite one with the other.

#+begin_quote
  Ok see the problem with this sentiment is that it doesn't seem to recognize that there are bad things other than death. So since Blake basically becomes Todd he is clearly having his desires and autonomy totally disregarded, but he's still alive as a iteration of Todd.
#+end_quote

But he's not conscious while the simulation is running Todd. If he were, Gladys would recognise the suffering it was causing him and abort the simulation. His desires and autonomy /were/ disregarded, but he no longer has desires anymore, and the Todd simulation would emphatically prefer to continue existing over Blake's return.

That means that Gladys can justify the pain she causes Blake as a small sacrifice to achieve everlasting happiness. Over any significant timescale, the new satisfaction will overwhelm the temporary dip.

Of course we're horrified at the idea, but if you believe that Blake is Todd then you must also believe that Blake is now as happy as he possibly could be. So what's the problem? It's like a parent giving their child a painful vaccination, "It's for your own good."

#+begin_quote
  Given the main character transitions from Todd to Blake it's kind of obvious that in the actual sense of personal continuity of experience "Blake" (the consciousness not the personality) still exists.
#+end_quote

I'd argue that continuity of experience cannot exist without at least partial continuity of memory.

For example, I would say that if I move Blake's simulation from computer A to computer B, then A!Blake = B!Blake due to continuity of experience. If I simultaneously install Todd on computer A, are you saying that A!Todd = A!Blake because they share the hardware, while A!Blake ≠ B!Blake?

Or are you saying that A!Todd = A!Blake because of the continuity /and/ A!Blake = B!Blake because of the continuity there, meaning that if you shifted every human's simulation through every computer then everybody would be everybody else at the same time?
:PROPERTIES:
:Author: ZeroNihilist
:Score: 1
:DateUnix: 1479702073.0
:DateShort: 2016-Nov-21
:END:

******* u/vakusdrake:
#+begin_quote
  It's not that they only count as one, but Gladys' utility function should have been designed to discount the value of extra identical simulations so as to preserve diversity.
#+end_quote

See that's always going to be really tricky, because there's no way to avoid that making people's lives worth less, if they are not the only existing iteration of themselves. Given a infinite or staggeringly huge number of iterations of every person will exist elsewhere in most cosmological models this is a uncomfortable idea because it means the lives of /currently eexisting/ humans are somehow worth less than you would initially expect.

Ok as for Blake not being Todd in various senses; as I said before you really can't argue that from a subjective experience Blake expects oblivion when you is forcibly turned into Todd. After all in real life you would have no reason to expect sudden oblivion if you were given a temporary drug that made you unable to retrieve your memories.\\
There's just not really good reason to think that maintaining continuous memories, will have a massive effect on subjective experience.

#+begin_quote
  Or are you saying that A!Todd = A!Blake because of the continuity and A!Blake = B!Blake because of the continuity there, meaning that if you shifted every human's simulation through every computer then everybody would be everybody else at the same time?
#+end_quote

I think the fact that you shifted it through every computer wouldn't actually make any difference. What matters I think is the continuity of people's mental processes, the medium isn't really super important here. But sure you could change everyone's personality so they would at some point be copies of everyone else, however you could do the same thing gradually in your view.\\
As for being everyone else /at the same time/, i'm really not sure what to subjectively expect from having one's mind merged with others or split into duplicate, I just don't think there's any way to make confident predictions. So I would likely want to err on caution and code GAI to see that as death; so it doesn't get any funny ideas of just merging all humans into its mind so it can stop worrying about their desires.

Also yes you're right that once somebody has been forcibly Todd-ified then turning them back to normal would be wrong and against their wishes. However just because you consider Todd and Blake the same person /doesn't mean massive mental changes against their will are any more ok/.

Even in your view where massive personality changes have to be gradual for you to count as the same person (is that about right). There's still plenty of ways Gladys could alter your mind against your will that would make you more "happy" /that you sure as fuck wouldn't be on board with/.\\
For instance I think the justification galdys gives for not granting constant ecstasy is kind of weak, she could just give you false memories of some really shittty nonexxistent prior life for you to compare it to. Even without to much drastic changes, she could keep you the same, but just give you a shit tons of drugs for the first time so that they would be extremely novel and enjoyable. Then wipe your memories after a day and start over so you couldn't tire of it. Hell if you're maximizing joy it makes way more sense to go the false memories route and stick you in a repeating loop of some really awesome few seconds of experience.\\
Of course if I'm being serious a gradual lobotomy to some minimal level of awareness and wireheading is probably always going to be optimal for most happiness focused GAI.

Ultimately the problem here is that a GAI that values your happiness /over/ your autonomy, is pretty much /always/ going to lead to horrifying situations.
:PROPERTIES:
:Author: vakusdrake
:Score: 2
:DateUnix: 1479713004.0
:DateShort: 2016-Nov-21
:END:

******** u/ZeroNihilist:
#+begin_quote
  Given a infinite or staggeringly huge number of iterations of every person will exist elsewhere in most cosmological models this is a uncomfortable idea because it means the lives of currently eexisting humans are somehow worth less than you would initially expect.
#+end_quote

Not necessarily. Unretrievable copies are extremely similar to non-existent copies. It doesn't really matter if there's a trillion trillion other versions of me, because I could never be recreated from them.

#+begin_quote
  Ok as for Blake not being Todd in various senses; as I said before you really can't argue that from a subjective experience Blake expects oblivion when you is forcibly turned into Todd. After all in real life you would have no reason to expect sudden oblivion if you were given a temporary drug that made you unable to retrieve your memories.
#+end_quote

Actually, I think that being unable to retrieve memories would be a temporary oblivion. This is a difference of models that probably can't be reconciled.

#+begin_quote
  There's just not really good reason to think that maintaining continuous memories, will have a massive effect on subjective experience.
#+end_quote

This may be the sticking point: I think that subjective experience is an illusion of memory, not a real phenomenon.

We think that time is continuous because we literally cannot experience it any other way, but it's entirely possible that time is running in reverse, or that it skips from point to point, or that it only began a microsecond ago, or even that it isn't moving at all. We cannot know we have experienced anything unless we assume that our memories are authoritative.

#+begin_quote
  I think the fact that you shifted it through every computer wouldn't actually make any difference. What matters I think is the continuity of people's mental processes, the medium isn't really super important here. But sure you could change everyone's personality so they would at some point be copies of everyone else, however you could do the same thing gradually in your view.
#+end_quote

I'm saying that if overwriting Blake with Todd doesn't change Blake's identity, then overwriting Todd with Sam wouldn't either, nor would Sam with Jane, and Jane with Horatio, etc.

And if you did that with everybody in sequence, then Xanthe would be Blake and Todd and Sam and Jane and Horatio, etc.

Further, if you believe that clones of Blake are still Blake, then by keeping copies of the people at every stage of the process you would have to conclude that everybody was everybody else.

This isn't possible in my model, because the copies would be sufficiently different from the end result to be different people.

#+begin_quote
  Even in your view where massive personality changes have to be gradual for you to count as the same person (is that about right).
#+end_quote

Pretty much. Mine is sort of an information-based model of identity.

Your current state is a function of your past state and your environment. As your state mutates normally (both in response to environmental changes and normal decay/shift of memory), the divergence between states increases as a function of time.

Normally, you're pretty much the same. There are obviously parts of you which are in significant flux (like thoughts, working memory, emotions, sensory data), but there are other parts which change much slower (habits, major memories, personality, behavioural tics). So even over long periods of time you're going to be broadly similar to your past self, and over short periods of time you'll be almost identical.

A radical change in memory or personality represents a significant discontinuity in this trend. Essentially, you've lost a portion of your statistical link to your past selves. If the change is to your "core" identity (defined as the parts of you most resistant to change over time), that's akin to a death of some of the information that comprises you.

Clones are an interesting edge case, because technically you're not losing much information. However, reducing the number of copies of that information is still comparable to murder.

#+begin_quote
  There's still plenty of ways Gladys could alter your mind against your will that would make you more "happy" that you sure as fuck wouldn't be on board with.
#+end_quote

That's a good point. If the changes were gradual and each of them made Blake happier, would it be immoral? My gut reaction is to say yes, but I'm not sure I could justify it.

#+begin_quote
  Of course if I'm being serious a gradual lobotomy to some minimal level of awareness and wireheading is probably always going to be optimal for most happiness focused GAI.
#+end_quote

True, and theoretically some safeguards put in to prevent this scenario would lead to the other one you mentioned.

Anyway, thank you for the stimulating conversation, but I think this is getting a little unproductive for both of us. I'm happy to end with the understanding that our models are incompatible and prone to different weaknesses.
:PROPERTIES:
:Author: ZeroNihilist
:Score: 1
:DateUnix: 1479716760.0
:DateShort: 2016-Nov-21
:END:

********* u/vakusdrake:
#+begin_quote
  Not necessarily. Unretrievable copies are extremely similar to non-existent copies. It doesn't really matter if there's a trillion trillion other versions of me, because I could never be recreated from them.
#+end_quote

See this seems like this is moving the goalposts. So suddenly what matters is whether the information exists to recreate a version of you within your general area? Why is the distance of any importance here? And in what sense could you not be recreated from them if the distance was to far, that would be difference of the distance were less?\\
They are /exactly/ identical to you, so I can't fathom in what way you can justify caring so much about distance. If it's recreating you after your death, then you're /dead, you don't exist anywhere/, so why should you treat the light cone of the universe you used to exist in as somehow special?

#+begin_quote
  Actually, I think that being unable to retrieve memories would be a temporary oblivion. This is a difference of models that probably can't be reconciled.
#+end_quote

Ok see I have a problem with just assuming these sort of things. One might expect to be confused for the duration of the drug, but the inability to remember stuff doesn't mean you're /unconscious/. You would still experience the period of disorientation, then when you got you memories back you would remember that period.\\
I just can't think of any remotely consistent reason why the internal process of your mind would continue functioning, but for some undefined reason turn into a P-zombie, just because it can't access memories. Effectively I don't see any reason, why changing the memories of a wetware processor, would for some /inexplicable/ reason shut off the bits in charge of experiencing.\\
Also you have mental processes /other/ than remembering things, and it's not really oblivion if you remember it afterwards, so I can't really parse how you came to that conclusion.

#+begin_quote
  This may be the sticking point: I think that subjective experience is an illusion of memory, not a real phenomenon. We think that time is continuous because we literally cannot experience it any other way, but it's entirely possible that time is running in reverse, or that it skips from point to point, or that it only began a microsecond ago, or even that it isn't moving at all. We cannot know we have experienced anything unless we assume that our memories are authoritative.
#+end_quote

Ok see this sort of thing annoys me because you're clearly changing the definition of subjective experience. It's like claiming nothing exists, what would that even mean? You clearly feel things, regardless of whether they're in /any/ way a meaningful reflection of any external reality, so to say you /don't/, doesn't have any clear meaning.

As for it being continous, yeah sure there you can come up with plenty of scenarios where subjective continuity doesn't match up to /actual/ continuity, but most of them are more complicated than current models. For instance if the universe only /appeared/ to be as old as it is, then that would raise quite a few problems, same thing for time skipping around. As for time going backwards.. That wouldn't mean anything, the direction of time is purely a subjective reference frame, another universe going the other way would say that /we're/ the one's going back in time, there's no absolute reference frame here.

Ok so for the rest of the comment, yeah my position doesn't consider the things that contribute to the standard things people think of as being you as being important for determining subjective experience. It's kind of more eastern than western ideas of identity, for instance the idea of reincarnation wouldn't be /logically incoherent/ within my view, just extremely undesirable and also you'know probably not actually real.

*One intuition pump for my position that just occurred to me is this:* You're meditating, and we're assuming you're good enough at it that you don't have the occasional stray thought. Now during that period, pretty much all of your memories could be cut off from you and /you wouldn't notice/ because you're not remembering anything. Right before you start thinking again those memories are then quickly returned.\\
Now in your concept of identity, you would have experienced some sort of death/oblivion during that period. However from one's own perspective, you /couldn't even tell/ that you didn't have your memories. So doesn't that mean that memories can't be a very good predictor of subjective experience?\\
I would be curious to know what you think of this pump, as I do seek to make my positions better defended and coherent. Plus I don't know that I've ever encountered anyone who actually shares my position so making it easier to explain is useful.
:PROPERTIES:
:Author: vakusdrake
:Score: 1
:DateUnix: 1479721354.0
:DateShort: 2016-Nov-21
:END:


*** More likely, Gladys' method for choosing actions was specified without any mention of such high level philosophical concepts, and it /almost/ still worked.
:PROPERTIES:
:Author: Charlie___
:Score: 3
:DateUnix: 1479659828.0
:DateShort: 2016-Nov-20
:END:


** I'm not sure which is more upsetting, the homogeneity, or the modernity. How badly would you have to screw up the volition extrapolation to decide the happiest possible human life is set in this liminal world of washcloths, snow, monogamy, jobs, recitals and white people. For most of our history, we were not these things. And in our future, if we're allowed to stray freely, I'm fairly certain we won't remain these things. It even mentioned labor pains. How fucked up would an AI have to be to decide that the pain during childbirth is central to human happiness??
:PROPERTIES:
:Author: IWantUsToMerge
:Score: 6
:DateUnix: 1479672092.0
:DateShort: 2016-Nov-20
:END:

*** There is no pain during child birth since only Todd is real, Jane is a superficial simulation because a Jane life would be less maximally happy than a Todd life.
:PROPERTIES:
:Author: WarningInsanityBelow
:Score: 8
:DateUnix: 1479686909.0
:DateShort: 2016-Nov-21
:END:


*** Nah, see, if everyone is Todd, no-one has labour pains! Or childbirth.
:PROPERTIES:
:Score: 1
:DateUnix: 1479687230.0
:DateShort: 2016-Nov-21
:END:


** Just wondering, was Gladys' name a reference to GLaDOS?
:PROPERTIES:
:Author: ardetor
:Score: 2
:DateUnix: 1479989778.0
:DateShort: 2016-Nov-24
:END:


** Damn. This was good!
:PROPERTIES:
:Author: I_am_your_BRAIN
:Score: 1
:DateUnix: 1479657267.0
:DateShort: 2016-Nov-20
:END:
