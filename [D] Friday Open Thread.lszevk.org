#+TITLE: [D] Friday Open Thread

* [D] Friday Open Thread
:PROPERTIES:
:Author: AutoModerator
:Score: 11
:DateUnix: 1614351624.0
:END:
Welcome to the Friday Open Thread! Is there something that you want to talk about with [[/r/rational]], but which isn't rational fiction, or doesn't otherwise belong as a top-level post? This is the place to post it. The idea is that while reddit is a large place, with lots of special little niches, sometimes you just want to talk with a certain group of people about certain sorts of things that aren't related to why you're all here. It's totally understandable that you might want to talk about Japanese game shows with [[/r/rational]] instead of going over to [[/r/japanesegameshows]], but it's hopefully also understandable that this isn't really the place for that sort of thing.

So do you want to talk about how your life has been going? Non-rational and/or non-fictional stuff you've been reading? The recent album from your favourite German pop singer? The politics of Southern India? Different ways to plot meteorological data? The cost of living in Portugal? Corner cases for siteswap notation? All these things and more could (possibly) be found in the comments below!

Please note that this thread has been merged with the Monday General Rationality Thread.


** I don't think it merits an actual post, so I'm writing it here.

I just finished The Erogamer (first readthrough), and I have... mixed feelings, shall we say.

On one hand, it's certainly brilliant, with a complex plot, lots and lots of references to almost ALL of my favorite books and authors (I swear, more than once I took screenshots and sent them to my girlfriend with an excited "LOOK, IT EVEN HAS THIS!"). The humor was great, the sex parts were inventive at the least (I'm not really into BDSM though, so I don't know how actually porny it is for those who like that), and there was an occasional insight on sexuality that resonated with me.

But the latter half of it was a really hard read. The endless, ENDLESS philosophizing, the internal monologues and Author Filibusters on metaphysics, parallel worlds, free will vis-a-vis plot requirements, sexual ethics, cosmic bullshit etc. bored me almost to tears. I'm here for the jokes and crazy sexy adventures, gorram it!

When I just started reading The Erogamer, I was ecstatic. I was looking forward to recommending it to all my friends, I was ready to hail it as the best thing I expect to read in 2021. Now I'm not so sure.

If anyone has similarly geeky sex-centered fiction to recommend, with actual plot, but with no meta-anything, I'll be very grateful.
:PROPERTIES:
:Author: AlexAlda
:Score: 12
:DateUnix: 1614358236.0
:END:

*** I think this happens quite a lot with popular web related fiction that is very serial and doesn't have a specific endpoint. It even happened with famous old school comics like Cerebus. At some point when the author gets enough attention on their product that they didn't expect they start to use that attention for other purposes.

It is truly unfortunate.
:PROPERTIES:
:Score: 6
:DateUnix: 1614375119.0
:END:


** Where/how do you listen to audio books/podcast and what would you recommend? I've recently started driving to work (having started from home since this pandemic began) and looking for things to help my drives along 20 minutes or 90 minutes long
:PROPERTIES:
:Author: TheFlameTest2
:Score: 4
:DateUnix: 1614377362.0
:END:

*** [[https://www.iheart.com/podcast/105-behind-the-bastards-29236323/][Behind the Bastards]]

The histories and backgrounds of the worst people in history. It's hilarious and educational. So much more stuff happened in history than we really know lol.

[[https://darknetdiaries.com/][Darknet Diaries]]

What happens on the darkside of the Internet?

True stories of cybercrime, darknet markets, and state sponsored cyberwarfare.

There's also Last Podcast on the Left
:PROPERTIES:
:Author: DrMaridelMolotov
:Score: 6
:DateUnix: 1614378272.0
:END:


*** 99% Invisible is great if you think the infrastructure that underlies modern life is really fascinating and neat.
:PROPERTIES:
:Author: PastafarianGames
:Score: 6
:DateUnix: 1614384098.0
:END:


*** I highly recommend the "Podcast Addict" app on android, I've used it for years and consistently think it's earned the few bucks I paid to remove ads.

I listen to a ton of podcasts due to work and exercise, any specific genres you like? Telling people your specific fiction, hobbies, and pop/pro-whatever you follow will help a lot. I also enjoy listening to things alongside other media, like commentary/analysis on shows or reading.
:PROPERTIES:
:Author: RetardedWabbit
:Score: 4
:DateUnix: 1614384020.0
:END:


*** For how to listen, I second the recommendation of Podcast Addict.

As for the podcasts, * 80,000 Hours does really in-depth interviews of experts in different fields. * The Arms Control Wonk podcast has some great episodes on how analysts use open-source intelligence to study nuclear weapons research and proliferation * Dressed has lots of interesting details about the history of fashion * Early and Often looks at the history of elections in the US, starting from the first colonies * Listen to an episode of My Brother, My Brother, and Me, because if you like it there's at least a thousand hours more McElroy podcast content out there * Rationally Writing is by Alexander Wales and Daystar Eld * The Film Reroll has a fun conceit: it's an actual-play podcast where the cast stats up and plays through a different film each episode * The Tip Off is all about the process of research and fact-checking behind recent big investigative journalism stories, following a different article each episode * Throwing Sheyd is about Jewish demonology
:PROPERTIES:
:Author: Radioterrill
:Score: 5
:DateUnix: 1614420331.0
:END:

**** Seconding Arms Control Wonk, happy to see it recommended! Great personalities being passionate about their field and the general crazy capabilities of civilian intelligence/reporting right now. It's also the single best reminder that nuclear weapons are political first, research/engineering second, and military last.
:PROPERTIES:
:Author: RetardedWabbit
:Score: 1
:DateUnix: 1614529392.0
:END:


*** For comedy, I like MbMbam (My brother, my brother, and me) and conan O'brien needs a friend. "Criminal" covers both interesting crime and flaws of the justice system. I'll second 99% Invisible as a great podcast.

I listen in the car; I subscribe to things with Google Podcasts on Android.
:PROPERTIES:
:Author: roochkeez
:Score: 2
:DateUnix: 1614408192.0
:END:


** One description for the theological notion of Heaven is that it's a lie wielded to maintain Hell; that is to say, instead of focusing on improving this world, which is our only world, the notion of Heaven redirects peoples' efforts towards a nonexistent world to come.

This doesn't seem obviously untrue to me, but I wonder about the causal relationship. Obviously, religion has been used to justify and perpetuate things ranging from the caste system in India to slavery in the Antebellum South to the concentration of wealth in the hands of the few in the United States today. But is that the case because religion is a social structure and social structures are prone to being weaponized by those who have power, or is it the case because the concept of Heaven is inherently toxic, inherently suited to siphoning effort away from creating a heaven on Earth?

I guess in order to test this I would have to know more about theologies that don't have an afterlife. Ironically, my own faith (Judaism) is one of those, but only kind of, because there are all these really fuzzy afterlife notions in different branches of Judaism even though there's no real canon about it, and also I don't know what the position on the afterlife was of the few sets/types of Jewish theological leaders who had substantial secular influence.

As an entirely separate thought, I've been likening AGI-boosterism to this concept in my head for a while now. There's this feeling I get from a lot of AGI boosters that there's no point in striving for a better tomorrow, because that's nothing compared to the post-singularity Good AI Overlord future (aka Heaven), so you might as well do nothing. It's extremely disorienting because metaphorically adjacent to those folks you have EAs who are all about "do the most effective thing for a less bad tomorrow".

[edit] - Similarly to the above phenomenon, I am constantly baffled by the occasional Mars-colonization-as-societal-panacea take I see or hear. Folks, if you think building a utopia on Earth is hard, doing it on Mars is gonna be a thousand times harder.
:PROPERTIES:
:Author: PastafarianGames
:Score: 9
:DateUnix: 1614358264.0
:END:

*** Waiting for agi is like waiting for retirement to live your life. Kind of backwards if you ask me. I'm more of a self reliance type of dude, make my own life as good as possible to the extent that I can, rather than relying on government or other people to do it for me at some point.

â€‹

There are thinking patterns that are arguably OP, like how you think about diet / exercise, or how much control over your life you perceive you have, how proud you're etc. Most people use the generic ones they got from their parents, and those are fine and clearly work, since you know your parents had kids and statistically are living average lives, but imho there's room for optimization in most people's thought patterns. It's hard to get introspective enough to question and if needed optimize them though.
:PROPERTIES:
:Author: fassina2
:Score: 6
:DateUnix: 1614376186.0
:END:

**** #+begin_quote
  There are thinking patterns that are arguably OP, like how you think about diet / exercise, or how much control over your life you perceive you have, how proud you're etc.
#+end_quote

I can guess at what you mean by these, but in case I'm mistaken could you elaborate?
:PROPERTIES:
:Author: imyourfoot
:Score: 1
:DateUnix: 1614378362.0
:END:

***** I don't see how I could elaborate without giving examples so here are a couple I use:

The default one: 'exercise needs to happen X times per week, each section has to be at least 50-60min long, and it needs to take a lot of effort'.

What I consider exercise is different: 'exercise takes around 10-20min per day, consistency is more important than effort'.

Another default one is: 'if you're not going to do things optimally, and at maximum efficiency it's a waste of time and you shouldn't do them'. I see this a lot in my chubby friends.

Mine is: 'Consistency is king, shitty execution with low efficiency beats optimal effort inconsistently'.

This one needs to be elaborated on, a guy who exercises at home (suboptimal) consistently, will most of the time be in better shape on the long run compared to a guy who would only consider exercising in a gym for 1-3h/d five times a week (optimal).

This happens because the effort required for the perceived optimal method is too high, which reduces the consistency of execution and causes them to give up after a while. The turtle beats the rabbit in this case.

I can give more examples if anybody wants but these I suspect will already get me plenty of hate.
:PROPERTIES:
:Author: fassina2
:Score: 3
:DateUnix: 1614386274.0
:END:

****** Perfect is the enemy of good
:PROPERTIES:
:Author: RMcD94
:Score: 2
:DateUnix: 1614423611.0
:END:


****** Thanks for replying, and I agree with your viewpoint.
:PROPERTIES:
:Author: imyourfoot
:Score: 1
:DateUnix: 1614399681.0
:END:


*** When I was religious I always took heaven as a goal for us to imitate and not a reward. This I think was a part of me getting disillusioned by the whole thing, when everyone else seemed to use it as an excuse to not do anything. Don't have to worry about the climate or war or poverty because Jesus is going to come and fix it all, dontcha worry.

If I were to have the chance to go back and rewrite Christianity, it would be to make it so that God died permanently on the cross after putting all the butterflies in place for heaven to be possible but not guaranteed. Let people have their guidance if they "listen" for the butterflies, but know that if they don't strive and if everyone doesn't strive, nothing will get done.

But then I bet it wouldn't have survived as long as it did.
:PROPERTIES:
:Author: ketura
:Score: 2
:DateUnix: 1614361169.0
:END:


*** #+begin_quote
  But is that the case because religion is a social structure and social structures are prone to being weaponized by those who have power, or is it the case because the concept of Heaven is inherently toxic, inherently suited to siphoning effort away from creating a heaven on Earth?
#+end_quote

I don't think that there are "inherently toxic ideas", at least not in a supply sufficient for something you identify as "inherently toxic" by sorting through globally popular human memes to be expected to actually be inherently toxic. At the very least, error rates are high enough- at most, calling something an "inherently toxic idea" is a fundamental mistake. I expect that the idea of Heaven would have the effect you mention in some really large majority of historical human societies, and in some privileged sense is rife for abuse in many counterfactual worlds, too.

#+begin_quote
  As an entirely separate thought, I've been likening AGI-boosterism to this concept in my head for a while now. There's this feeling I get from a lot of AGI boosters that there's no point in striving for a better tomorrow, because that's nothing compared to the post-singularity Good AI Overlord future (aka Heaven), so you might as well do nothing. It's extremely disorienting because metaphorically adjacent to those folks you have EAs who are all about "do the most effective thing for a less bad tomorrow".
#+end_quote

The AGI booster idea is that developing aligned AGI is the best way to strive for a better tomorrow, not that the optimal strategy is to buy a straightjacket and wait for Robot God to save you.
:PROPERTIES:
:Author: Valeide
:Score: 1
:DateUnix: 1614368488.0
:END:

**** #+begin_quote
  The AGI booster idea is that developing aligned AGI is the best way to strive for a better tomorrow, not that the optimal strategy is to buy a straightjacket and wait for Robot God to save you.
#+end_quote

That's the thing; since I'm not a believer in AGI in that sense, or at least not on any near-future (this century) timescale, working on AGI as a way to strive for a better tomorrow is indistinguishable from sending missionaries into Africa to try to get people into Heaven.
:PROPERTIES:
:Author: PastafarianGames
:Score: 2
:DateUnix: 1614378313.0
:END:


*** #+begin_quote
  Folks, if you think building a utopia on Earth is hard, doing it on Mars is gonna be a thousand times harder.
#+end_quote

Not necessarily. Mars colonist can (in fact, MUST) be hand-picked to be extremely capable, highly educated, cool-under-pressure stoics, rational, emphatic, and able to easily cooperate with others. On top of that Martians would be picked to be top health and fitness. Basically, all martian colonists start as astronauts and must pass the same tests.

If you cannot make an utopia using Peak Human altruist heroes in a remote isolated location away from Earth's ills, then we can pretty much assume that utopia is impossible.
:PROPERTIES:
:Author: Freevoulous
:Score: 1
:DateUnix: 1614584463.0
:END:

**** Then it's impossible. First, because this selection only determines the initial composition of the first generation of colonists. Second, because harsh enough conditions can crack people in all sorts of ways. The blank slate also doesn't work unless you actively /erase/ ideas from Earth you deem toxic (and that's supposing your judgement is 100% right on that), and doing so would in itself require a pretty authoritarian approach, or sending only babies and caretaker robots.
:PROPERTIES:
:Author: SimoneNonvelodico
:Score: 2
:DateUnix: 1615104325.0
:END:

***** #+begin_quote
  First, because this selection only determines the initial composition of the first generation of colonists.
#+end_quote

But that generation would birth, raise and educate the second generation, beign their pretty much only source of culture, norms and morality. The saturation of "astronaut culture" in society will be close to 99% in the forseeable future.

#+begin_quote
  Second, because harsh enough conditions can crack people in all sorts of ways.
#+end_quote

Definitely, though a realistic utopia does not require automatic perfect mental health, just access to top of the line mental health professionals.

#+begin_quote
  The blank slate also doesn't work unless you actively erase ideas from Earth you deem toxic (and that's supposing your judgement is 100% right on that)
#+end_quote

I agree there would be more than a bit of selection bias when it comes to importing ideas from Earth, but most of it would be simply by picking the right colonists. For example, since most colonists would be extremely highly educated, asutronaut-like specialists, we can pretty much guarantee the society will be agnostic/atheistic (since almost all specialists of that level are).

#+begin_quote
  doing so would in itself require a pretty authoritarian approach,
#+end_quote

"Authoritarian" approach is inherent in the bottleneck caused by the harsh transit and colony creation. One can put it that way: planetary colonists come in two flavors: rational materialist stoics, and dead. everyone who is not physically, emotionally, and philosophically fit to function in such a society is likely to go insane/die/cause death in transit, nevermind on site.

#+begin_quote
  or sending only babies and caretaker robots.
#+end_quote

In theory, that would be ideal, but would likely require true AGI (or at least a very, very good SAI that passes the basic Turing test flawlessly ), so if we could have that, all our problems would be solved anyway.

#+begin_quote
  or sending only babies and caretaker robots.
#+end_quote
:PROPERTIES:
:Author: Freevoulous
:Score: 1
:DateUnix: 1615142571.0
:END:

****** My problem is your assumption that whatever causes trouble on Earth are just bad viral ideas that were born at some point in the past and that we can't rid ourselves of, but that if only we could excise, would be sure to never trouble us again. And I don't buy it. You're treating our problems like a virus that can be exterminated, albeit with great effort. I'm saying they're more like cancer: an unavoidable nasty side-effect of multicellular life itself, that we can certainly get better at managing, but never outright eliminate at its root. First, all sorts of conflicts can arise out of entirely rational motives. Rational doesn't mean selfless. Someone who would rather eat twice as much and let someone else starve than share their food isn't being irrational, just a dick. But such conflicts could arise in any context, and would arise all the much more in a situation of true scarcity. Conflicts then have to be rationalized away, which is often conveniently done via dehumanisation of the opponent, and /that's/ where the real trouble begins. It doesn't matter that these colonists didn't carry with them the specific flags we rally around here on Earth; they will just make /their own/ flags at that point. Any society built around a certain set of values has already a perfect accusation to levy against its opponents: /they/ don't adhere to the values! They want to ruin our perfect society! They're not doing their part, or are pushing against our progress, or something. And so on. Most of these conflicts don't even necessarily start irrational, they /turn/ irrational as people dig their heels in because that's how group dynamics work. And the problem is, I can only see the conditions of a space colony exacerbating these issues, not making them better. You have scarcity, you have a closed environment, a small overall population (thus a lack of meaningful outside input that could inject some much needed perspective), and conditions that are already intrinsically unhealthy for the human mind (long term seclusion, lack of natural sunlight, lack of natural environments, probably limitations and controls on reproduction, and various other hardships).

Honestly, I'd put my money on the colonists going crazy within 10 years and either slaughtering each other or turning into some sort of dictatorial cult in 20, almost regardless of their original backgrounds. Regular astronauts come and go from Earth, so space cabin fever can't get to them as easily. This would be a completely different situation.
:PROPERTIES:
:Author: SimoneNonvelodico
:Score: 1
:DateUnix: 1615145041.0
:END:


** So anyway [[https://twitter.com/liminal_warmth/status/1366814447625379841][there's a person on Twitter offering to buy human souls for $10]] who's drafted [[https://liminalwarmth.com/contract-for-sale-of-soul/][a full and extremely detailed contract for it]].

So far, I think they got 8.
:PROPERTIES:
:Author: SimoneNonvelodico
:Score: 3
:DateUnix: 1614786984.0
:END:
