#+TITLE: [D] Rationalist fiction and ethics

* [D] Rationalist fiction and ethics
:PROPERTIES:
:Score: 16
:DateUnix: 1479570936.0
:END:
[deleted]


** Most people here think of utilitarianism as being the "correct" moral framework.

But beyond that, rational fiction tends to put a focus on thought, and it's difficult for me to see how that exists within a deontological framework. That is, if you're a deontologist, you just ... do the right thing, even if it has bad consequences. Where's the thought in that?

Kant said that it was wrong to tell a lie to save a friend from a murderer. If you put that into a story ... I just don't see how that works /unless/ it's a deontologist flirting with consequentialism.

The current story that I'm writing for National Novel Writing Month /does/ have a deontologist protagonist paired with a utilitarian protagonist, with both utilitarian and deontological villains, but it's not super rational, and in part it's an argument against absolutist moral rules.

I was raised Mennonite, a rather extreme sect of Christianity which holds that non-resistance is morally correct, e.g. if a man comes to your house and attempts to rape your wife, you and she are both obligated not to resist him. Reading some of the interviews with Mennonites from the World War I conscientious objector board is a look into the eyes of moral madness, in my opinion. Edit: [[https://archive.org/details/conscientiousobj00kelluoft][/The Conscientious Objector/ by Walter Guest Kellogg]], starting in the section "The Mennonites and Others", though I think the whole book is worth a read; it was written by one of the three members of the Board of Inquiry which assessed whether those seeking CO status were just faking it.

#+begin_quote
  You can not get him to say whether in his opinion the United States should triumph over Germany or Germany over the United States --- he will tell you, "It is not for me to judge." He will, in all likelihood, testify that if some brute were to break into his mother's or sister's room and attempt to rape her, he would allow his mother or sister to be raped before he would shoot or otherwise injure her assailant. He will not admit having been in any fight or having ever used force against a human being since joining the church.
#+end_quote

(Now that I think about it, I did actually put some of this into [[https://www.fanfiction.net/s/10360716/1/The-Metropolitan-Man][/Metropolitan Man/]].)
:PROPERTIES:
:Author: alexanderwales
:Score: 25
:DateUnix: 1479572031.0
:END:

*** I guess I find it interesting how certain things are assumed as moral axioms without justification. As in, "do the thing that benefits the most people" is often the reason for the protagonist to go against the world-conquering despot, but rarely is it explained why they want to do that. I guess deep down I just want to read a story where there is a completely self-absorbed protagonist, if only for novelty's sake.

P.s. Glimwarden is heroin I need it
:PROPERTIES:
:Score: 8
:DateUnix: 1479572770.0
:END:

**** Given how we're raised on the axiom that caring about innocent bystanders and other such actions signals the hero, while not doing that signals the villain, I think what you're looking for, to an extent, is the [[http://tvtropes.org/pmwiki/pmwiki.php/Main/VillainProtagonist][Villain Protaognist]]. From the above hero/villain traits, if such a story ever talks about morality, the protagonist is usually classified as evil, but that doesn't stop the villain from having a sympathetic portrayal.

I just recently finished [[https://www.fanfiction.net/s/10677106/1/Seventh-Horcrux][Seventh Horcrux]], recommended from another thread here, in which when Voldemort died his identity overwrote Harry's, and Harry!Voldemort decides that going through life again as the saviour of wizarding Britain isn't so bad. It re-imagines Voldemort as less 'completely evil' and more amoral with a tendency to believe what's told to him (a byproduct of growing up in the house of purebloods after living in a muggle orphanage; he has to give off the impression that he already knows what they're talking about, and knew it all along, or else they'll turn on him). It's a rather funny story, and Harry fits the bill of always having a selfish motive for whatever he's doing.
:PROPERTIES:
:Author: InfernoVulpix
:Score: 7
:DateUnix: 1479581094.0
:END:


**** Super interesting about your background too! I have been struggling with the concept of just war and pacifism, and how the two coexist (if they do). What exactly does non-resistance look like? Is fleeing allowed, or non-lethal incapacitation?
:PROPERTIES:
:Score: 5
:DateUnix: 1479573232.0
:END:

***** Matthew 5:38

#+begin_quote
  “You have heard that it was said, ‘Eye for eye, and tooth for tooth.' But I tell you, do not resist an evil person. If anyone slaps you on the right cheek, turn to them the other cheek also. And if anyone wants to sue you and take your shirt, hand over your coat as well.
#+end_quote

They take this seriously and literally. They /are/ allowed to run (but there are some instructions in the texts not to), but not at all allowed to use force upon another person. That is, you're not allowed to break someone's leg, punch someone in the face, or even to use force to restrain them without harming them. There is no such thing as a just war, to the extent that paying taxes which will be used for a war is either forbidden or strongly discouraged.

[[http://www.homecomers.org/mirror/martyrs152.htm][/Martyr's Mirror/]] is one of the most important Mennonite texts, which has stuff like this:

#+begin_quote
  Being brought before the lords and judges, he was asked, whether he had been baptized upon his faith, which he finally confessed and acknowledged, not ashamed of what he had done by the command of his Lord and Master Christ Jesus, though he certainly knew that they did not ask him to be taught of him, but only to get a word from his mouth by which they might sentence him to death. When the lords and criminal judges had heard this Christian confession, they rose up and went to sentence him to death; and having returned from their evil consultation, they pronounced and declared their sentence over this servant of God: that he should publicly be burnt alive at the stake till death should ensue.
#+end_quote

(This was during a time when being a Mennonite was cause for death without any other crime being committed.) And insane stuff like this:

#+begin_quote
  When the executioner had come to him, he commanded him to put out his tongue, which he (faithful and pious servant of God), willingly did, since he had not a member on his body, which he was not willing to deliver up to suffering for the name of Christ, being well assured that all the sufferings of this present time are not worthy to be compared with the joy and glory which God has promised them that overcome. Matt. 10:22; Romans 8:18; Rev. 2:7.

  And when he put out his tongue, the executioner fastened it with a piece of iron, and screwed it very tight with a vise or screw, and then touched the end of the tongue with a hot iron, that swelling, the screw might not slip off or become loose. O bitter cruelty and great tyranny.
#+end_quote

The moral lesson here is basically that if someone comes to you with a searing hot iron to pull out your tongue, you act as a willing participant. (Though there always appears to be some consequentialist thinking in these things, because there's explicit acknowledgement that God's glory is greater, and things like "whose reward is the crown of eternal, imperishable life" which very much seems to be an argument that in part this is all done with the expectation of reward. That's always something that I struggle with though, because I'm not sure how much I'm reading these texts with my own utilitarian mindset.)
:PROPERTIES:
:Author: alexanderwales
:Score: 14
:DateUnix: 1479582225.0
:END:

****** You know what, I can respect that. If they believe that violence is wrong, then their commitment even unto death strikes me as brave, not foolish. The question behind the question is: are they right? If yes, great people. If no, unfortunately misguided people. Interesting point on divine reward! I guess the classic rebuttal would be that reward is a byproduct of obedience, not the reason for it. The reason for obedience is not because it benefits us, but because it's one's function. And the fact that reward exists is a cause for celebration.
:PROPERTIES:
:Score: 6
:DateUnix: 1479613769.0
:END:


****** To be honest, I don't go to /quite/ that extreme (I would defend myself or others from injury, etc.), but I can kind of see their point. I've thought about it, and decided that if someone broke into my house, I'd talk to them, help them get what they wanted, and call the police afterwards (in large part because their showing up could trigger a robber to take a hostage i.e. me).

But... well, the reason for my behaving that way is more because of my personality and the fact that few people are psycho/sociopaths, even robbers. I don't have the build that would be capable of physically restraining them, and even if I did I wouldn't feel right to do so over /property/ -- it can always be replaced, where I could do serious damage bludgeoning someone over the head with a crutch or whatever, much less shooting them. I figure I'm better off talking it through -- or pretending I'm asleep -- and seeing if I can't get them to see me as someone who cares about them.

...well, that was a little rambly.
:PROPERTIES:
:Author: Cariyaga
:Score: 5
:DateUnix: 1479685619.0
:END:

******* I agree with your property statement. My problem with killing and the like is that it is so definite. I am removing in an instant any future probabilities for this person to be reformed and happy for the sake of my own protection or protection of my possessions. The thorny side of it is when you are killing for the sake of another- then you are prioritising one life over another.
:PROPERTIES:
:Score: 2
:DateUnix: 1479704721.0
:END:


****** Serious question:

What about tickle fights? Or lip biting and affectionate nugies? Assisted stretching and massage, even.
:PROPERTIES:
:Author: TennisMaster2
:Score: 2
:DateUnix: 1479586766.0
:END:


****** Makes sense in context of an eternal afterlife I suppose
:PROPERTIES:
:Author: RMcD94
:Score: 2
:DateUnix: 1480195868.0
:END:


***** Speaking as someone who was an ardent pacifist in the waning days of his theism, it can vary according to the theory that you subscribe to. I was personally considering learning aikido, which was designed to be "an art that practitioners could use to defend themselves while also protecting their attacker from injury."

(and truth be told, I still hold "thwarting violence without killing anyone" to be the ideal, and as [[/u/eaturbrainz]] has said, we should regard it as a horrible, tragic thing when someone is killed, even when there was literally no other option, because a mind was just destroyed forever and it is awful that things ever had to get to this point)

You could also probably find pacifists who are okay with inflicting temporary harm but not draw the line at killing.

It's a much easier philosophy if you believe that the world is ruled by supernatural beings who are willing and able to make sure that everything turns out right in the end.

I'm on a tablet right now but if you're interested in more, then let me know and I can elaborate as much as you'd like when I get to my laptop. Most of my knowledge is from a Mormon pov, but I'm familiar with some other traditions, like the Jains.
:PROPERTIES:
:Author: callmebrotherg
:Score: 5
:DateUnix: 1479578490.0
:END:

****** I would love to know more! Here in Western Australia Mormonism is not exactly widespread. I must confess that my knowledge of Mormonism comes from: Fallout New Vegas, cursory reading of the first Mormon website on google search, and some anecdotal stories about Joseph Smith. If you wouldn't mind, would you mind telling me what the central tenets of Mormonism are?
:PROPERTIES:
:Score: 1
:DateUnix: 1479614146.0
:END:

******* Hmm...hadn't previously heard of Fallout: New Vegas (I run Linux, so I lean more toward running old games in Dosbox, that kind of thing). Just from the passing reference in Wikipedia, though, it's probably not a very accurate representation :D.

#+begin_quote
  the central tenets of Mormonism
#+end_quote

Well, if you're starting from a blank slate, probably the best starting point is our [[https://www.lds.org/scriptures/pgp/a-of-f/1?lang=eng][Articles of Faith]]. They're a good summary regardless.

If you're comparing with other Christian faiths, we believe that the church must be led by prophets who have received specific authority from God to do so, somewhat like the Catholic view. However, whereas the Catholic church teaches that that authority has been passed down from the original Apostles in an unbroken chain, we believe that with the martyrdom of the Apostles, the priesthood authority was lost, leading to the Dark Ages, and that God gave authority again through specific revelation and heavenly messengers in the 19th century; since that time, it has been passed down through a line of prophets, who lead the church.

If you're curious about how my faith interacts with spending time on [[/r/rational][r/rational]] and Less Wrong, I'd say that we're strongly encouraged to examine and test our beliefs, to ask questions, and to accept & benefit from true principles wherever we find them. The restoration of the gospel and priesthood authority started with a boy asking, Who/what should I believe, and how will I know?

On some topics that are often of interest in rationalist circles...we do believe that "miracles" occur, that God interacts with humanity in ways we don't understand, but we don't view these as violating any laws of physics; rather, they reflect His vastly superior knowledge and understanding of those laws. Any sufficiently advanced technology looks like magic, after all. If HJPEV actually succeeded in his ambitions of living forever, learning everything about the laws of physics, and getting so smart that he could actually make the right decisions, every time, instead of just having the language to describe where he went wrong - then we might find that he would have a lot in common with the God I believe in.

We do accept the existence of spirits, that we are inhabiting our bodies like a hand in a glove, but they too are composed of (a finer, generally-invisible form of) matter. On the other hand, there is an element of dualism, since our scriptures do state that "Intelligence, or the light of truth, was not created or made, neither indeed can be" - though that's pretty much at the limits of what has been revealed on that subject, leaving the rest to speculation.

And we take literally the Biblical statements that we are God's children. We anticipate that through a gradual process of teaching us correct principles, refining our moral character, testing our willingness to act on what we know, etc, He is preparing us - if we are willing - to create and govern worlds of our own.
:PROPERTIES:
:Author: thrawnca
:Score: 2
:DateUnix: 1479640176.0
:END:

******** Anyway, that was a bit long and probably OT, but feel free to message me any questions.
:PROPERTIES:
:Author: thrawnca
:Score: 2
:DateUnix: 1479640712.0
:END:

********* No, that was very concise, thankyou! If you don't mind me asking, how are prophets confirmed as prophets? What is the burden of proof? And sorry I am afraid I've missed the meaning of HJPEV...
:PROPERTIES:
:Score: 1
:DateUnix: 1479642174.0
:END:

********** HJPEV is Harry James Potter-Evans-Verres, the protagonist of Harry Potter and the Methods of Rationality (the founding story of rationalism as a literary genre, imo - beforehand there wasn't really a concept of rationalist literature as an area). A lot of people on this sub (maybe even most) have read it.
:PROPERTIES:
:Author: waylandertheslayer
:Score: 1
:DateUnix: 1479666083.0
:END:


********** #+begin_quote
  how are prophets confirmed as prophets?
#+end_quote

It's a pretty straightforward succession. When the current president of the church passes away, the council of the twelve apostles meets and unanimously appoints his successor (which, to date, has always been the most senior Apostle), then appoints a new Apostle to fill the vacancy. All of the Apostles hold the keys of presidency, but dormant while there is a president.

I myself have a piece of paper in my wallet, tracing my ordination (as an elder in my local congregation) back in a chain through Joseph Smith, to the original Apostles (Peter, James, John), and thus to Jesus Christ.

So, the burden of proof, then, basically hinges on whether Joseph Smith indeed received any authority.

#+begin_quote
  What is the burden of proof?
#+end_quote

Well, everyone has to decide for themselves, of course, whether they believe Joseph Smith's claims or not. Exhibit A in his case would be the [[https://www.lds.org/scriptures/bofm][Book of Mormon]], where we get our nickname from. It's a volume of about 500 pages that Joseph claimed to have translated (through divine assistance) from an ancient record of the Americas, written by prophets between 600BC and 400AD. As stated in the introduction, "We invite all men everywhere to read the Book of Mormon, to ponder in their hearts the message it contains, and then to ask God, the Eternal Father, in the name of Christ if the book is true."

You might be particularly interested in the first 4-5 chapters of Nephi, as they relate to the original topic of utilitarian vs deontological ethics. Nephi is commanded by God to kill someone for the greater good, and he freaks out a bit about it (even though the man in question had robbed and attempted to murder them, and was likely still hunting them).

What kinds of evidence would you anticipate from a prophet?
:PROPERTIES:
:Author: thrawnca
:Score: 1
:DateUnix: 1479701136.0
:END:

*********** Oh okay that makes sense. What were Joseph Smith's claims and evidential support?
:PROPERTIES:
:Score: 1
:DateUnix: 1479704395.0
:END:

************ #+begin_quote
  What were Joseph Smith's claims and evidential support?
#+end_quote

Er...I think I've already addressed a fair chunk of that above. But in more detail - he stated that a number of heavenly messengers visited him over time, and gave him directions, including:

- A personal visit from God and Jesus Christ, when he was fourteen, instructing him (in answer to his question at the time) not to join any existing church;
- An angel, several years later, directing him to the location where the Book of Mormon (engraved in an ancient language, on metal plates) was buried, along with a device that assisted him in translating it into English;
- John the Baptist, and later three of Jesus' original Apostles (Peter, James, and John) giving him priesthood authority;
- Various other messengers and visions (mostly related to directing the activities of the church and revealing doctrinal principles) at various times.

The most visible evidence is the Book of Mormon itself; whether or not it is genuine pretty much determines whether his whole account is genuine. He certainly couldn't have legitimately translated anything from an ancient language /without/ external assistance of some kind, and moreover the text itself speaks about the man who would bring it to the world, saying that he would be Joseph the son of Joseph (which Joseph Smith Jr was). So he stands or falls with the book.

Other kinds of evidence are generally much harder to quantify (such as impact on individual lives), or not demonstrable to others (such as personal revelation), but if there are particular kinds of evidence you'd expect a prophet to produce, I'm happy to discuss.

Although actually, the above-mentioned types of evidence, while not demonstrable to others, can still be reproducible. There's a good discussion in the [[https://www.lds.org/scriptures/bofm/alma/32.17-43#16][32nd chapter of Alma]].
:PROPERTIES:
:Author: thrawnca
:Score: 1
:DateUnix: 1479706912.0
:END:

************* The Book of Mormon was translated? Where did they find the originals? and Thank-you for this! Edit: I'm sorry, I've just noticed you've addressed this above. I guess my question is: do they still have these plates?
:PROPERTIES:
:Score: 1
:DateUnix: 1479707133.0
:END:

************** #+begin_quote
  do they still have these plates
#+end_quote

Unfortunately not (unfortunate for scientific inquiry, at least). It appears that the angel who showed him where to find the plates was also responsible for keeping them safe, and when Joseph was finished translating them, the angel took them back.

Since the metal used in making the plates was apparently some alloy of gold (probably because of its durability and ease of engraving), security of the plates was actually a significant issue, with many attempts at theft being narrowly thwarted.

However, there were 11 witnesses who signed statements that they saw the plates. [[https://www.lds.org/scriptures/bofm/three][Three]] stated that they were shown the plates by an angel, and heard the voice of God telling them that the plates were genuine, while the other [[https://www.lds.org/scriptures/bofm/eight][eight]], on another occasion, simply hefted them, examined them, and passed them around. Their statements are printed at the start of every copy of the book.
:PROPERTIES:
:Author: thrawnca
:Score: 2
:DateUnix: 1479731318.0
:END:

*************** Were these 11 witnesses trustworthy? Why do people believe them?
:PROPERTIES:
:Score: 1
:DateUnix: 1479801000.0
:END:

**************** Hmm...how do you measure trustworthiness? They were longtime associates of Joseph Smith, not strangers he pulled off the street; whether that makes them more reliable (because they were under more scrutiny) or less (because they might be biased by association with him), I'll leave to you. I don't know all of their personal histories, but I gather that they were known and generally respected within their communities. Martin Harris was a wealthy gentleman farmer, and Oliver Cowdery was a schoolteacher.

What I can say is that all of the three witnesses later became disaffected and were excommunicated from the church, along with several of the eight witnesses, and only a few returned - but none of them is known to have ever denied their testimony. Indeed, David Whitmer (who did not return to the church), near the end of his life, made a public statement in the newspaper affirming his testimony of the Book of Mormon, in response to allegations that he had denied it. So even when they felt no loyalty to Joseph personally, they were still apparently convinced of what they saw.

Ultimately, though, the best test of the Book of Mormon's truthfulness is contained in the book itself. First, does it teach true principles that help people to become better (eg more focused on what matters, more concerned with others' welfare, more understanding) than they were before? And second, the book gives an open promise that we can receive confirmation of its truthfulness directly from God, if we are willing to meet the conditions.
:PROPERTIES:
:Author: thrawnca
:Score: 1
:DateUnix: 1479894891.0
:END:

***************** #+begin_quote
  And second, the book gives an open promise that we can receive confirmation of its truthfulness directly from God, if we are willing to meet the conditions.
#+end_quote

Could you elaborate on that? Are you saying that there is, like, an accepted way in which you increase your chances to get a personal message from God or something? Do a significant amount of Mormons claim to actually have gotten such messages?
:PROPERTIES:
:Author: Bowbreaker
:Score: 1
:DateUnix: 1480024616.0
:END:

****************** #+begin_quote
  Could you elaborate on that?
#+end_quote

It's in [[https://www.lds.org/scriptures/bofm/moro/10.3-5?lang=eng#2][the last chapter]] of the book, inviting us, after reading it, to consider its message, and ask God whether it is true. Other conditions include "a sincere heart" (so asking just to see what happens will likely get no answer), "real intent" (which to me means, you're prepared to act on the answer if you receive it), and "faith in Christ" (although the word "faith" can be misunderstood; see [[https://www.lds.org/scriptures/bofm/alma/32.17-43#16][Alma 32]]).

#+begin_quote
  Are you saying that there is, like, an accepted way in which you increase your chances to get a personal message from God or something? Do a significant amount of Mormons claim to actually have gotten such messages?
#+end_quote

Yes, and yes - including myself. I would be happy to expand on the details, but putting it into words doesn't really express it properly. Consider: how would you describe the taste of salt? If the other person has tasted salt, you don't need to describe it, and if they haven't, there's really nothing you can say that will help them understand it. The experiment can't be demonstrated, only reproduced. But the answer to both of your questions is yes.
:PROPERTIES:
:Author: thrawnca
:Score: 1
:DateUnix: 1480045936.0
:END:


******** #+begin_quote
  I run Linux, so I lean more toward running old games in Dosbox, that kind of thing
#+end_quote

It runs great under wine.
:PROPERTIES:
:Author: traverseda
:Score: 1
:DateUnix: 1479682466.0
:END:

********* Linux has native DOSBox, actually. I guess when you're emulating an entire architecture anyway, it's not that big a deal to port it to multiple platforms...
:PROPERTIES:
:Author: thrawnca
:Score: 1
:DateUnix: 1479685545.0
:END:

********** Not dosbox runs great under wine. Fallout NV runs great under wine.
:PROPERTIES:
:Author: traverseda
:Score: 1
:DateUnix: 1479686537.0
:END:

*********** #+begin_quote
  Fallout NV runs great under wine
#+end_quote

Ah, right. Not really my style, but thanks for the heads-up.
:PROPERTIES:
:Author: thrawnca
:Score: 1
:DateUnix: 1479701531.0
:END:


**** #+begin_quote
  I guess deep down I just want to read a story where there is a completely self-absorbed protagonist, if only for novelty's sake.
#+end_quote

A recently-written quote from my NaNoWriMo attempt, "[[https://docs.google.com/document/d/1jPU6QKEohcrw6l6O3SxorIxf2Tnq54h36LtQO6Qv86w/edit][Extracts]]":

#+begin_quote
  "I may be a selfish bastard in the middle of a war zone, but I'm not /evil/."
#+end_quote

Minor spoiler: IIRC, some of the other journal entries therein include discussions about making plans to kill innocent people to survive if necessary, and the selfish reasoning for avoiding doing so if other reasonable options are available.
:PROPERTIES:
:Author: DataPacRat
:Score: 4
:DateUnix: 1479581015.0
:END:

***** I'll have to give it a look! I love the rationalisation in that quote, by the way. EDIT: Just realised how that sounded. I mean the self-justification in that quote.
:PROPERTIES:
:Score: 1
:DateUnix: 1479614258.0
:END:


**** This is my problem with stories like Luminosity. I just find that level of extreme altruism to be unbelievable. It's just not how people act, even good or saintly people. There is also nothing more inherently rational about not drinking human blood as a vampire, any more than it's necessarily more rational to be a vegan. The question comes down to your goals and values, or utility function as they say around here.

If you want stories about self-interested protagonists that can occasionaly veer into the rational, try Wuxia stories like ISSTH or WMW. The prose can be a bit sloppy in translation, though.

[[http://www.wuxiaworld.com/issth-index/]]
:PROPERTIES:
:Author: Amonwilde
:Score: 5
:DateUnix: 1479579861.0
:END:

***** #+begin_quote
  any more than it's necessarily more rational to be a vegan.
#+end_quote

Except that if you're a utilitarian without any speciesism in your system, then it *totally* follows that you should be a vegan, at least unless you make certain arguments which are only true under particular conditions that may or may not exist.

If you say "utilitarian" without qualifying it, then I'm going to assume that you're talking about the most common kind of utilitarian, who tries to maximizes pleasure and minimize pain on a universal scale (and in my experience is either vegan/vegetarian or recognizes that not being so is a shortcoming rather than something that Isn't Wrong After All)
:PROPERTIES:
:Author: callmebrotherg
:Score: 6
:DateUnix: 1479600043.0
:END:

****** I didn't mean that it wasn't rational to be a vegan, I think it can be quite rational. However, it's not axiomatic that veganism is more rational than non-veganism, you need a justification based on some chosen values. My issue isn't the conclusions they came to, more the fact that the values and ethics presented in that story are presented as if they were self-evident. The story would be stronger if there were a carnivorous (hemoverous?) vampire to articulate that side of the argument, even if they were set up to lose the debate.
:PROPERTIES:
:Author: Amonwilde
:Score: 2
:DateUnix: 1479703285.0
:END:

******* #+begin_quote
  it's not axiomatic that veganism is more rational than non-veganism
#+end_quote

He didn't say more rational. He said more utilitarian. You can be rational and not give a rat's ass about anyone or anything that can't pose a danger to your own well being.
:PROPERTIES:
:Author: Bowbreaker
:Score: 1
:DateUnix: 1480025368.0
:END:


****** How would you call someone who believes that utilitarianism is correct but chooses, on purpose, to not do the right thing?

To give an example, I personally agree that eating meat is Evil (and not a necessary evil) but I still do it. And I plan on continuing to do so until society disadvantages me for it. I know that it is wrong from a moral standpoint but I accept that level of immorality from myself.

I thought I was still a utilitarian when it comes to my beliefs and world view, but it sounds like in your opinion only people who either always act that way, or always try to act that way, or at the very least wish they /would/ try to always act that way can consider themselves utilitarians.
:PROPERTIES:
:Author: Bowbreaker
:Score: 2
:DateUnix: 1480025279.0
:END:

******* #+begin_quote
  or at the very least wish they would try to always act that way can consider themselves utilitarians.
#+end_quote

There are arguments for being a little stricter, but I feel safe in saying that this is the bare minimum. I think that this is a similar situation to a Christian whose actions evince only "belief in belief" and not actual belief. If you claim to have been convinced of a particular ethical system, but you don't even wish you would try to act in accordance with it, then I would point to this as evidence that you haven't actually been convinced.
:PROPERTIES:
:Author: callmebrotherg
:Score: 1
:DateUnix: 1480031095.0
:END:

******** I'd more compare it to someone who believes that the Christian God exists but decides to not follow his commandments. Although the lack of a hell-like threat in natural philosophy makes the analogy less than perfect.

In other words I believe that utilitarianism is the ultimately best path to do good or even to know the difference between good and not good in any given scenario. I just choose to not always do good, if that makes sense.

That doesn't mean that I am completely selfish or in any other way consistent in all my actions. My deliberate evil is pretty limited as far as I know. And I am human and thus don't do all the things I would like to do as well of course, including some things where I actually would like to be more consistently good. It simply doesn't extent to everything.

I am a happy meat eater, I place more value in my friends and family than in any amount of complete strangers, I am a self-proclaimed pro-human specieist and if there were a pill to "cure" me of all of those things (and more) I would vehemently refuse it. Yet I think that taking said pill would make me a objectively better person morally speaking.

But maybe you're right and the term utilitarian doesn't apply to me. No idea what term would instead though.
:PROPERTIES:
:Author: Bowbreaker
:Score: 1
:DateUnix: 1480037512.0
:END:


****** #+begin_quote
  if you're a utilitarian without any speciesism in your system, then it totally follows that you should be a vegan

  the most common kind of utilitarian
#+end_quote

So vegan utilitarians are vegan, and you have met a lot of vegan ulitlitarians. Which together I don't find convincing or universal.

Claiming humans are the only known animals that meet your requirements for moral worth is suspiciously convenient but not inconceivable. Usual arguments about language get there with only a little special pleading. There are other arbitrary but not unreasonable goalposts you could choose to disqualify whatever animals you wish. It's not obvious to me that there should be a strong consensus among utilitarians. Personally I doubt the consciousness of insects, and milk and cheese.
:PROPERTIES:
:Author: raisins_sec
:Score: 1
:DateUnix: 1479644327.0
:END:

******* #+begin_quote
  Claiming humans are the only known animals that meet your requirements for moral worth is suspiciously convenient but not inconceivable.
#+end_quote

Here's a variant I don't know if I've actually seen, but seems self-consistent: there is a certain probability that solipsism is actually an accurate description of reality, and that oneself really is the only being with moral worth. It's not a particularly /high/ probability, but in some highly-uncertain, near-balanced edge cases (of the sort which authours tend to love inflicting on their characters), then that tiny probability may be enough to nudge someone's actions in one direction rather than another.
:PROPERTIES:
:Author: DataPacRat
:Score: 1
:DateUnix: 1479660955.0
:END:


**** #+begin_quote
  I guess deep down I just want to read a story where there is a completely self-absorbed protagonist, if only for novelty's sake.
#+end_quote

I thought /Gone With the Wind/ was an excellent example of this, if you're into 1,000-page historical romances.
:PROPERTIES:
:Author: bassicallyboss
:Score: 1
:DateUnix: 1479887156.0
:END:


*** Oh hey! Just wanted to say I loved metropolitan man. I'll be watching for your new fic!
:PROPERTIES:
:Author: wren42
:Score: 3
:DateUnix: 1479587159.0
:END:


*** #+begin_quote
  Reading some of the interviews with Mennonites from the World War I conscientious objector board is a look into the eyes of moral madness, in my opinion
#+end_quote

Wait, really? The USA entering World War I was very beneficial to their interests, and it broke up the years-long stalemate between the two sides, but otherwise it was very morally neutral at best. Allying with Germany to defeat France+UK+Russia would not have been any less ethical than what they did.

I mean, maybe the people in whose interviews you read had very poor reason to hold their position. But I don't think it's an invalid position at all.
:PROPERTIES:
:Author: CouteauBleu
:Score: 3
:DateUnix: 1479635607.0
:END:

**** As Kellogg says, Mennonites didn't know anything about the first World War. (And more to the point, it's not even their rejection of war, including defensive war, it's their stance towards ever using force against another human being.)

#+begin_quote
  I had spent some time in examining Mennonites concerning the sinking of the /Lusitania/, but nothing significant developed from my questioning: many of them were equally unsatisfying when asked regarding General Foch and Edith Cavell. It occurred to me one day to ask a Mennonite what the Lusitania was. He did not know! He had, he told me, never heard of Edith Cavell, nor of General Foch, nor, strange to say, of General Pershing. Nor, I later ascertained, was his case an exception. I have examined at least fifty Mennonites at random in widely separated camps who did not know what the /Lusitania/ was, who Edith Cavell was, nor who General Foch or who General Pershing is. Others had heard of the /Lusitania/ --- that she was a boat which they thought had been sunk by the Germans, but they knew nothing about the surrounding facts. Several thought her an American ship; one said ''she had got into a glazier (sic) of ice." Two or three had an idea that ''Edith Cavell was some nurse who was shot." About half of them had heard of General Foch; one said he was "the manager of the French army." Pershing was more familiar; he was "the American general" or, as several of them put it, "one of the big men in the American army."

  Such ignorance, to one who has seen many of them, is hardly surprising. They are an isolated people; they do not mix freely with others.
#+end_quote

But in any case, you couldn't get CO status if you just objected to /that particular war/, due to how Congress had drafted their criteria:

#+begin_quote
  The objector who happened to disagree with the Congress or with the President regarding our entrance into this particular war clearly did not come within the Congressional enactment requiring that the objection be "against warfare in any form."
#+end_quote

Which is its own thorny moral issue.
:PROPERTIES:
:Author: alexanderwales
:Score: 5
:DateUnix: 1479659826.0
:END:


*** #+begin_quote
  Kant said that it was wrong to tell a lie to save a friend from a murderer
#+end_quote

It's interesting to note the Ten Commandments' take on this. Generally the 8th is rendered as "Don't lie", but actually it's "Thou shalt not bear false witness against thy neighbour." So it prohibits false accusation, but it doesn't blanket-prohibit lying. Which could apply in cases like the above.
:PROPERTIES:
:Author: thrawnca
:Score: 1
:DateUnix: 1479781227.0
:END:


*** I think that most if not all moral frameworks are a form of Utilitarianism. The only difference is what you define as good, how you measure it, and how much you weigh each good compared to another.
:PROPERTIES:
:Author: Radix2309
:Score: 1
:DateUnix: 1480485567.0
:END:


** I think it's about control. The deontological moral framework acknowledges that attempting to predict the future that will result from your actions is at best a crapshoot and at worst a goad to do otherwise unacceptable things. In real life, this is spot on. Humans always think they can predict the future, and in general fall short.

Rationalism as presented here is largely a way of attempting to better predict the future or understand the present. I think this appeals to a certain kind of person, and in my opinion makes a great (and different) kind of story. Unfortunately , in the real world, even people who have reread Thinking Fast and Slow and hang out on Less Wrong should probably build their ethics around the assumption that they can't predict future events. So I guess the answer is that a story about a deontologist might actually be more rational, as it acknowledges reality and our inability to actually do the things we read about in stories like HPMoR. On the other hand, it doesn't allow one to indulge in the fantasies of control that characterize most rationalist fiction, which admittedly I find as appealing as anyone here on this subreddit.
:PROPERTIES:
:Author: Amonwilde
:Score: 10
:DateUnix: 1479579184.0
:END:

*** I think that dismissing utilitarianism just because the world isn't totally predictable is a mistake. It is at the very least disingenuous, if you don't also bite the bullet and extend the same argument in favour of discarding any kind of planning and prediction in life and just simply live by following some set of rules. I think that when you try to extend deontologist reasoning to every decision it becomes obvious that we are indeed capable of imperfectly predicting the consequences of our actions to some degree and consequentialist reasoning really makes more sense most of the time.

The issue with people doing otherwise unacceptable things is a failure mode, true, although it's a failure mode of the user, rather that the system, and can be avoided in principle. Deontological reasoning has similar failure modes and you can easily construct scenarios in which rigidly following it leads people to make decisions which will have obviously unacceptable and quite predictable consequences, unless you smuggle the ability to make consequentialist judgements into it.

Consequentialism is vulnerable to abuse, but giving up on predictive reasoning entirely is throwing out the baby with the bathwater.
:PROPERTIES:
:Author: AugSphere
:Score: 5
:DateUnix: 1479654823.0
:END:

**** I'm sympathetic to your point about prediction, but I think conflating ethical and non-ethical decisions isn't fully valid. Experimentation might be ethical in one sphere and not in another, making iterative learning and planning acceptable in, say, planning milestones for a coding project but not in deciding when to tell the truth to your partner.

Funny enough, Kant uses a failure mode in describing deontological ethics, and it's the most famous example...the story with the crazed man running down the street and asking the location of your loved one. (Unfortunately a terrible branding exercise for deontological ethics.) I think justification for a deontological stance isn't really something I can bring across in this format, since a preference for deontological ethics or utilitarianism comes about through personal experience, and I'm no exception to that. But I will say that many (in my mind) impressive Weltanschung or systems of seeing the world are based on accepting the extent to which we don't have control in life, and these systems are therefore more compatible with deontological ethics. I'm thinking of stoicism and zen Buddhism among others. Note that Christianity is actually more utilitarian in my mind, as it's based on deciding you know exactly what the outcome of your actions will be (heaven or hell).

I think the extent to which Kantianism appeals to you will also have to do with personal experiences of control or acceptance, i.e. has there been something in your life that wasn't solvable and the extent of one's acceptance or non-acceptance of that. I personally think deontological ethics are generally undervalued, not just here but in general. Lying, for example, seems to be something people do very casually, often because they think or assume the lie won't come out. In my experience, lies come out far more often than people predict and a policy of never lying, even in extraordinary circumstances, has paid off with dividends for me over the years. I think part of being rational (a large part) is accepting our shortcomings. Deonotological ethics does that well. That's not to say I'm a perfect deontologist (it's hard) or that there aren't failure states (there are). But my experience has led me to believe that there are better outcomes when you make decisions based on the ethics of your actions rather than the relative desirability of that which may or may not follow.

I
:PROPERTIES:
:Author: Amonwilde
:Score: 3
:DateUnix: 1479692287.0
:END:

***** Could a useful deontological ethics system even be constructed without smuggling in consequentialism in one form or another? When you're establishing a rule against experimentation in some medical field, or a rule against lying, you're using your knowledge of the world to predict which rules will perform better. Any consistently useful system will in the end depend on predicting the consequences of the actions, there is simply no alternative that I can see. So, as I see it, the argument about deontological reasoning being advantageous due to the world being hard to predict doesn't really work. That's my sole point here. I'm not claiming that consequentialism is superior in some absolute sense, or even that it performs better in most real-world situations, I just think that particular argument from unpredictability to be flawed.

I think deontological reasoning has its place and can achieve better results in many cases. Ultimately though, I think it's a kludge that works as well as it does purely by the virtue of being optimised to counter human stupidity, rather than any inherent elegance or optimality. The less stupidity there is to counter, the less advantage over consequentialism it offers.

Amusingly enough you can also recover a fairly decent approximation of rules against lying if you [[https://sideways-view.com/2016/11/14/integrity-for-consequentialists/][add some fancy decision theory to consequentialism.]]
:PROPERTIES:
:Author: AugSphere
:Score: 3
:DateUnix: 1479704410.0
:END:

****** Yes, to come up with the axioms you need to study consequences, though those axioms have been evaluated over time. (Often a lot of time.) Kantian ethics isn't really about purity from consequences, though, it's about an ideal. That is, if everyone were to behave that way, then what would the world look like? If no one were to kill other humans, then there would be no murder, etc. The point of interest (or level of abstraction, or whatever) is set here in the moment you make the decision, not really at the point where you set up the moral system. In that way, deontological ethics seems kind of scientific. You precommit to a set of actions that have been determined to work (at least in general) through a process of long-term observation.

The post is interesting. I think if people were (or are) that clear-eyed about consequences and didn't (don't) overestimate their ability to forecast, then utilitarianism could (does) work. It seems like the mental homework you have to do to be an effective consequentialist is substantial. There might be more useful flexibility in that worldview. though.
:PROPERTIES:
:Author: Amonwilde
:Score: 1
:DateUnix: 1479711561.0
:END:

******* Looks like we're in agreement then. On one hand you have flexibility and ability to tackle new problems for which people are yet to come up with working deontological axioms; on the other: ease of use, resistance to abuse/mistakes, and the perks of precommitment.

I think that the lack of flexibility is a major factor in why we don't see much deontological reasoning in rational fiction. When you're dealing with decisions that will affect hundreds of lives, the lack of finesse can be very deadly. Rational fiction usually isn't about some store clerk whose potential mistakes won't cost hundreds of lives trying to have a happy married life, or something similarly mundane.
:PROPERTIES:
:Author: AugSphere
:Score: 2
:DateUnix: 1479750556.0
:END:


****** #+begin_quote
  the argument about deontological reasoning being advantageous due to the world being hard to predict doesn't really work
#+end_quote

Well, if I'm not mistaken, the word "deontological" implies the involvement of a deity. Generally the theory is, although we can't accurately predict the future, the deity has done so and provided suitable rules based on that prediction.
:PROPERTIES:
:Author: thrawnca
:Score: 1
:DateUnix: 1479766654.0
:END:

******* [[https://en.wikipedia.org/wiki/Deontological_ethics][Wiki]] tells me:

#+begin_quote
  from Greek δέον, deon, "obligation, duty"
#+end_quote

Doesn't seem god-related at all. Sure would have been handy if we actually had a reliable source of ready-made rules to follow.
:PROPERTIES:
:Author: AugSphere
:Score: 1
:DateUnix: 1479778699.0
:END:

******** #+begin_quote
  Doesn't seem god-related at all
#+end_quote

Huh, browsing through Wiktionary etc, it appears that you're quite right.

Though in practice, there is a lot of overlap between "moral duty imposed by some agency outside my own predictive power" and "a higher power commands it".
:PROPERTIES:
:Author: thrawnca
:Score: 1
:DateUnix: 1479781001.0
:END:

********* "Moral duty imposed by some agency outside my own predictive power" could also mean something as simple as the general consensus of a group of people you trust.
:PROPERTIES:
:Author: Bowbreaker
:Score: 1
:DateUnix: 1480027425.0
:END:


***** Also forgot to say that I agree with your point in general (prediction is important) and that I liked your response. Though that is, perhaps, a dorky sentiment.
:PROPERTIES:
:Author: Amonwilde
:Score: 2
:DateUnix: 1479692462.0
:END:


*** I've never seen rationality as a predictive element. It's always been about becoming optimally self-consistent and -efficient.
:PROPERTIES:
:Author: TennisMaster2
:Score: 2
:DateUnix: 1479587177.0
:END:

**** I don't know how one could effectively practice rationality without understanding the predictive elements. Have you read the sequences? Particularly "Making beliefs pay rent in anticipated experiences".
:PROPERTIES:
:Author: traverseda
:Score: 6
:DateUnix: 1479588355.0
:END:

***** I don't form my understanding of reality and myself based off of predictions; I base it off of observations and experiences. I have few strongly held beliefs, and those I do hold are either formed and consistent with my values or have become strong through repeated experience and observation. Even those are subject to change should I notice inconsistency.

Spending time trying to predict the consequences of my beliefs sounds like a waste of it.
:PROPERTIES:
:Author: TennisMaster2
:Score: 1
:DateUnix: 1479591241.0
:END:

****** #+begin_quote
  through repeated experience and observation
#+end_quote

That sounds an awful lot like "beliefs that predict reality, predict what I'm going to experience, are more useful".

I think you imagine prediction as a bit magical, instead of the the more mundane examples. The belief in gravity helps you predict the behavior of a falling ball.

Repeated experience and observation is another way of saying that a hypothesis has predictive power.

It doesn't mean xanatos pileups.

Standard rationalist dialect on trying to make "predictions" in the way I think you're imaging we mean prediction

[[#s][Minor hpmor spoiler]]

[[#s][continued]]

[[#s][continued]]

[[#s][continued]]

See also, the valley of bad rationality.

When we say a belief needs to have predictive power, it's not how I think you're imagining it. That's where the "bayesian" thing comes in. Percentages, not certainties.

I'm not explaining it as well as "making beliefs pay rent in anticipated experiences", but hopefully that explains what I'm talking about more or less.
:PROPERTIES:
:Author: traverseda
:Score: 8
:DateUnix: 1479591878.0
:END:

******* #+begin_quote
  When we say a belief needs to have predictive power, it's not how I think you're imagining it. That's where the "bayesian" thing comes in. Percentages, not certainties.
#+end_quote

I do think like that. And your first bit is clearly explained, thank you.

I don't want to read the HPMoR spoiler.

I suppose the phrasing 'predictive power' isn't an epistemically useful way for me to think about things. I'd rather not internalize that paradigm, especially since I've arrived at the same place.

Thanks for explaining.
:PROPERTIES:
:Author: TennisMaster2
:Score: 1
:DateUnix: 1479606036.0
:END:

******** Ah, apologies for the spoiler. Entirely my bad. I don't think it spoiled any major plot points. I'll mark it as such though.

I like prediction because it's important to doing good science. It's easy to come up with a hypothesis that fits the data post-hoc, and often time those hypothesis are wrong.

Phrasing it as predictive power does two things

- Reminds us that a hypothesis is worthless unless it's /actually/ giving as useful information

- Reminds us to create hypotheses before we get the data, which reduces mistakes a whole lot.
:PROPERTIES:
:Author: traverseda
:Score: 1
:DateUnix: 1479643953.0
:END:

********* No worries - I didn't read any of it.

To me prediction is too similar to making assumptions. I'll assume and presume, and will act accordingly, which might result in mistaken action.

Instead, I'll have an understanding; if I feel my understanding is lacking certainty in some scenario, then I'll seek to update or alter my understanding.

I see you're viewing it as:

- Experience ---> Post-hoc Hypothesis

Whereas to me that small segment is on a continuum looking like this:

- ... ---> Experience and Observation ---> Hypothesis ---> Experience and Observation ---> Hypothesis ---> Experience and Observation ---> Hypothesis ---> Experience and Observation ---> Hypothesis ---> Experience and Observation ---> Hypothesis ---> Experience and Observation ---> Hypothesis ---> ...

From that continuum you can just as verily focus on Experience and Observation ---> Hypothesis as you can on Hypothesis ---> Experience and Observation; I rather like to view it as the latter than the former, if I'm to focus on just one segment.
:PROPERTIES:
:Author: TennisMaster2
:Score: 1
:DateUnix: 1479645558.0
:END:


** HPMoR!Hermione is a rational deontologist. Harry finds clever consequentialist justifications to do unpalatable things; Hermione just doesn't do them. And she is frequently (though not always) vindicated even on consequentialist grounds. This showcases Yudkowsky's position in [[http://lesswrong.com/lw/uv/ends_dont_justify_means_among_humans/][Ends Don't Justify Means (Among Humans)]].
:PROPERTIES:
:Author: Roxolan
:Score: 13
:DateUnix: 1479599533.0
:END:


** I've always thought it's because optimization and utilitarianism complement each other very well. It makes sense that a rationalist would be drawn to these concepts. I agree though, there's room for more variety. Has there been any rational fiction that highlights the flaws with utilitarianism?
:PROPERTIES:
:Author: That2009WeirdEmoKid
:Score: 10
:DateUnix: 1479573344.0
:END:

*** I like to think that utilitarian protagonists can quickly become villains when confronted with a large enough timeframe. Establishing that a certain morally reprehensible action would result in the prolonging of the human race by another million years and seeing what the protagonist would do would be very interesting...
:PROPERTIES:
:Score: 3
:DateUnix: 1479573578.0
:END:

**** Well, that is something that comes up in the community. Donating money to friendly AI research or donating to an effective-altruist charity? Closely related to "pascals mugging" and the like. How to deal with very small probabilities that have very large consequences.
:PROPERTIES:
:Author: traverseda
:Score: 6
:DateUnix: 1479587822.0
:END:

***** I love that phrase! "Pascals mugging". Would you mind going into more depth as to what that is?
:PROPERTIES:
:Score: 2
:DateUnix: 1479614398.0
:END:

****** [[http://lesswrong.com/lw/kd/pascals_mugging_tiny_probabilities_of_vast/]]
:PROPERTIES:
:Author: 696e6372656469626c65
:Score: 8
:DateUnix: 1479628992.0
:END:


****** Sure. Imagine someone comes up to you and says "I'm a god. If you don't give me $100 right now, I'll create a billion-billion new earths, and torture everyone to death on them"

Now, if you're running preference utilitarianism and bayesian probability, the obvious answer is to say "okay". There's very little chance that they're telling the truth, but the result if they are is /so/ bad, that it balances out a $100. Is it not bad enough to balance out $100? They can just add a few more order of magnitude.

In this case the bayesian decision theory so many of us use day-to-day fails completely.

And this is why the standard lesswrong decision theory is unsuited for use in an AI or the like. When you're weird niche decision theory and common sense are both telling you very different things, go with common sense. Also, rationalists should win and adopting what the decision theory tells us to would very quickly lead to us losing.

It's worth noting that pascals mugging is actually "roko's basilisk" told differently. A solution to one is a solution to the other. It's been carefully reformatted not to cause anyone any distress. So the next time someone goes off about lesswrong banning roko's basilisk, keep in mind that the question is still open, just with less distressing connotations.
:PROPERTIES:
:Author: traverseda
:Score: 2
:DateUnix: 1479644556.0
:END:

******* The general gist of your post seems accurate enough, but there are a couple of (relatively small) factual errors. The most important such error is that a billion billion Earths isn't /nearly/ enough to balance out the Kolmogorov complexity of the hypothesis in question; you'd need something on the order of a googolplex or so before the utility of paying the $100 /actually/ starts to outweigh the improbability of a statement like "I'm a god".

Note also that there /is/ in fact a (proposed) solution to the problem: Robin Hanson has suggested that a [[http://lesswrong.com/lw/h8k/pascals_muggle_infinitesimal_priors_and_strong/][leverage penalty]] be applied to situations in which you find yourself in a unique position to affect large numbers of other individuals. Personally, I'm not entirely convinced that this solution is, in fact, a satisfactory answer to the problem (as opposed to a post-hoc patch), but the fact remains that it /has/ been proposed, and therefore you're not quite correct when you say that "the standard lesswrong decision theory... fails completely".

Finally, I'm not sure why you think Pascal's Mugging is simply a rephrasing of Roko's Basilisk. The two are, in my mind, two different thought experiments that ask two distinct questions about two separate concepts, and it doesn't seem at all obvious that they ultimately reduce to the same thing. I'm less inclined to call this a "factual error" than I was with the other two things I mentioned, but if there was any particular line of reasoning that lead you to this conclusion then I'm not seeing it.
:PROPERTIES:
:Author: 696e6372656469626c65
:Score: 1
:DateUnix: 1479677384.0
:END:

******** #+begin_quote
  Earths isn't nearly enough to balance out the Kolmogorov complexity of the hypothesis in question
#+end_quote

As the same time, rhetoric and scope insensitivity. Notice I included "add a few more billion". That particular one isn't a mistake, and I'm aware that's too low. But adding more arrows isn't how you explain the problem any better.

My hope is that a billion-billion earths is almost understandable, and then then I said "if that's not enough, they can always claim more as needed".

I also posted it well after the link to the actual article was posted.

#+begin_quote
  you're not quite correct when you say that "the standard lesswrong decision theory... fails completely".
#+end_quote

I'd argue that the standard lesswrong decision theory doesn't include that. They didn't cover it in the CFAR workshops I went to, etc. But I'll be sure to include that if I cover it again. Call it the "advanced lesswrong decision theory", where mostly what gets covered in the sequences and CFAR is the standard.

Also, post-hoc exceptions and all that. But it does seem pretty reasonable. If it becomes more widely accepted I'll count it.

#+begin_quote
  Finally, I'm not sure why you think Pascal's Mugging is simply a rephrasing of Roko's Basilisk.
#+end_quote

Roko's basilisk coming to fruition is a very unlikely event, that was treated seriously because the results are /so/ horrible. I suspect that pascals mugging is a direct result of Roko's basilisk, and attempt to prevent the lesswrong decision theory from choking on it by providing a safe example where these horrible things are so obviously not a problem.

Part of my suspicion is just the timing, and I admit is just a suspicion. But someone devout (someone who's forgotten the common sense rule) who's been exposed to pascals mugging is less likely to fall for roko's basilisk.

It addresses the core problem that could cause some people to fall for roko's basilisk, and that's why I think it's a response to it. It does ignore the acausal blackmail stuff, but that's cut-off already if you're trained not to take is seriously. Not simply a rephrasing, but saying that one solves the other is useful.

So I concede the point, but I'm still going to keep saying it.
:PROPERTIES:
:Author: traverseda
:Score: 1
:DateUnix: 1479681148.0
:END:

********* I think the thing with Roko's basilisk is that according to some people it /isn't/ necessarily an unlikely event. If you a) believe that a super-intelligence of that power level is likely to be /eventually/ created (as in, before humanity's extinction), b) expect that said super-intelligence would rather be created earlier than later if it has the choice, and c) think that acasual negotiation with completely binding precomitments are a thing even between creatures of uneven power, then the Roko's basilisk problem can seem downright probable to you.
:PROPERTIES:
:Author: Bowbreaker
:Score: 1
:DateUnix: 1480028269.0
:END:


******** What you need is not a leverage penalty, but a penalty of a type that is not directly related to complexity. A larger number is more likely to be a scam in a world full of fakers, because a faker benefits more from using a large number in his fake than using a small number.
:PROPERTIES:
:Author: Jiro_T
:Score: 1
:DateUnix: 1479845753.0
:END:

********* Unfortunately, I'm pretty sure that doesn't work. Whatever probability penalty you appeal to, it has to scale /as fast or faster than the size of the number itself/, e.g. your penalty has to penalize someone who says "a million people" /a thousand times more/ than it penalizes someone who says "a thousand people". In the case of your proposed resolution, that's obviously false--if I wanted to mug you, I'm not literally /a thousand times more likely/ to say "a million" than "a thousand". (And what if I added an extra up-arrow and said "3↑↑↑↑3" instead of "3↑↑↑3"? Am I literally ~3↑↑↑↑3 times more likely to say the former than I am to say the latter? What if I said I would torture Graham's number of people instead? How likely is /that/?)

In short, no matter how much evidence the statement that "a faker benefits more from using a large number... than using a small number" provides, it's simply /not enough/ to cancel out utilities from numbers that huge. You can't use a probability penalty like that to cancel out the expected utility because I can always just say bigger and bigger numbers and thereby outpace your penalty. The only way around this dilemma (that I can see) is to use a penalty that /scales with the number itself/, and the leverage penalty is the only one I've heard of that does that.
:PROPERTIES:
:Author: 696e6372656469626c65
:Score: 1
:DateUnix: 1479850273.0
:END:

********** A faker can't use bigger and bigger numbers because any faker would have to say a finite number and there's no even distribution over all numbers, which implies that all fakers are choosing from a distribution with a peak.
:PROPERTIES:
:Author: Jiro_T
:Score: 1
:DateUnix: 1479877099.0
:END:


** There's a common phrase I've heard which goes something like "I'm a virtue ethicist (deontologist) and I think the virtue is 'what makes the most good (utilitarianism).'"

I'm a rational deontologist whose guiding light is "What would Ender do?"

No, really.
:PROPERTIES:
:Author: TK17Studios
:Score: 2
:DateUnix: 1479642306.0
:END:

*** #+begin_quote
  I'm a rational deontologist whose guiding light is "What would Ender do?"
#+end_quote

Sounds more like an agent-based virtue ethics position than a deontological one to me.

Are we talking pre- or post-Bugger War Ender? Either way, basing your morality off a YA genre fiction character doesn't seem very rational.
:PROPERTIES:
:Author: semiurge
:Score: 2
:DateUnix: 1479677893.0
:END:

**** Eh, I've never had the subtle differences between deontology and virtue ethics clarified for me enough that I bother to label them separately. That could possibly change now, depending on people's replies.

We're talking Ender-as-sum-of-lessons-and-experiences in Ender's Game (Speaker for the Dead Ender held himself to a not-high-enough standard). And ... I dunno, I think I agree with you that it doesn't /seem/ very rational, on the face of it, but ... it works.
:PROPERTIES:
:Author: TK17Studios
:Score: 1
:DateUnix: 1479717515.0
:END:

***** Basically, deontology is defined by obligation to follow a set of rules, justified on a basis other than (or not solely by) their consequences. How these rules are justified and what they are is determined by what branch you adhere to, such as divine command theory, or Kantian, or whatever else.

Virtue ethics by contrast is defined by the character and intentions of moral actors, rather than universal principles. As a simple example, a deontologist might judge an act to be good if it does not treat another human being as a means to an end, while a virtue ethicist judges the act on whether it was motivated by justice, love, temperance, or whatever, and whether it was executed to the best of the actor's competence. Again, there are many varieties, such as Aristotelian, Confucian, agent-based, care ethics, and so on.

I say that your position is an agent-based one because it's based on you holding a set of character traits you find admirable, and then emulating a(n abeit fictional) person who possesses those traits. Feel free to disagree, there are fuzzy areas between the branches, like rules-based utilitarianism.

#+begin_quote
  but ... it works
#+end_quote

Which is great. The most sophisticated moral system in the world doesn't amount to jack shit unless it motivates its adherents to do good.
:PROPERTIES:
:Author: semiurge
:Score: 3
:DateUnix: 1479729245.0
:END:
