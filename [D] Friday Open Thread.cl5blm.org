#+TITLE: [D] Friday Open Thread

* [D] Friday Open Thread
:PROPERTIES:
:Author: AutoModerator
:Score: 22
:DateUnix: 1564758437.0
:END:
Welcome to the Friday Open Thread! Is there something that you want to talk about with [[/r/rational]], but which isn't rational fiction, or doesn't otherwise belong as a top-level post? This is the place to post it. The idea is that while reddit is a large place, with lots of special little niches, sometimes you just want to talk with a certain group of people about certain sorts of things that aren't related to why you're all here. It's totally understandable that you might want to talk about Japanese game shows with [[/r/rational]] instead of going over to [[/r/japanesegameshows]], but it's hopefully also understandable that this isn't really the place for that sort of thing.

So do you want to talk about how your life has been going? Non-rational and/or non-fictional stuff you've been reading? The recent album from your favourite German pop singer? The politics of Southern India? The sexual preferences of the chairman of the Ukrainian soccer league? Different ways to plot meteorological data? The cost of living in Portugal? Corner cases for siteswap notation? All these things and more could possibly be found in the comments below!

Please note that this thread has been merged with the Monday General Rationality Thread.


** I just want to say I /think/ I may have a new boyfriend (I do not know the French mores on when someone is a boyfriend or not, but, /bof/, just a matter of time) and what made me "like" his profile on OkCupid was that his favourite stories was basically a list of the [[/r/rational]] greatest hits.

So yeah, uh, a big thanks to this subreddit for being in the chain of causation.
:PROPERTIES:
:Author: MagicWeasel
:Score: 23
:DateUnix: 1564841185.0
:END:


** This my /Animorphs: The Reckoning/ encouragement mini-thread, inspired by a conversation I had at lunch when I recommended the fic to someone.

To [[/u/TK17Studios][u/TK17Studios]]: if you need any help and/or encouragement, here it is! We totally believe in you, and we know that whatever you post, it's going to be awesome! I myself can't wait to read what follows last chapter's cliffhanger.

To everyone else, if you've recently felt the need to post anything related to r!Animorphs or whatever, or if you want to encourage the author yourself, this is the thread.
:PROPERTIES:
:Author: CouteauBleu
:Score: 13
:DateUnix: 1564761851.0
:END:

*** ༼ つ •́•́ •́•́ ,, _ ,, •́•́ •́•́ ༽つ TK17 TAKE OUR ENERGY ༼ つ •́•́ •́•́ ,, _ ,,•́•́ •́•́ ༽つ
:PROPERTIES:
:Author: callmesalticidae
:Score: 19
:DateUnix: 1564765917.0
:END:

**** Oh, right, I forgot to say that.
:PROPERTIES:
:Author: CouteauBleu
:Score: 6
:DateUnix: 1564769477.0
:END:

***** <3 <3 <3
:PROPERTIES:
:Author: TK17Studios
:Score: 11
:DateUnix: 1564803238.0
:END:

****** Happy Cake Day!
:PROPERTIES:
:Author: daytodave
:Score: 1
:DateUnix: 1565025739.0
:END:


*** 8,800 words into Ax, with literally no other goal for the next five weeks except writing r!Animorphs.
:PROPERTIES:
:Author: TK17Studios
:Score: 2
:DateUnix: 1566352852.0
:END:

**** Yaaaaaay!
:PROPERTIES:
:Author: CouteauBleu
:Score: 1
:DateUnix: 1566383129.0
:END:

***** Wrapped at 17,600. Proceeding to Marco.
:PROPERTIES:
:Author: TK17Studios
:Score: 2
:DateUnix: 1566990852.0
:END:

****** Picked this up again after stopping reading some years ago (I think there were no more chapters). I really like what you've written so far! Any estimate on how many chapters you plan to do in the end? Will the story ever end?
:PROPERTIES:
:Author: Amezis
:Score: 1
:DateUnix: 1567100751.0
:END:

******* There are approximately fifteen chapters left; I finished one yesterday and am holding off on releasing more until I have three or four in the queue (my only goal for the next month is writing).

I hope to have a more exact count after the next chapter or two.
:PROPERTIES:
:Author: TK17Studios
:Score: 2
:DateUnix: 1567102720.0
:END:


*** [[/u/TK17Studios][u/TK17Studios]] dude, I have read the entire story up to this point at least twice and my girlfriend makes fun of me because I've been checking for a new chapter every morning since November. It's such an amazing story, and I really wish the canon book series had been this satisfying. Thanks for writing it, I had a jolt of excitement when I read that comment about the next Ax chapter being done and you working on Marco's.

​

You're kind of a dick for the ending of chapter 32 though.
:PROPERTIES:
:Author: Acroseal2019
:Score: 2
:DateUnix: 1567726626.0
:END:

**** It hurts me every bit as much as it hurts you guys; I'm only writing this because I want to get to read it. <3 <3

I'm going to wait until I have four in the tank before I start posting again, because I want to /try/ to post regularly to the very end. My guess is you'll want to look for a new chapter round about October 1, but maybe as late as October 15-20.
:PROPERTIES:
:Author: TK17Studios
:Score: 2
:DateUnix: 1567729558.0
:END:

***** How is it going?
:PROPERTIES:
:Author: BeniBela
:Score: 1
:DateUnix: 1571655595.0
:END:

****** I've written Ax and Marco and an interlude and am currently writing Rachel. Once Rachel is finished and I'm at least a third of the way through whoever's next, I'll start publishing. So a little slower than Oct 20 (obvs) but I wouldn't be surprised if it was this week, and I /would/ be surprised if it was /more/ than the end of next week.
:PROPERTIES:
:Author: TK17Studios
:Score: 1
:DateUnix: 1571670123.0
:END:


**** (you might want to consider using a RSS reader)
:PROPERTIES:
:Author: CouteauBleu
:Score: 1
:DateUnix: 1567756193.0
:END:


*** I'm really curious how thought-speak and the other kinds of telepathy work in the r!Animorphs universe.
:PROPERTIES:
:Author: daytodave
:Score: 1
:DateUnix: 1565025688.0
:END:

**** Ah geez this is a bump

Um. It's basically radio waves (not literally radio, but an electromagnetic something-or-other that can affect how neurons fire).

I took rationalization in the direction of "explain what /else/ thought-speak can do, then" rather than "explain where this came from/how it works." Thus, /given/ the ability to alter the firing of neurons in someone else's brain at long distance, what else can you do? You can scream, like Garrett, and you can cause humans to have seizures, like Ax, and you can do something that, in his own head, Visser Three refers to as "Compulsion"?
:PROPERTIES:
:Author: TK17Studios
:Score: 1
:DateUnix: 1566990647.0
:END:


** How do you think Hollywood movie production will change as China becomes an increasingly large market? They have 5x the population of the US, so if they begin to watch movies as much as the US, Europe, etc. it'll become much profitable to target them as a demographic. Will franchises like the MCU slowly shift over to asian characters do you think?
:PROPERTIES:
:Score: 14
:DateUnix: 1564785928.0
:END:

*** I think the tokenism you see in current Hollywood blockbusters is more or less how it's going to be going forward. There won't be /all/ asian characters, but there will probably be more of them. Partly I think that Hollywood isn't going to be able to out-China China, if that makes sense, and it really doesn't seem like the current state of affairs is hurting consumer response in China, at least so far as I can tell.

Current trends:

- Token characters who are Chinese and/or big names in China
- Minor Chinese characters who have a larger role in the plot in the Chinese cut
- Awareness/avoidance of Chinese taboos or things that the Chinese government doesn't like (no Taiwan, Tibet, Tienanmen Square)
- More movies that adapt Chinese history and/or mythology
- Elements of Chinese propaganda and/or changes to meet Chinese government approval
- Movies set in China
- Chinese product placement

I think all those are on-track to continue, but I'm skeptical that we're going to see Hollywood succeed at catering to the Chinese audience by being more Chinese in other ways. One high-profile failure was /The Great Wall/, which failed to capture the market share in China that it was hoped to. More attempts will obviously be made, but if you're going to have a full Chinese cast with a very Chinese story, it doesn't make sense (to me) to have it be made in/by Hollywood at all. (And I personally think that Hollywood is better off not having much of China in their films, given how much the Chinese government likes to regulate the appearance of China and Chinese characters in their films, which really constrains the kinds of stories that can be told.)
:PROPERTIES:
:Author: alexanderwales
:Score: 22
:DateUnix: 1564786954.0
:END:


*** I mean it seems like to a certain extent it's just more of the big budget, large amount of special effects type things, ala the Transformers movies or i dunno the Warcraft movie did pretty well overseas. I've heard that if anything the lowering of the story elements and increasing of the more Action Movie plot made it do better in China although it could just be that over time there are more people watching movies in general. But even from last year the Hollywood movies that sold the best were like Infinity Wars, the Jurassic Park movie, Aquaman, Venom. And from this year it's much the same in terms of big ticket action films with impressive special effects.
:PROPERTIES:
:Author: anenymouse
:Score: 11
:DateUnix: 1564798561.0
:END:


*** I think there'll be a slow but growing number of films made in the USA using US money that have limited domestic release, but wide release in China, with huge box office hauls in Chinese markets. The real question is: at what point do Hollywood studios set up Chinese offices, and how much of their staffing transfers there?
:PROPERTIES:
:Author: red_adair
:Score: 1
:DateUnix: 1564786579.0
:END:


** Is there something like a chapter synopsis of the Sequences?

I've finally got around to start reading them, but I find myself forgetting some of the earlier chapters I've read, it doesn't help that many chapter titles aren't very indicative of the content, and often it takes a while for Yudkowsky to get to his point. So I was wondering if is there a table somewhere with just a few words to help me remember whenever I forget something so I don't need to scan through several pages to remember. Something similar to that [[https://forums.spacebattles.com/threads/worm-chapter-synopsis.291627/][Worm Chapter Synopsys you can find on SpaceBattles]].
:PROPERTIES:
:Author: Nivirce
:Score: 6
:DateUnix: 1564779295.0
:END:

*** There's a shortened version of RAZ called Rationality Abridged, which summarizes each chapter into a paragraph or two. At the end of the fifth book of RAZ there's also the interlude The Twelve Virtues of Rationality, which summarizes most of the book if you've read them.
:PROPERTIES:
:Author: minekasetsu
:Score: 8
:DateUnix: 1564801217.0
:END:

**** #+begin_quote
  Rationality Abridged
#+end_quote

Here's the link to the LessWrong [[https://www.lesswrong.com/posts/uQ3AgiaryeWNpDrBN/rationality-abridged][page]] on it.

Paging [[/u/Nivirce]].
:PROPERTIES:
:Author: xamueljones
:Score: 7
:DateUnix: 1564803711.0
:END:


*** I believe there's a less wrong wiki somewhere that summarizes each concept, but I don't know where.
:PROPERTIES:
:Author: ketura
:Score: 2
:DateUnix: 1564782929.0
:END:


** I know this is more suited to the Monday thread, but I've just caught up with the Cradle books and am looking for something else to sink my teeth into.

My main requirement is that its something that can distract me for long periods of time so ideally something long (right now I'd prefer series to standalone books unless the books are really long) but also not so challenging to read that it needs to be read in one chapter chunks. It doesn't have to be rational or rational adjacent, I've just seen a lot of people here share my taste in books.

Things I've enjoyed (list not exhaustive): hitchhiker's guide to the galaxy, most of Terry Pratchett's stuff, Neil Gaiman's stuff, The Gods Are Bastards, Worth the Candle, Worm, Sanderson's books, Meiville's book, The Magicians series, Mother of Learning, Ready Player One, Ender's Game series, Dune
:PROPERTIES:
:Author: theibbster
:Score: 6
:DateUnix: 1564785887.0
:END:

*** I've got a bunch of long things to inhale.

- The Symbiote by farmerbob1, guy gets a biocomputer AI in his body, then upgrades himself and earth.

- The Suneater series by Christopher Ruocchio, has 2 books so far. It's like the name of the wind in the universe of Dune. Prose can be a bit purple sometimes but it's high quality.

- The System Apocalypse by Tao Wong. System apocalypse story with some neat ideas for litrpg. Characters are pretty good for the most part. Fun power fantasy.

- The Games We Play by Ryuugi and Forged Destiny by Coeur Al'aran. Both are fanfiction of rwby but might as well be separate stories altogether.

- Twig and pact by wildbow. Twig is better than pact.

- Savage Divinity by Ruffwriter. It's an english wuxia with transmigration. Easy to binge.

- Zombie Knight Saga by George M Frost. Cool powers and they're used very interestingly. Some of my favorite superpowered fights outside of worm.
:PROPERTIES:
:Author: CaramilkThief
:Score: 6
:DateUnix: 1564872366.0
:END:

**** #+begin_quote
  Twig is better than pact.
#+end_quote

Hey now, them's fighting words. Twig was also excellent, but I enjoyed Pact much more.

​

Though for recommendations I'd add Malazan Book of the Fallen by Steven Erikson. It's a fantasy series following the Malazan Empire, with a thoroughly unique magic system. Each book starts out painfully slow, so try to push through it if it doesn't catch you attention immediately. Also, it's 3.4 million words total, or somewhere in there.
:PROPERTIES:
:Author: lillarty
:Score: 1
:DateUnix: 1564890282.0
:END:

***** Twig has 100% more dick jokes than pact, thus it is 100% better. :)
:PROPERTIES:
:Author: CaramilkThief
:Score: 2
:DateUnix: 1564891958.0
:END:


*** For long series to inhale:

- Redwall
- Discworld
- Garth Nix's /Abhorsen/ books
:PROPERTIES:
:Author: red_adair
:Score: 4
:DateUnix: 1564786634.0
:END:

**** Redwall is a great popcorn read. I really think it fits this question perfectly.
:PROPERTIES:
:Author: Dent7777
:Score: 1
:DateUnix: 1564835930.0
:END:


**** Thanks for the recs. I've read most pf Discworld and all of Abhorsen but I will check out Redwall. I remember not getting into them as a kid but perhaps my perspective now will be different.
:PROPERTIES:
:Author: theibbster
:Score: 1
:DateUnix: 1564842668.0
:END:


*** - Codex Alera would suit you. It's a six-book series, where each book is a standard long-ish fantasy novel.
- If you haven't read the Belgariad/Mallorean yet, those are fun as well, if a bit tropey (partly due to age, partly just because they're like that, but these are classics for a reason). I'm mostly recommending this because the tone is ever-so-slightly like The Gods Are Bastards (Tellwyrn occasionally seems near-indistinguishable from Belgarath).
- The Long Earth series is quite neat, and is a Terry Pratchett/Stephen Baxter collaboration iirc. It's more sci-fi than fantasy.
- The Powder Mage trilogy is fairly good. I'm most of the way through book 2 at the moment and I'm enjoying it so far.
- [[http://www.ironteethserial.com][The Iron Teeth]], a webserial about a cowardly goblin who falls in with outlaws. It's a great deal of fun, even though the technical parts of the writing can be a bit weak. If you enjoyed Mother of Learning it shouldn't bother you too much though.
- I'm not sure exactly how to best describe it (gritty crossed with idealistic?) but David Gemmell wrote quite a few books that I really loved (my username is drawn from one of his characters). A good starting point is /Legend/ - if you like that, ping me and I can recommend a reading order if you want, or just go through in whatever order catches your fancy. Other than the Waylander and Skilgannon books, I don't think the order in which you read them matters much.

I'm happy to elaborate on any series you're intrigued by and want more info on too.
:PROPERTIES:
:Author: waylandertheslayer
:Score: 5
:DateUnix: 1564935859.0
:END:

**** Thanks for the long list. I loved the long earth but don't often come across people who've read or enjoyed it haha.

Will check out a few of those others :)
:PROPERTIES:
:Author: theibbster
:Score: 2
:DateUnix: 1564947921.0
:END:


*** You may enjoy the craft sequence by Max Gladstone.
:PROPERTIES:
:Author: James_python
:Score: 1
:DateUnix: 1564796677.0
:END:


** I've joined the Search & Rescue team for my county as a means of volunteering & learning useful skills. Team members are asked to share their skills in training sessions, and while I haven't been tapped yet, I'd like to have something to teach if and when I am.

I'm a novice at most of the outdoor skills that the group practices (technical climbing, river rescues, tracking, etc.) The one thing I think I could bring to the team is tactics for eliminating cognitive biases and fallacies which could get in the way during a crisis situation.

What tools would be most useful for a group of people who often need to operate as a team in dangerous circumstances? DaystarEld's "problem debriefing" from OoS, in which each team member brings forward the things they did wrong & could improve on, seems perfectly suited to this. Any other suggestions of tactics, or of different topics that a bookish rationalist could usefully teach a group of hardy outdoorspeople?
:PROPERTIES:
:Author: LazarusRises
:Score: 12
:DateUnix: 1564761493.0
:END:

*** You would probably want to classify your skills as planning, rather than something specific and obscure as eliminating biases. You don't want to try explaining why some processes could be biased during an emergency situation, that would be insane given how long it could take, you would want to be one of the people who sets up the procedures that are taught to everyone for emergency situations. Although it's an open question as to whether those procedures are currently biased enough that you could meaningfully improve them in a short time.

Honestly it just doesn't seem like all that applicable a skillset. Maybe try doing some cardio at the gym so that even if you aren't skilled in what the group does, you wouldn't be physically left behind.
:PROPERTIES:
:Author: sicutumbo
:Score: 15
:DateUnix: 1564790389.0
:END:

**** Yeah, I'm realizing it might not be useful after all. Oh well, worth a shot, thanks for debunking.

I'm a long-distance runner, so I'm all set on fitness. Good tip though :)
:PROPERTIES:
:Author: LazarusRises
:Score: 2
:DateUnix: 1564794244.0
:END:

***** Better start lifting and running with weight for S&R. Where I'm from it means a lot of stretcher carries, running with your pack of gear, lifting people, moving obstacles, and stabilizing spines/breaks in awkward positions.

I'm also a distance runner and it's especially rough because being good at moving your bodyweight means little compared to moving the average person.
:PROPERTIES:
:Author: RetardedWabbit
:Score: 2
:DateUnix: 1564873152.0
:END:


*** Personal opinion here: rationality is overrated.

I mean, if you know a good briefing/debriefing system, it /is/ something worth sharing, but otherwise, specific domain knowledge beats general rationality almost every time.

One failure mode of rationalism and other self-help domains is trying too hard to apply a few specific techniques in situations where they don't really bring anything.

If you wanna go that route, I'd recommend looking into crisis management advice from other emergency workers (eg emergency triage, risk-taking, advice on communication in crisis situations) and look for applicable exercises.
:PROPERTIES:
:Author: CouteauBleu
:Score: 12
:DateUnix: 1564788772.0
:END:

**** #+begin_quote
  I mean, if you know a good briefing/debriefing system, it is something worth sharing, but otherwise, specific domain knowledge beats general rationality almost every time.

  One failure mode of rationalism and other self-help domains is trying too hard to apply a few specific techniques in situations where they don't really bring anything.
#+end_quote

Perhaps better to phrase that as "thinking hard is overrated". In this case I agree with you that domain knowledge wins. Because we agree on this, I propose that having / relying on domain knowledge is the rational thing to do - and us deciding whether to rely on domain knowledge, or to question it, is us being rational.
:PROPERTIES:
:Author: Maxeonyx
:Score: 3
:DateUnix: 1564962402.0
:END:

***** I don't think "thinking hard" is quite it either, but yeah.
:PROPERTIES:
:Author: CouteauBleu
:Score: 2
:DateUnix: 1565027840.0
:END:


*** #+begin_quote
  What tools would be most useful for a group of people who often need to operate as a team in dangerous circumstances?
#+end_quote

(Things that seem useful, seem like things you'll already be doing.)

Work on the skills*** you need to use - individually, and as a group.

Work on team work/team effectiveness. (Make sure everyone has what's needed to communicate. I don't know how Search & Rescue operates or how likely it is for the team/individual members to get lost, but sensible ways of operating might prepare for this (communication devices* such as walky-talkies) and prevent it (buddy system + navigator tech &/or skills****).

Other answers mentioned domain specific knowledge.** This might be what you're looking for. You could try research, and talking to people - *do you know anyone who has done this?*

*Only thing I might add here is backup batteries. Also might be a good idea if you won't necessarily be back somewhere you can charge stuff for a time. Generally make sure you have everything you're supposed to have. (Use a checklist?)

**If I were to make this point, I'd say, knowledge wise, the goal isn't re-inventing the wheel - it's getting up to speed. I started this with skills and equipment because those will probably be needed, and are how preparation/planning cashes out - they're what you need to achieve the goal.

***I'm not sure if this is your job (find out), but depending on the circumstances, in addition to /finding/ people, if they're injured/too cold/too hot/starving/thirsty/etc. or some combination thereof, having skills to recognize the problem + stuff to fix it might be useful. Emergency blankets, basic first aid (skills and supplies), etc.

****I don't think you'll end up needing to navigate using only a paper map (perhaps best sealed in a bag, so it's safe from water) and a compass, but I could be wrong.
:PROPERTIES:
:Author: GeneralExtension
:Score: 2
:DateUnix: 1564839097.0
:END:


*** #+begin_quote
  DaystarEld's "problem debriefing" from OoS, in which each team member brings forward the things they did wrong & could improve on, seems perfectly suited to this. Any other suggestions of tactics, or of different topics that a bookish rationalist could usefully teach a group of hardy outdoorspeople?
#+end_quote

Also from DaystarEld, but I really like pre-mortems. They could be especially useful to go through en route to the problem area, as a way of preparing for the likely issues you will face once you arrive.
:PROPERTIES:
:Author: waylandertheslayer
:Score: 1
:DateUnix: 1564935991.0
:END:


** If you were 16, could teleport, and have a competent government agency looking for a teleporter, how could you make money without getting caught or doing anything that would hurt people?
:PROPERTIES:
:Author: chlorinecrown
:Score: 5
:DateUnix: 1564835985.0
:END:

*** Haave you read much/any [[https://www.goodreads.com/series/49082-jumper][Steven Gould]] or Larry Dahners?
:PROPERTIES:
:Author: iftttAcct2
:Score: 7
:DateUnix: 1564883027.0
:END:


*** Range, accuracy, speed, energy cost, carrying capacity?

Edit: Sufficiently analyzed, doing anything eventually hurts people.

Edit 2: Are you sure that this isn't [[/r/rational/comments/cljqeu/d_saturday_munchkinry_thread/][munchkinry]]?
:PROPERTIES:
:Author: kcu51
:Score: 4
:DateUnix: 1564858224.0
:END:

**** Range, ~10km, speed, 1 or 2 seconds, carrying capacity is whatever he can hold. So yes to a bike, no to a car. If he tried holding an attached steering wheel it just wouldn't work, it wouldn't break it off.

I'll prob repost this there Monday/search through old threads in a bit.

I guess the greater concern with bank robbing is the attention it draws, assuming they're insured.
:PROPERTIES:
:Author: chlorinecrown
:Score: 5
:DateUnix: 1564867287.0
:END:


*** I wouldn't work for the government. I would be a high end courier who can take your package directly from your door to it's intended recipient in a flash. I would charge enough that I could cover a reasonable standard of living for myself as well as hire competent people at decent wages to deal with the legals, client management, etc.

Perhaps I would do a combination of private couriering door to door as well as m9ve bulk deliveries internationally (maybe transporting produce to far off countries saving on refrigeration or whatever else is involved in transit).

Part of the job of the people I hire would be to ensure I never transport something I find ethically questionable like weapons, I would probably carry a scanner to check on things or require a visual inspection.

I think I would also not necessarily need to make a lot of money if I didn't want to. I could have a tent I pitch up wherever the weather's good, teleport to public toilets wherever they're cleanest, bathe in hot springs, forage food from several countries or eat at temples where food is free. I think at 16 something like this would have been appealing to me. It's also appealing to know you can afford to turn down work cause you'd always be fine anyways.
:PROPERTIES:
:Author: theibbster
:Score: 4
:DateUnix: 1564846061.0
:END:

**** Sorry, the govt agency in question is hostile to said teleporter. So acting as a courier would require a plausible mundane explanation /advertising method.

The money is required to pay rent and groceries for ~10 kids who also need to be kept hidden.
:PROPERTIES:
:Author: chlorinecrown
:Score: 4
:DateUnix: 1564849297.0
:END:

***** Can the government track teleporters? If not why not just camp somewhere? Teleport to remote villages with no surveillance or maybe even electricity for food/sustenance/etc? Just be off the grid and gather tools with teleporting as an ability?
:PROPERTIES:
:Author: theibbster
:Score: 2
:DateUnix: 1564866742.0
:END:

****** The teleprting has a range of ~10 km and requires good knowledge of the destination ahead of time.

I think living off the land would still be difficult, no?
:PROPERTIES:
:Author: chlorinecrown
:Score: 2
:DateUnix: 1564867008.0
:END:


***** Does the agency want to kill us? Will they otherwise violate the law?
:PROPERTIES:
:Author: kcu51
:Score: 2
:DateUnix: 1564876376.0
:END:

****** I'm envisioning a black ops sorta thing, they capture kids with weird powers and abuse them, like Eleven in the beginning of stranger things, and have few issues killing innocent people to uphold the masquerade/capture the kids. MC is trying to rescue/protect them.
:PROPERTIES:
:Author: chlorinecrown
:Score: 2
:DateUnix: 1564877914.0
:END:


***** Just reveal yourself to a celebrity or celebrities (e.g Oprah) that it would be incredibly inconvenient for the gov to disappear and get their assistance
:PROPERTIES:
:Author: MrCogmor
:Score: 2
:DateUnix: 1564884263.0
:END:

****** Y'know, I don't want to write that story but with the rules I have so far this probably would be safest. I guess I need to make the hostiles scary enough that they could plausibly kill any celebrity he might care to try. Maybe even have him try it and the celebrity gets smeared and then have a convenient overdose.
:PROPERTIES:
:Author: chlorinecrown
:Score: 2
:DateUnix: 1564891528.0
:END:


*** Claim asylum from another country on account of being hunted by your current one, and work there instead.
:PROPERTIES:
:Author: GeeJo
:Score: 2
:DateUnix: 1564856308.0
:END:

**** The hostile agents have no problem illegally crossing borders in this scenario.
:PROPERTIES:
:Author: chlorinecrown
:Score: 2
:DateUnix: 1564877983.0
:END:

***** A country with well-guarded borders, then. China or Russia, maybe.
:PROPERTIES:
:Author: kcu51
:Score: 1
:DateUnix: 1564935629.0
:END:


** I've been wondering- is there some sort of updated map/link directory to other rationalist communities?

And I don't mean Slate Star Codex or Lesswrong. I mean international communities.

Various political terms, 'famous' people references, references in general, meetup locations and CFAR made me realize- I am an outsider here, in practical terms. It's an American site with (mostly) American people, referring to events and terms local to you. It'll be nice to find a place where a theoretical meetup wouldn't require getting a visa and crossing the ocean.

Other than that, it'll be fascinating to see how does this community connect to others- rationalists are focused on global issues, and it's hard to work on those alone.
:PROPERTIES:
:Author: PurposefulZephyr
:Score: 5
:DateUnix: 1564857830.0
:END:

*** [[https://www.lesswrong.com/community]], then SSC has an about yearly tradition to initiate new meetups and lastly its very easy to try to start your own meetup. Just set a time/date/place, make this public by spamming all the webspaces you have access to.
:PROPERTIES:
:Author: SvalbardCaretaker
:Score: 5
:DateUnix: 1564860093.0
:END:


** So The Hero was released for Smash Bros Ultimate. I love the Dragon Quest series so Ive gotten into Smash now. Does anyone want to be friends and play together? I am not very good at Smash Bros

My friend code is: SW-8030-5632-6924
:PROPERTIES:
:Author: SkyTroupe
:Score: 5
:DateUnix: 1564874566.0
:END:

*** sure, I'll add you.
:PROPERTIES:
:Author: roochkeez
:Score: 3
:DateUnix: 1564883762.0
:END:

**** Thanks!
:PROPERTIES:
:Author: SkyTroupe
:Score: 2
:DateUnix: 1565022756.0
:END:


** The GMTK Game Jam starts in about 35 minutes (2pm UK time). We on the [[/r/rational]] discord have a team of around 7 people aiming to contribute at least a little in various disciplines. If you can do digital art and would like to make it look a little prettier, or you just want to help playtest, or just want to admire the chaos, then the server's thattaway: [[https://discord.gg/cpqPkYx]].

We'll be sure to post our monstrous creation here next week so you can gawk and laugh at it.
:PROPERTIES:
:Author: ketura
:Score: 4
:DateUnix: 1564770292.0
:END:


** Hey all! Anyone want to code on the gigantic LED butterfly I'm working on? :D [[https://github.com/rangerscience/butterfly]]
:PROPERTIES:
:Author: narfanator
:Score: 3
:DateUnix: 1564863978.0
:END:


** I've started playing chess, because it's a "smart person" hobby that I was embarrassingly bad at. Not really the best reason, or the best use of my time, but it's fun!

I currently have a rating of 870 for 10 minute games on [[https://chess.com][chess.com]]. This puts me at around the 35th percentile (from the bottom) for this category, still pretty bad.

Does anyone else play?
:PROPERTIES:
:Author: Revisional_Sin
:Score: 3
:DateUnix: 1564946208.0
:END:

*** I enjoy playing the Fried Liver attack, but don't usualy get to play it. It depends on the opponent making certain moves, including a mistake. The important part is when you fork the queen and rook with the knight, prompting the King to take it. The next usual move is to attack with the Queen, forcing the King into the middle of the board; you now have a lot of attacking opportunities.

Instead of moving the King into the middle, some players will move the King to the back rank (g8) where the Knight starts. This is a TERRIBLE idea, causing an unavoidable checkmate in 5 moves.

If they play the best move (King to the middle of the board) the position is considered theoretically equal, but much easier to play as white. Surprisingly, I've lost the two games I played from this position; I couldn't attack fast enough, allowing them to neutralise the threat.

​

Before writing this post, I thought the Fried Liver Attack was considered to begin when the King was in the middle, but it's actually when the King accepts the Knight sacrifice. So I have actually won with the Fried Liver Attack!
:PROPERTIES:
:Author: Revisional_Sin
:Score: 1
:DateUnix: 1564955141.0
:END:


** Why do rationalists stereotypically deny an afterlife? Isn't every possible reality predicted by/included in the universal dovetailer function?
:PROPERTIES:
:Author: kcu51
:Score: 3
:DateUnix: 1564971074.0
:END:

*** Can you unpack your argument a little? You're not giving us much to work with.
:PROPERTIES:
:Author: Revisional_Sin
:Score: 4
:DateUnix: 1565005099.0
:END:

**** I don't have many specific citations, but [[/u/EliezerYudkowsky]] once said "[[https://lesswrong.com/lw/3j/rationality_cryonics_and_pascals_wager/6dv?context=3][the dead are dead]]". And there's the popularity of the idea of local immortality, despite its potentially only prolonging separation from deceased relations.
:PROPERTIES:
:Author: kcu51
:Score: 2
:DateUnix: 1565006515.0
:END:

***** I meant the second part. I agree with the first ;)

#+begin_quote
  Isn't every possible reality predicted by/included in the universal dovetailer function?
#+end_quote
:PROPERTIES:
:Author: Revisional_Sin
:Score: 2
:DateUnix: 1565028358.0
:END:

****** Are you familiar with the concept of said function?
:PROPERTIES:
:Author: kcu51
:Score: 2
:DateUnix: 1565029600.0
:END:

******* I spent about 20 seconds googling it. I guess it's possible, but there's no evidence that we're being run by a UDF.

I don't see how this gives us an afterlife. Do you think our consciousness gets transported to another world when we die?

I don't buy it, please explain.
:PROPERTIES:
:Author: Revisional_Sin
:Score: 3
:DateUnix: 1565070668.0
:END:

******** #+begin_quote
  I spent about 20 seconds googling it. I guess it's possible, but there's no evidence that we're being run by a UDF.
#+end_quote

What about Occam's razor?

If you compute the first 1000 numbers of the Fibonacci sequence, and someone else independently computes the first 10000, does the sequence "get transported" from one computer to the other?
:PROPERTIES:
:Author: kcu51
:Score: 1
:DateUnix: 1565125766.0
:END:

********* I still have no idea how this connects to the afterlife. I'm guessing you're going for some kind of Quantum Immortality scenario, but this doesn't really map to an afterlife.

Can you give your argument so we're all on the same page? Here's my model of your argument:

- Our reality could be run on a Turing Machine (TM).
- A TM could enumerate every possible reality and run it.
- We're more likely to be on the second TM than the first.
- There is a version of you in multiple realities. ??
- ???
- Afterlife.

Please provide your entire chain of reasoning.
:PROPERTIES:
:Author: Revisional_Sin
:Score: 1
:DateUnix: 1565162145.0
:END:

********** I might as well ask for your "entire chain of reasoning" to the contrary. It's difficult to build a bridge when you can't see the place you're building it to. And it annoys both parties if one ends up giving elaborate "explanations" of things that the other already recognizes as obvious.

To try to address your bulleted points:

- Any observation can be modeled as or in a Turing machine (or the equivalent) in infinitely many ways.
- We have no reason to assume that any one or set of these has some magical quality of "realness" which the others lack. We can't even coherently define what that would mean. By definition, any observation we make only gives us information common to all possible Turing machines containing us and that observation.
- If for some reason we were compelled to believe it, though, we'd apply Occam's razor in determining what kind of machine it was. That would give us the universal dovetailer, which would give us every possible Turing machine anyway.
- This is to say nothing of the possibilities of quantum superpositions, recurrent Earths in a sufficiently large universe, or recurring Big Bangs.
- Between these factors, we can safely say that every mind-moment (edit: or mind-transformation) exists in an infinite variety of realities.
- We can also say that for every mind-moment, at least one successor mind-moment exists. (An infinite variety, in fact.)
- In other words, you can always expect your experience of consciousness to continue. It might dip below the level of self-awareness for periods (as in sleep), or it might become something no longer recognizable as you, but there is no true "oblivion" or "nothingness".
- Pull back to the "the universe" as we usually understand it; a single, unique Turing machine containing/implementing single, unique versions of us perceiving it from the inside. Pick any of the infinite versions of it.
- This machine both exists in itself, and is implemented in infinitely many ways by others.
- Most of these implementations are inconsequential to us.
- However, one class of them is potentially highly consequential.
- A universe's native sapience --- presumably coordinating via, or possibly consisting of, AI --- decides to implement an afterlife.
- The AI computes a randomly chosen Turing machine; or else the universal dovetailer; and monitors it for sentient processes.
- When such a process ends within the computed machine, the AI extracts it and continues it outside the machine.
- Such universes seem likely to be much more probable/have greater measure than any "quantum immortality" or Boltzmann brains, especially in the long run.

What's unclear or missing?
:PROPERTIES:
:Author: kcu51
:Score: 1
:DateUnix: 1565224755.0
:END:

*********** Taking as axiomatic "this universe is running on a turing machine", the leap to "this universe is being generated by a universal dovetailer which is simulating every possible turing machine" still does not seem to be the result given by Occam's Razor. Any explanation for our universe as turing machine which does not also require the existence of every other possible turing machine would have the advantage where Occam's Razor is concerned, given that we have observed the existence of our universe, and have not observed the existence of infinitely many other universes. Even if we take many-worlds to be the correct interpretation of quantum physics, that only guarantees the existence of every universe which could follow from our universe's initial state, which is infinitesimally small compared to the existence of every possible turing machine. From these points, the remainder of the argument falters.
:PROPERTIES:
:Author: reaper7876
:Score: 1
:DateUnix: 1565293258.0
:END:

************ #+begin_quote
  Taking as axiomatic "this universe is running on a turing machine", the leap to "this universe is being generated by a universal dovetailer which is simulating every possible turing machine" still does not seem to be the result given by Occam's Razor. Any explanation for our universe as turing machine which does not also require the existence of every other possible turing machine would have the advantage where Occam's Razor is concerned, given that we have observed the existence of our universe, and have not observed the existence of infinitely many other universes.
#+end_quote

How do you add restrictions to what the dovetailer produces without making it more complicated?

#+begin_quote
  Even if we take many-worlds to be the correct interpretation of quantum physics, that only guarantees the existence of every universe which could follow from our universe's initial state, which is infinitesimally small compared to the existence of every possible turing machine.
#+end_quote

How much do we know about the possible universes that could follow from ours' initial state? Is there any reason to think that the right quantum phenomena couldn't make them arbitrarily large, resource-rich and stable?
:PROPERTIES:
:Author: kcu51
:Score: 1
:DateUnix: 1565315314.0
:END:

************* #+begin_quote
  How do you add restrictions to what the dovetailer produces without making it more complicated?
#+end_quote

By not having a universal dovetailer at all. There are many, /many/ turing machines with functionality less complicated than "produce every possible turing machine". (To say that there is merely many such machines is understating the issue, actually.)

#+begin_quote
  How much do we know about the possible universes that could follow from ours' initial state? Is there any reason to think that the right quantum phenomena couldn't make them arbitrarily large, resource-rich and stable?
#+end_quote

The law of conservation of energy has been known to hold some strong opinions on the subject of creating arbitrarily large quantities of resources, yes. Is it /conceivable/ that we'll find a way around that? Sure! All it would take (as far as we know) is making it so that physics is not symmetrical over time. But if such a work-around exists, knowledge of it is beyond our current level of scientific understanding, and is absolutely not something on which to base the guarantee of an afterlife.
:PROPERTIES:
:Author: reaper7876
:Score: 1
:DateUnix: 1565316994.0
:END:

************** #+begin_quote
  By not having a universal dovetailer at all. There are many, many turing machines with functionality less complicated than "produce every possible turing machine". (To say that there is merely many such machines is understating the issue, actually.)
#+end_quote

And that nevertheless could plausibly produce our universe? How?

#+begin_quote
  The law of conservation of energy has been known to hold some strong opinions on the subject of creating arbitrarily large quantities of resources, yes.
#+end_quote

Even at the quantum level, with virtual particles and the like? Some people say that the universe began with infinite energy at infinite density; is that now known to be wrong?
:PROPERTIES:
:Author: kcu51
:Score: 1
:DateUnix: 1565317708.0
:END:

*************** #+begin_quote
  And that nevertheless could plausibly produce our universe? How?
#+end_quote

Instead of assuming initial conditions that produce a universal dovetailer that produces a turing machine that produces our universe, you could instead assume initial conditions that produce a turing machine that produces our universe. It's a simpler assumption, and also one that doesn't posit infinitely many universes we have no indication exist.

#+begin_quote
  Even at the quantum level, with virtual particles and the like? Some people say that the universe began with infinite energy at infinite density; is that now known to be wrong?
#+end_quote

/Known/ to be wrong? No, we don't have any ironclad proof of that. We also don't have any ironclad proof that the universe didn't begin as three interlocking serpents, each consuming the tail of another. But given that the universe does not /currently/ appear to contain infinite energy, and given that infinite energy does not reduce to finite energy no matter how many times you subdivide it, there is not a strong case in favor of the claim. (Starting from infinite density is another matter entirely, and is assumed by the Big Bang Theory.)

Edit: sorry, forgot to address the first part of that. Quantum Mechanics /may/, conceivably, allow for breaking continuous time translation symmetry, but again, scientific knowledge hasn't advanced to the point where we can make that claim with any confidence.
:PROPERTIES:
:Author: reaper7876
:Score: 1
:DateUnix: 1565318512.0
:END:

**************** #+begin_quote
  Instead of assuming initial conditions that produce a universal dovetailer that produces a turing machine that produces our universe, you could instead assume initial conditions that produce a turing machine that produces our universe.
#+end_quote

What "conditions" would those be?

#+begin_quote
  /Known/ to be wrong? No, we don't have any ironclad proof of that. We also don't have any ironclad proof that the universe didn't begin as three interlocking serpents, each consuming the tail of another.
#+end_quote

Is anything known, then?

#+begin_quote
  infinite energy does not reduce to finite energy no matter how many times you subdivide it
#+end_quote

Not even if it expands into infinite space?
:PROPERTIES:
:Author: kcu51
:Score: 1
:DateUnix: 1565319991.0
:END:

***************** #+begin_quote
  What "conditions" would those be?
#+end_quote

I haven't the slightest. I assume you don't know what initial conditions produce a universal dovetailer, either. (If I'm wrong on that, feel free to correct me, and then feel free to collect your Nobel.) Nonetheless, the requirements for a universal dovetailer to exist are substantially more intricate than the requirements for a turing machine to exist, and as a consequence, whatever initial conditions might give rise to it would also need to be more complicated. For one thing, a universal dovetailer would necessarily require both infinite turing tape and the ability to run infinitely many programs in parallel (or else it would sputter out the first time it found a program that didn't halt). A turing machine running our universe wouldn't necessarily require either of those things--it could instead use, for example, a single very large strip of turing tape, which is nonetheless finite, and we wouldn't notice up until the moment it ran out.

#+begin_quote
  Is anything known, then?
#+end_quote

Not in the sense of being [[https://en.wikipedia.org/wiki/Certainty][irrevocably certain]], no. In the layman's sense, it is possible to be very confident about things.

#+begin_quote
  Not even if it expands into infinite space?
#+end_quote

Trying to do math with infinity gets messy, especially with multiple infinities, because infinity isn't actually a number (unless you're playing with hyperreals). In this particular case, dividing infinity by infinity doesn't give any coherent result. More specifically, depending on how you calculate it, ∞ / ∞ can give any number of results, all of which are mutually contradictory. If the energy involved was growing without bound (toward a limit of infinity), and the division across space was growing without bound (toward a limit of infinity), then we could do some analysis of the rates and get a reasonable calculation of the energy density involved that way. As is, though, the scenario doesn't mathematically parse.
:PROPERTIES:
:Author: reaper7876
:Score: 2
:DateUnix: 1565322377.0
:END:

****************** #+begin_quote
  I haven't the slightest. I assume you don't know what initial conditions produce a universal dovetailer, either. (If I'm wrong on that, feel free to correct me, and then feel free to collect your Nobel.)
#+end_quote

A universal dovetailer. It's not a hard question.

#+begin_quote
  For one thing, a universal dovetailer would necessarily require both infinite turing tape and the ability to run infinitely many programs in parallel (or else it would sputter out the first time it found a program that didn't halt).
#+end_quote

Are we talking about the same algorithm? It runs a cycle of program 1, then a cycle each of programs 1 and 2, and so on. It never reaches infinity; and in fact, no Turing machine can.

"Infinite tape" is part of the definition of a Turing machine.

#+begin_quote
  A turing machine running our universe wouldn't necessarily require either of those things--it could instead use, for example, a single very large strip of turing tape, which is nonetheless finite, and we wouldn't notice up until the moment it ran out.
#+end_quote

"The universe will behave as it has, until some arbitrary future point when it stops" is a strictly more complex hypothesis than "The universe will behave as it has".

#+begin_quote
  Not in the sense of being irrevocably certain, no. In the layman's sense, it is possible to be very confident about things.
#+end_quote

Most people call that knowledge.

#+begin_quote
  Trying to do math with infinity gets messy, especially with multiple infinities, because infinity isn't actually a number (unless you're playing with hyperreals). In this particular case, dividing infinity by infinity doesn't give any coherent result. More specifically, depending on how you calculate it, ∞ / ∞ can give any number of results, all of which are mutually contradictory. If the energy involved was growing without bound (toward a limit of infinity), and the division across space was growing without bound (toward a limit of infinity), then we could do some analysis of the rates and get a reasonable calculation of the energy density involved that way. As is, though, the scenario doesn't mathematically parse.
#+end_quote

And yet, many cosmologists will tell you for a fact (or at least a seriously held belief) that the universe is infinite.
:PROPERTIES:
:Author: kcu51
:Score: 2
:DateUnix: 1565327223.0
:END:

******************* #+begin_quote
  A universal dovetailer. It's not a hard question.
#+end_quote

Sorry, your hypothesis is that the universal dovetailer is run by another universal dovetailer? That seems to very obviously just push the question back a step. Where did that one come from? Is it turtles all the way down?

#+begin_quote
  "The universe will behave as it has, until some arbitrary future point when it stops" is a strictly more complex hypothesis than "The universe will behave as it has".
#+end_quote

The point is that a dovetailer would require the infinite tape to exist, or else it wouldn't produce every single program. The singular universe is produced equally well with or without it, thus does not require an assumption either way, thus is the less complex hypothesis.

#+begin_quote
  And yet, many cosmologists will tell you for a fact (or at least a seriously held belief) that the universe is infinite.
#+end_quote

They are certainly welcome to that belief. It doesn't change the fact that taking infinite energy and dividing it across infinite space produces no coherent mathematical result.
:PROPERTIES:
:Author: reaper7876
:Score: 2
:DateUnix: 1565353064.0
:END:

******************** #+begin_quote
  Sorry, your hypothesis is that the universal dovetailer is run by another universal dovetailer? That seems to very obviously just push the question back a step. Where did that one come from? Is it turtles all the way down?
#+end_quote

If everything that things "come from" has to "come from" something else, then yes, there must necessarily be turtles all the way down. It doesn't make sense to me, but taking it as a premise, Occam's razor favors the simplest possible form of turtle.

#+begin_quote
  The point is that a dovetailer would require the infinite tape to exist, or else it wouldn't produce every single program. The singular universe is produced equally well with or without it, thus does not require an assumption either way, thus is the less complex hypothesis.
#+end_quote

The point is that "the tape is infinite" doesn't add complexity. It's the normal state of any model/hypothesis. "The tape will eventually run out" does. The tape is a metaphor, not an actual physical substance.

#+begin_quote
  They are certainly welcome to that belief. It doesn't change the fact that taking infinite energy and dividing it across infinite space produces no coherent mathematical result.
#+end_quote

How do you take nonzero density and spread it across infinite space without producing infinite energy?
:PROPERTIES:
:Author: kcu51
:Score: 2
:DateUnix: 1565363848.0
:END:

********************* #+begin_quote
  If everything that things "come from" has to "come from" something else, then yes, there must necessarily be turtles all the way down. It doesn't make sense to me, but taking it as a premise, Occam's razor favors the simplest possible form of turtle.
#+end_quote

That is not the simplest form of turtle, though! The simplest form of that assumption would be that the universe in some way reproduces other universes, not that the universe in some way produces every single conceivable kind of universe ad infinitum!

#+begin_quote
  The point is that "the tape is infinite" doesn't add complexity. It's the normal state of any model/hypothesis. "The tape will eventually run out" does. The tape is a metaphor, not an actual physical substance.
#+end_quote

Sure, fine. That's acceptable.

#+begin_quote
  How do you take nonzero density and spread it across infinite space without producing infinite energy?
#+end_quote

How are you spreading a central source of energy across infinite space in finite time at all? The universe does have a speed limit. To answer your question, though, I would not expect energy to distribute itself evenly, but clump together, leaving more energy in some places and less (maybe even no or negligible quantities) in others.
:PROPERTIES:
:Author: reaper7876
:Score: 1
:DateUnix: 1565365302.0
:END:

********************** #+begin_quote
  That is not the simplest form of turtle, though! The simplest form of that assumption would be that the universe in some way reproduces other universes, not that the universe in some way produces every single conceivable kind of universe ad infinitum!
#+end_quote

Are you saying that it's simpler to assume that the universe somehow produces only identical copies of itself?

#+begin_quote
  Sure, fine. That's acceptable.
#+end_quote

Then I've convinced you?

#+begin_quote
  How are you spreading a central source of energy across infinite space in finite time at all? The universe does have a speed limit.
#+end_quote

Are you rejecting the Big Bang and cosmic inflation, then?

#+begin_quote
  To answer your question, though, I would not expect energy to distribute itself evenly, but clump together, leaving more energy in some places and less (maybe even no or negligible quantities) in others.
#+end_quote

So we inhabit a finite "clump" of matter and energy, beyond which is infinite empty space without even background radiation? Why assume that our region of the universe is atypical?
:PROPERTIES:
:Author: kcu51
:Score: 1
:DateUnix: 1565367819.0
:END:

*********************** #+begin_quote
  Are you saying that it's simpler to assume that the universe somehow produces only identical copies of itself?
#+end_quote

I'm saying that "universes produce new universes of some description" is strictly simpler than "universes produce new universes comprising the set of all conceivable universes". Nowhere did I say all universes had to be the same.

#+begin_quote
  Then I've convinced you?
#+end_quote

Of the overall point? Not by a mile, no.

#+begin_quote
  Are you rejecting the Big Bang and cosmic inflation, then?
#+end_quote

"Space is expanding" is different from "space is infinite". The former is completely consistent with finite density and finite mass, and would see a steady decrease in the overall density of the universe, eventually leading to the finite clumps of energy and mass, beyond which is primarily empty space.
:PROPERTIES:
:Author: reaper7876
:Score: 1
:DateUnix: 1565370788.0
:END:

************************ #+begin_quote
  I'm saying that "universes produce new universes of some description" is strictly simpler than "universes produce new universes comprising the set of all conceivable universes". Nowhere did I say all universes had to be the same.
#+end_quote

I thought we'd agreed that adding restrictions on what a model/hypothesis "produces" doesn't make it simpler.

#+begin_quote
  Of the overall point? Not by a mile, no.
#+end_quote

Then I wish I understood your rejection better. So far it doesn't seem very grounded in epistemology.

#+begin_quote
  "Space is expanding" is different from "space is infinite". The former is completely consistent with finite density and finite mass, and would see a steady decrease in the overall density of the universe, eventually leading to the finite clumps of energy and mass, beyond which is primarily empty space.
#+end_quote

But the former is what involves the speed of light being exceeded. The speed of light limits movement through space, not the expansion of space itself.

Are you now agreeing that finite mass is inconsistent with infinite space and nonzero density?
:PROPERTIES:
:Author: kcu51
:Score: 1
:DateUnix: 1565374655.0
:END:

************************* #+begin_quote
  I thought we'd agreed that adding restrictions on what a model/hypothesis "produces" doesn't make it simpler.
#+end_quote

The former isn't the one putting in restrictions, the latter is. The former is true across the set of all realities in which universes produce other universes of any description. The latter is only true in the subset of those realities in which universes generate /every conceivable/ universe. The probability space is narrower for the latter than the former, hence the latter is the more restricted.

#+begin_quote
  Then I wish I understood your rejection better. So far it doesn't seem very grounded in epistemology.
#+end_quote

Gezundheit.

#+begin_quote
  But the former is what involves the speed of light being exceeded. The speed of light limits movement through space, not the expansion of space itself.

  Are you now agreeing that finite mass is inconsistent with infinite space and nonzero density?
#+end_quote

Ah, okay. Let me make sure I understand what you're suggesting. The idea you have is that the universe starts with infinite energy of infinite density at a singularity. Then, space expands at infinite speed, creating a universe of infinite space, with finite energy at any given point. Is that correct? If so, then I'll offer my rebuttal, but first I want to make sure that that is in fact what you mean.
:PROPERTIES:
:Author: reaper7876
:Score: 1
:DateUnix: 1565391075.0
:END:

************************** #+begin_quote
  The former isn't the one putting in restrictions, the latter is. The former is true across the set of all realities in which universes produce other universes of any description. The latter is only true in the subset of those realities in which universes generate /every conceivable/ universe. The probability space is narrower for the latter than the former, hence the latter is the more restricted.
#+end_quote

But if universes produce others, which produce others, and so on ad infinitum, they'll eventually produce all universes possible within whatever variance is allowed.

Also, it sounds like you're now acknowledging multiple realities regardless.

#+begin_quote
  Ah, okay. Let me make sure I understand what you're suggesting. The idea you have is that the universe starts with infinite energy of infinite density at a singularity.
#+end_quote

I wouldn't say "singularity", but essentially. This is where you get infinite energy ÷ infinite density = ???.

#+begin_quote
  Then, space expands at infinite speed, creating a universe of infinite space, with finite energy at any given point.
#+end_quote

Depends on how you define speed of expansion. Any two actual points are separated by finite distance, and moving away from each other at finite speed proportional to that distance.

#+begin_quote
  Is that correct? If so, then I'll offer my rebuttal
#+end_quote

Offer it to the mainstream cosmologists; I'm just describing my understanding of the mainstream "infinite universe" model. Do I have it wrong?
:PROPERTIES:
:Author: kcu51
:Score: 2
:DateUnix: 1565403017.0
:END:

*************************** #+begin_quote
  But if universes produce others, which produce others, and so on ad infinitum, they'll eventually produce all universes possible within whatever variance is allowed.

  Also, it sounds like you're now acknowledging multiple realities regardless.
#+end_quote

'Within whatever variance is allowed' would be the key point there. Even the universe that only replicates itself would meet that condition (the amount of variance allowed in that case being zero).

I'm not agreeing that multiple realities are guaranteed to be a thing. The point I was shooting for is that, even under the assumption of multiple realities, the most likely explanation would /still/ not be a universal dovetailer.

#+begin_quote
  I wouldn't say "singularity", but essentially. This is where you get infinite energy ÷ infinite density = ???.

  Depends on how you define speed of expansion. Any two actual points are separated by finite distance, and moving away from each other at finite speed proportional to that distance.

  Offer it to the mainstream cosmologists; I'm just describing my understanding of the mainstream "infinite universe" model. Do I have it wrong?
#+end_quote

...You don't have it wrong, I was mistaken. Current experimental data is indicative of the universe being flat in curvature, which does actually lead to a universe infinite in scope by way of ΛCDM. Which is embarrassing, but I do try to admit when I've got something completely wrong (especially when it's out of my field), so there you go.

Let me try to swing back around to the part of all this that I /actually/ took issue with, which was not the universe being infinite, or even the possibility of a universal dovetailer, but the /guarantee of an afterlife/. The rationale behind the universal dovetailer was that, given that everything must have a cause, something being caused by itself in an infinite regress solves the problem. However, there are many turing machines less complicated than a universal dovetailer that would also produce an infinite regress. Universal quines, for example, or universes that produce other universes in a limited, well-defined set, both of which would not guarantee an afterlife. An infinitely large universe also does not guarantee an afterlife; the number 0.210100100010000100000... is infinite, but it only contains a single two, and will never produce another, and likewise your mindstate has no assurance of being replicated elsewhere. And as for someone artificially constructing a universal dovetailer...how? Even if the universe has infinite energy, our current understanding of physics has us limited to the area in which space expands away from us more slowly than the speed of light, and consequently, the energy actually /available/ to us is finite. We would not be able to run the dovetailer. Is it possible that our understanding of physics will develop to the point that that is no longer a restriction? Sure, it's /possible/, but it is again nowhere near a guarantee.
:PROPERTIES:
:Author: reaper7876
:Score: 1
:DateUnix: 1565408069.0
:END:

**************************** #+begin_quote
  'Within whatever variance is allowed' would be the key point there. Even the universe that only replicates itself would meet that condition (the amount of variance allowed in that case being zero).
#+end_quote

But then you're back to adding arbitrary restrictions to avoid what the theory/model would otherwise imply.

#+begin_quote
  The rationale behind the universal dovetailer was that, given that everything must have a cause, something being caused by itself in an infinite regress solves the problem. However, there are many turing machines less complicated than a universal dovetailer that would also produce an infinite regress. Universal quines, for example, or universes that produce other universes in a limited, well-defined set, both of which would not guarantee an afterlife.
#+end_quote

I thought we'd agreed that adding restrictions on what a model/hypothesis "produces" doesn't make it simpler. Especially if it still has to produce something as complex as our observed reality.

#+begin_quote
  the number 0.210100100010000100000... is infinite, but it only contains a single two, and will never produce another
#+end_quote

It also displays a clear pattern, whereas the distribution of matter in the universe appears to be random.

#+begin_quote
  And as for someone artificially constructing a universal dovetailer...how? Even if the universe has infinite energy, our current understanding of physics has us limited to the area in which space expands away from us more slowly than the speed of light, and consequently, the energy actually /available/ to us is finite.
#+end_quote

But gravity counteracts the pull of expansion. Couldn't regions dense enough to be stable (without collapsing) be arbitrarily large?

#+begin_quote
  Sure, it's /possible/, but it is again nowhere near a guarantee.
#+end_quote

What total probability would you give to the disjunction of possibilities that would imply our experience being instantiated by a party or process that will later extract us? The stereotypical rationalist would put it at the Russell's-teapot level. I put it high enough to not be interested in being cryopreserved.
:PROPERTIES:
:Author: kcu51
:Score: 1
:DateUnix: 1565432869.0
:END:

***************************** #+begin_quote
  But then you're back to adding arbitrary restrictions to avoid what the theory/model would otherwise imply.
#+end_quote

Again, I am not the one putting in restrictions here. I am saying that there are many possible forms that a universe-producing cycle could take, the majority of which do not produce every conceivable universe. You are taking that width of possibility and narrowing it down to a single model. /That/ is the restrictor.

#+begin_quote
  I thought we'd agreed that adding restrictions on what a model/hypothesis "produces" doesn't make it simpler. Especially if it still has to produce something as complex as our observed reality.
#+end_quote

Again, see above.

#+begin_quote
  But gravity counteracts the pull of expansion. Couldn't regions dense enough to be stable (without collapsing) be arbitrarily large?
#+end_quote

Could it? If two bits of matter are far enough apart, then the expansion of space between them is faster than the speed of light. Doesn't that put an upper bound on the size of any such system?

#+begin_quote
  What total probability would you give to the disjunction of possibilities that would imply our experience being instantiated by a party or process that will later extract us? The stereotypical rationalist would put it at the Russell's-teapot level. I put it high enough to not be interested in being cryopreserved.
#+end_quote

Low enough to not consider it the /guarantee/ your initial post implies. And, to be honest, I'm not going to litigate it further. 48 hours is the cutoff point that I've set on my involvement in any arguments online, for sanity reasons. So if you have further points, then I apologize and concede them to you.
:PROPERTIES:
:Author: reaper7876
:Score: 1
:DateUnix: 1565457117.0
:END:

****************************** Fair enough. Thanks for the discussion.

In the hope of having the record straight for my part:

#+begin_quote
  Again, I am not the one putting in restrictions here. I am saying that there are many possible forms that a universe-producing cycle could take, the majority of which do not produce every conceivable universe.
#+end_quote

While still accounting for all of our observations? I'd like to see the math on that.

#+begin_quote
  If two bits of matter are far enough apart, then the expansion of space between them is faster than the speed of light. Doesn't that put an upper bound on the size of any such system?
#+end_quote

That doesn't sound right. With density constant, as the distance increases doesn't the force of gravity countering the expansion increase too? And it would make the universe effectively finite after all, given the limit of ways matter can be arranged within a limited volume. But it is something I hadn't considered, and it might be true.

#+begin_quote
  Low enough to not consider it the /guarantee/ your initial post implies.
#+end_quote

If anything, the stereotypical rationalists are the ones who speak in guarantees. "No matter how small the odds for cryo-preservation, they're /guaranteed/ to be better than for dirt preservation". And they're (stereotypically) the same ones who love to talk about the "Big World" and its supposed implications.
:PROPERTIES:
:Author: kcu51
:Score: 1
:DateUnix: 1565476363.0
:END:


*********** #+begin_quote

  - We have no reason to assume that any one or set of these has some magical quality of "realness" which the others lack. We can't even coherently define what that would mean.
#+end_quote

Sure we do, and sure we can. That which /is/, is real. All possible things either do or do not exist as a subset of our own universe, the only one that we can observe and know. This is a perfectly coherent place to draw a line, if you're inclined to use Occam's razor to conclude that the smallest possible number of things are real.

#+begin_quote

  - If for some reason we were compelled to believe it, though, we'd apply Occam's razor in determining what kind of machine it was. That would give us the universal dovetailer
#+end_quote

I am not convinced that a universal dovetailer is the simplest possible algorithm that contains our universe. I don't know of any specific alternatives, mind, but I'm not aware of any irrefutable proof that that is as good as it could possibly get. I'm not even convinced that it is necessarily simpler than our universe's theory of everything on its own, which I expect will end up being pretty short. Further, Occam's razor is extremely useful, but it is just a heuristic. The simplest explanation that fits your current knowledge is not always actually the true one.

But then, I'm not sure if this is actually important to your point. I'm willing to postulate a Tegmark IV multiverse containing every mathematically valid structure.

#+begin_quote

  - We can also say that for every mind-moment, at least one successor mind-moment exists. (An infinite variety, in fact.)
  - In other words, you can always expect your experience of consciousness to continue.
#+end_quote

You are using a rather idiosyncratic definition of "experience of consciousness" here. In the majority of philosophical conceptions of identity, this is /not/ sufficient to count as "you".

#+begin_quote

  - A universe's native sapience --- presumably coordinating via, or possibly consisting of, AI --- decides to implement an afterlife.
  - The AI computes a randomly chosen Turing machine; or else the universal dovetailer; and monitors it for sentient processes.
  - When such a process ends within the computed machine, the AI extracts it and continues it outside the machine.
#+end_quote

If you're willing to stomach the infinite processing power that this requires, then sure, it is inevitable that this will occur in infinitely many parts of the Tegmark IV multiverse. But most mathematically valid systems that harvest minds are not the sorts of places you would want your mind to end up, I think. The vast majority of such systems don't politely wait until your process naturally ends, either. You are postulating a multiverse where infinitely many successor mindstates of "you" are being kidnapped by every mathematically possible kidnapper, all the time. In fact, there is a sense in which "most" possible future mindstates involve you being stolen out of reality /right now./ That's... comforting?

The fact that you've gone a whole lot of Planck times without being kidnapped is evidence that there is no infinite kidnapping going on, or else that you are lucky to be one of the strains of your mind that evolved this far without interference.

#+begin_quote

  - Such universes seem likely to be much more probable/have greater measure than any "quantum immortality" or Boltzmann brains, especially in the long run.
#+end_quote

...How? We /know/ that, within quantum physics, your current mindstate has at least one physically permitted successor state. If you are sure of anything, you should be sure of that. Compared to that, how certain are you that there is not a single mis-step in this entire chain of suppositions?
:PROPERTIES:
:Author: Anakiri
:Score: 1
:DateUnix: 1565517638.0
:END:

************ Thanks for answering in [[/u/Revisional_Sin]]'s absence.

#+begin_quote
  Sure we do, and sure we can. That which /is/, is real. All possible things either do or do not exist as a subset of our own universe, the only one that we can observe and know.
#+end_quote

What "is", and what we can observe and know, are exactly what seems to be in dispute.

#+begin_quote
  This is a perfectly coherent place to draw a line, if you're inclined to use Occam's razor to conclude that the smallest possible number of things are real.
#+end_quote

But that's not what Occam's razor does.

#+begin_quote
  I am not convinced that a universal dovetailer is the simplest possible algorithm that contains our universe. I don't know of any specific alternatives, mind, but I'm not aware of any irrefutable proof that that is as good as it could possibly get. I'm not even convinced that it is necessarily simpler than our universe's theory of everything on its own, which I expect will end up being pretty short.
#+end_quote

The shorter it is, the less it specifies and the more it allows/produces.

#+begin_quote
  Further, Occam's razor is extremely useful, but it is just a heuristic. The simplest explanation that fits your current knowledge is not always actually the true one.
#+end_quote

But it's the one that rationality requires you to employ.

#+begin_quote
  You are using a rather idiosyncratic definition of "experience of consciousness" here. In the majority of philosophical conceptions of identity, this is /not/ sufficient to count as "you".
#+end_quote

If you're not somewhere in an infinite variety of possible mind-moments, where /are/ you?

#+begin_quote
  If you're willing to stomach the infinite processing power that this requires
#+end_quote

"Reality/existence has limited processing power" is a pretty esoteric hypothesis in itself.

#+begin_quote
  most mathematically valid systems that harvest minds are not the sorts of places you would want your mind to end up, I think.
#+end_quote

This comes down to whether you believe that good is stronger than evil.

#+begin_quote
  The vast majority of such systems don't politely wait until your process naturally ends, either.
#+end_quote

How are you calculating that?

#+begin_quote
  You are postulating a multiverse where infinitely many successor mindstates of "you" are being kidnapped by every mathematically possible kidnapper, all the time.
#+end_quote

Is downloading a song theft?

#+begin_quote
  In fact, there is a sense in which "most" possible future mindstates involve you being stolen out of reality /right now/.
#+end_quote

Do "senses" come into it? Is Kolmogorov complexity not the only systematic way of assigning probability/measure so that the sum over all hypotheses/outcomes/realities is 1?

#+begin_quote
  The fact that you've gone a whole lot of Planck times without being kidnapped is evidence that there is no infinite kidnapping going on, or else that you are lucky to be one of the strains of your mind that evolved this far without interference.
#+end_quote

But not evidence that can distinguish between the two.

#+begin_quote
  ...How? We /know/ that, within quantum physics, your current mindstate has at least one physically permitted successor state. If you are sure of anything, you should be sure of that.
#+end_quote

Isn't the "many-worlds interpretation" of quantum physics hotly disputed? Is this that "inverted certainty" that G. K. Chesterton talked about?

#+begin_quote
  Compared to that, how certain are you that there is not a single mis-step in this entire chain of suppositions?
#+end_quote

I was specifically asked to explain the reasoning for the position in as much detail as possible. Are you now asking me to take the length of that explanation as evidence against it?
:PROPERTIES:
:Author: kcu51
:Score: 1
:DateUnix: 1565534234.0
:END:

************* #+begin_quote
  Further, Occam's razor is extremely useful, but it is just a heuristic. The simplest explanation that fits your current knowledge is not always actually the true one.

  But it's the one that rationality requires you to employ.
#+end_quote

Not really.

You should be aware of your level of certainty of your beliefs, and how each supposition makes the whole thing less likely.

You shouldn't pick a possibility and say "This is the most simple, therefore it's true. Following on from this, the following thing is most likely, therefore it's true..."

If you have three steps of supposition, each of which you think has an 80% chance of being correct, this gives you a 51% chance of being right overall. Clearly this isn't a very good tenet to follow!
:PROPERTIES:
:Author: Revisional_Sin
:Score: 2
:DateUnix: 1565538799.0
:END:

************** Yes, every additional supposition reduces a hypothesis's probability. That's what Occam's razor is.

If you're saying that I need to be [[http://www.overcomingbias.com/2008/06/against-disclai.html][giving explicit probabilities for everything]], all I can say is that I don't see anyone else doing the same.
:PROPERTIES:
:Author: kcu51
:Score: 1
:DateUnix: 1565542450.0
:END:

*************** #+begin_quote
  But it's the one that rationality requires you to employ.
#+end_quote

This suggests too me that you're being too dogmatic in declaring UDF the "correct" solution, rather than saying it has high likelihood.
:PROPERTIES:
:Author: Revisional_Sin
:Score: 2
:DateUnix: 1565557310.0
:END:

**************** I didn't even use that word.
:PROPERTIES:
:Author: kcu51
:Score: 1
:DateUnix: 1565557662.0
:END:

***************** It's the impression I got through several posts, apologies if it's incorrect.
:PROPERTIES:
:Author: Revisional_Sin
:Score: 2
:DateUnix: 1565558133.0
:END:


*************** What did you mean by the link? I'll refrain from guessing, as it complains about that at the end.
:PROPERTIES:
:Author: Revisional_Sin
:Score: 1
:DateUnix: 1565558663.0
:END:

**************** That I prefer to speak in plain language and clear up misunderstandings as they arise, rather than dress everything up in qualifiers and disclaimers to head off every possible contingency and edge case, or demand that everyone else do the same. I feel like a general norm to that effect makes for overall better communication, and I'd hoped that that would be understood here.
:PROPERTIES:
:Author: kcu51
:Score: 1
:DateUnix: 1565558995.0
:END:


************* #+begin_quote
  The vast majority of such systems don't politely wait until your process naturally ends, either.

  How are you calculating that?
#+end_quote

It's possible that there exists an AI running the UDF, which extracts entities upon death.

Why wait? Why not an AI that extracts you now?

Why not an AI that extracts a version of you from every moment of your life?

Why not an AI that does the above and gives you a puppy, a pineapple, a live grenade, a punch in the ear?
:PROPERTIES:
:Author: Revisional_Sin
:Score: 1
:DateUnix: 1565539369.0
:END:

************** Why not? Weren't you just talking about the importance of not [[/r/rational/comments/cl5blm/d_friday_open_thread/ewly81x/?context=8][compounding unneeded assumptions]]?
:PROPERTIES:
:Author: kcu51
:Score: 1
:DateUnix: 1565542626.0
:END:


************* #+begin_quote
  You are postulating a multiverse where infinitely many successor mindstates of "you" are being kidnapped by every mathematically possible kidnapper, all the time.

  Is downloading a song theft?
#+end_quote

Are you disagreeing with the moral connotations of the word "kidnapper", or are you saying that the "kidnapping" won't impact the real you?

#+begin_quote
  In fact, there is a sense in which "most" possible future mindstates involve you being stolen out of reality right now.

  Do "senses" come into it? Is Kolmogorov complexity not the only systematic way of assigning probability/measure so that the sum over all hypotheses/outcomes/realities is 1?
#+end_quote

They just mean "In a manner of speaking".
:PROPERTIES:
:Author: Revisional_Sin
:Score: 1
:DateUnix: 1565557583.0
:END:

************** #+begin_quote
  Are you disagreeing with the moral connotations of the word "kidnapper", or are you saying that the "kidnapping" won't impact the real you?
#+end_quote

We're all real. If copying a person is "kidnapping", then copying a song is "stealing"; which I didn't think was a widely held position around here. Unless they can explain where the analogy fails.

#+begin_quote
  They just mean "In a manner of speaking".
#+end_quote

Are you in contact with [[/u/Anakiri]]? Regardless, the question stands for either word choice.
:PROPERTIES:
:Author: kcu51
:Score: 1
:DateUnix: 1565557892.0
:END:

*************** What is the analogy? It seems such a non-sequitur, I can't figure out what you're arguing.
:PROPERTIES:
:Author: Revisional_Sin
:Score: 1
:DateUnix: 1565558455.0
:END:

**************** "Theft" is unlawful removal of an object from its owner. "Kidnapping" is unlawful removal of person from their home. In neither case does copying remove the original, or affect it in any way.
:PROPERTIES:
:Author: kcu51
:Score: 1
:DateUnix: 1565558650.0
:END:

***************** "Kidnapping", as I am using the term, is bringing a person into your custody unlawfully. I don't care about the source. You may imagine that I am using some distinct term for the distinct act of mind piracy, if you prefer.
:PROPERTIES:
:Author: Anakiri
:Score: 2
:DateUnix: 1565614524.0
:END:


***************** Your argument hinges on an AI simulating us, and extracting us into another simulation where we can continue living.

[[/u/Anakir]] says that there is no need for an AI to wait for you die first, it could simulate you and extract you at any moment.

Why do you think simulation-extraction is possible on a dying entity, but not a living one? If 99 copies of you are going to be extracted in 1 minutes time, shouldn't you expect a 99% chance of being extracted?
:PROPERTIES:
:Author: Revisional_Sin
:Score: 1
:DateUnix: 1565559273.0
:END:

****************** #+begin_quote
  Your argument hinges on an AI simulating us, and extracting us into another simulation where we can continue living.
#+end_quote

A "simulation" imitates a thing while falling short of actually being that thing. We are ourselves in all Turing machines/directed acyclic graphs/whatever that contain/implement us, wherever they're computed/instantiated/implemented.

#+begin_quote
  If 99 copies of you are going to be extracted in 1 minutes time, shouldn't you expect a 99% chance of being extracted?
#+end_quote

"Number of copies" is a [[https://lesswrong.com/lw/ws/for_the_people_who_are_still_alive/][meaningless measurement]]. What matters is relative measure of different anticipations/experiences. Hypotheses with no practical implications (e.g. you have no idea what the copies will experience and no control over what will be done with them) can also be safely discarded.

If you're being redundantly computed in 100 locations, and 99 of them are going to be shut down in 1 minutes' time, do you expect a 99% chance of experiencing nonexistence?
:PROPERTIES:
:Author: kcu51
:Score: 1
:DateUnix: 1565562018.0
:END:


************* Cutting the conversation into a million tiny parallel pieces makes it less fun for me to engage with you, so I will be consolidating the subjects I consider most important or interesting. Points omited are not necessarily conceded.

#+begin_quote
  If you're not somewhere in an infinite variety of possible mind-moments, where /are/ you?
#+end_quote

I'm in the derivative over time.

If I give you the set of all 2D grids made up of white stones, black stones, and empty spaces, have I given you the game of Go? No. That's the wrong level of abstraction. The game of Go is the set of rules that defines which of those grids is valid, and defines the relationships between those grids, and defines how they evolve into each other. Likewise, "I" am not a pile of possible mindstates, nor am I any particular mindstate. I am an algorithm that produces mindstates from other mindstates. In fact, I am just one unbroken, mostly unperturbed chain of such; a single game of Anakiri.

(I admit the distinction is blurrier for minds than it is for games, since with minds, the rules are encoded in the structure itself. I nonetheless hold that the distinction is philosophically relevant: I am the bounding conditions of a series of events.)

#+begin_quote
  This comes down to whether you believe that good is stronger than evil. [...] How are you calculating that?
#+end_quote

Keeping humans alive, healthy, and happy is hard to do. It's so hard that humans themselves, despite being specialized for that exact purpose, regularly fail at it. Your afterlife machine is going to need to have a long list of things it needs to provide: air, comfortable temperatures, exactly 3 macroscopic spatial dimensions, a strong nuclear force, the possibility of interaction of logical components... And, yes, within the space of all possible entities, there will be infinitely many that get all of that exactly right. And for each one of them, there will be another one that has a =NOT= on line 73, and you die. And another that has a missing zero on line 121, and you die. And another that has a different sign on line 8, and you die. Obviously if you're just counting them, they're both countable infinities, but the ways to do things wrong take up a much greater fraction of possibility-space.

Even ignoring all the mistakes that kill you, there are still far more ways to do things wrong than there are ways to do things right. Just like there are more ways to kidnap you before your death than there are ways to kidnap you at exactly the moment of your death. We are talking about a multiverse made up of all possible programs. Almost all of them are wrong, and you should expect to be kidnapped by one of the ones that is wrong.

#+begin_quote
  Occam's razor [...] Kolmogorov complexity [...] evidence
#+end_quote

If rationality "requires" you to be overconfident, then I don't care much for "rationality". Of /course/ your own confidence in your argument should weigh against the conclusions of the argument.

If you know of an argument that concludes with 100% certainty that you are immortal, but you are only 80% confident that the argument actually applies to reality, then you ought to be only 80% sure that you are immortal. Similarly, the lowest probability that you ever assign to anything should be about the same as the chance that you have missed something important. After all, we are squishy, imperfect, internally incoherent algorithms that are not capable of computing non-computable functions like Kolmogorov complexity. I don't think it's productive to pretend to be a machine god.
:PROPERTIES:
:Author: Anakiri
:Score: 1
:DateUnix: 1565614573.0
:END:

************** #+begin_quote
  Cutting the conversation into a million tiny parallel pieces makes it less fun for me to engage with you, so I will be consolidating the subjects I consider most important or interesting. Points omited are not necessarily conceded.
#+end_quote

Understood. I try to minimize assumptions about others' beliefs regardless. (Hence my original questions.) Still, I hope you'll be patient if I make mistakes in my necessary modeling of yours.

#+begin_quote
  If I give you the set of all 2D grids made up of white stones, black stones, and empty spaces, have I given you the game of Go? No. That's the wrong level of abstraction. The game of Go is the set of rules that defines which of those grids is valid, and defines the relationships between those grids, and defines how they evolve into each other.
#+end_quote

What if I give you all the grid-to-grid transitions that constitute legal moves? (Including the information of whose turn it is as part of the "grid", I guess.)

#+begin_quote
  Likewise, "I" am not a pile of possible mindstates, nor am I any particular mindstate.
#+end_quote

Hence why I specifically used the term "mind-/moments/". Are you not one of those across any given moment you exist in? Is there a better/more standard term?

#+begin_quote
  I am an algorithm that produces mindstates from other mindstates.
#+end_quote

Exclusively? Are you a solipsist?

If you learned that you had a secret twin, with identical personality but none of your memories/experiences, would you refer to them in the first person?

#+begin_quote
  In fact, I am just one unbroken, mostly unperturbed chain of such; a single game of Anakiri.
#+end_quote

But you have imperfect knowledge of your own history. And in a world of superimposed quantum states (which you reportedly /know/ that you inhabit), countless different histories would independently produce the mind-moment that posted that comment. Which one are you referring to? If you find out that you've misremembered something, will you reserve the first person for the version of you that you'd previously remembered?

#+begin_quote
  Keeping humans alive, healthy, and happy is hard to do. It's so hard that humans themselves, despite being specialized for that exact purpose, regularly fail at it. Your afterlife machine is going to need to have a long list of things it needs to provide: air, comfortable temperatures, exactly 3 macroscopic spatial dimensions, a strong nuclear force, the possibility of interaction of logical components... And, yes, within the space of all possible entities, there will be infinitely many that get all of that exactly right. And for each one of them, there will be another one that has a NOT on line 73, and you die. And another that has a missing zero on line 121, and you die. And another that has a different sign on line 8, and you die. Obviously if you're just counting them, they're both countable infinities, but the ways to do things wrong take up a much greater fraction of possibility-space.
#+end_quote

And how about probability-space? Surely the more an intelligence has proved itself capable of (e.g. successfully implementing you as you are), the less likely it is that it'll suddenly start making basic mistakes like structuring the implementing software such that a single flipped bit makes it erase the subject and all backups?

I am me regardless of any specific details of the physical structures implementing me.

#+begin_quote
  If rationality "requires" you to be overconfident, then I don't care much for "rationality". Of course your own confidence in your argument should weigh against the conclusions of the argument.

  If you know of an argument that concludes with 100% certainty that you are immortal, but you are only 80% confident that the argument actually applies to reality, then you ought to be only 80% sure that you are immortal. Similarly, the lowest probability that you ever assign to anything should be about the same as the chance that you have missed something important.
#+end_quote

I feel unfairly singled out here. I don't see anyone else getting their plain-language statements --- especially ones trying to /describe/, without endorsing, a chain of reasoning --- read as absolute, 100% certainty with no possibility of update.

Also, strictly speaking, an argument can be wrong and its conclusion still true.

#+begin_quote
  After all, we are squishy, imperfect, internally incoherent algorithms that are not capable of computing non-computable functions like Kolmogorov complexity.
#+end_quote

But we can't exist without forming beliefs and making decisions. In the absence of a better alternative, we can still have reasonable confidence in heuristics like "hypotheses involving previously undetected entities taking highly specific actions with no clear purpose are more complex than their alternatives".
:PROPERTIES:
:Author: kcu51
:Score: 1
:DateUnix: 1565619662.0
:END:

*************** #+begin_quote
  Hence why I specifically used the term "mind-moments". Are you not one of those across any given moment you exist in?
#+end_quote

No. Just like a single frame is not an animation. Thinking is an action. It requires at minimum two "mind-moments" for any thinking to occur between them, and if I don't "think", then I don't "am". I need more than just that minimum to be /healthy,/ of course. The algorithm-that-is-me expects external sensory input to affect how things develop. But I'm fully capable of existing and going crazy in sensory deprivation.

Another instance of a mind shaped by the same rules would not be the entity-who-is-speaking-now. They'd be another, separate instance. If you killed me, I would not expect my experience to continue through them. But I /would/ consider them to have just as valid a claim as I do to our shared identity, as of the moment of divergence.

I would be one particular unbroken chain of mind-transformations, and they would be a second particular unbroken chain of mind-transformations of the same class. And since the algorithm isn't perfectly deterministic clockwork, both chains have arbitrarily many branches and endpoints, and both would have imperfect knowledge of their own history. Those chains may or may not cross somewhere. I'm not sure why you believe that would be a problem. The entity-who-is-speaking-now is allowed to merge and split. As long as every transformation in between follows the rules, all of my possible divergent selves are me, but they are not each other.

#+begin_quote
  Surely the more an intelligence has proved itself capable of (e.g. successfully implementing you as you are), the less likely it is that it'll suddenly start making basic mistakes like structuring the implementing software such that a single flipped bit makes it erase the subject and all backups?
#+end_quote

"Mistake"? Knowing what you need doesn't mean it has to care. Since we're talking about a multiverse containing all possible programs, I'm confident that "stuff that both knows and cares about your wellbeing" is a much smaller target than "stuff that knows about your wellbeing".

#+begin_quote
  I feel unfairly singled out here.
#+end_quote

Sorry. I meant for that to be an obviously farcical toy example; I didn't realize until now that it could be interpretted as an uncharitable strawman of your argument here. But, yeah, now it's obvious how it could be seen that way, so that's on me.

That said, you do seem to have a habit of phrasing things in ways that appear to imply higher confidence than what's appropriate. Most relevantly, with Occam's razor. The simplest explanation should be your best guess, sure. But in the real world, we've discovered previously undetected effects basically every time we've ever looked close at anything. If all you've got is the razor and no direct evidence, your guess shouldn't be so strong that "rationality requires you to employ" it.
:PROPERTIES:
:Author: Anakiri
:Score: 1
:DateUnix: 1565690804.0
:END:

**************** #+begin_quote
  mind-transformations
#+end_quote

I'm not convinced that that's a better term; it sounds like "transforming" a mind into a different mind. (And it's longer.) But I'll switch to it provisionally.

#+begin_quote
  As long as every transformation in between follows the rules, all of my possible divergent selves are me
#+end_quote

That seems different from saying that "you" are exclusively a single, particular one of them. But it looks as though we basically agree.

Going back to the point, though, does every possible mind-transformation /not/ have a successor somewhere in an infinitely varied meta-reality? What more is necessary for it to count as continuing your experience of consciousness; and why wouldn't a transformation that met that requirement /also/ exist?

And, if you don't mind a tangent: If you were about to be given a personality-altering drug, would you be no more concerned with what would happen to "you" afterward than for a stranger?

#+begin_quote
  "Mistake"? Knowing what you need doesn't mean it has to care. Since we're talking about a multiverse containing all possible programs, I'm confident that "stuff that both knows and cares about your wellbeing" is a much smaller target than "stuff that knows about your wellbeing".
#+end_quote

/You/ called them "mistakes". Why would any substantial fraction of the programs that don't care about you extract and reinstantiate you in the first place? Isn't that just another kind of Boltzmann brain; unrelated processes coincidentally happening to very briefly implement you?

(Note that curiosity and hostility would be forms of "caring" in this case, as they'd still motivate the program to get your implementation right. Their relative measure comes down to the good versus evil question.)

#+begin_quote
  Sorry. I meant for that to be an obviously farcical toy example; I didn't realize until now that it could be interpretted as an uncharitable strawman of your argument here. But, yeah, now it's obvious how it could be seen that way, so that's on me.
#+end_quote

Thanks for understanding, and sorry for jumping to conclusions.

#+begin_quote
  That said, you do seem to have a habit of phrasing things in ways that appear to imply higher confidence than what's appropriate. Most relevantly, with Occam's razor. The simplest explanation should be your best guess, sure. But in the real world, we've discovered previously undetected effects basically every time we've ever looked close at anything. If all you've got is the razor and no direct evidence, your guess shouldn't be so strong that "rationality requires you to employ" it.
#+end_quote

When faced with a decision that requires distinguishing between hypotheses, rationality requires you to employ your best guess regardless of how weak it is. (Unless you want to talk about differences in expected utility. I'd call it more of a "bet" than a "belief" in that case, but that might be splitting hairs.)
:PROPERTIES:
:Author: kcu51
:Score: 1
:DateUnix: 1565698671.0
:END:

***************** #+begin_quote
  I'm not convinced that that's a better term; it sounds like "transformations" of a mind into a different mind. (And it's longer.) But I'll switch to it provisionally.
#+end_quote

I /do/ intend for the term "mind-transformation" to refer to the tranformation of one instantaneous mindstate into a (slightly) different instantaneous mindstate. My whole point is that I care about the transformation over time, not just the instantaneous configuration.

#+begin_quote
  Going back to the point, though, does every possible mind-transformation not have a successor somewhere in an infinitely varied meta-reality? What more is necessary for it to count as "you"; and why wouldn't a transformation that met that requirement also exist?
#+end_quote

For an algorithm that runs on a mindstate in order to produce a successor mindstate, it is a requirement that there be a direct causal relationship between the two mindstates. That relationship needs to exist because that's where the algorithm is. Unless something weird happens with the speed of light and physical interactions, spatiotemporal proximity is a requirement for that. If a mind-moment is somewhere out in the infinity of meta-reality, but not /here/, then it is disqualified from being a continuation of the me who is speaking, since it could not have come about by a valid transformation of the mind-moment I am currently operating on. Similarly, being reconfigured by a personality-altering drug is not a valid transformation, and the person who comes out the other side is not me; taking such a drug is death.

#+begin_quote
  Why would any substantial fraction of the programs that don't care about you extract and reinstantiate you in the first place?
#+end_quote

Most likely, because that's just what they were told to do. You're talking about AI; They "care" insofar as they were programmed to do that, or they extrapolated that action from inadequate training data. There are a lot of ways for /programmers/ to make mistakes in ways that leave the resulting program being radically, self-improvingly optimized for correctly implementing the wrong thing.

It's not about good versus evil, it's about how hard it is to perfectly specify what an AI should do, then, additionally, perfectly impement that specification. Do you think that most intelligently designed programs in the real world always do exactly what their designer would have wanted them to do?

#+begin_quote
  When faced with a decision that requires distinguishing between hypotheses, rationality requires you to employ your best guess regardless of how weak it is.
#+end_quote

If someone holds a gun to your head and will shoot you if you're wrong, sure. But if there is no immediate threat, I think you will usually get better results in the real world if you admit that your actual best guess is "I don't know."
:PROPERTIES:
:Author: Anakiri
:Score: 1
:DateUnix: 1566302778.0
:END:

****************** #+begin_quote
  For an algorithm that runs on a mindstate in order to produce a successor mindstate, it is a requirement that there be a direct causal relationship between the two mindstates. That relationship needs to exist because that's where the algorithm is. Unless something weird happens with the speed of light and physical interactions, spatiotemporal proximity is a requirement for that. If a mind-moment is somewhere out in the infinity of meta-reality, but not /here/, then it is disqualified from being a continuation of the me who is speaking, since it could not have come about by a valid transformation of the mind-moment I am currently operating on.
#+end_quote

I thought we just agreed to talk about "mind-transformations". What's this talk about states and moments?

#+begin_quote
  Similarly, being reconfigured by a personality-altering drug is not a valid transformation, and the person who comes out the other side is not me; taking such a drug is death.
#+end_quote

So if you were sentenced to a painful death, you'd take the +pill+ drug so that "you" would escape it? Even if it came at a price; like additional pain, or forgoing your "last meal"? If someone took out a loan from you, spent it, then had their personality altered, you'd write the money off rather than holding the "new person" accountable?

How old are you? Is that age counted from a birth event, or a personality shift? Did you change your name to avoid being confused with the deceased?

#+begin_quote
  Most likely, because that's just what they were told to do. You're talking about AI; They "care" insofar as they were programmed to do that, or they extrapolated that action from inadequate training data. There are a lot of ways for /programmers/ to make mistakes in ways that leave the resulting program being radically, self-improvingly optimized for correctly implementing the wrong thing.
#+end_quote

And how many of those ways still result in successfully implementing you as you are, extracting you and reinstantiating you? I think [[/u/EliezerYudkowsky]] wrote about the astronomical unlikeliness of a Friendliness failure still permitting anything like conscious life.

#+begin_quote
  If someone holds a gun to your head and will shoot you if you're wrong, sure. But if there is no immediate threat, I think you will usually get better results in the real world if you admit that your actual best guess is "I don't know."
#+end_quote

"I don't know" isn't a guess. Do ye what ye will, or do ye assume that all of your actions are being seen and impartially judged? Have kids, to ensure that part of you outlives your death; or refrain, to avoid your resources being divided for eternity? Sign up for cryonics (and call people who withhold it from their kids [[http://lesswrong.com/lw/1mc/normal_cryonics/][insane, lousy parents]]), or not? [[/r/TheMotte/comments/csclze/culture_war_roundup_for_the_week_of_august_19_2019/exf26qm/?context=1][Promote lies to fight climate change]], or not?
:PROPERTIES:
:Author: kcu51
:Score: 1
:DateUnix: 1566332371.0
:END:

******************* #+begin_quote
  I thought we just agreed to talk about "mind-transformations". What's this talk about states and moments?
#+end_quote

What did you think was being transformed? My mind is made of your mind-moments in the same way that my body is made of atoms: more than one, and with specific physical relationships between them, but they are a necessary component. Did I not introduce the concept as the derivative of mind-moments over time? If the derivative is undefined, then there is no "me".

#+begin_quote
  So if you were sentenced to a painful death, you'd take the pill so that "you" would escape it?
#+end_quote

/I/ wouldn't, because I don't bargain with death, and because the person who came out the other side of the operation is my heir in virtually all significant ways (inheriting my debts and other paperwork) and I don't torture my heirs. But if I were a sociopath who somehow knew that there was no possible escape, then yes, I would kill myself by breaking continuity with the future tortured person.

My age is measured by whatever is most useful at the time, which usually means the birth of the body I inhabit. In practice, I do not consider my identity to actually be as binary as I've simplified here; minor disruptions to my mind happen all the time and though the resulting algorithm is slightly less "me" than the preceding one (or the preceding one is less "me" than the resulting one, depending on which one you ask), it doesn't especially bother me to have a neuron or two zapped by a cosmic ray and their contribution distorted. To my knowledge, I've never experienced such a significant instantaneous disruption that I would consider death. But if I had, then yes, I would consider it to be meaningful to count "my" age from that event, in some contexts.

(I wouldn't especially care about disambiguating the new me from the old one. They're dead. They're not using our name and identity anymore, and I'm their heir anyway.)

#+begin_quote
  And how many of those ways still result in successfully implementing you as you are, extracting you and reinstantiating you?
#+end_quote

Nearly zero, of course. But of the ones that do instantiate a version of you, most of them are /still/ bugged.

#+begin_quote
  "I don't know" isn't a guess. Do ye what ye will, or do ye assume that all of your actions are being seen and impartially judged? Have kids, to ensure that part of you outlives your death; or refrain, to avoid your resources being divided for eternity? Sign up for cryonics (and call people who withhold it from their kids insane, lousy parents), or not? Promote lies to fight climate change, or not?
#+end_quote

My answer to literally all of those questions is "[shrug] I dunno. Do what you want. Maybe don't be a dick, though?" I do recommend having some half-reasonable deontological safety rails, however you choose to implement them, and most half-reasonable deontological safety rails have a "Don't be a dick" clause. That'll serve you better than hair-splitting utilitarianism that you physically can't calculate.
:PROPERTIES:
:Author: Anakiri
:Score: 1
:DateUnix: 1566370717.0
:END:

******************** #+begin_quote
  What did you think was being transformed? My mind is made of your mind-moments in the same way that my body is made of atoms: more than one, and with specific physical relationships between them, but they are a necessary component. Did I not introduce the concept as the derivative of mind-moments over time? If the derivative is undefined, then there is no "me".
#+end_quote

Is time necessarily continuous and infinitely divisible, rather than a series of discrete "ticks" between discrete states?

#+begin_quote
  /I/ wouldn't, because I don't bargain with death
#+end_quote

What does this mean?

#+begin_quote
  minor disruptions to my mind happen all the time...the resulting algorithm is slightly less "me" than the preceding one (or the preceding one is less "me" than the resulting one, depending on which one you ask)
#+end_quote

That's exactly (partly) why I was/am so incredulous that your sense of identity/anticipation is dependent on something so fluid and potentially imperceptible. Are the "rules" even rigorously defined?

#+begin_quote
  To my knowledge, I've never experienced such a significant instantaneous disruption that I would consider death.
#+end_quote

Is "significant, instantaneous" a necessary condition now? You didn't specify the hypothetical drug working instantaneously. What difference does it make, if the end result is the same?

#+begin_quote
  Nearly zero, of course. But of the ones that do instantiate a version of you, most of them are /still/ bugged.
#+end_quote

Most /ways of making mistakes/ result in bugs, yes.

#+begin_quote
  My answer to literally all of those questions is "[shrug] I dunno. Do what you want. Maybe don't be a dick, though?"
#+end_quote

"Dunnoing" isn't one of the options. Which is the "good" and which the "dick" option is (at least for part of that, and in many more situations) exactly the question.

#+begin_quote
  I do recommend having some half-reasonable deontological safety rails, however you choose to implement them, and most half-reasonable deontological safety rails have a "Don't be a dick" clause. That'll serve you better than hair-splitting utilitarianism that you physically can't calculate.
#+end_quote

The rational[ist] response to an uncalculable problem is to make the best approximation that you can; not to pretend to not care. There's nothing "safe" about trying to outsource your decisions. And eventually, you'll find yourself beyond where the rails can guide you.
:PROPERTIES:
:Author: kcu51
:Score: 1
:DateUnix: 1566407290.0
:END:


******* Not really, but I've heard enough similar arguments that I think I can still make the point. You may need to elaborate.

We certainly don't have enough evidence that every possible reality exists to make any sweeping statements about reality, if that's what you're hinting at. If anything the anthropic principle strongly suggests otherwise, boltzmann brains notwithstanding.

That's all esoteric enough that it's not really going to be useful though. We try to stick to the practical.
:PROPERTIES:
:Author: traverseda
:Score: 2
:DateUnix: 1565048105.0
:END:

******** #+begin_quote
  We certainly don't have enough evidence that every possible reality exists to make any sweeping statements about reality, if that's what you're hinting at.
#+end_quote

How about "every possible reality that contains us"? Isn't that the basis of probabilistic reasoning?

#+begin_quote
  If anything the anthropic principle strongly suggests otherwise, boltzmann brains notwithstanding.
#+end_quote

How, exactly? Isn't the anthropic principle just "we find ourselves in places where +it's possible for us to+ we exist, no matter how a priori 'improbable' that would be"?

#+begin_quote
  We try to stick to the practical.
#+end_quote

Whether to be cryopreserved is a pretty practical question.
:PROPERTIES:
:Author: kcu51
:Score: 2
:DateUnix: 1565054679.0
:END:

********* #+begin_quote
  How about "every possible reality that contains us"? Isn't that the basis of probabilistic reasoning?
#+end_quote

No? Nothing about probabilistic reasoning implies any kind of splitting, or any support for a many-worlds interpretation of reality. We use probabilistic reasoning simply because we can't take perfect measurements of reality, not because there are multiple realities to be measured. It seems your arguments (?) are predicated on a multiple-worlds interpretation of reality. There's just no real evidence for that.

But without really understanding what point you're trying to make with the whole "universal dovetailer function" thing I can't really elaborate.
:PROPERTIES:
:Author: traverseda
:Score: 2
:DateUnix: 1565065555.0
:END:

********** Isn't it the simplest theory that predicts/accounts for our experience?

How do you handle the Sleeping Beauty problem? Use something other than probabilistic reasoning? Dismiss it (edit: the problem's premises) as impossible?
:PROPERTIES:
:Author: kcu51
:Score: 1
:DateUnix: 1565125748.0
:END:

*********** It being the universal dovetailer theory? I don't think so.
:PROPERTIES:
:Author: traverseda
:Score: 1
:DateUnix: 1565127219.0
:END:

************ What's simpler?
:PROPERTIES:
:Author: kcu51
:Score: 1
:DateUnix: 1565127912.0
:END:
