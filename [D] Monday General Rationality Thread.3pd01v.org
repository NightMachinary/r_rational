#+TITLE: [D] Monday General Rationality Thread

* [D] Monday General Rationality Thread
:PROPERTIES:
:Author: AutoModerator
:Score: 11
:DateUnix: 1445267110.0
:END:
Welcome to the Monday thread on general rationality topics! Do you really want to talk about something non-fictional, related to the real world? Have you:

- Seen something interesting on [[/r/science]]?
- Found a new way to get your shit even-more together?
- Figured out how to become immortal?
- Constructed artificial general intelligence?
- Read a neat nonfiction book?
- Munchkined your way into total control of your D&D campaign?


** I read /The Art of Language Invention/ over the weekend, which I found quite interesting. I recommend it if you have any interest in the complexity of language, or in conlangs themselves. I think it might have been a little confusing if I hadn't had a linguistics background, because it's trying to cover /lots and lots/ of things that a proper linguistics textbook would spend hundreds of pages on, but the advantage here is that it's not as dry as most textbooks are. (The book was written by the guy responsible for making Dothraki and Valyrian more than the minor sketches that GRRM put into the books.)

I personally think conlangs are /cool/ but usually complete overkill for use in fiction; you could teach the reader the language, but that's probably not a good idea if you also want a plot that moves anywhere. Since most readers aren't linguists or conlangers, that effort is wasted.
:PROPERTIES:
:Author: alexanderwales
:Score: 7
:DateUnix: 1445275417.0
:END:

*** True, but if you take the time to make a language sound consistent and like an actual language instead of randomly throwing words together then you can have an extra layer of immersion to make the story flow better.

For example in /The Hobbit/ and /Eragon/, the made up languages added a nice touch to the world building without slowing things down due to how they contributed to the story and the authors didn't let it take attention away from the plotline.

As a counter-point, J K Rowling never intended her magic spells to be an actual language, so it sounds a bit ridiculous to have her characters to be speaking psuedo-Latin whenever they used their magic. It only works, because of how it's taken so seriously by her characters.
:PROPERTIES:
:Author: xamueljones
:Score: 5
:DateUnix: 1445293868.0
:END:

**** There are varying degrees of conlangs. I'm into the ones that sound like languages, but that's only the first 2% of actual language creation. You choose which sounds you're going to be using, you pick some patterns for consonants and vowels, then you string them together into something that scans well. But /actually making a language/ is different, because you need phonology, intonation, inflection, agreement, tense, etc. Stuff [[http://imgur.com/a/G9vac][like this]] is what I mean when I'm talking about overkill.

(My friends and I are actually doing a Harry Potter themed version of D&D where one of the house rules is that you have to speak all of your spells in Dog Latin. So "Hold Person" becomes "/Holdus personi!/". So that's fun.)
:PROPERTIES:
:Author: alexanderwales
:Score: 3
:DateUnix: 1445297953.0
:END:

***** Ah, conlangs. The topic that most concisely describes the conjunction of love and complete, total avoidance.

[[http://www.zompist.com/resources/][The seminal work.]]
:PROPERTIES:
:Author: Transfuturist
:Score: 1
:DateUnix: 1445309642.0
:END:


** For once, I'm not DMing my D&D campaign-- I'm a player. The DM seems pretty good and moderately experienced. Our campaign setting is modern world + parahumans who only began emerging in the past 30 years or so. The PCs are all powered.

Following a series of violent and destructive clashes between powered humans, the government policy for dealing with this tiny minority of empowered people is effective imprisonment. The government sends parahumans to live in a walled-off section of Montana with power-suppressing machines built into the walls and ground to prevent their powers from doing anything. Also, the government has secretly added a chemical to most processed food that harmlessly suppresses powers.

The plot of the campaign is that basically we think this is a bad thing and are willing to lie, steal, kill, and terrorize in order to end this policy. It's pretty clear my character is willing to do all this stuff, but she was a criminal and a murderer before she got her powers.

Somehow, everyone seems totally on-board with the terrorism. I tried suggesting we quit our lives of villainy (since our secret identities were still secret) and start a political movement. We could write blog posts about how C41B (the secret chemical that suppresses superpowers) causes autism or obesity or something, and support Whole Foods which stocks C41B-free food. Run for local government, pass bills, etc. Maybe get started in Seattle and have our political movement work South, then East. Sadly, the rest of the party wanted the violent terrorism approach so I followed along.

During a snack break I discussed with the others that the government was doing something fundamentally reasonable. After all, if our world was one in which one in every hundred thousand people had the innate ability to level mountains and shatter buildings with impunity... well, /I'd/ want the government to shut these people into internment camps. Heck, I'd even support the idea of a secret harmless chemical that inhibits these peoples' powers. Superpowers /scare/ me. I was not persuasive enough! I don't think they're really thinking it through, though. I don't think they understand the visceral fear that they'd have if such people really existed.

I guess at some point I started viewing our party as a group of villains, even though the DM and the other players don't see that way. I don't mind this. Maya, my character, is definitely a villain. She's not even the worst. She's not the cop-killer-- that's Abigail. Baldwin hasn't murdered anyone yet, but that's more due to his power set than his will. Particleese has. Maya has.

Nobody thinks twice about the bodies we leave behind in our quest to destabilize a society that's already on the brink, a society that's barely controlling the parahuman menace. When the chips fall and we've given the empowered minority free reign to burn this world, will we be remembered as heroes? Probably not. We won't be remembered as anything, because this fledgling Democratic civilization will come to an end. We had millennia of dictatorship, a couple brief centuries of almost-just, almost-liberal rule, almost escaping despotism, serfdom, and the divine right of kings-- before being plunged back into the darkness by parahumans.
:PROPERTIES:
:Author: blazinghand
:Score: 5
:DateUnix: 1445316824.0
:END:

*** Are you arguing to others as players, or as characters? Infusing Maya's behavior with this recalcitrance would make for interesting drama and plots, but if you're seriously trying to argue that the other players shouldn't have fun doing what they want, you'll be in for a bad time.
:PROPERTIES:
:Author: Transfuturist
:Score: 2
:DateUnix: 1445377093.0
:END:

**** Oh, I'm having fun in the campaign, and Maya has no compunctions about what's going on. The issue isn't that the campaign isn't fun, it's that I don't think we're the heroes of the story. We're definitely villains. We're hip villains with good motivations to do what we do, but in the end, when we're successful, the world will be a worse place for most people. Maya is okay with this.
:PROPERTIES:
:Author: blazinghand
:Score: 2
:DateUnix: 1445377347.0
:END:


** I'm currently in the planning stages of making a video game, and I'm having a bit of trouble figuring out how to code the AI to do what I want.

The simplest way to describe the problem is "biased rock paper scissors". Imagine a game of RPS, to 100 points, except that every time rock beats scissors, that game counts as two points instead of one. What's the optimum strategy in that case? It's not 33/33/33% anymore.

Now imagine that the two players had /different/ payoffs for various outcomes. How would you solve this in the general case?

Edit for clarification: Both players know the payoff matrix, and (to start with) I'm assuming that both players will play the Nash Equilibrium, and will add in the biases later. It is also Zero-sum, as it's a simple 1v1 arena battle with a binary win/loss condition.
:PROPERTIES:
:Author: ulyssessword
:Score: 3
:DateUnix: 1445269517.0
:END:

*** Do the players know each other's payoffs?

#+begin_quote
  Imagine a game of RPS, to 100 points, except that every time rock beats scissors, that game counts as two points instead of one. What's the optimum strategy in that case? It's not 33/33/33% anymore.
#+end_quote

This depends almost entirely on your opponent.

- If facing an opponent who throws randomly, the ideal strategy is 100% rock, because you'll average 2 points per 3 rounds.
- If facing an opponent who throws 100% rock, the ideal strategy is 100% paper, because you'll get 1 point every round.
- If facing an opponent who does tit-for-tat (they do whatever you did last), the optimum strategy is to pick rock, paper, scissors, rock, etc., because you'll get 4 points per 3 rounds.

See [[http://www.rpscontest.com/leaderboard][this RPS]] computerized competition for strategies - all have their code exposed. Basically, what you're asking for is /complex/ because it depends on knowing what the other player's strategy is, which at higher levels depends on trying to hide your own strategy from them.
:PROPERTIES:
:Author: alexanderwales
:Score: 6
:DateUnix: 1445272173.0
:END:


*** Sounds like you're looking for the [[https://en.wikipedia.org/wiki/Nash_equilibrium][Nash Equilibrium]] of the game. In your example - where you get 2 points for winning as rock, and the game is still zero-sum - the Nash equilibrium is where both players use a random strategy which plays 25% rock, 50% paper, 25% scissors.

The Nash Equilibrium gives the strategy where neither player has any incentive to change, /as long as the other player doesn't change either/. There is usually some element of randomness, but not always. There may be more than one Equilibrium, such as in the [[https://en.wikipedia.org/wiki/Stag_hunt][Stag Hunt]].

Oh, and in the [[https://en.wikipedia.org/wiki/Prisoner's_dilemma][Prisoner's Dilemma]], the Nash Equilibrium is defect-defect, even though cooperate-cooperate is better for both players. This is one way in which classic game theory fails to model the real world. But that sort of problem doesn't happen in zero-sum games (where the players are strictly opponents, with no incentive to cooperate with one another).
:PROPERTIES:
:Author: Chronophilia
:Score: 4
:DateUnix: 1445273266.0
:END:

**** #+begin_quote
  Oh, and in the Prisoner's Dilemma[3] , the Nash Equilibrium is defect-defect, even though cooperate-cooperate is better for both players. This is one way in which classic game theory fails to model the real world.
#+end_quote

I don't see how that is failing to model the real world. What conclusion are they reaching that is false? Also, defect-defect is only the NE in a one-shot game.

In an infinite game, a better strategy is tit-for-tat (leading to both players cooperating forever).

When you get into high amount of rounds, but finite games where things get tricky.
:PROPERTIES:
:Author: electrace
:Score: 3
:DateUnix: 1445287304.0
:END:

***** The Prisoner's Dilemma demonstrates how players can get a better outcome by following a non-equilibrium strategy, so the Nash equilibrium isn't a useful guide to playing the game.

"Both players always defect" is still a Nash equilibrium for the iterated prisoner's dilemma - neither player gains from using a different strategy as long as the other one keeps playing all-defect. I'm fairly sure "both players cooperate on the first game and play tit-for-tat thereafter" is not a Nash equilibrium - at the very least, you can improve on that strategy by suddenly defecting in the very last game.
:PROPERTIES:
:Author: Chronophilia
:Score: 5
:DateUnix: 1445290788.0
:END:

****** #+begin_quote
  The Prisoner's Dilemma demonstrates how players can get a better outcome by following a non-equilibrium strategy, so the Nash equilibrium isn't a useful guide to playing the game.
#+end_quote

Unless you can control both players (in which case it isn't a real prisoner's dilemma ), it's a fantastic guide for playing the game.

You aren't looking for the best payoff for both players, only the player that you have control over. Since you can't control the other person, defect is the better strategy in both cases.

If you /do/ have control over both players, the options become CC, CD, DC, DD, in which case, of course, you would choose CC.

#+begin_quote
  "Both players always defect" is still a Nash equilibrium for the iterated prisoner's dilemma - neither player gains from using a different strategy as long as the other one keeps playing all-defect
#+end_quote

For an infinitely repeated game, technically yes, it's an equilibrium, but it's a pretty stupid one. Playing tit-for-tat has the potential for an incredible long-term return, at the risk of only one game's lost points.

#+begin_quote
  I'm fairly sure "both players cooperate on the first game and play tit-for-tat thereafter" is not a Nash equilibrium - at the very least, you can improve on that strategy by suddenly defecting in the very last game.
#+end_quote

Which is why I specified that it was an infinite game I was talking about. There is no last game.

In finite games, as you say, you can defect in the last round. Knowing that you opponent will defect in the last round, you have no incentive to cooperate in the second to last round, which leads you opponent to defect in the third to last round... which eventually leads to you both defecting in the first round. Backward induction sucks...

There are ways to get around this (which normally involve changing aspects of the game, but traditionally, all finite games of prisoner's dilemma with rational players and perfect information have a NE of always defect.
:PROPERTIES:
:Author: electrace
:Score: 2
:DateUnix: 1445308717.0
:END:


**** #+begin_quote
  In your example - where you get 2 points for winning as the Nash equilibrium is where both players use a random strategy which plays 25% rock, 50% paper, 25% scissors.
#+end_quote

Could you give me any advice to be able to estimate the Nash equilibrium of such a game (mixed strategy is the term I think). Did you have this example memorized, or could you calculate it in your head?
:PROPERTIES:
:Author: Seth000
:Score: 2
:DateUnix: 1445322738.0
:END:

***** Ok, so for *symmetric zero sum games*, the expected value of any strategy must be 0 at Nash Equilibria points. Why? Because if you were earning a negative expected return, you could always copy the other player's strategy. And if you're both players are playing the same strategy, (while they sum to 0), then they must both be 0.

So, all you really have to do is take rock, paper, and scissors, and find the strategy that will make it sum to 0 through a system of equations.

Rock: Against paper, -1, against rock, 0, against scissors, 2

0 = -1P + 0R + 2S

Paper: Against paper, 0, against rock, 1, against scissors, -1

0 = 0P + 1R - 1S

Scissors: Against paper, 1, against rock, -2, against scissors, 0

0 = 1P - 2R + 0S

And the final equation, P + R + S = 1 (All percentages sum to 100%), which can be rewritten as...\\
P = 1 - R - S

From the Rock equation... 0 = -1(1 - R - S) + 0R + 2S = -1 + R + 3S

1 = R + 3S

From the Paper equation... 0 = 0(1 - R - S) + 1R -1S = R - S

S = R

(from 1 = R + 3S, and S = R), 1 = R + 3R = 4R ----> *R = .25* ----> *S = .25*

And finally (from P + R + S = 1), P + .25 + .25 = 1 ----> *P = .5*

If you can do that in your head, I salute you.
:PROPERTIES:
:Author: electrace
:Score: 2
:DateUnix: 1445359226.0
:END:

****** Thanks, You're helping.

Your scissors formula should be 0=1P-*2*R right?
:PROPERTIES:
:Author: Seth000
:Score: 2
:DateUnix: 1445361102.0
:END:

******* Yes, fixed. Thank you.

Although luckily, it didn't end up altering the conclusion because I didn't end up using the scissors equation to find R, S, or P.
:PROPERTIES:
:Author: electrace
:Score: 1
:DateUnix: 1445362007.0
:END:


*** Here you go:

[[https://gamebalanceconcepts.wordpress.com/2010/09/01/level-9-intransitive-mechanics/]]

Your 2-1-1 example is located reasonably early in the post, and it goes into a lot of detail from there, including asymmetric scoring. (where each player has a different payoff matrix) This should be exactly what you're looking for.
:PROPERTIES:
:Author: Salivanth
:Score: 3
:DateUnix: 1445332662.0
:END:

**** Thank you. It's at pretty much the right level of mathiness too, and flipping through the other pages looks interesting.
:PROPERTIES:
:Author: ulyssessword
:Score: 1
:DateUnix: 1445385920.0
:END:


*** Is this zero-sum? Because the two players could probably co-operate to get more than either could in competition.

More generally, I think this becomes a game of second-guessing your opponent, so there may /be/ no single winning strategy. (Just as it's strictly better to predict your opponant's moves in RPS than to be completely random.)
:PROPERTIES:
:Author: MugaSofer
:Score: 2
:DateUnix: 1445271338.0
:END:


*** This seem like the sort of situation that would evolve a Nash Equilibrium, with a mixed solution. For an example of one method of calculating Nash Equilibria that is pretty general, I found [[http://www.mathworks.com/matlabcentral/fileexchange/27837-n-person-game/content/npg/npg.m][this matlab script]] which requires only [[http://www.mathworks.com/matlabcentral/fileexchange/27837-n-person-game/content/npg/gamer.m][this function]]. This works for any n-person game where you can explicitly define payoffs for each combination of strategies.

+The nash equilibrium for a RPS game where rock wins 2 points and other wins are 1 point, I /think/ works out to choosing Rock 20% of the time and each of the others 40% of the time - but I am not an expert on this sort of thing.+ edit: see comment below

Scholarly reference: [[http://www.pnas.org/content/36/1/48.full]]

Lesswrong stuff: [[http://lesswrong.com/lw/dc7/nash_equilibria_and_schelling_points/]]
:PROPERTIES:
:Author: Escapement
:Score: 2
:DateUnix: 1445273126.0
:END:

**** #+begin_quote
  The nash equilibrium for a RPS game where rock wins 2 points and other wins are 1 point, I think works out to choosing Rock 20% of the time and each of the others 40% of the time - but I am not an expert on this sort of thing.
#+end_quote

Close, but against that strategy, always-Rock wins an average of 0.4 points per game. The Nash Equilibrium is when both players choose Paper 50% of the time and each of the others 25% of the time.
:PROPERTIES:
:Author: Chronophilia
:Score: 1
:DateUnix: 1445277461.0
:END:

***** Whoops, you are right, I am wrong. I forgot that the game was zero-sum and that therefore your opponent's points effectively count against your own - using a payout matrix that reflects this fixes this error.

Thanks for noticing!
:PROPERTIES:
:Author: Escapement
:Score: 2
:DateUnix: 1445278469.0
:END:


*** If the two players have different payoffs, my first thought is that this has a high chance of becoming a prisoner's dilemma type situation. Maybe I'm utterly wrong though.
:PROPERTIES:
:Author: NNOTM
:Score: 1
:DateUnix: 1445270768.0
:END:


*** The general optimal strategy for regular rock-paper-scissors is 33/33/33%, but when fighting against an unknown faulty random number generator - that is, a human - the optimal strategy (for a computer unable to read someone's poker face) is 33/33/33% at first, followed at some point by weighting the scale according to your opponent's frequencies.
:PROPERTIES:
:Author: LiteralHeadCannon
:Score: 1
:DateUnix: 1445271361.0
:END:

**** That's not the optimal strategy: AIXI performs better.
:PROPERTIES:
:Author: Gurkenglas
:Score: -3
:DateUnix: 1445274233.0
:END:

***** How do you know?
:PROPERTIES:
:Score: 2
:DateUnix: 1445279097.0
:END:

****** Merely analyzing the frequency with which the opponent plays each move is an ugly hack, and not the best one; one might imagine a strategy that also analyzes how the opponent's behavior changes over time, or more explicitly use human psychology. Plugging solomonoff induction into bayesian updating and outputting the best guess at each turn (in other words, using AIXI) captures all these strategies and more.

Granted, the hundred moves may not be enough time to deduce human game-theoretic psychology from scratch, but asymptotically it should waste only constant turns on finding the correct strategy.
:PROPERTIES:
:Author: Gurkenglas
:Score: 0
:DateUnix: 1445280905.0
:END:

******* Except that AIXI is incomputable, intractable to "computably approximate", and can be made arbitrarily stupid by biasing the programming language it uses to represent models.
:PROPERTIES:
:Score: 3
:DateUnix: 1445282694.0
:END:

******** "Strategy" need not be restricted to computables, the arbitrary stupidity is still just a constant amount of wasted turns, and I only used AIXI to illustrate how no amount of heuristics smaller than human game-theoretic psychology is going to be optimal.

In deterministic games like chess, brute-force minmax's intractability doesn't make it less optimal, either.
:PROPERTIES:
:Author: Gurkenglas
:Score: 1
:DateUnix: 1445283446.0
:END:

********* There's actually a significant semantic difference between "computable but intractable" and "incomputable".
:PROPERTIES:
:Score: 3
:DateUnix: 1445284085.0
:END:


***** AIXI doesn't perform period, let alone better.
:PROPERTIES:
:Author: Transfuturist
:Score: 2
:DateUnix: 1445377234.0
:END:


***** Optimal today.
:PROPERTIES:
:Author: LiteralHeadCannon
:Score: 1
:DateUnix: 1445277273.0
:END:


*** As to the question of designing the AI, a super-naive and inefficient implementation (aka the first thing that came to mind) would be keeping track of the scores of each play, finding the smallest ratio among them, then filling an array with that many instances of each choice, and choosing from the array with a pseudorandom number.

I wouldn't recommend it if you're aiming for optimal. It's just the first thing that came to mind. It also gets messy if you play sufficiently many rounds that the ratios don't reduce well (5:8:7 is icky enough).
:PROPERTIES:
:Author: cae_jones
:Score: 1
:DateUnix: 1445285676.0
:END:


** I found this over the weekend: [[http://en.arguman.org/]] It's an online tool to dissect arguments and structure agreement and refutation.
:PROPERTIES:
:Author: Predictablicious
:Score: 6
:DateUnix: 1445269319.0
:END:

*** The level of discourse is not as high as I'd like. Anyone feel like using it if I set up a clone focused on rationalists?
:PROPERTIES:
:Author: traverseda
:Score: 6
:DateUnix: 1445285420.0
:END:

**** Only if you actually have a way to keep the level of discourse high, which is tough to do without mods.
:PROPERTIES:
:Author: electrace
:Score: 5
:DateUnix: 1445287036.0
:END:


*** I remember hearing about something like this in a computer science seminar... Although there it was used as an inference algorithm rather than a social platform.
:PROPERTIES:
:Author: NNOTM
:Score: 1
:DateUnix: 1445269928.0
:END:


*** Damn, there goes my idea. Glad it exists though, thanks for sharing!
:PROPERTIES:
:Author: DaystarEld
:Score: 1
:DateUnix: 1445273898.0
:END:

**** Implementations are a thousand times more valuable than the idea. There are several implementations of debate decomposition, and all of them are lacking.
:PROPERTIES:
:Author: Transfuturist
:Score: 4
:DateUnix: 1445309451.0
:END:


** I think cellular automata would seriously benefit from a probabilistic component. At its simplest - how would Conway's Game Of Life change if the following addenda were added?

1) Living cells with two neighbors have a .1% chance of dying on each turn.

2) Dead cells with two neighbors have a .1% chance of coming to life on each turn.

That's just a Conway's Game Of Life mod, but I think it might be even more interesting to design entire cellular automata from the ground up around probabilities, rather than certainties.
:PROPERTIES:
:Author: LiteralHeadCannon
:Score: 2
:DateUnix: 1445286827.0
:END:

*** That would be interesting, but it would also be strictly different and way less interesting in the ways that Conway's Life is. CL is cool because it's a set of four simple, intuitive rules which combined produce a turing complete system, technically capable of any and all arbitrary calculation. Fungal life would be interesting to watch a few times, but would then lose interest because it wouldn't be possible to actually construct things in it.
:PROPERTIES:
:Author: Frommerman
:Score: 5
:DateUnix: 1445302924.0
:END:

**** It would be interesting to see what structures were more resistant to decay.
:PROPERTIES:
:Author: LiteralHeadCannon
:Score: 1
:DateUnix: 1445306836.0
:END:

***** Nope. the most resistant structures would be the ones with the fewest blocks which met the requirements, which basically means whatever structure has the fewest blocks. A box destabilizes on average every 12.5 generations, and a blinker destabilizes on average every 20 generations. I think it's likely that fungal life is one of the cellular automata in which everything always vanishes quickly.
:PROPERTIES:
:Author: Frommerman
:Score: 1
:DateUnix: 1445308936.0
:END:

****** How about flammable vacuum life? Same rules as regular Life, but with a tiny chance for any dead block with no living neighbors to come to life.
:PROPERTIES:
:Author: LiteralHeadCannon
:Score: 1
:DateUnix: 1445317754.0
:END:

******* Similarly impossible to build anything useful, but would be the kind of thing you could put on a huge wall screen as a display.
:PROPERTIES:
:Author: Frommerman
:Score: 1
:DateUnix: 1445355611.0
:END:


*** Have you heard of [[https://www.youtube.com/watch?v=KJe9H6qS82I][SmoothLife?]]
:PROPERTIES:
:Author: Transfuturist
:Score: 1
:DateUnix: 1445390020.0
:END:

**** No, but it looks fascinating! I hadn't even considered the possibility of a non-cellular cellular automata.
:PROPERTIES:
:Author: LiteralHeadCannon
:Score: 1
:DateUnix: 1445390543.0
:END:

***** I don't think most people would. :P I think the continuous form is referred to as reaction-diffusion. Look at U-Skate or the Rock Paper Scissors CA.

The U-Skate world demonstrates the concept of metastability very nicely. A perturbation induces the false vacuum to collapse, resulting in a more stable configuration.
:PROPERTIES:
:Author: Transfuturist
:Score: 1
:DateUnix: 1445445779.0
:END:


** Has the definition of Kolmogorov Complexity ever been extended to probabilistic Turing machines?
:PROPERTIES:
:Score: 1
:DateUnix: 1445279213.0
:END:

*** That could make Occam's razor a lot easier. And the make a lot more stuff easier...

Sounds like a large part of something dangerous. See my name.
:PROPERTIES:
:Author: traverseda
:Score: 1
:DateUnix: 1445285770.0
:END:

**** Not really, since it still wouldn't be computable or tractably approximable.

My desired application is to sort of quantify the difference between a string that's "random" as in very compressed versus one that's "random" because it was created by flipping coins. The latter can be generated by a very short probablistic program whereas the former... could /also/ be generated by a coin-flip process but would come with greater likelihood from a complex causal process.

Or something. One reason I want the concept is to clarify my confused intuitions.
:PROPERTIES:
:Score: 3
:DateUnix: 1445285944.0
:END:


**** Further thought: extending =K(x)= to probabilistic machines is trivial and dumb, because the shortest program for /any/ =n=-bit string is =(take n . repeat) flip= (Haskell notation), or in Church:

#+begin_example
  (define (all-possible-strings n)
    (if (= 0 n) () (cons (flip) (all-possible-strings (1- n)))))
#+end_example

Also, separating the structural bits from the random bits in a string's representation is incomputable, which is why we don't actually use Kolmogorov structural information to do "algorithmic statistics" in the real world. We can of course approximate the division by adding up the bits used for deterministic program code and then the bits of Shannon entropy in the primitive random procedures from which we sample /in the shortest trace generating the string/, but then we still need to define some neat way to talk about the trade-off /between/ those two sets of bits.

So on third or fourth thought, /actually/, when we use /that/ definition, we've actually got a useful concept, I think. A long string with a lot of structure can be more shortly described by a short deterministic program with very few coin flips than just by an enumeration of all strings via a whole shit-ton of coin flips. The /shortest trace/ part was important, as the use of random sampling puts us closer to linear-logic type semantics in which we can't treat =flip= as only one bit but instead as one bit per call.
:PROPERTIES:
:Score: 3
:DateUnix: 1445293417.0
:END:


**** Fuller context:

In the probabilistic approach to cognitive science, we often observe that under tractability constraints (lack of both sample data and processing time), the mind forms very noisy but very simple and /still usefully approximately correct/ intuitive theories about various phenomena. We also know that as part of scientific reasoning, we invent theories of increasing complexity (of their deterministic causal structure) in order to increase the precision with which we can match our observable data, which we then obtain in large amounts so as to be increasingly sure of our inferences.

I want a way to quantify the sliding scale of precision and complexity from intuitive theories to precise theories, preferably by talking about the tradeoffs between Kolmogorov structural information (number of bits of deterministic structure) versus random information (number of coins flipped).

Oh hey, there's that concept. So it's actually pretty easy...
:PROPERTIES:
:Score: 1
:DateUnix: 1445286610.0
:END:


*** I believe if you try to define such a concept you will get something essentially equivalent to ordinary Kolmogorov complexity, or even more trivial if you define it badly.

For instance, consider this concept: A (m,p) description of a string s consists of an m-bit description of a probabilistic Turing machine M which has a probability p of outputting s. Given M we can calculate the list of all possible outputs of M in decreasing order of likelihood. Every entry appearing before s must have a probability of appearing which is at least p, which means there can be at most 1/p such entries. Then describing M as well as the place of s in this list requires around m+log(1/p) bits, which means that we can bound above the Kolmogorov complexity of s by around m+log(1/p).

In the other direction, we can consider a universal Turing machine whose first m bits of input are hardcoded into it and the rest are generated randomly. Using machine of this form we can generate a (m,p) description for any string with Kolmogorov complexity slightly less than m+log(1/p).
:PROPERTIES:
:Author: itaibn0
:Score: 1
:DateUnix: 1445460669.0
:END:

**** Scroll down, there was something less trivial and more interesting.
:PROPERTIES:
:Score: 1
:DateUnix: 1445464062.0
:END:


** Has anyone else here read [[http://www.amazon.com/The-000-Year-Explosion-Civilization/dp/0465020429][The 1000 Year Explosion]]?

I wanted to see what other people's thought of it.
:PROPERTIES:
:Author: xamueljones
:Score: 1
:DateUnix: 1445293504.0
:END:

*** That sounds dangerously close to a heretical position on human biodiversity. As I understand it, the current dogma is that evolution stopped long before any form of civilisation took place, or at the very least it did so from the neck up. This is a religious/political position, not a scientific one.
:PROPERTIES:
:Author: BadGoyWithAGun
:Score: 1
:DateUnix: 1445419611.0
:END:

**** You're correct that the current idea is that currently there is no form of human evolution occurring......which is why this book is so interesting to me. They took a widely-held idea and gathered extensive evidence against it, and clearly and consistently explained why this idea is wrong and how humans are still evolving.

#+begin_quote
  This is a religious/political position, not a scientific one.
#+end_quote

I feel that the idea being argued is a simple scientific question "Are humans currently evolving?", however people are motivated for political/religious reasons to choose one side or the other instead of following the evidence.

If you're curious, I currently believe humans are evolving because of the book, and the reason why I think this concept is not easily obvious is because the entire history of human civilization is shorter than the amount of time it takes for a mere handful of simple genetic mutations to spread throughout a species' population. So people look at how humans appear virtually identical throughout history and conclude that evolution has stopped instead of it being the fact that not enough time has passed.
:PROPERTIES:
:Author: xamueljones
:Score: 2
:DateUnix: 1445438431.0
:END:


** We know of theoretical materials with low mass and preternaturally high tensile strength such as carbon nanotubes. Are there any theoretical materials with low mass and high compressive strength? Also, what about high stiffness?

This is for a setting with nanotech.
:PROPERTIES:
:Author: Transfuturist
:Score: 1
:DateUnix: 1445445870.0
:END:

*** In terms of "able to deal with tons of weight on top of it or compressing" I think our best widely used material nowadays is concrete or maybe ceramic. From what I've heard, concrete is basically the perfect material for dealing with compressive forces and is hilariously good at the job for its weight. The reason we add iron bars to concrete has more to do with sheer or tensile forces rather than compressive ones.
:PROPERTIES:
:Author: blazinghand
:Score: 1
:DateUnix: 1445536816.0
:END:
