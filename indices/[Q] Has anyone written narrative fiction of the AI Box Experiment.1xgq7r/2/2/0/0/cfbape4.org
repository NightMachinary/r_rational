:PROPERTIES:
:Author: HamillianActor
:Score: 1
:DateUnix: 1391993556.0
:DateShort: 2014-Feb-10
:END:

Which I don't quite understand as a scenario. If you create an AI and put it in a box with no access to the outside world (other than through the gatekeeper), how can it use personal knowledge as leverage against a gatekeeper it doesn't know?

This is part of my potential dramatic scenario. Presume the AI, when first created, had enough contact with the larger world for long enough to have a dossier on anybody with a substantial enough electronic footprint. And that it's far enough in the future that just about everybody has a substantial electronic footprint.

As a gatekeeper, why not hire somebody with no electronic footprint (even if you have to go to substantial lengths to do so) to act as guard? The AI may still learn the relevant info through conversation, but at least it'd be a handicap and if the guard were sufficiently strong willed, could keep the AI from learning any information to use as leverage in the first place.