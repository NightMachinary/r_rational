:PROPERTIES:
:Author: vakusdrake
:Score: 2
:DateUnix: 1505223580.0
:DateShort: 2017-Sep-12
:END:

#+begin_quote
  Useful, though might I recommend learning the difference between beneficial bacteria (e.g. gut flora) and harmful bacteria first. (Ideally, in fact, learning a lot of biology; I'm sure some otherwise quite deadly bacteria play important parts in decomposition, for example).
#+end_quote

Yeah I'd start by just removing all the lifeforms that aren't already present in basically everybody from everyone's bodies, since people are dying all the time. After that though I could refine things a bit eliminating harmful infections which are nonetheless extremely common, likely by just going through lists of common diseases since all the rare stuff was already eliminated.

#+begin_quote
  Slicing bits of neurons out of someone's brain may well leave them a drooling vegetable. Especially if memories are stored in a highly distributed manner... test this first on people who are about to die (condemned criminals at first, I think).
#+end_quote

While I would test it first (say on some people who found out secret information) it seems very unlikely anything bad would happen. After all I'm only killing a handful of cells and neurons die all the time, hell I might be able to get away with just deleting the synapses forming the memory without even killing most or any affected neurons.

#+begin_quote
  I don't think it would be completely post-scarcity, though the world would certainly have different scarcities while you and your power remain present. (Major scarcity: matter. Your power works only by destroying it, never creating it, so your power has a limit there.)
#+end_quote

While at pre singularity tech levels we would have /some/ limits that seems besides the point that this still meets the criterion for a post scarcity civilization even if it's not post singularity.\\
Of course once we had GAI then you could avert heat death by deleting one particle from pairs of virtual particles to create as much matter/energy as needed. Actually to avoid any slight annoyances due to charge imbalances I might as well just have the power generators work that way, having them delete either positrons or electrons from virtual particle pairs inside the box. Plus I could use that method to create unlimited amounts of hydrogen, though anything heavier would need too many resources to be worth it at our tech level.\\
I also just remembered that in virtual particle pairs one half always has negative mass making FTL unavoidable, so the shenanigans I mentioned in my other post to obtain FAI without your civ having to do any research seem probably unavoidable.

#+begin_quote
  ...not so helpful. Wanting to get there before the "other guy" tends to help humans to work harder. (The easy fix for this, of course, is to control two or three different tech companies yourself and play them off against each other...)
#+end_quote

Yeah I suppose I mostly agree with you. The issues I was concerned with really are only an issue with AI wherein rushing it almost certainly kills everyone. Why competition is a terrible idea was of course covered in /Superintelligence/ and also I'm pretty sure it was in one of [[https://www.youtube.com/channel/UCLB7AzTwc6VFZrBsO2ucBMg/videos?shelf_id=1&sort=dd&view=0][Robert Miles Youtube]] videos, though I'm not sure which one, though they're all pretty great and that channel and the videos he did on computerphile are probably the best videos on the topic on youtube if not anywhere online.