:PROPERTIES:
:Author: vakusdrake
:Score: 2
:DateUnix: 1505233868.0
:DateShort: 2017-Sep-12
:END:

#+begin_quote
  This is one potential point of trouble, and it is a big one. What happens when you search through future worlds for the perfect AI according to your list of criteria might not be what you intend to happen...
#+end_quote

I don't think this is nearly as bad as it seems, since the metrics I'm using can rely on my own intuitions and don't all need to be formally defined. More importantly however siren worlds are relatively rare so when I tell it to find a world that meets them (so long as I'm not telling it to /maximize/ IC) then it's staggeringly unlikely to end up with a siren world.