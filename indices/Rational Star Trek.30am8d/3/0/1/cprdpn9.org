:PROPERTIES:
:Author: GopherAtl
:Score: 3
:DateUnix: 1427380166.0
:DateShort: 2015-Mar-26
:END:

Part of the problem is that it is simply too broad to be a simple, absolute rule. It should absolutely be a crime of the highest order to take a primitive world and use advanced tech to dominate them, whether it's by posing as gods or just through brute-force oppression. Any reasonable person should agree with that, I think you can safely say. And that /does/ branch out a bit. If you were to plop down onto a planet with a pre-industrial civilization and just start transforming their world in the most benevolent way possible, giving them medicine, technology, and education - you would be helping the people, yes, but it seems almost inevitable that you would, in the process, murder their culture in the process, displacing it in favor of a little parody of your own. Regardless of your good intentions, they would still effectively be subservient, at least until they grew to the point that they could sustain this improved quality of life without your assistance. To make that happen quickly, would mean being immensely disruptive in the short term. To throttle their development, make it happen slowly, would just prolong their period of dependence. There's no obvious, perfect answer. So I could accept an expansion beyond a simple prohibition against direct exploitation, as I can see the consequences of benevolent interference being destructive, too.

But to extend it as far as a vague prohibition against any interference, interpreted so broadly as to mean you can't fire a few photon torpedos at an asteroid you happen to notice is on course to hit their planet and render it uninhabitable in a few years, from the complete safety and anonymity of space, where they will never know you were even there? That is just madness, and completely unjustifiable. The only rationale I can even conceive to defend that would be a resort to a higher power, that the asteroid is some god's will, and that we should not interfere. Which is flimsy even if it's true, since if there is such a powerful god going around willing things like that, why should it be assumed that we are somehow able to subvert that omnipotent being's plans?

It is harsh, but I could accept going so far as to say you will not, under /almost/ any circumstances, save them from their own actions or choices. If you encounter the equivalent of a nuclear WWIII, you don't just step in and force them to be peaceful. However good your intentions, and however good the immediate impact, it seems likely it would only lead back to another situation where you were forced to dominate their civilization until they stopped wanting to blow each other up. And once you start to justify that sort of thing, where do you stop? At what point do you deem the planet "mature" enough to withdraw from? Can you imagine how the military and government leadership on Earth would react in such a scenario? How many generations would it take for the resentment that kind of interference would create to be completely forgotten, even if it's kept alive only in the subculture of the world's military? Now, sometimes, all of that might not be necessary; if, during the cold war, someone had gotten twitchy and launched the first nuke, and set a whole chain of MAD into action, had some unknown alien agents simply destroyed /all/ the missiles in the air, it /might/ have nipped the whole thing in the bud, given us a second chance. Or, they might simply have launched more. So that level of interference might be acceptable, in theory, but in practice, do we keep a heavily-armed, cloaked ship parked in orbit of every world that might destroy itself? That alone, if discovered, would certainly be a source of fear and resentment should it become known, and again, once you start that sort of thing, where do you stop? When do you declare a planet "safe enough" to withdraw your orbital suppression platforms?

So it's not a simple matter. There are cases where it is obviously right, and cases where it is obviously wrong, but in between, there are many cases where it is gray. Which is why I think you can't just "tweak" the prime directive into a single, better rule, but rather, it should be treated as the complex issue that it is. It should be, not a pithy phrase you can put on a plaque, but the title of lengthy book, delving into the philosophy and morality, admitting that there are no perfect answers to some questions.