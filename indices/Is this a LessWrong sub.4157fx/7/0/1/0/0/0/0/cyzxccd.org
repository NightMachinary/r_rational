:PROPERTIES:
:Author: traverseda
:Score: 10
:DateUnix: 1452907308.0
:DateShort: 2016-Jan-16
:END:

I think motives are important, but they're not at the layer of ethics, they're at the layer of game theory or politics.

The goodness of an action doesn't change based on motive, but how you treat the person doing the action still should, if that makes sense?

Likewise, someone can be a good person, and not have much of an affect on the world. Someone can be a horrible person and do great things.

You're using ethics to judge yourself, but I think you should be using it to judge the world.

Virtue ethics is an alright shim to deal with all the complicated game theory bullshit, because it let's you predict future actions. An evil person who does one great thing isn't "better" (in the sense that you should associate with and reward them) then a good person who doesn't get a lot done. because that evil person is willing to do evil. On the whole, the good person will end up being better.

There's also the layer where we don't want to implement anything like the churches "indulgence" system. There are all kinds of social reasons why we don't want people to be able to buy off their sins.

I'm describing it poorly I know.

The point I'm trying to get at is that something that looks a lot like virtue ethics is that natural result of social structures and preference utilitarianism, but that I see it as just another tool to help us work towards preference utilitarianism. I view it as a social tool in service of good ethics instead of as good ethics itself.

--------------

#+begin_quote
  I find it horrifying to assign ethical culpability when the consequences of an action can be ridiculously, insanely hard to predict with surety
#+end_quote

Lesswrong says is pretty abrasively, but I'm inclined to agree.

#+begin_quote
  You know what? This isn't about your feelings. A human life, with all its joys and all its pains, adding up over the course of decades, is worth far more than your brain's feelings of comfort or discomfort with a plan. Does computing the expected utility feel too cold-blooded for your taste? Well, that feeling isn't even a feather in the scales, when a life is at stake. Just shut up and multiply.
#+end_quote

To put it a bit nicer, I consider preference utilitarianism to be a virtue, and I'm more inclined to help out those that I consider to be virtuous, as a policy. I like virtuous people more then evil people.

If I help out people with that virtue, and they help other people with that particular virtue, more bednets are likely to be distributed to africa, more people get to live happy full lives, etc.

That's what virtue is for, determining what people/corporation you should like and therefore help out.

But how you decide what is a virtue is in the realm of preference utilitarianism and game theory.

Sorry, that was a bit rambly, but hopefully I've got my point across.