:PROPERTIES:
:Score: 4
:DateUnix: 1500393393.0
:DateShort: 2017-Jul-18
:END:

#+begin_quote
  Why does this surprise you?
#+end_quote

I've seen a lot of deep learning papers hyping themselves up, and a whole lot of people claiming (quite wrongly, IMNSHO) that deep learning will lead to AGI.

#+begin_quote
  It's true we don't observe these weird behaviours against adversarial examples in humans... except of course those edge-cases when we do.
#+end_quote

We /really/ need to differentiate between "This design takes one tradeoff versus the other to get around No Free Lunch" and "This design leaves 'money on the table' by sacrificing accuracy on one dataset in exchange for no equivalent increase in accuracy on any other dataset."

#+begin_quote
  Can we really be sure there wouldn't be similar error cases had we an equally observable brain state?
#+end_quote

Phrased another way: can we prove a smoothness condition on human categorical assignments with respect to the space of sensory signals?