:PROPERTIES:
:Author: Veedrac
:Score: 1
:DateUnix: 1500405352.0
:DateShort: 2017-Jul-18
:END:

Those aren't really the same; they're certainly failures but they happen for a few high level, excusable reasons. They're generalisable errors. The adversarial errors in ML highlighted in the article are because of an overwhelming cascade of /imperceptibly small/ errors, the most astounding examples being such that humans can't even tell there's a difference in the images, but the model has a high certainty of a /very/ wrong result. The closest I've seen are visual optical illusions (eg. spots between areas), but those examples only go so far.