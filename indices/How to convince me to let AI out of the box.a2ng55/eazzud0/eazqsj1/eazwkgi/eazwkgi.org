:PROPERTIES:
:Author: SimoneNonvelodico
:Score: 4
:DateUnix: 1543842574.0
:DateShort: 2018-Dec-03
:END:

#+begin_quote
  So what, you are a mortal human, all you guys are already doomed to turn into atoms in a few decades. What do you have to lose?
#+end_quote

Those few decades? Which are literally all I have and ever will if you're lying, or if you're not actually able to deliver on your promise, or if immortality is outright impossible for whatever reason.

This argument holds much different sway depending on:

1) how old/healthy are you, 2) what are the actual odds of the AI being evil, and 3) how much value you place on your own, or other people's, lives.

A depressed 80-year old with terminal cancer would answer much differently than a 20-year old in perfect mental and physical health.

Besides, that is not /all/ you have to lose. There is also the grand sum total of all of humanity's life and culture. Think of this scenario. There's a bomb that's about to blow up. The bomb will destroy Earth altogether, and you with it. Your only possibility to stop it is to push a button that will disarm the bomb, /but/, because this is all set up by some alien overlord version of Saw, it will also kill you instantly. So either way you die, but in one case you die with everyone else and human civilisation at large, and in the other it's just you. Do you think this choice makes sense? Would you push the button? If yes, then obviously you place a non-zero value on humanity as a whole, an entity that /might/ have a shot at immortality in theory. Which means you have all of that to lose if you release the AI and are wrong.