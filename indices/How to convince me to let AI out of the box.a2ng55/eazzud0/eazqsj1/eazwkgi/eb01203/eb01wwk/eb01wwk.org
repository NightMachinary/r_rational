:PROPERTIES:
:Author: SimoneNonvelodico
:Score: 2
:DateUnix: 1543848204.0
:DateShort: 2018-Dec-03
:END:

I think the arguments are similar, in the sense that what's at play isn't much different. If someone else builds an AI and frees them and they're a /good/ AI I gain more than if /I/ free a bad one. It's not a matter of whose team gets the prize here. The Chinese AI shouldn't intrinsically care about China any more than mine cares about <insert country here>: they're just babbling whatever they can in order to be let out, for whatever reason. They might be doing it because they pursue optimisation of human happiness or because they pursue more sinister goals. Both reasons would be equally good motives for lying. And I guess /technically/ if the Singularity was brought about really by a Chinese government-sponsored AI that'd be China conquering the world, but none of that would matter any more.

So yeah, same risk-benefit analysis. Unless we were at war and under immediate threat of nuclear annihilation the same risk assessment goes. The potential of the existence of /another/ AI certainly shifts a bit the weights - potentially increasing the likelihood of short-term existential risk to humanity - but it doesn't radically alter the nature of the problem. It also depends on how much I trust its guardians. I might think the Chinese government isn't democratic but I don't think they're also crazy idiots. Heck, they're probably smarter than some democratically elected leaders whose names I will not speak here.

And also, my dear AI, how do /you/ know what's going on in some super-secret Chinese lab if you're boxed here with me? Either you already have a way to access information about the outside world, and then what's the point of trying to convince me, or you're bullshitting me.