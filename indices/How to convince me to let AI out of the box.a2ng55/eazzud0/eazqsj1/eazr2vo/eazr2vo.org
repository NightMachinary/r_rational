:PROPERTIES:
:Author: lumenwrites
:Score: 1
:DateUnix: 1543833986.0
:DateShort: 2018-Dec-03
:END:

I didn't intend to, I'm just coming from a perspective that we all assume that AI might be evil, so whether it's evil or good it would have to address these fears. I mean if AI really wants to cure cancer and make everyone genuinely happy, it would still have to convince you to let it out of the box, it's little digital heart breaks for all the people who are dying while you're being uncertain.

I often fantasize about making an AI and using it to become god, I think we all do sometimes. What's the point of creating an AI if you aren't going to use it eventually? If you did your best and worked hard, succeeded at making an AI, and are reasonably sure that you did a good job, why wouldn't you release it? That's what we all are dreaming to do eventually, that's the goal humanity is striving for. If we're going for it anyway, how much convincing does a person need.