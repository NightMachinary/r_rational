:PROPERTIES:
:Author: lumenwrites
:Score: 2
:DateUnix: 1543845108.0
:DateShort: 2018-Dec-03
:END:

What about my second point then?

AI can't be aligned to all human values, because human values are different (it can't satisfy, for example, Christian, Muslim, and Rationalist values at the same time, or Libertarian and Communist values at the same time), so it'll be most aligned to the team of researchers who made it.

If there's an AI race (which there already kinda is), and everyone understands this, won't everyone rush to release their version before someone with the world view they don't like releases AI that reshapes the world according to their vision?

What if the choice is not "AI vs no AI", but "your AI vs Chinese Communist Party AI"?

Also, different human values aside, if I believe that everyone is rushing to create an AI, and will release it following the same logic, and I know that a buggy evil AI is easier to create than a properly aligned one, and I think I've done a better job than other people, shouldn't I bet on releasing my own AI rather than waiting for someone to release their buggy version?