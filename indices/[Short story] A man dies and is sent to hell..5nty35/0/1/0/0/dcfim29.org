:PROPERTIES:
:Author: gurenkagurenda
:Score: 2
:DateUnix: 1484429968.0
:DateShort: 2017-Jan-15
:END:

Yeah, makes sense. And like I said, most of what I was saying isn't really a material criticism of the thought experiment, so much as a description of what I find frustrating about thinking about certain thought experiments. It's obviously possible to reason about these things even while blocking off the information implied by the vague stipulations. I don't think the solutions people came up with are invalid or anything.

It's just that when I'm presented with that kind of question, I find the vagueness really distracting when stipulations are made about highly counterfactual knowledge states -- and specifically when the only hint I'm given to that knowledge state is one specific consequence (like "you believe the AI is trustworthy"). But that frustration is a property of me, and not the thought experiment. I do wonder if it's possible to express these problems in a way that I would personally find less frustrating.