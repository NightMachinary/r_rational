:PROPERTIES:
:Author: yaolilylu
:Score: 5
:DateUnix: 1484670952.0
:DateShort: 2017-Jan-17
:END:

I see your point but don't necessarily agree; if I pre-commit to "I'll never jump off a cliff into molten lava while holding three pet hamsters" and resolve to keep the commitment, the AI would presumably be able find a way to crack me if it can manipulate my environment inside its own simulation, but I don't see how it could do that to the real me while it's sitting in its box. A commitment to never open the box could be similar, the right kind of mind may never crack under any dialogue.