:PROPERTIES:
:Author: owenshen24
:Score: 2
:DateUnix: 1484749261.0
:DateShort: 2017-Jan-18
:END:

The thing is, if you have reason to believe the AI could torture one million (or any other high enough number), then from your perspective, it becomes very likely that you're the copy.

But yes, your other point stands. Other people have pointed out that if the AI can simulate you, then it can just run simulations to figure out what it can say to get you to open the box.

This is why precommitment is necessary. If you never let it out in simulations, then you won't face the threat in real life.