:PROPERTIES:
:Author: jtolmar
:Score: 19
:DateUnix: 1553026756.0
:DateShort: 2019-Mar-19
:END:

This is a proposal for a setting, not a proposal for something someone should actually do. If you can create a values-aligned AI you should, you know, ask it to figure out what we should have asked for instead of CEV and then go do that.

But in-setting some alien intelligence was able to create FAI and decided the best thing to do was to prevent anyone else from blowing up the universe. Maybe they also created a utopia on their planet and this was their gift to the rest of the universe, I don't know.