:PROPERTIES:
:Author: Wereitas
:Score: 3
:DateUnix: 1553073963.0
:DateShort: 2019-Mar-20
:END:

People are intelligent. But we're constrained in our capacity for self-modification and self-deception.

I might -- with enough alcohol and effort -- trick myself into thinking that I had a winning lottery ticket. But to really enjoy the delusion, I'd have to ALSO trick myself into thinking that the lottery commission accepted the ticket. And also that they money was in my bank. And that I was able to spend the money on a car.

My limited capability for self-deception means that eventually reality will assert itself, and I won't experience the life that would come with winning the lottery. So trickery doesn't work.

(And if there was a sufficiently tricky spell, it would be identical to a spell that actually made me win)

AIs are digital, and so have much more capacity for self modification.

Consider a paperclip maximizer. If we're precise, it's not maximizing paperclips, as paperclips aren't the sort if thing you can free into a CPU. Instead, the AI is maximizing some sensor's *report* about the number of paperclips.

If the AI is properly boxed, then this distinction doesn't matter. We can just say, "No editing that function!" and then the AIs only option for improving its utility is the long and tedious process of killing all humans and turning us into paperclips. But if the AI is properly boxed, then we can also impose restrictions like "no killing humans".

An unboxed AI has two paths forward. Either it can spend billions of years trying to turn matter into a finite number of paperclips. Or it can hack a single sensor and get infinity paperclips right now.

So, an unboxed AI is an AI that has every reason to just hack its own inputs to instantly-win. And at that point, the unboxed AI stops caring about the outside world. The only remaining AIs are boxed