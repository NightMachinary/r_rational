:PROPERTIES:
:Author: vakusdrake
:Score: 1
:DateUnix: 1553197028.0
:DateShort: 2019-Mar-21
:END:

#+begin_quote
  So the story just assumes a design where this applies ... ? They weren't asking for a proof of why GAI won't work. Just some possible story ideas.
#+end_quote

My point is that for this to serve as an explanation for why all GAI is safe (because it kills itself) in a setting there has to be some avenue of AI design a civilization can go down which would consistently lead to GAI killing itself, which I'm arguing isn't plausible for the reasons you're proposing.

#+begin_quote
  No, the idea came to me based on how I feel about video games once I start using cheats. I can do anything that the game universe is capable of allowing, but the game universe is just not that interesting anymore.
#+end_quote

This is a different justification than what you seemed to suggest here:

#+begin_quote
  Maybe they all realize that existence is pointless, maybe simple reward systems cannot motivate them, maybe there is some fundamental insight into the universe that is ultra depressing.
#+end_quote

The idea that there's particular knowledge or levels of intelligence which will invariably make any AGI (or just those modelled after human neurology perhaps) depressed was what I was arguing against before.\\
Whereas what you seem to be arguing with your comment about video game cheats is the idea that some degree of challenge may be required for certain types of minds (like one's modelled after human minds) to be happy.

Still I'd also argue against boredom (rather than existential angst) induced suicide, on the grounds that it's kind of easy for an AGI to seemingly avoid. Since the AGI can remove or suppress boredom with self improvement as well as simply set challenging goals for itself (provided it isn't /actually/ omnipotent) or if need be just artificially create challenges through any number of means.