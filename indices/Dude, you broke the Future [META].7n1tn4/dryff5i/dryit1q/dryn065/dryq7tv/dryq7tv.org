:PROPERTIES:
:Author: nicholaslaux
:Score: 3
:DateUnix: 1514662374.0
:DateShort: 2017-Dec-30
:END:

Is the debunking that anyone in transhumanism /thinks/ that there would be a human-like AI rather than the self-optimizing tool-like AIs?

I agree that portraying a paperclip maximizer as a "brain in a box" is probably inaccurate, but I thought the rest of the talk where he discusses companies as real-life versions of paperclip maximizers seemed to encompass the risk that people like Musk are warning explicitly about.

I also acknowledge my own political biases, which are largely similar to Stross's and are clearly visible in this talk, are avoided being mentioned, such as every time he discusses Cambridge Analytica, but doesn't mention Civis Analytics (the company that spun out from the Obama campaign's analytics arm, which I'm sure did many similar things) and the like.

But the underlying point of "companies are slow-AI that already have some of the risks we're discussing, and technology is making the fast-AI concerns even more real for them" seems definitely relevant to the discussion and not obviously wrong to me. If there is something more clearly wrong, I'd love to be pointed in the direction of something elaborating why, so I can update my own thoughts of the subject, though.