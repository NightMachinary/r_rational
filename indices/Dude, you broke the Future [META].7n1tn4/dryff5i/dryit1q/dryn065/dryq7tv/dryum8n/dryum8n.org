:PROPERTIES:
:Author: Veedrac
:Score: 9
:DateUnix: 1514667696.0
:DateShort: 2017-Dec-31
:END:

It's hard to call any one issue with his comments on superintelligence definitive, and there are people who think brain uploads are an easier problem than bona fide artificial intelligence, so I would hesitate to point to that issue.

To jump to your next point, in my understanding Musk is worried about AI as “our biggest existential threat”, and [[https://www.youtube.com/watch?time_continue=105&v=Ze0_1vczikA][seems to have have a very Yudkowskian view of it]], rather than view it as a social hazard.

There is a fundamental discontinuity in superintelligence that, if it acts like traditional AI risk advocates suspect, makes any attempt to analogise them to corporations unhelpful. A corporation with misaligned incentives attempts to subvert its political safeguards, whereas a superintelligence with misaligned incentives converts the Earth to computronium.

I don't consider the argument that “companies are slow-AI” particularly interesting because it serves him as nothing but a label. He never uses it to take insights learned from AI research and apply it to his problem, something you can test by hypothesizing the same talk without using this term and noting that it is basically the same.

Note that whereas my objection to the “companies are slow-AI” analogy is that I don't feel it is helpful, my objection to his comments on superintelligence are that his claims are simply wrong. I don't think you've asked for clarification here, so I'll leave it as that, but the offer is still open.