:PROPERTIES:
:Author: kcu51
:Score: 1
:DateUnix: 1565619662.0
:DateShort: 2019-Aug-12
:END:

#+begin_quote
  Cutting the conversation into a million tiny parallel pieces makes it less fun for me to engage with you, so I will be consolidating the subjects I consider most important or interesting. Points omited are not necessarily conceded.
#+end_quote

Understood. I try to minimize assumptions about others' beliefs regardless. (Hence my original questions.) Still, I hope you'll be patient if I make mistakes in my necessary modeling of yours.

#+begin_quote
  If I give you the set of all 2D grids made up of white stones, black stones, and empty spaces, have I given you the game of Go? No. That's the wrong level of abstraction. The game of Go is the set of rules that defines which of those grids is valid, and defines the relationships between those grids, and defines how they evolve into each other.
#+end_quote

What if I give you all the grid-to-grid transitions that constitute legal moves? (Including the information of whose turn it is as part of the "grid", I guess.)

#+begin_quote
  Likewise, "I" am not a pile of possible mindstates, nor am I any particular mindstate.
#+end_quote

Hence why I specifically used the term "mind-/moments/". Are you not one of those across any given moment you exist in? Is there a better/more standard term?

#+begin_quote
  I am an algorithm that produces mindstates from other mindstates.
#+end_quote

Exclusively? Are you a solipsist?

If you learned that you had a secret twin, with identical personality but none of your memories/experiences, would you refer to them in the first person?

#+begin_quote
  In fact, I am just one unbroken, mostly unperturbed chain of such; a single game of Anakiri.
#+end_quote

But you have imperfect knowledge of your own history. And in a world of superimposed quantum states (which you reportedly /know/ that you inhabit), countless different histories would independently produce the mind-moment that posted that comment. Which one are you referring to? If you find out that you've misremembered something, will you reserve the first person for the version of you that you'd previously remembered?

#+begin_quote
  Keeping humans alive, healthy, and happy is hard to do. It's so hard that humans themselves, despite being specialized for that exact purpose, regularly fail at it. Your afterlife machine is going to need to have a long list of things it needs to provide: air, comfortable temperatures, exactly 3 macroscopic spatial dimensions, a strong nuclear force, the possibility of interaction of logical components... And, yes, within the space of all possible entities, there will be infinitely many that get all of that exactly right. And for each one of them, there will be another one that has a NOT on line 73, and you die. And another that has a missing zero on line 121, and you die. And another that has a different sign on line 8, and you die. Obviously if you're just counting them, they're both countable infinities, but the ways to do things wrong take up a much greater fraction of possibility-space.
#+end_quote

And how about probability-space? Surely the more an intelligence has proved itself capable of (e.g. successfully implementing you as you are), the less likely it is that it'll suddenly start making basic mistakes like structuring the implementing software such that a single flipped bit makes it erase the subject and all backups?

I am me regardless of any specific details of the physical structures implementing me.

#+begin_quote
  If rationality "requires" you to be overconfident, then I don't care much for "rationality". Of course your own confidence in your argument should weigh against the conclusions of the argument.

  If you know of an argument that concludes with 100% certainty that you are immortal, but you are only 80% confident that the argument actually applies to reality, then you ought to be only 80% sure that you are immortal. Similarly, the lowest probability that you ever assign to anything should be about the same as the chance that you have missed something important.
#+end_quote

I feel unfairly singled out here. I don't see anyone else getting their plain-language statements --- especially ones trying to /describe/, without endorsing, a chain of reasoning --- read as absolute, 100% certainty with no possibility of update.

Also, strictly speaking, an argument can be wrong and its conclusion still true.

#+begin_quote
  After all, we are squishy, imperfect, internally incoherent algorithms that are not capable of computing non-computable functions like Kolmogorov complexity.
#+end_quote

But we can't exist without forming beliefs and making decisions. In the absence of a better alternative, we can still have reasonable confidence in heuristics like "hypotheses involving previously undetected entities taking highly specific actions with no clear purpose are more complex than their alternatives".