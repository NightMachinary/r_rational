:PROPERTIES:
:Author: kcu51
:Score: 1
:DateUnix: 1565562018.0
:DateShort: 2019-Aug-12
:END:

#+begin_quote
  Your argument hinges on an AI simulating us, and extracting us into another simulation where we can continue living.
#+end_quote

A "simulation" imitates a thing while falling short of actually being that thing. We are ourselves in all Turing machines/directed acyclic graphs/whatever that contain/implement us, wherever they're computed/instantiated/implemented.

#+begin_quote
  If 99 copies of you are going to be extracted in 1 minutes time, shouldn't you expect a 99% chance of being extracted?
#+end_quote

"Number of copies" is a [[https://lesswrong.com/lw/ws/for_the_people_who_are_still_alive/][meaningless measurement]]. What matters is relative measure of different anticipations/experiences. Hypotheses with no practical implications (e.g. you have no idea what the copies will experience and no control over what will be done with them) can also be safely discarded.

If you're being redundantly computed in 100 locations, and 99 of them are going to be shut down in 1 minutes' time, do you expect a 99% chance of experiencing nonexistence?