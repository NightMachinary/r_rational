:PROPERTIES:
:Author: derefr
:Score: 2
:DateUnix: 1519988897.0
:DateShort: 2018-Mar-02
:END:

#+begin_quote
  When you phrase it like that, it looks like one of those super obvious "which one doesn't belong?" multiple choice questions.
#+end_quote

Eh, maybe in that specific phrasing. I prefer Euclid's thought process that, basically, God is a Friendly AI, but specifically, God is the /Friendliest AI/---the /best possible/ world-optimizer from a human perspective.

So, to start with, definitionally, God is omnibenevolent---at least in the weak way the philosophers who first conceptualized that term defined it. Today we'd more say the Abrahamic God is taught to be globally optimizing for [something something] /of humanity specifically/, while not really caring so much what happens to other species. Homobenevolent. Anthropobenevolent?

But, then, given that, of course God is also omniscient and omnipotent---taking control of the universe was an obvious instrumental sub-goal under the goal of becoming the Friendliest AI.

And of course God exists rather than doesn't, because making Roko's Basilisk-like bargains from outside of time is /also/ an instrumental subgoal of becoming the Friendliest AI.