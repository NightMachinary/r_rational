:PROPERTIES:
:Author: PlaneOfInfiniteCats
:Score: 1
:DateUnix: 1444515571.0
:DateShort: 2015-Oct-11
:END:

#+begin_quote
  People as a general matter set moral barriers because of predictable experience that while it's easy to rationalize doing something doing it actually commonly leads to negative results. Avoiding mass murder is not a comparable example to refusing blood transfusions or banning stem cells, as causing massive harm is against most moralities.
#+end_quote

This is a very romanticised view of morality. The actual process that shapes morals is [[http://www.paulgraham.com/say.html][more akin to emergence of fashion]] than to organized effort to set up reasonable rules that you describe. Morality, therefore, can and does contain arbitrary bits and inconsistencies.

Also, some Jehovah's witnesses do in fact think that refusing blood transfusions is more important than avoiding lots of deaths. I think these example are comparable. And, most morality systems endorse harm, provided i's done to outsiders. Slavery, wars, conquests and genocides were all performed by people whose morals allowed, endorsed or even demanded all that.

That's why I think morality shouldn't be blindly trusted. Instead it should be examined and maybe corrected, if flaws are found.

Also, I think people would be much better off if they learned to, as [[/u/EliezerYudkowsky]] once put it, [[http://wiki.lesswrong.com/wiki/Shut_up_and_multiply][shut up and multiply]], i.e. apply their morals consistently.

#+begin_quote
  They can try to solve it without mass murder.
#+end_quote

Mass murder is a bad thing and carries large utility penalty. However, if after cost-benefit calculation the option involving mass murder seems the best one, this option should be implemented, even though mass murder is bad. [[http://lesswrong.com/lw/n3/circular_altruism/][A little article on the topic]]

If you feel you are about to take an action that " commonly leads to negative results", you can just quantify your uncertainty and include it in your cost-benefit calculation.

#+begin_quote
  You're assuming, with no evidence, that the primordial kills everyone?
#+end_quote

I wouldn't call it "no evidence". There is plenty of evidence regarding existence of primordials. Dungeon, monsters that get stronger with depth, creation myth heard from real, existing gods that used to communicate with their followers, etc.

Sure, primordial could be harmless or benevolent, but considering historical records it doesn't seem likely. You could probably make a case that all this evidence is not solid enough to justify the extreme plans I mentioned. But claiming there is /no/ evidence is flat out wrong.

#+begin_quote
  It doesn't sound like you're using your algorithm in any rigorous manner. You're making an assumption to justify your desired outcome without considering obvious other possibilities, and aren't greatly saddened by the mass deaths of everyone.
#+end_quote

In this discussion I propose a patch to decision-making algorithm, because I consider current algorithm, with its ethical injunctions, suboptimal and inconsistent. To show the difference between proposed algorithm and current one I provide remarkable edge cases where behaviour of algorithms differs. Of course "it doesn't sound like I'm using my algorithm in any rigorous manner". I don't use algorithm to generate examples, I just provide illustrative examples for edge cases.

Once more: mass murder is not the desired outcome. The desired outcome is the world that fits my values more. If the way to reach this world is mass murder, then this is the path that should be taken. If there is way to this world not involving mass murder, this path should be taken instead.

Minimizing harm is part of the goal. It's just that, for example, eradicating plague by in-loop experimenting is likely to cause much less harm than prevent. If we are in loop: Killing million people temporary (in loop) is preferable to letting million or more die permanently. If there is dimension-hopping going on: Killing million in one dimension is better than letting million or more die from plague later in *every* dimension.

#+begin_quote
  Infecting everyone with a disease obviously increases the chance you get infected.
#+end_quote

Yes, but I wasn't talking about infecting everyone. Global pandemic is detrimental to search for cure. Scenario I meant was "Searching for plague cure, even if there will be 10 containment breaches that cause global pandemics and humanity extinction in the loop, may still be worth it, because number of lives saved by the cure is very large ". Sorry if it wasn't clear from my post.

And, there is no evidence of existence of soul-afflicting plague. Now you are venturing into "no evidence" realm.

I agree with other points you made. Thanks for the reminder about anti-fever potion, I completely forgot.