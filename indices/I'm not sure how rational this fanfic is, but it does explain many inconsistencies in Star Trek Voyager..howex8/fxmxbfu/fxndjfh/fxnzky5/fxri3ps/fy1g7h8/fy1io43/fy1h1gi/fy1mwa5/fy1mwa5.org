:PROPERTIES:
:Author: derefr
:Score: 3
:DateUnix: 1594740910.0
:DateShort: 2020-Jul-14
:END:

#+begin_quote
  the point is that AI was so good it could happen without even trying... but the population as a whole was blithely unaware of it
#+end_quote

I mean, my point was that the population /couldn't/ have known, since these things are only happening on these ridiculously over-engineered military ships. It's not like these things were happening /all the time/. I think we saw, in the show, exactly the /only/ times this ever happened.

#+begin_quote
  By the time of Voyager they had hand-sized devices capable of running a human-equivalent AI and using handwave force field technology to generate a virtual projected force field body.
#+end_quote

I would note that a trained GPT-3 model isn't very large, and can run on a commodity computer. It's the training---the learning-to-be-what-it-is---of such a model that requires a vast expansive computer. The Doctor could /continue to run/ on a little comm-badge-looking device; but he could likely only have /learned to become self-aware in the first place/ by spending his 'childhood' living in the bio-neural circuitry of Voyager's ridiculous computer system, where he could sprawl out to fill petabytes of RAM and take over thousands (millions?) of cores with his learning process.

Note how this never happened in the lab of Dr. Zimmerman, the guy who created the EMH hologram. Not only because he never had a computer on the scale of Voyager to deploy an EMH onto, but also because he wouldn't have thought deploying /an EMH program/ onto such a substrate was a sensible idea.

As Zimmerman said in the episode where the Doctor was sent to him for fixing, the EMH program was trained on a limited set of routines. Essentially, the EMH was created as "embedded software" (like the OS on a watch)---intentionally small and limited compared to other programs, designed for a single purpose. It /could/ learn more while active, like any hologram; but given the constraints it would usually be run under, it never /would/ learn anything.

But the Doctor /did/ learn; and the /way/ he had learned everything else, all through active experiences like a human, meant that his program was /bloated/. I get the sense that the holographic architecture wasn't designed for online skill acquisition. It was designed to learn facts, create memories, etc.; but skills were something that was especially easy to train /offline/, and then to /optimize down/ into a small model that can be included in the hologram. Whereas the online learning process for skills---linking the skill to memories, facts, beliefs, etc---produces a far more inefficiently-organized model than the offline learning process.

Probably, Zimmerman was offended by the "bloat" of the Doctor's model, and saw it all as ridiculous and useless, /not/ because he didn't think the Doctor was a person that deserved to have hobbies, but rather because he knew that the Doctor had done everything "the round-about way" by building up these routines through online learning; whereas a hologram that had been /built/ with e.g. social/emotional skills, could have held them in a much more efficient representation that wouldn't tax its computational substrate at all.

In other words, Zimmerman was thinking, internally, "if the Federation had told me they wanted a thinking, learning, feeling, 'person-like' AI, I could have built them one that was /optimized/ for that! This one is optimized for /the opposite/ of that!"

Presumably, even though the Doctor did get to live out /his own/ life without any major changes to his architecture, the Federation (Zimmerman et al) learned from his example and /did/ then go on to design an AI architecture that was 1. purpose-built for online skill acquisition (probably using something like the human brain's continuous memory reconsolidation) and 2. came with a vast library of modular pre-trained skill components, all optimized to remove the "bloat" of online learning; where 3. either 1 or 2 could be used for any given skill as the holographic person saw fit, perhaps even with the online learning modularized to allow the hologram to sometimes "archive" a large skill and just take around the embedded version, when it wants to learn other large skills in its place. And then AIs /like/ the Doctor (there were probably a few) that wanted to "have children", would have been given /that/ AI program to base them off of, rather than (to Zimmerman et al's horror) basing them on their own templates.

tl;dr: the Doctor's online persisted meta-learning means that he's 1% program, and 99% data in a ridiculous Business Rules Engine simulating a Prolog interpreter simulating Q learning simulating a fuzzy expert system. Nothing could have allowed that to work, /except/ a computer on the scale of Voyager's.