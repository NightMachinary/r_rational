:PROPERTIES:
:Author: vakusdrake
:Score: 1
:DateUnix: 1491252213.0
:DateShort: 2017-Apr-04
:END:

Yeah if you haven't already I definitely suggest that you read Bostrom's superintelligence, because otherwise discussions with a lot of the people on this subreddit will involve a lot of just reiterating what is for them common GAI knowledge.

See while some people try to say it would take a substantial amount of time for an AI to improve itself (though if it is run at substantial speed then a substantial time for it may not be very long at all), the position that self improvement /wouldn't/ entail corresponding intelligence isn't one that I've ever heard even mentioned, because intelligence is the obvious thing you'd be improving and that improvement would then make you immediately better at finding new more clever ways to improve yourself.\\
Just a look at humans should start to make it obvious how massive a slight improvement to intelligence can be, as is often said the hardware and software differences among humans is really pretty small (people can't even hack their brains to be very good at things the simplest computer can do with ease!).

Here's a alternate thought experiment: Some world class genius scientists come up with a intelligence boosting drug that fundamentally changes one's neurology so there are clearly ways to make better versions of the drug. As soon as the drug's available it's going to be used by the scientists working on making its next iteration. Except this time the scientists ability to make breakthroughs is as far above what is was before, as their original ability was over average researchers. This time despite the next iteration being more difficult it comes much faster since they are both building on previous research and are step above einstein level.\\
Of course there's no reason to think there's something special about the human intelligence level specifically, so the next few iterations shouldn't be insurmountable compared to the previous one's (at least to the boosted intelligence of the researchers) except now the scientists are no longer just "smart" they're fundamentally on a different level than human like we are on a different level from chimps, despite the hardware differences not being really that massive.\\
Of course with the AI scenario things are much quicker because of how much faster silicon is, it's ability to spend literally all it's time at top performance working on self improvement, and other such benefits.

This really short article likely makes these points better: [[http://yudkowsky.net/singularity/intro/]]