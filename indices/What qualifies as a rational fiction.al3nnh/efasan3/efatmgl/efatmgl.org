:PROPERTIES:
:Author: quark_epoch
:Score: 2
:DateUnix: 1548798913.0
:DateShort: 2019-Jan-30
:END:

"Okay this is entirely outside my wheelhouse- you want some kind of machine-learning implementable definition of rational fiction?"

Yeah. I was trying to rethink everything I've read in HpMor and all of the others as being -rightly captured- some kind of machine learning process.

I'm trying to model the feasibility/practicality of Hierarchical Temporal Memories and this seemed like a fair thought experiment.

What you're suggesting in terms of "cross-referencing" and "thoughtful" and "informed" is really what's bothering me. They almost feel like the *Words of False Comprehension*. I mean I get the idea. But when I'm thinking in terms of agent behavior, I can't quite mark a tipping point apart from this that some models are simply more accurate in such portrayals than others. Which I presume you've defined with the "Thoughtfulness" score.