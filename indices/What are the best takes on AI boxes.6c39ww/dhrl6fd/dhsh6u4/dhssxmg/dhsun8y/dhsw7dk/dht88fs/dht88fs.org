:PROPERTIES:
:Author: crivtox
:Score: 4
:DateUnix: 1495293794.0
:DateShort: 2017-May-20
:END:

The ai box experiment doesn't presuppose the person being able to swayed by rational argument , an AI doen't have any reason to only use a certain group of tactics labelled "rational arguments " to win , in fact in the roleplay the people who(presumably) lost had a economic incentive to just ignore everything the other person said, we don't have many logs of people who won but generally(based of their latter comments about it) they seem to have recurred to personal and seriously dark arts things to win .The idea that the AI box is that the AI would be able to be able to convince most if not all people to get it out of the box , if a person cant be convinced by "rational argument " well then the ai will say whatever will cause that particular person to get it out of the box , its not like narcissistic sociopaths are impossible to convince to do things or that what other people say doesn't affect them at all , humans are far from perfect reasoners and we are optimised for surviving in communities with other humans in ways that are really exploitable for an AI in this scenario.