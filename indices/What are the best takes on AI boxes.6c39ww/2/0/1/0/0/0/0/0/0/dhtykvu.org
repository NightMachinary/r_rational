:PROPERTIES:
:Author: GaBeRockKing
:Score: 1
:DateUnix: 1495332947.0
:DateShort: 2017-May-21
:END:

#+begin_quote
  it can manipulate the emotions of the gatekeper so he wants to open the box and or subjecting him to enough psychological torture that he ends up giving up
#+end_quote

I don't think that's necessarily true. Unless the AI can simulate the person effectively enough to perfectly understand them (which I think would more or less count as them being "outside the box" regardless) then there's always the chance that the jailer diverges enough from the normal human mindstate to be effectively opaque to the AI.