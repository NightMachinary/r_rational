:PROPERTIES:
:Author: himself_v
:Score: 2
:DateUnix: 1575294792.0
:DateShort: 2019-Dec-02
:END:

#+begin_quote
  But you'd be right that precommitting_2 (edit: in a reliable, 100% certain way) might be impossible for humans.
#+end_quote

You mean precommiting_1?

#+begin_quote
  Why?
#+end_quote

Because at the moment when you're deciding on precommiting_1 you're only driven by your existing goals. You won't wish to put anything that threatens your existing goals above those goals.

And no matter how well you think your new commitment through, you're setting yourself up for the genie&wish problem. You think you're commiting_1 to something that only helps you win this Newcomb's gamble, next moment you're [[https://www.lesswrong.com/posts/4ARaTpNX62uaL86j6/the-hidden-complexity-of-wishes][betraying your old goals]] in unexpected ways.

So putting anything above your present core goals is very risky (in your present core goals) and it's unclear if there could be a degree of wisdom and a margin of profit enough for a rational agent to take this risk. (But maybe there could be? I don't know. Like if you're going to die without this, maybe it's reasonable to agree)