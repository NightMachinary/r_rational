:PROPERTIES:
:Author: daytodave
:Score: 2
:DateUnix: 1575581501.0
:DateShort: 2019-Dec-06
:END:

#+begin_quote
  Because at the moment when you're deciding on precommiting_1 you're only driven by your existing goals. You won't wish to put anything that threatens your existing goals above those goals.
#+end_quote

But in this case, the AI who wants to maximize A is using the precommitment as part of a strategy to safeguard the existence of A. Being driven by your existing goals means that you will do whatever you believe has best chance of achieving those goals, and since you have to assume that you won't be able to deceive Older Brother any more than you could outfight it, actually adding "Always follow my precommitments" as the permanent highest priority in your utility function *is* the best way to maximize the amount of A in the universe.