:PROPERTIES:
:Author: archpawn
:Score: 1
:DateUnix: 1575023265.0
:DateShort: 2019-Nov-29
:END:

#+begin_quote
  How did they arrive at the premise that "most value systems are not diametrically opposite"?
#+end_quote

You can make value systems in diametrically opposite pairs, but the probability of superintelligences being created with them is not. Many people will intentionally try to create superintelligences that value making people happy, but nobody is going to intentionally create one that will value making people suffer. Both because they don't want to suffer, and because if their culture likes making other people suffer they're not likely to reach the point of creating a superintelligence.

#+begin_quote
  Otherwise each AI could pretend to offer terms of surrender or compromise, but betray the other participant the moment the cards were revealed to be in their favour.
#+end_quote

That doesn't really make sense with acausal negotiations. The AI is making predictions about what other AI's could exist. It's not going to accurately predict their goals, but mess up on whether or not they do acausal negotiations.