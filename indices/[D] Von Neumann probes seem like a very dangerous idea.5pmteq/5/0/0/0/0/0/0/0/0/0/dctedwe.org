:PROPERTIES:
:Author: cjet79
:Score: 1
:DateUnix: 1485211401.0
:DateShort: 2017-Jan-24
:END:

Or it flips just one bit. That one bit is the bit in charge of doing the comparison between the different blueprints. Now its always true.

Or the antennae is taken out so now it doesn't stop other probes from landing on that planet.

Or a micrometeorite pierces the internal machinery and the signal from the "don't produce more probes" section is cut off.

Or you have a flood of radiation in space from a cosmic event that hits all of the data storage devices at the same time. They all have 25% of their data corrupted but not the same 25%. How much do you trust the integrity of its safety mechanisms now?

Or you have a noisy area of space that overpowers whatever signalling device your probes are using so they keep thinking a solar system is empty when instead its already will with a bunch of other probes.

#+begin_quote
  A trillion is a astonishingly small number in this context. Four seperate memories checking each other means that a bit has to be flipped in all of them at the same time.
#+end_quote

Its not just a trillion. Its a trillion probes, each with a ~2500 year lifespan flying through space dust, radiation bursts, and magnetic fields. Data integrity is only ONE of your concerns. You also need to make sure its ability to produce new probes isn't compromised, its communication isn't compromised, its processing of communication isn't compromised, etc. Oh and this all pretends as if you were able to perfectly code this probe when you sent it out. If you perfectly preserve code that has a deadly error in it then we are equally as screwed as if the code had been perfectly modified to contain this deadly error.