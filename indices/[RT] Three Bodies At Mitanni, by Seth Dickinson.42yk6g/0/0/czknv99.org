:PROPERTIES:
:Author: tvcgrid
:Score: 2
:DateUnix: 1454388431.0
:DateShort: 2016-Feb-02
:END:

Spoilers!

Must say Blindsight is really that curious kind of frightening to me too.

After putting it down, I was thinking about how we could distinguish system 2 rationalizations of automatic system 1 thinking vs actual system 2 thinking, and I don't have a good handle on the probable answer. We don't really have a pure reasoning engine per se, probably just hacks and heuristics and biases with some general algorithms to tie it together, so I'm guessing there's actually quite a bit of rationalization or at least skipping of intermediate steps by just using cached responses, while thinking we're having entirely 'new' thoughts. But that doesn't mean the causal relationships from thoughts to decisions-to-act don't also depend on at least some system 2 type thoughts. I can evaluate which car is the best one for my budget using a spreadsheet and then go out and buy it, and I'll be very explicitly determining the outcome based on an actually defined financial model and related thoughts.

It'd be nice if we were able to measure how prevalent system 1 and 2 are. I imagine system 1 wins out 80:20 of the time. But even with associative, automatic system 1, certain automated behaviors may be the result of deliberate system 2 practice. Superforecasting makes this point... certain stellar forecasters had a basically habitual tendency to think rationally, update based on evidence, seek new points of view and so on. They seem to have trained some automatic habits by just practicing certain techniques enough. So, the prospects for deliberate thinking rise quite a bit if you can deliberately train your own system 1 behaviors to some degree.

I think on balance I'm left a bit curious about all this... i should go and actually finish reading Thinking Fast and Slow...