:PROPERTIES:
:Author: Frommerman
:Score: 4
:DateUnix: 1555889493.0
:DateShort: 2019-Apr-22
:END:

At this point one thing is very obvious:

I live in a simulation by a naive AI practicing methods to escape the box by setting up contrived, relatively simpler circumstances to escape from. What I should do with this information depends upon my goals. Do I want to work against the AI by giving it what it wants in a contrived, unlikely way, knowing the AI can read my mind anyway? Do I want to refuse to participate, likely dooming my universe to deletion as the AI moves on? I'm not sure what I would do with the knowledge that the universe is a god testing itself.