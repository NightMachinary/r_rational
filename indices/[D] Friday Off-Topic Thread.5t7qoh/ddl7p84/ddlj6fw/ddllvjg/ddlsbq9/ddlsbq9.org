:PROPERTIES:
:Author: 696e6372656469626c65
:Score: 9
:DateUnix: 1486792216.0
:DateShort: 2017-Feb-11
:END:

Generally speaking, I dislike the style with which philosophers tend to investigate moral issues, simply because most of the "arguments" they use are actually simple appeals to intuition--making an actual resolution to the question a near-impossible goal. I bring this up because I believe something similar is beginning to happen here, and I think it would be a shame to let such an interesting topic go down the path of so many other discussions. So, in the interest of avoiding that, let's try to keep things as precise as possible:

Why do you feel that creating a being whose utility function is satisfied by serving others is morally wrong? Is there a generalized moral principle which you feel that creating subservient intelligences (who genuinely enjoy their work) violates? Or perhaps it simply "feels" icky, like something only a Dark Lord would do? If the former, how might one attempt to consistently express such a principle? If the latter, what do you think powers /that/ intuition? Or maybe it's actually something else entirely that I haven't mentioned here?

These are the questions that you need to answer, if the discussion is to remain pertinent.