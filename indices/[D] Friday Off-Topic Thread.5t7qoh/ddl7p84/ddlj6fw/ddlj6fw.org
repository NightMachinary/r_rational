:PROPERTIES:
:Author: Anderkent
:Score: 8
:DateUnix: 1486776134.0
:DateShort: 2017-Feb-11
:END:

#+begin_quote
  So while its obviously unethical to create a human-level intelligence to pass you butter or some other menial job, some boring things need to be done, it's unavoidable, and sometimes those will need some adaptability. So if you're going to make an AI for those tasks, why not design it to relish its intended role? And if you can make an AI that loves whatever its made to do, then where is the ethical line drawn if no one is suffering? At what point does it become unethical to create a society of adoring slaves, with you as the slavemaster?
#+end_quote

I don't think that's the unethical part, at least in the context of the book. The unethical part was that the created conscious minds might not be capable of deciding they want to leave (a hard thought blocker, rather than incentive/desire design), and whenever the created androids did want to leave they weren't allowed to and had to build a resistance movement.

Simply engineering minds that enjoy doing what you want them to do does not seem unethical to me, as long as whenever the situation changes and they stop enjoying it they are free to live. (And probably with additional requirement of fair compensation, so that if they do decide to leave at some point they have some capital earned with their service) .

With your example - creating a society of adoring /citizens/ doesn't seem unethical. Enslaving them does. A mind that doesn't actually enjoy what it's doing, but is somehow artificially prohibited from thinking of leaving or executing such plan is a slave.