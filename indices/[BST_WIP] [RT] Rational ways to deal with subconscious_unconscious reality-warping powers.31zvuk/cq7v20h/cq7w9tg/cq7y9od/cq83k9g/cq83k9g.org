:PROPERTIES:
:Author: CauldronCape
:Score: 1
:DateUnix: 1428695895.0
:DateShort: 2015-Apr-11
:END:

#+begin_quote
  LÃ¶b's theorem is not hard enough to grok to require "super-intuitive understanding of mathematics". People claim to have used it for comparable purposes.
#+end_quote

It's hard enough to grok that not everyone can use it for comparable purposes, or else you'd never see someone with knowledge of Lob's theorem who has social anxiety.

#+begin_quote
  I subconsciously expect(ed) the universe to be able to derive my CEV from my brain automatically, and for it to go all right.
#+end_quote

Yes, and it would go alright from your perspective, I suppose, but not necessarily from everyone elses', and you wouldn't be able to perceive any difference in how happy they were because you can't have knowledge of previous states of things you've changed.

#+begin_quote
  My body and mind would therefore also automatically be CEV-optimised, which means it cleverly avoids traps like "not being able to learn anything" by expecting to receive truly accurate information, and storing it in a brain lobe believed to be unalterable, which doesn't automatically alter the world, either by being conscious, by expecting it not to alter the world, or by not putting it through the mental method required to turn thought into fact. Similarly, through transhumanism, I would expect my mind to expand to the point of being able to comprehend reality well enough to verify that CEV is truly being applied smoothly.
#+end_quote

How can you acquire information that surprises you -- that you don't expect -- if the world that you perceive changes specifically to fulfill your expectations? Any information you acquire would be altered to not surprise you, and the very act of looking for more information would change more things.

Not to mention that altering your brain with that level of precision isn't possible if you're only able to affect reality subconsciously. If any radical changes happened, chances favor optimization in the direction of a flawed CEV, not a perfect one. Hence, UFAI.

Also, thanks for the tip on relativity! If I now make the authorial decision that the magic is /not/ coded in at a higher level than relativity, what are the implications, in your opinion?