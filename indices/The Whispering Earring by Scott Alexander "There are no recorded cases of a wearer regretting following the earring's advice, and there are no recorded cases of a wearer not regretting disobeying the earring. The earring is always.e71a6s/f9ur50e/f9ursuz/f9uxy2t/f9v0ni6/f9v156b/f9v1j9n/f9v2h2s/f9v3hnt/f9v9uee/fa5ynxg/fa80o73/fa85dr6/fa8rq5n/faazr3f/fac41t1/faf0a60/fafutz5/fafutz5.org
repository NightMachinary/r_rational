:PROPERTIES:
:Author: ElizabethRobinThales
:Score: 1
:DateUnix: 1576032435.0
:DateShort: 2019-Dec-11
:END:

#+begin_quote
  Glial cells exist.
#+end_quote

That they do. I got a bit carried away.

#+begin_quote
  And those neurons are composed of chemical compounds (and some unbound elements). Chemical compounds and elements are composed of atoms. Atoms are composed of fields and subatomic particles and other things. Fields and subatomic particles can, so far as we've discovered, be completely and entirely described by math. Which can be computed.

  If I can simulate particles and fields, I can simulate the atoms which make up the compounds which make up the neurons which make up the networks which make up a brain. Actually doing so is just a matter of scope.
#+end_quote

You're spittin' straight facts. It should definitely be possible to simulate a brain.

#+begin_quote
  There are details which complicate things a little, sure, but in all /brains run on physics/, and saying that brains can't be computed is equivalent to saying that physics cannot be computed.
#+end_quote

Where, /exactly/, do you believe that you saw me claim that brains can't be computed? Do you know what the computational theory of mind is?

#+begin_quote
  [[https://en.wikipedia.org/wiki/Computational_theory_of_mind]['Computational system' is not meant to mean a modern-day electronic computer. Rather, a computational system is a symbol manipulator that follows step by step functions to compute input and form output.]]
#+end_quote

It's a philosophical metaphor.

An excerpt from [[https://aeon.co/essays/your-brain-does-not-process-information-and-it-is-not-a-computer][an article]]:

#+begin_quote
  In his book In Our Own Image (2015), the artificial intelligence expert George Zarkadakis describes six different metaphors people have employed over the past 2,000 years to try to explain human intelligence.

  In the earliest one, eventually preserved in the Bible, humans were formed from clay or dirt, which an intelligent god then infused with its spirit. That spirit ‘explained' our intelligence -- grammatically, at least.

  The invention of hydraulic engineering in the 3rd century BCE led to the popularity of a hydraulic model of human intelligence, the idea that the flow of different fluids in the body -- the ‘humours' -- accounted for both our physical and mental functioning. The hydraulic metaphor persisted for more than 1,600 years, handicapping medical practice all the while.

  By the 1500s, automata powered by springs and gears had been devised, eventually inspiring leading thinkers such as René Descartes to assert that humans are complex machines. In the 1600s, the British philosopher Thomas Hobbes suggested that thinking arose from small mechanical motions in the brain. By the 1700s, discoveries about electricity and chemistry led to new theories of human intelligence -- again, largely metaphorical in nature. In the mid-1800s, inspired by recent advances in communications, the German physicist Hermann von Helmholtz compared the brain to a telegraph.

  Each metaphor reflected the most advanced thinking of the era that spawned it. Predictably, just a few years after the dawn of computer technology in the 1940s, the brain was said to operate like a computer, with the role of physical hardware played by the brain itself and our thoughts serving as software. The landmark event that launched what is now broadly called ‘cognitive science' was the publication of Language and Communication (1951) by the psychologist George Miller. Miller proposed that the mental world could be studied rigorously using concepts from information theory, computation and linguistics.

  This kind of thinking was taken to its ultimate expression in the short book The Computer and the Brain (1958), in which the mathematician John von Neumann stated flatly that the function of the human nervous system is ‘prima facie digital'. Although he acknowledged that little was actually known about the role the brain played in human reasoning and memory, he drew parallel after parallel between the components of the computing machines of the day and the components of the human brain.

  Propelled by subsequent advances in both computer technology and brain research, an ambitious multidisciplinary effort to understand human intelligence gradually developed, firmly rooted in the idea that humans are, like computers, information processors. This effort now involves thousands of researchers, consumes billions of dollars in funding, and has generated a vast literature consisting of both technical and mainstream articles and books. Ray Kurzweil's book How to Create a Mind: The Secret of Human Thought Revealed (2013), exemplifies this perspective, speculating about the ‘algorithms' of the brain, how the brain ‘processes data', and even how it superficially resembles integrated circuits in its structure.

  The information processing (IP) metaphor of human intelligence now dominates human thinking, both on the street and in the sciences. There is virtually no form of discourse about intelligent human behaviour that proceeds without employing this metaphor, just as no form of discourse about intelligent human behaviour could proceed in certain eras and cultures without reference to a spirit or deity. The validity of the IP metaphor in today's world is generally assumed without question.

  But the IP metaphor is, after all, just another metaphor -- a story we tell to make sense of something we don't actually understand. And like all the metaphors that preceded it, it will certainly be cast aside at some point -- either replaced by another metaphor or, in the end, replaced by actual knowledge.
#+end_quote

/Where are the hydraulic valves?/

/Where are the little gears?/

/Where are the algorithms?/

Cc [[/u/DuskyDay][u/DuskyDay]]