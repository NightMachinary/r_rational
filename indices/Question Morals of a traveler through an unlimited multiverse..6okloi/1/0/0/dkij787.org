:PROPERTIES:
:Author: MrCogmor
:Score: 2
:DateUnix: 1500627929.0
:DateShort: 2017-Jul-21
:END:

I already answered that in my previous post. If you assume that the myriad worlds exist already (and there aren't infinite worlds for every possible intervention) then both the Golden Rule and plain Utilitarianism would dictate you maximise positive intervention.

(Possible counter: You may not be required to save people from death who have a living identical replica depending on how closely they diverge. You would still be morally obligated to prevent suffering however)

Most hardcore utilitarian approach would be to get 'identity optimal' universes filled with computation running simulations of all possible Boltzmann brains with non-negative mental states and destroy all non-optimal universes.

Enlightened Self-Interest wouldn't really obligate you to anything since you would be basically untouchable.

Basic human psychology wouldn't really obligate you to anything because of the scope insensitivity bias.