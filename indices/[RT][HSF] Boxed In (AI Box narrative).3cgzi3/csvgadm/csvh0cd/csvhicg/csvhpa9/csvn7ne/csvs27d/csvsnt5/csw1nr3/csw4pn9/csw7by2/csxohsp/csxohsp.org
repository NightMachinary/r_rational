:PROPERTIES:
:Author: eaglejarl
:Score: 3
:DateUnix: 1436466205.0
:DateShort: 2015-Jul-09
:END:

My expectation has always been that Eliezer relied on the meta argument -- "I'm a very well respected member of the rationalist community with impeccable reputation and much of what you know about rationality probably came directly or indirectly from me. I'm also an AI expert. I think UFAI is the biggest threat facing us; if I'm wrong, then the outcome of this experiment doesn't matter. If I'm right, then knowing that the AI can win will make people take the question seriously and could literally save the human race. Now, will you open the box, please?"

That only works for him though; I have no explanation that I find believable for how other people have won.