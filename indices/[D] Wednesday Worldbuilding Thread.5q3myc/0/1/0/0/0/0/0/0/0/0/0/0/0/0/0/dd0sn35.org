:PROPERTIES:
:Author: Krashnachen
:Score: 1
:DateUnix: 1485621682.0
:DateShort: 2017-Jan-28
:END:

#+begin_quote
  I was saying that getting people to create an AI that they know will wipe out humanity would require you get them to buy into some insane ideas, because it's literally suicidal. Remember it's not actually granting them happiness because it's much more efficient to just do it for itself. See it's not even a matter of wireheading because there's no question that they aren't the one's actually getting the benefit here.
#+end_quote

I just said that no human would die, they just would reproduce (physically) anymore. I don't see what's monstrous about that. Besides, one could argue that keeping human race alive at all cost is irrational. If we could have greater happiness by not keeping it alive, it would be immoral to do so. You force people who are suffering from depression everyday and children that are dying to some disease to continue living a shit life because you believe we have some god-given task to reproduce ourselves at all costs.

#+begin_quote
  Remember my original point was that the goal of maximizing happiness would not lead to wireheading humans, because it's much more effective to kill all humans and just maximize your own happiness which saves resources you would have to waste uploading (albeit crudely) humans.
#+end_quote

A normal utilitarian would be more extreme than me in that regard. He would argue that if all humans have to die for the greater good of the galactic community, then we have to sacrifice ourselves. I am more an ego√Østical kind of utilitarian and the scientists creating the robots would have at least their own interests and probably the interests of the whole human race in mind. Since the humans (or another sentient species) are require to start the project, there is no way around it. Also, just implement a certain line of code, interdicting the robots of closing the servers of the first humans.

#+begin_quote
  Though I got sidetracked on how extremely uncommon and terrifying to most people your non-problem with wireheading is.
#+end_quote

If you observe it with a cool head, I don't think the prospect of endless continuous orgasm is really terrifying.

May I also ask you want kind of school of thought you are 'following'?