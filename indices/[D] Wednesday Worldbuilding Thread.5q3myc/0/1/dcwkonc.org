:PROPERTIES:
:Author: vakusdrake
:Score: 2
:DateUnix: 1485379517.0
:DateShort: 2017-Jan-26
:END:

I think if you gave such an obviously flawed goal to strong AI things would go south a bit faster than you portray.\\
I suspect as soon as they manage to make the first strong AI with the horrifyingly naive goal of maximizing happiness, you get an intelligence explosion where everything available is deconstructed to simulate as much happiness for the AI as possible as it expands outwards as quickly as possible..