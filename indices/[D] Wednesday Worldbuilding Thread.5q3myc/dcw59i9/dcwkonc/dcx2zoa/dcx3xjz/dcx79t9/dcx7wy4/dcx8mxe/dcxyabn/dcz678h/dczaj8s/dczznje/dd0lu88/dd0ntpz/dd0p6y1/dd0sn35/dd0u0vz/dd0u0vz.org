:PROPERTIES:
:Author: vakusdrake
:Score: 1
:DateUnix: 1485623646.0
:DateShort: 2017-Jan-28
:END:

#+begin_quote
  I just said that no human would die, they just would reproduce (physically) anymore. I don't see what's monstrous about that. Besides, one could argue that keeping human race alive at all cost is irrational. If we could have greater happiness by not keeping it alive, it would be immoral to do so. You force people who are suffering from depression everyday and children that are dying to some disease to continue living a shit life because you believe we have some god-given task to reproduce ourselves at all costs.
#+end_quote

Given my point that everybody would be killed by a happiness maximizing AI, I don't mean that humanity would die out in some non-standard definition. I mean you would be creating a AI that /immediately/ wipes everybody out once it gets nanotech.

#+begin_quote
  Also, just implement a certain line of code, interdicting the robots of closing the servers of the first humans.
#+end_quote

It's not really that simple since you have to encode really complex goals in order to prevent it just circumventing any restrictions. I mean you could do that, but you kind of seem to be underscoring how hard it is to get an AI to do anything except expand uncontrollably.

#+begin_quote
  If you observe it with a cool head, I don't think the prospect of endless continuous orgasm is really terrifying. May I also ask you want kind of school of thought you are 'following'?
#+end_quote

/Except I do find it horrifying and so do the vast majority of people/. In surveys most people wouldn't even plug into /experience machines/ and that's not even full blown wireheading. So not only do people want a great deal of things from their mental states other than happiness, but they also care whether the source of that happiness corresponds to the state of reality they desire.