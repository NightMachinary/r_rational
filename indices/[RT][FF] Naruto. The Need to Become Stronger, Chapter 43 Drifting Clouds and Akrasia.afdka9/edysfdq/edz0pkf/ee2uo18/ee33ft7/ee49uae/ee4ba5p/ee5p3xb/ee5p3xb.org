:PROPERTIES:
:Author: EthanCC
:Score: 2
:DateUnix: 1547595956.0
:DateShort: 2019-Jan-16
:END:

The real reason you care about your friends and family probably isn't their qualities, in the sense that you logically should then care equally about anyone else with those qualities, because we, empirically, /don't/ equally care about strangers that are similar to our friends and said friends. If their qualities were the only reason we care about them, we would already care about strangers that much. Unless you mean "qualities" in such a broad sense it includes identity, in which case you're just saying "you should care about them because you already care about them", which is kind of pointless. Emotion-driven goals have too much context about them to apply that sort of logic and still be correct about what the reality is. I don't think that's a leap you can/should make.

And anyway, this is a tangent. We've gone from discussing the definition of "rational", which doesn't say anything about what your goals are/should be (just how to go about them), to the expected qualities of a normal rational human being from our culture. I take exception to the idea that every rational person will inevitably come around to some given goal. For one thing, self-aware AI count as people (according to most people on here, I'd think) and you could have a hypothetical AI with /any/ goal, or lack thereof, while still being rational in how they go about their goals.