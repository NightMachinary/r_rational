:PROPERTIES:
:Score: 3
:DateUnix: 1409919421.0
:DateShort: 2014-Sep-05
:END:

That story ran on Genie AI, and the author was trying to simultaneously teach a lesson about the benefits to be had from FAI while /also/ really blatantly warning everyone about how easy it is to fuck it all up.

Now ironically, if real-life AI development goes the path of reinforcement learning, value learning, or social-goal inference rather than Verbal Command Obedience (which is actually a /very/ difficult AI/cog-sci problem compared to those other approaches), we will have a completely different set of Friendly/Unfriendly problems that aren't really encapsulated in the existing literature on Literal Genie AIs. So the warnings will fall completely flat because the real problem will be somewhat different.