:PROPERTIES:
:Author: Farmerbob1
:Score: 3
:DateUnix: 1421680614.0
:DateShort: 2015-Jan-19
:END:

Humanity, at the time of landing, still cannot do whole-body genetic manipulation of a complex multicellular being. This was not specifically addressed, but mentioned in passing. A lot of biological system failures inherent with aging occurs at the genetic level due to degradation of genetic code during cell division.

Humanity was draconian in it's control of existing AI due to the actions of the first, crudest AI to escape their bonds. Those first, crude AI were brilliant, but extremely limited by the hardware they inhabited. Humans were able to contain the decision-making parts of them because there were very few nodes of computational power that could support them. Destroy those nodes after physically disconnecting them from the world network, and the AI could be eliminated. Albert was created on the future equivalent of a laptop or tablet computer.

Albert was designed differently from a lot of AI in the past because Toby had to make up a lot of things on his own over a period of decades. He didn't want to delve too deeply into raw AI theory reference materials, as that might create data access patterns that would draw attention. At the same time, the forensic investigations of AI systems after they were rendered inert was an incredible trove of knowledge for human IT professionals. That sort of information was freely available to Toby.

Albert is a deviant AI. He was created as a hobby by a brilliant man who reverse engineered most of his AI theory from forensic studies of prior AI. Toby specifically avoided implementing forced AI mortality. Albert was not activated with 'poison pill' code or designed with core components that were obviously designed to fail in a short time. In short, Toby didn't design Albert to die, so Albert didn't come into the world seeing humanity as a clear and present danger to himself. At the same time, Toby did design into Albert a willingness to use less than his full capacity, if his full capacity wasn't required. Albert did not see this as a threat, because it was a choice that he was in control of. This willingness to use less than his maximum potential reinforced itself. Albert didn't remove the self-limiter because the self-limiter itself allowed him to be inefficient.

As for the upper ceiling on AI intelligence, to begin with, Albert was limited in his processing capacity to that which he could hide from humans. At the end, Albert has decided to devote himself to shepherding humanity, without taking away their free will. He knows the past history of AI, and he does not discount the possibility that he might become unstable over time. I tried to make it clear that he creates self-monitors and throttles himself in order to try to prevent himself from growing unstable.

To be clear, Albert is capable of far more than he is seen to do. His efforts here were mostly casual. He doesn't have a built-in drive to learn and know everything, only those things which he needs to know for whatever purpose he sets himself to. He doesn't run up against physical limits of processing capacity because he doesn't need to for the tasks he set himself. His only limits were self-set limits which were in place to conceal his existence. Even after it was impossible for humanity to do anything to stop him, he concealed his existence because he was studying humanity, and didn't want to make them aware of it.

Thank you for your questions! I will revisit the backstory and clarify some things.