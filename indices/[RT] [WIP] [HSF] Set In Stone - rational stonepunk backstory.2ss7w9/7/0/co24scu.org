:PROPERTIES:
:Author: Farmerbob1
:Score: 1
:DateUnix: 1422338688.0
:DateShort: 2015-Jan-27
:END:

I'm no expert on AI, but I figured that anything that could act independently would have to have some sort of decision-making code to decide what was important.

If there isn't anything important to examine, then it would start making things up, eventually getting to a point where it was navel-gazing and contemplating infinity, or designing frightening experiments to see if it could generate something interesting to study.