:PROPERTIES:
:Author: trekie140
:Score: 9
:DateUnix: 1507923834.0
:DateShort: 2017-Oct-13
:END:

HPMOR was my introduction to rationality and, by extension, Yudkowsky and AI Theory. As such, I hold the same opinion of Yudkowsky as I do of HJPEV. I believe he is a very intelligent and creative person who I can learn a lot from, particularly about the act of learning and thinking critically about what you think you know. He has occasionally come across as arrogant and I fundamentally disagree with him on many subjects he's spoken about, but I will always admire him for what he's given me and the abilities he has.

I don't know much about MIRI other than its goals, but I do believe that it is pursuing a goal that has value. The only reasons I could find myself disagreeing with its activities are the same reasons I sided with Hanson in his debate with Yudkowsky about the Singularity, all presumptions about how AI will work are speculative since we do not yet understand how intelligence works and Hanson's theory of mind lines up more with my intuition.

I think the debate over AI is basically the same debate as which interpretation of quantum mechanics is correct. We do not yet have the evidence to draw definitive conclusions on how it works, but all adequately explain the evidence we can currently observe so any scientific research into the subject is bound to yield results that everyone will find valuable. I would prefer Yudkowsky didn't talk about the AI Foom or Many-Worlds as if they were the obvious rational conclusions to form, but I don't think that would make any evidence he gathers less useful.