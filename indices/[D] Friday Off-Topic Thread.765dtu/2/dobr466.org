:PROPERTIES:
:Score: 5
:DateUnix: 1507921766.0
:DateShort: 2017-Oct-13
:END:

I'm curious about your opinions on the mission of MIRI, and what you think about [[/u/EliezerYudkowsky]]. Is making progress on AI friendliness really an important issue? Do you think it's a real problem? Do you donate to MIRI?

I've recently been working through depression and I've managed to reach a point where I can be curious about things again. And... life now seems a bit positive. Although I'm not happy yet, I can see that I can be eventually. And so now, possible existential threats are a relevant concern to me. They sort of /feel scary/, in a way they weren't before, when I didn't feel like life was worth living. I guess now that I have [[http://lesswrong.com/lw/nb/something_to_protect/][something to protect]], I want to learn more about this. If you don't care about MIRI, then you could talk about other things you think might be an existential threat. Let's have a discussion, shall we?