:PROPERTIES:
:Author: Transfuturist
:Score: 2
:DateUnix: 1444231383.0
:DateShort: 2015-Oct-07
:END:

Because the space of dangerous minds is magnitudes larger than the space of benevolent ones. [[http://blog.exosphe.re/why-do-we-need-friendly-artificial-intelligence-conversation-with-eliezer-yudkowsky/][You're basically asking me why AI safety is a problem.]]

We don't know how intelligent it is. It could be connected to another universe that an AI has already tiled with computronium. It appears to be incredibly powerful due to the accuracy of knowledge displayed about the present and the future. And the simple fact is, benevolence is completely orthogonal from this. It's already dangerous, benevolence is simply being dangerous to our obstacles. We know that it is dangerous to be its obstacle. We don't know that it is benevolent, i.e. aligned with us. It is very, very improbable that it is aligned with us, since there are so many things it could be. Burn it.