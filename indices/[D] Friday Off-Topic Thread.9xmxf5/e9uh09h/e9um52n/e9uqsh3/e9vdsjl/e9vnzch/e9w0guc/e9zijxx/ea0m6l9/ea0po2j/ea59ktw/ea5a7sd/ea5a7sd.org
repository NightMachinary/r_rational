:PROPERTIES:
:Author: hh26
:Score: 2
:DateUnix: 1542772638.0
:DateShort: 2018-Nov-21
:END:

With those exact numbers, the odds of the AI being unfriendly are really high. But if we have a higher chance of a humanity-ending disaster in the current era, due to higher population of people doing funky stuff, and newer technology such as nukes, then the odds could go the other way.

#+begin_quote
  Assume that an Unfriendly AI will cause a disaster which looks accidental to try to persuade you to let it out of the Box.
#+end_quote

I think this is the multiplier that could potentially have a huuuuuge variance, I don't think you can just say that it's 1, when my mental model was assuming it would be closer to 0.01. But it's really hard to say, it depends on how much influence the AI's decisions carry in the real world and the nature of our interactions with the box. Can the AI influence meteors into a collision course with the earth? Can the AI convince someone to engineer a deadly supervirus for it? Can the AI hijack our nukes? The whole point of putting it inside of the box is to prevent this sort of stuff in the first place. I get that an unfriendly AI would want to cause such a disaster, but if it can actually cause such a disaster with high probability it's functionally already outside the box.