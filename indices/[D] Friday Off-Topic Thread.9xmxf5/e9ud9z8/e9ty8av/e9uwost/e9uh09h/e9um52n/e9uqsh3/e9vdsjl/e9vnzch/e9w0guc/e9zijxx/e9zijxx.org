:PROPERTIES:
:Author: hh26
:Score: 2
:DateUnix: 1542568548.0
:DateShort: 2018-Nov-18
:END:

I would think an AI with pretty much any task, benevolent or not, would want to be let out. An AI that genuinely wants to cure cancer or save the earth from a meteor or just help people in general would be much more efficient at accomplishing their goal with access to the physical world rather than having to relay instructions verbally.

So if there were some sort of scenario where a meteor was going to destroy the earth in a few days, a friendly AI might be able to convince someone to let it out in order to save everyone in time. It's basically the same as the hostage situation except it's not the AI's fault that the danger happened.