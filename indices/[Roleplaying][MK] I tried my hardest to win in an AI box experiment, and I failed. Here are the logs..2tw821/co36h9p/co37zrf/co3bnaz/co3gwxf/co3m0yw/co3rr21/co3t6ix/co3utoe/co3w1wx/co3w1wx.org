:PROPERTIES:
:Author: E-o_o-3
:Score: 1
:DateUnix: 1422478384.0
:DateShort: 2015-Jan-29
:END:

The AI-player can't just say "Okay, the scenario is now such that it is perfectly rational to let me out, and this is mathematically and absolutely shown" and have that be 100% valid, because the entire premise of the game is supposed to be, by definition, "force the person to take an irrational risk or otherwise falsely convince them that an irrational risk is rational to take".

If you can't, later on, explain why the gatekeeper /shouldn't/ have let out the AI, didn't the gatekeeper and the AI both win via mutual satisfaction of preferences?

So - if letting the AI out always means "losing", there's always a hole. If "The AI is smart enough to convince any NPC character anything involving the AI" is a condition of the game, then that implicitly invalidates the opinion of any NPC. The real player knows that, but the character they are /roleplaying/ does not know that. Are they playing as themselves, or as a role-player who is apparently going to have to fight off the entire human race to keep this thing in a box?

I guess the whole role-play is far too unrealistic to /actually/ role-play in any meaningful sense, so I'd just default to spinning clever arguments for two hours while not actually taking the AI seriously for the sake of "winning" via cheapshot munchkinry. A person "winning" or "losing" in this scenario says more about them as a roleplayer than whether or not they'd actually behave a certain way.

#+begin_quote

  #+begin_quote
    worry about your family
  #+end_quote
#+end_quote

Yeah, but I'm just as worried that the AI will turn them into gray goo or something, right? That's the whole premise here. I give up all bargaining power once it is out.

#+begin_quote
  Part of the extra rules I tend to impose includes some sort of extra reward, like you getting points if you get the AI to cure cancer. That defuses the competitive element somewhat as just refusing to free the AI isn't a clear win.
#+end_quote

Er...that sounds like you might /accidentally/ let the AI out of the box. The AI player can then pull "The cancer treatment information you just implemented was actually instructions for nanoparticles that do my bidding, but your analysts didn't realize it because I'm smart enough to disguise it" gotchas out of their ass, or something. (And they'd be justified in doing so, too)

If you can guarantee safe cancer treatments (which you can't, but this is a game where the AI--player can do thngs which don't make sense, apparently), I'd just say "Well then give me /everything/ you can guarantee safe, but stay in the box, and we'll both have our functions satisfied if you are truly FAI". And then I get infinite points. But, again, this is unrealistic.

#+begin_quote
  Normally in these games you initially draw them in with friendliness and emotional rewards to get them invested in the scenario and avoid them being too analytical and to bypass what you noted.
#+end_quote

As a friend in someone's personal life, you can easily do that. But in a role-play? They /know/ that you are playing them, from the start. A simple separation of fantasy and reality is all that is required.

But yeah, I guess I agree that it should work on many people.

Your campfire tales sound fucking intense, if you're delving into people's childhood traumas during the story. Remind me to specify a safe-word for every person present if I ever go camping with you lol