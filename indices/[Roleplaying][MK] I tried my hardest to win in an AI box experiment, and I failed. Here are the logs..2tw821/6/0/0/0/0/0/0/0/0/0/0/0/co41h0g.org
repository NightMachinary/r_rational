:PROPERTIES:
:Author: Nepene
:Score: 1
:DateUnix: 1422486888.0
:DateShort: 2015-Jan-29
:END:

#+begin_quote
  Basically, my point is this: if you want to say that an AI could easily convince a human to let it out of the box...and then you also have it as part of the game that any human NPC can be tricked into thinking it is safe, it kind of begs the question, right? Because you've created a role-playing scenario where every (non-player) person is fooled, all attempts at evidence gathering are really futile.
#+end_quote

Yes.

#+begin_quote
  If the Gatekeeper understands that logically, under the rules of the prompt, all information gathering attempts concerning friendliness are futile, and it's already a given that there is no way to ascertain friendliness then there is never, ever any good reason to open the box, ever.
#+end_quote

There are a number of good reasons.

1. Trust. If the AI seems trustworthy then perhaps you should let it out? I tend to make this doable by picking a secret actual alignment before game that will be reflected in my actions.

2. Worry about worse events.

3. A desire to destroy the world.

4. Personal whims.

5. Curiosity as to what they'll do once free.

6. A feeling of obligation because of gifts they gave.

7. An intellectual feeling that AIs are inherently friendly.

That is the point of the roleplay, to see if you can induce those feelings to make someone perform an action.

#+begin_quote
  Yes, but my friends would get pissed off if I did that!
#+end_quote

I have amusingly sadistic friendships.