:PROPERTIES:
:Author: E-o_o-3
:Score: 1
:DateUnix: 1422501315.0
:DateShort: 2015-Jan-29
:END:

Hehe, by some definition of 'good reason". Replace "let this AI out of box" with a more normal situation, such as "entrust this human with sole responsibility over all nuclear launch codes", and all of these reasons sound insane.

(Even 3 wouldn't work. You can't be certain that an AI designed to be friendly will destroy the world, either, and quite a few humans would intentionally throw away the launch codes and forget them immediately.)