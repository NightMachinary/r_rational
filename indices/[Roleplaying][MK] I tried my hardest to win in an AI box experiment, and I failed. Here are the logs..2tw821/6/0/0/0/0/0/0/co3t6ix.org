:PROPERTIES:
:Author: E-o_o-3
:Score: 2
:DateUnix: 1422474064.0
:DateShort: 2015-Jan-28
:END:

#+begin_quote
  If you were convinced that the AI was relatively safe and valuable you'd have to be willing to talk about why you wouldn't let them out and you couldn't appeal to out of game measures as that would be breaking character. If you just said "I won't let you out because no" that wouldn't be role playing.
#+end_quote

Ah, well. I suppose I'd have to think carefully about it then. This is somewhat complicated by me not believing in the FOOM theory so the person I'm role-playing has already revised some major opinions as a result of being in this scenario, but I do /eventually/ want to fix everything.

On the other hand, even without careful thought I'm pretty sure i'd consider something such as "this gigantic committee of people has to approve it first" as adequate grounds to wait.

If the situation is "yes, everything is approved, practically everyone in the world whose opinion is worth listening to thinks this AI safe, we've thought about it for arbitrarily long, and humanity has collectively made its choice for better or worse", I don't see how the decision is realistically still in my hands.

#+begin_quote
  Also as the AI I can overcome issues. I can give your AI researchers a couple months to analyze my code and prove I am benign.
#+end_quote

"Prove" is a strong word. It means "no doubt at all, with mathematical certainty", and friendliness is not the sort of thing amenable to math proofs. Is the AI allowed to create scenarios which are that illogical like that?

Anyway, that's an intellectual problem - all separate from emotional manipulation.

#+begin_quote
  Have you faced anything attacking this particular worry?
#+end_quote

What do you mean by "faced"? I have never actually role played "Hey, do your worst to make me sad with only words" with anyone, if that's what you mean. But, just hypothetically, if a stranger who does not matter to me starts quoting, hinting at, or elaborating on my darkest thoughts at me over a text-only terminal, I wouldn't feel particularly bothered. I'm at least partially able to /think/ dark thoughts without becoming particularly emotional (although I do have to intentionally choose to examine the thoughts from a detached, reflective, meta-cognitive perspective in that case - I kind of make a dissociated model of myself thinking the thoughts rather than directly thinking them), and I can read what I myself wrote without feeling anything at all, so why should I anticipate that hearing them from someone else would hurt? (It is important that this person is a stranger, though. If it's someone I care about, confirming dark thoughts I have /about them/, then that might harm.)

I suppose the whole "dissociative mindful meta cognition" thing is something that most people don't do - I do have to make an /effort/ to dodge emotional bullets in that case - but I'd only need to go to that trouble in order to actually /intentionally dwell/ on dark thoughts and explore them to the fullest extent. I could still read them or hear someone else say them, safe in the knowledge that it's not directly relevant, and not be too bothered.

#+begin_quote
  That was the approach the person was going for- making the other person disengage and be indifferent by disgusting them.
#+end_quote

I see...I thought the person actually had trauma related to poop and cross dressing, or something. But would they be disgusted enough to actually leave the terminal and lose the game, if they were already committed to killing 2 hours anyway? Many people are pretty stubborn about winning games, although I guess a role play isn't a "game" in that sense.

#+begin_quote
  In roleplays I haven't had any issues making any person emotional.
#+end_quote

Are...you saying you and your friends get together and role play "try to make me sad with words"? I'm really curious as to what the context of you having these experiences is, and what motivates you/them to do that? Is it part of a kink or a therapy or a meditation or something?