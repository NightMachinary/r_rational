:PROPERTIES:
:Score: 1
:DateUnix: 1429983471.0
:DateShort: 2015-Apr-25
:END:

#+begin_quote
  I'm not too sure of where to go for graduate schools yet. I'm planning on doing all of that research over the summer.
#+end_quote

Well, with a double-major in cog-sci and computer-sci, good marks, and summer research experience, you should be well-set-up for just about anything. What were you thinking of specializing to research?

I suppose I don't have to give you the "Probabilistic approaches, /best/ approaches" shpiel, since you've already been bombarded with that enough.

#+begin_quote
  Listen, if you're going to blindly trust AIs, I'm not building you one.
#+end_quote

That's a nice flair, but it doesn't really capture the conversation we had. I mean, he didn't blindly trust AIs. He wanted /that specific one/.

Which, now that I think of it, is actually a good strategy for dealing with these problems. When we normally talk about this problem, we tend to act as though our task is to get a /philosophically correct/ goal-system. But really, if your FAI goal-system design can't beat good-old Reedspacer's Lower Bound, then you /should/ throw it out, even if it appears to be saying many of the same things that real-life people are prone to saying when they wax philosophical.

In fact, /especially/ if it starts saying the same things as real-life people when they wax philosophical. We want AI to [[http://lesswrong.com/lw/j2/explainworshipignore/][/solve/ our problems, not fucking contemplate them]]!

So really, my friend on Facebook was being kinda clever.