:PROPERTIES:
:Author: Veedrac
:Score: 1
:DateUnix: 1562567594.0
:DateShort: 2019-Jul-08
:END:

I don't think you understand how far I am from working through this viewpoint. “Racist AI, Religiously biased AI, Politically biased AI” sounds about as obvious as “spiteful refrigerator”. How would you even build a superintelligent AGI system that had any of these traits as their predominant failings? Like, what actually happens in your hypothesis that results in these failings?

“Programmed badly” doesn't explain this much more than “badly built” would explain a fridge getting spiteful.

Are you perhaps talking about the creators having too much power to choose how the AI would look, and building it to push their particular ideologies? I'd hesitate to assume this since again you seem to be talking about an AI takeover situation, whereas this is more the China-becomes-totalitarian route.

#+begin_quote
  Or people consider X wrong AI doesn't because when it was programmed people didn't consider X wrong..
#+end_quote

This idea I can buy, and it does concern me, but it seems unlikely to lead to societies worse than today.