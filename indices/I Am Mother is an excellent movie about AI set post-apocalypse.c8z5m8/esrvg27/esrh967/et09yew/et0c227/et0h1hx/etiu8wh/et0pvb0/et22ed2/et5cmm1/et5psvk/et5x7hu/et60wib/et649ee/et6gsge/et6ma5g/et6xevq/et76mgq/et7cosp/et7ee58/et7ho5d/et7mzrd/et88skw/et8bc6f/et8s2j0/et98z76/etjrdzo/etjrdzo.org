:PROPERTIES:
:Author: Veedrac
:Score: 1
:DateUnix: 1562879763.0
:DateShort: 2019-Jul-12
:END:

#+begin_quote
  We are talking about an alien god with near limitless power and intelligence
#+end_quote

I mean, I agree with this. But I find it hard to believe that if we had alien visitors from Alpha Centauri they would be racist, religiously biased, or politically motivated in any traditional sense. My question is not whether the AI would care about being fair wrt. race, but how an AI could plausibly be dystopically bad in this topic whilst still being generally well enough aligned for that to not to be completely overshadowed (eg. by not caring about human wellbeing, and thus killing us all).

I guess one major sticking point for me is that I don't see a way to solve this problem which is not fundamental; i.e. which does not require the AI actually knowing about and optimizing for underlying human goals like wellbeing, fulfillment and happiness. If you're doing that even passably, dystopias are implausible. If you're not, the AI kills the humans (or does the closest thing it is allowed to do) so it can get on with doing whatever it considers fundamentally important, like making buckets of dopamine.