:PROPERTIES:
:Author: Veedrac
:Score: 2
:DateUnix: 1562512377.0
:DateShort: 2019-Jul-07
:END:

#+begin_quote
  Why? Link, evidence, arguments ?
#+end_quote

To someone born in 1800, the idea that today we would have thousands of satellites orbiting earth and flown to pluto and well beyond, have bombs that could easily kill a million people each, that the average person can afford a device that fits over their head and replaces their sight with a realistic virtual world of our devising, that the average person can, whenever they wish, engage with a conversation with a random person wherever in the world, at real-time, that people not only can see and map the inner working of human beings, but can literally edit our own genes, and the same technology allows us to eradicate species by creating new subspecies out of whole cloth that have specifically-engineered reproduction failures... the list goes on and on and on and on.

To someone born in 1800, this is not just a ‘surprising' or ‘advanced' future, it is a literally impossible fantastical delusion.

We know a lot of physical limits that we're nowhere close to hitting, with few other limits of any kind, when it comes to the progress we can make from here. The idea that the future will be a simple reimagining of the present, that it will moderate itself out to outcomes that sound sensible /today/ with /today's/ technology is frankly implausible.

The question is thus not whether the future will be wacky and extreme and seemingly implausible, but in what way it will be wacky and extreme and seemingly implausible. Arguments to moderation don't work to solve this question.

#+begin_quote
  What's the likelihood AI safety is bad enough to extinguish humans? Low.
#+end_quote

You're begging the question. AI risk people have given an argument as to why this should be high. You've not given any (non-narrative) reasons as to why it should be low.

#+begin_quote
  It's just low probabilities added together, which get's us even lower probabilities.
#+end_quote

Uh, the risk is the disjunction, safety is the conjunction. Combining them makes the numbers more in favour of annihilation.