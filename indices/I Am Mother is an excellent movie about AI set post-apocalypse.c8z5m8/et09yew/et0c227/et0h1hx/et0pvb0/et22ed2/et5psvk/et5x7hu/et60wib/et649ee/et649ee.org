:PROPERTIES:
:Author: fassina2
:Score: 1
:DateUnix: 1562503338.0
:DateShort: 2019-Jul-07
:END:

Fair enough AI human extinction is a simpler hypothesis than bad morality AI, my bad. The moderate position is more likely though..

#+begin_quote
  You should probably also keep in mind that an argument to moderation as it applies to far-term futures is a uniformly terrible heuristic.
#+end_quote

Why? Link, evidence, arguments ?

Besides it's not even that, it's just statistics, what's the likelihood AI is created without safety? low. What's the likelihood AI safety is bad enough to extinguish humans? Low. It's just low probabilities added together, which get's us even lower probabilities.

For full apocalypse you need either low chance rogue ai, or low chance bad morality ai. Everything else is more likely, not necessarily ideal or utopia but not apocalypse.