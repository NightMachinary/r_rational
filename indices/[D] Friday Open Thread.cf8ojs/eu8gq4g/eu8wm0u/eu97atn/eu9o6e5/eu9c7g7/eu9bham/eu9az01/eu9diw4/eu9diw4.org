:PROPERTIES:
:Author: laegrim
:Score: 2
:DateUnix: 1563577720.0
:DateShort: 2019-Jul-20
:END:

I also think it's likely that we'll see AGI in the next 20-100 years, but I don't agree that fact devalues everything else a person can do for a couple reasons:

1. While I think that on many tasks task specific AI will have seriously superhuman performance, I don't necessarily think that translates to superhuman AGI. In fact I give it even odds that AGI plateaus roughly around human level.

2. The value of what you do will always have a subjective component.

Even without AGI, task specific AI will have a huge impact on human labor in the next few decades - so you should already be thinking about what you can be doing in that intersection of things that make you happy and things that might have monetary value. As the value of your labor drops, perhaps because of AI or AGI, that subjective value doesn't and becomes a larger share of the reason to do things. If AGI happens to roll around, then the more superhuman that AGI is the closer the share of subjective value as a reason to do something gets to total.

If learning about AI makes you happy, I'd encourage you to continue to do do that! That's why I study machine/reinforcement learning; the expectation that I'll meaningfully contribute to the field doesn't really play a part. I never really bought into the idea that these fields have more intrinsic value though (Either the Utilitarian or the Roko's Basilisk style arguments), and if something else makes you happier you should feel free to focus elsewhere.