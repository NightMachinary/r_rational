:PROPERTIES:
:Author: Jose1561
:Score: 10
:DateUnix: 1599143200.0
:DateShort: 2020-Sep-03
:END:

I think the idea of that second epilogue would be somewhat dramatically unnecessary. We already /know/ what kind of future the protagonist envisions, and any deviation from that would be too much detail to contain in a single epilogue. It feels like wish-fulfilment at that point, because it adds nothing to the story.

In most of the stories you described, there are good reasons why Artificial Intelligence never occurred to the protagonist as a viable option. In The Waves Arisen and Mother of Learning, there's no in-world equivalent of AI. In HPMOR, I'm fairly certain Harry plans at some point to build a Friendly AI, but the problem is that even as far as magic's reality-bending powers go, creating new sentient beings that /aren't/ human-derivative would take a long time to work on, and a better idea might simply be to keep track of Muggle AI research, and find ways to improve it with magic, and return the results.

Apart from that, there is also the fact that the existence AI is kind of unsatisfying from a narrative standpoint. As in, instead of having a story about a protagonist who's trying to get smarter and save the world, you'd end up with an idealized autobiography of a real-world AI researcher (or of Eliezer or the like, if it's a world where AI exists in some form, and alignment is the issue).

The benefits to AI are more nuanced than simply sticking one in charge. That's something that would go deeply against public sentiment, and for the sake of democracy, would not be implemented. Powerful AI would exist to advance mathematics, technology, and social /systems/ that benefit the most people while catering to our sensibilities. A weird illustration that just popped into my head is the Yogurt episode from Love Death Robots, where the yogurt didn't ask at first to be in charge of society, but instead gave world leaders a plan that would end the world's problems.

In the real world, AI is inevitable. It's just the natural next stage of a scientific - or indeed, a sentient - civilization. Of course, the downside to creating AI without proper alignment systems is deeply horrifying, which is why given the choice, I'd delay AI research until AI alignment research reaches commensurate levels. But we /don't/ have that choice.