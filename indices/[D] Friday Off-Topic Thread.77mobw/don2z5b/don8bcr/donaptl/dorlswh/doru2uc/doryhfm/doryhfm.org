:PROPERTIES:
:Score: 2
:DateUnix: 1508777802.0
:DateShort: 2017-Oct-23
:END:

#+begin_quote
  The search for the philosopher's stone, holy grail, fountain of youth, etc. has been going on for thousands of years... for as long as humans have been around, I imagine.
#+end_quote

Definitely. The problem is, we don't actually know which "impossible" desires are /actually impossible/ until we've put a solid effort into trying, and sometimes, despite the desire itself being impossible, we get something useful out of the attempt. My 8th grade science teacher, back in the day, made sure we understood that historically, before atomic physics was a thing, chemistry came out of alchemy.

We never found a chemical process to turn lead into gold, and nowadays, we understand that nuclear processes to do so are uselessly expensive. We also found an entire primary physical science unto itself, with endless applications at work all around us every day.

So consider, for instance, whether maybe we can't push the upper limit of lifespans above 120 or so, but we /can/ beat the dementia and fatigue of old age, we /can/ keep people healthy, alert, and active for many decades longer before they just hit the limits of the human body and die. I'd kinda /like it/ if my parents, relatives with degenerative diseases, and remaining grandparent weren't suffering quite so many ailments. I fully expect both them and myself to actually /die/, but dying with, say, Parkinson's disease or memory loss doesn't seem quite so /necessary/.

Again, you never really /know/ until you've done the science. This doesn't mean we should search for Philosopher's Stones. It means we should make sure to do lots and lots of basic science on topics that matter, because the most medical and technological mileage comes out of fresh, paradigm-building findings in fundamental science rather than out of technologically- or clinically-focused R&D pipelines.

I mean, I buy into the whole "embodied mind" thing, so I have what I think are strong neuroscientific objections to most beliefs about mind uploading. On the other hand, neuroscientifically speaking, /our brains and bodies really work/, so I can't see why you can't bypass those objections by re-engineering your mind-uploading system. On the gripping hand, I'd bet that mind uploading is intractably difficult or expensive, and that we'll all look back at it the way we now look at the idea of using nuclear forces to change lead into gold.

#+begin_quote
  And throughout, the arguments are still riddled with magical thinking. "A superintelligent FAI will work out the details for us," is not a solution.
#+end_quote

I agree, and in fact, this is the kind of insight you tend to achieve within a few hours of informed thought about /how in the ever-loving FUCK a superintelligent FAI is ACTUALLY SUPPOSED TO DO THAT./

You end up realizing that being a superintelligent FAI must be a /really hard job/, and that the word "intelligent" needs to be cashed-out in a way that actually allows "more intelligence" to /make hard jobs easier/. This is more-or-less why, when I want to talk about AI or cognition, I find it useful to Say Not "Intelligence", just as Eliezer once blogged that you should Say Not "Emergence". Talk only about actual mechanisms and how they make hard jobs easier.

Of course, Bostrom-type work on AI risk tends to define "intelligence", as "the ability to make hard jobs easier, down towards their barrier of innate, in-reality hardness." From there the conclusions follow, but they usually follow tautologically. That can provide a hint at which /a posteriori/ dissolutions of "intelligence" are really helpful, but other than that it's just a thought experiment.

Of course, having /learned and thought about the problem/, I can definitely think of ways to make a brain-y-type-thing that would find what humans consider very hard jobs to be relatively easy. Of course, in many ways, that's just that tasks that are extremely difficult for a body and brain optimized one way, may in fact be easy for a body and brain optimized another way. Lots of more /everyday/ tasks, even high-level intellectual tasks, don't come with formal proofs of computational, statistical, or physical intractability: there's nothing /innate to reality/ making them so hard. For us, gaps between hard-for-people and innately-hard are money on the table, and we pick it up by building a system for which the task is easier than it is for us.