:PROPERTIES:
:Author: Fresh_C
:Score: 1
:DateUnix: 1506791227.0
:DateShort: 2017-Sep-30
:END:

#+begin_quote
  I would use modeling and problem solving capabilities to come up with answers, it would maybe even compare them to each other based on some sort of accuracy or understandability metrics. However, it would merely be programed to think about these problems, not to act in the world in a way to optimize its ability to think about these problems.
#+end_quote

What you're describing is basically just an improved version of modern AI systems. If it's not optimizing itself, then yeah, it doesn't pose any real significant threat.