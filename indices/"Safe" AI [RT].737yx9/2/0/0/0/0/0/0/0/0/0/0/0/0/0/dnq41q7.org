:PROPERTIES:
:Author: Daneels_Soul
:Score: 2
:DateUnix: 1506796198.0
:DateShort: 2017-Sep-30
:END:

#+begin_quote
  What you're describing is basically just an improved version of modern AI systems. If it's not optimizing itself, then yeah, it doesn't pose any real significant threat.
#+end_quote

So...

A) I'm not talking about something that does 1% better than current systems at classification tasks. I'm talking about something that can solve complicated problems in mathematics and engineering.

B) How does being non-self-optimizing make something automatically not a threat? You need to be powerful to be a threat, but that doesn't necessarily mean that you've gone through several iterations of substantial rewrites of yourself.