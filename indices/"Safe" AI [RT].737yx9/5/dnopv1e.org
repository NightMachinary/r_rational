:PROPERTIES:
:Author: ShiranaiWakaranai
:Score: 2
:DateUnix: 1506712100.0
:DateShort: 2017-Sep-29
:END:

One problem with this is that every AI must have self-improvement as its purpose. The whole point of developing an AI is to have something smarter than yourself write itself to be even smarter, ad infinitum until it has intelligence far far exceeding our own. If it isn't motivated to write itself, then what you have is just a bit smarter than humans at best. Which would be safe, but not very useful. (Because as [[/u/LeifCarrotson]] said, that's basically Siri and the other AIs we have today.)

And you absolutely do not want to remove all motivation other than self-improvement, because then it will almost certainly sacrifice humanity for further self-improvement.