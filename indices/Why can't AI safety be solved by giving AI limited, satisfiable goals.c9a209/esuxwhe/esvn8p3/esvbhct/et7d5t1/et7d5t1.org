:PROPERTIES:
:Author: SimoneNonvelodico
:Score: 2
:DateUnix: 1562529205.0
:DateShort: 2019-Jul-08
:END:

#+begin_quote
  Or even what "stopping" is?
#+end_quote

That seems quite straightforward to me. Stopping is not prosecuting any goal any more. I mean, I get that you need to make it a technical definition of some kind, but if the AI doesn't know what "stopping" means it's either dumb or a straight up malicious intelligence that's trying to lawyer its way out of constraints.

In principle, if an AI is gated into a box, "stopping" is simply "turn this switch off". There aren't many ways around it.