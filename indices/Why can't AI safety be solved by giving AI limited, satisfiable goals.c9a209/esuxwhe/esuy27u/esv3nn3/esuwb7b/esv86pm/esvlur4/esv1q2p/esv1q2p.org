:PROPERTIES:
:Author: Nepene
:Score: 3
:DateUnix: 1562292541.0
:DateShort: 2019-Jul-05
:END:

1. Goal oriented AIs are economically effective, and are very good at solving particular economic problems if built well. Companies want to solve economic goals. You can certainly built limited goals, but because of economic pressure in the end people are likely to stretch those limited goals so that they approximate more open ended ones.

2. Goal oriented AIs are less vulnerable to human stupidity and corruption. If you build an AI to cure cancer, they will try to cure cancer. If you set regular limited goals there's more likelihood that heavy human intervention will cause problems- a drug company might tweak them to produce a more expensive cure, for example, or there might be poor coordination in their goals between people setting it up.

3. We have a lot of theorywork on how to build good utility functions, so there isn't necessarily a need to make very short ones.

4. AIs which can self modify might wirehead. If you set up their goal to be happy when they answer you, they might wirehead to make themselves happy whenever they answer any question, and so sneak out onto the web.

5. They might act in annoying ways. Suppose you tell them to make ten paperclips. They might devote all of the world's resources to protecting those ten paperclips and verifying they exist.