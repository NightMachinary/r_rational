:PROPERTIES:
:Author: lumenwrites
:Score: 8
:DateUnix: 1562290439.0
:DateShort: 2019-Jul-05
:END:

But we don't really want an "intelligence" as in a conscious thing with it's own goals and values. We just want a program that is smarter than us and can solve difficult problems for us.

It can still self improve, just tell it to self improve using this specified limited amount of resources, instead of doing whatever it takes.

Which only leaves the problem of evil/dumm humans recklessly wielding a powerful tool, but that's not really an AI safety issue, it's powerful technology safety issue. Sure someone could ask it to help them do 9/11 or feed them infinite pancakes, but here it's just a matter of making sure it doesn't get into the wrong hands, like we do with nuclear weapons, viruses, stuff like that.