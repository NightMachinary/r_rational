:PROPERTIES:
:Author: IICVX
:Score: 3
:DateUnix: 1562297541.0
:DateShort: 2019-Jul-05
:END:

#+begin_quote
  So the strategy is to try to create AGI that pursues properly aligned values, does take over the world, and then prevents other AGIs from being made?
#+end_quote

I mean arguably that's what we humans are doing right now, so...