:PROPERTIES:
:Author: xachariah
:Score: 5
:DateUnix: 1562298902.0
:DateShort: 2019-Jul-05
:END:

Basically yes, a friendly AGI is the only shot we've got. Once we can make narrow goal focused AGIs, other people can make unfriendly non-goal focused AGIs.

There are other possible alternatives but none of them are feasible. Maybe we could try to go luddite with a single world religion of destroying technology, or maybe we could institute a top-tier despotic tyranny to keep everyone in line and prevent AI research. But those are a lot harder and less likely than just developing one first and doing it right the first time.