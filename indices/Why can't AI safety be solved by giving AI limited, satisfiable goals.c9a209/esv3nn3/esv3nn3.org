:PROPERTIES:
:Author: multi-core
:Score: 20
:DateUnix: 1562293370.0
:DateShort: 2019-Jul-05
:END:

[[https://intelligence.org/2016/12/28/ai-alignment-why-its-hard-and-where-to-start]] is Eliezer Yudkowsky discussing the problems with trying to get an AI that just wants to do one bounded task. IIRC he thinks task AGI still /is/ the way to go in the short term but not many of the problems have been solved yet.