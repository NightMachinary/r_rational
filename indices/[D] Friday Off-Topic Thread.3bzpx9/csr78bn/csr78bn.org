:PROPERTIES:
:Author: DataPacRat
:Score: 2
:DateUnix: 1435946837.0
:DateShort: 2015-Jul-03
:END:

*Quick thought: Meta-Bayesian analysis?*

I've just realized I've been thinking about a problem in a way I don't recall seeing mentioned elsewhere: "I know that, given all the data I have and unlimited computing power, there is one particular best-guess I can make about how confident I should be that the answer is 'yes'. On the other hand, I don't have unlimited computing power. On the gripping hand, some quick analysis suggests that I can be more confident that a 5% confidence in the main question's 'yes' is the better answer than a 95% confidence."

Put another way: Instead of merely picking a confidence-level for the answer, such as 'I'm 5% sure this is true', pick confidence-levels for the confidence levels, such as "I'm 90% sure that I should be between 0 and 25% sure, 5% sure that I should be between 25% and 50% sure, and 5% sure that I should be between 50% and 100% sure."

Has such an approach been previously discussed, in the LW blogosphere or in probability reference texts? Does anyone else already use this approach? Is it a viable approach?

(If you're curious, it was the discussion of the Fermi Paradox in the Rational Horror thread that set my mind on the path to explicitly realizing what I've been implicitly thinking; and I'm considering adding some mention of this in the novel I'm almost back to writing daily again.)