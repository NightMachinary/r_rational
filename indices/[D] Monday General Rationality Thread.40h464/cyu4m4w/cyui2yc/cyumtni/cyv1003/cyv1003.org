:PROPERTIES:
:Score: 3
:DateUnix: 1452577546.0
:DateShort: 2016-Jan-12
:END:

Well that opened a major can of worms.

Most usages of the word "rationality" don't refer to LW. In this case, it partially does, and partially doesn't. This isn't trolling with my Tzeentch hat on, this is just being weirded out by certain things.

[[http://nostalgebraist.tumblr.com/post/83006103140/what-is-bayesianism-we-i-just-dont-know][Some of them]] [[http://bactra.org/weblog/569.html][/are/ LW-associated.]] [[http://delong.typepad.com/sdj/2011/08/economic-downturns-the-social-darwinist-waltz-and-the-navigation-of-the-starship-asgard.html][Others are less associated, at a remove.]]

The result is just that I've become extremely suspicious of the tendency to apply "rational" or "rationality" to mean, "Use algorithm X" or "Solve well-specified problem Y", with a vast body of assumptions just /lurking behind things/ about why I should use algorithm X, or about /whether/ well-specified problem Y even /can/ be solved tractably, and how desirable it is to solve problem Y using algorithm/technique X instead of solving a similar problem, call it Z', which takes actual explicit account of the flaws in the preconceptions about Y and thus can be solved with a much more tractable, robust algorithm W, which the Xians will promptly yell at you for using because it isn't X and doesn't solve problem Y all that well.

Actually, the links about statistics are way obscure. If you really want to get what I mean, just look at the economics example, and then think of all the other times fucking economists have basically said, "Homo Economicus does X, actual human beings do different-thing Y, and we can therefore conclude that human beings are /irrational/, not because Y has /no reasons behind it/, no cognitive processes that could make sense or optimize some goal, but instead because Homo Economicus is the /normative/ theory of a /rational/ agent." (See: Robin Hanson, Tyler Cowen, Bryan Caplan, and in fact much of the rest of economics.)

Where this becomes problematic for things like the "rationality community" is that the entire edifice of the dual-process, heuristics-and-biases, and evolved-modularity approach to cognition is the work in behavioral /economics/ by Tversky and Kahneman, which founds itself on... yep, taking Homo Economicus (eg: the expected-VNM-utility maximizer with Bayesian updating of unlimited numerical accuracy and no causal reasoning) as the /normative model/ of a /rational agent/.

I mean, honestly, what the hell is the point of calling stereotypes of corporations the "normative theory" of how /human beings/ should act? Even the corporations themselves only act that way because someone /told them/ the damned theory was "normative".

In which case, sure, all the normal things like base-rate neglect seem like Bad Ideas /to me/, but what algorithm is generating them? Are they really /worse/ than /completely ignoring causal structure/ because you think a good predictive distribution is /all that matters/?

In summary, you'd think that the definition of concepts like "ought" would be an obscure matter for overly metaphysical philosophers, but actually, confusion over what "should" (ahaha) count as normativity seems to play a role in most /willfully held/ delusions, as people start asserting that by gosh, /it's a normative theory/, and that means it doesn't have to correlate with /anything/ else or match up to /anything/ or bear any resemblance to, for instance, the thing you would choose in its place given full information and full cognitive accuracy.