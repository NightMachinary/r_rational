:PROPERTIES:
:Author: Transfuturist
:Score: 2
:DateUnix: 1452581724.0
:DateShort: 2016-Jan-12
:END:

#+begin_quote
  [nostalgebraist]
#+end_quote

"we live in a universe in which theory X holds" does not strike me as meaningfully different from "theory X holds", and can be enumerated in pretty much the same way with a prior over the mutually exclusive theories to which theory X belongs.

Not that I have ever actually done or used such an enumeration. I'm not quite sure if we should be using systems where theories/hypotheses are the unit of currency, or systems where evidences/data are. I'm not sure if that distinction means anything. But I still think diachronous Bayes is correct.

I have never seen people pull arbitrary small probabilities out of their ass in the manner described to get '0.01'. As SSC puts it, even statistics with guessed numbers is better than guessed results, because the results can surprise. Additionally, this is why a log-odds formulation of probability is recommended, because it puts the probabilities in less alien terms. I've never actually seen a Bayesian, though.

#+begin_quote
  The result is just that I've become extremely suspicious of the tendency to apply "rational" or "rationality" to mean, "Use algorithm X" or "Solve well-specified problem Y", with a vast body of assumptions just lurking behind things about why I should use algorithm X, or about whether well-specified problem Y even can be solved tractably, and how desirable it is to solve problem Y using algorithm/technique X instead of solving a similar problem, call it Z', which takes actual explicit account of the flaws in the preconceptions about Y and thus can be solved with a much more tractable, robust algorithm W, which the Xians will promptly yell at you for using because it isn't X and doesn't solve problem Y all that well.
#+end_quote

Is this paragraph motivated by AIXI-worship vs. bounded intelligence?

#+begin_quote
  all the other times fucking economists have basically said
#+end_quote

Well, I mean, those economists are wrong. /We know/ they're wrong. The last section covered in my microeconomics class was all about how Homo economicus differs from humans. It was not presented as a "normative theory" at all, and I've never seen Homo economicus be presented as the way humans "should" be, save perhaps some very deluded ancaps.

#+begin_quote
  Are they really worse than completely ignoring causal structure because you think a good predictive distribution is all that matters?
#+end_quote

Yeah, I'm guessing AIXI.