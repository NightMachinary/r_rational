:PROPERTIES:
:Score: 1
:DateUnix: 1496188808.0
:DateShort: 2017-May-31
:END:

Depends on the fidelity.

If we're saying that the computer fungus slowly eats my brain and write it to an super-duper-uber next-gen x86 PC, or anything classical in general? Gonna go with /no/. No classical computing substrate will preserve the operation of the mind with total fidelity, so the graph of that person's futures (as a heatmap of probability of branches) wouldn't look the same as mine. Small computational errors effectively mean that if we put the upload and original in identical universes, with equivalent brain-states, those universes won't branch the same way (assuming mwi is ^{t^{r^{u^{u^{u^{e^{e}}}}}}} ).

If we say it's replacing normal neurons with computronium neurons...? Well, is long as they fire appropriately, this method should be far more likely to preserve experiential identity. So it's already better. You can also, by lengthening the upload process indefinitely, make it almost arbitrarily likely that your configuration space locus is a necessary part of the upload's stochastic history. I need to devote a few days of careful thought to what, precisely, that means before I venture anything like an opinion on it, but my intuition a vaguely indicating in favour of your proposition. A notion of identity is after all useless unless it can actually identify things uniquely. We'll call this a "Maybe?".

If we're talking 1:1 substrate, then hell /yeah/ that's me. That was already the case before we made it slow, but the beauty of 1:1 substrate and 1:1 information uploading is that it's still you, no matter how you do it. That's why it's the technology I'm holding out for.