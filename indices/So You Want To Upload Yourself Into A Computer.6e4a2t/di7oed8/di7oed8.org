:PROPERTIES:
:Score: 16
:DateUnix: 1496116008.0
:DateShort: 2017-May-30
:END:

Hm... You know, I consider myself a rationalist and believe in almost none of the fundamental premises this infopic espouses.

First of all, there are two senses of "me" I believe in. The first is the "me in the moment". The second is the global me. The me in the moment is merely the agent experiencing that moment from my perspective. The global me is defined as the agents generated by iterating from a specific locus in configuration space. Most uploading violates the causal identity by introducing a discontinuity - and for gods sake if someone posts that sleep is also a discontinuity, it /fucking isn't/. You can re-enable memory transcription during sleep by blocking the breakdown of acetylcholine. I can't recommend the experience, but it's certainly /a/ form of conciousness. Just one that doesn't get transcrbed to LTS.

Most uploading also violates the second sense of identity as, when the information of the upload is considered in a global sense, there is a significantly reduced probability of the locus in stochastic history as compared to the "original self".

While I don't believe that P-Zombies are necessarily likely in nature, I also consider it a (very) open question if most computational subtrates are capable of supporting concioussness, /especially/ when it's abstracted. As a reductionist, I am forced to believe - in the absence of better evidence - that conciousness arises from a basic property of matter combined with a very specific structure of matter. As such, I believe that it's reasonable to talk about "what it would feel like to be a CPU" or "what it feels like to be the internet" so long as we acknowledge that, given such things have no structures designed for experiential self-assessment, and as such, while it might be like something to be such a thing, that thing does not have the capacity of knowing what it is like.

What all of the vaguery boils down to is that I truly believe that a computer running an upload might be feeling something, but that, the upload may not be feeling anything at all given that it's physical hardware is, in fact, not the process that it's running.

For me to be confident in uploading, we'd either need one of two sets of conditions. The first set requires new science showing that my notions of identity are fundamentally incorrect - unlikely, since mine, like yours, are essentially arbitrary in the sense that nature didn't give them to us. Rather, we picked them. This set also requires proof that qualia exist for mind-shaped-things on arbitrary substrates.

The other set of conditions - and one I believe is far more likely and technologically plausible - is upload of the full quantum information of the entire nervous system into a quantum substrate that (regardless of physical nature) /first/ preserves the totality of that information, and /second/, implements the evolution of that information over time in a manner that is 1:1 with what would have been expected had the upload never occured.

Of course the no-cloning principle means that no copy can ever be made, but who even cares? Either anthropic immortality means that nothing can kill us, or there will never be a world in which we attain eternity. Either way, again, so /what/? Dying copies still die. You don't know you won the gamble until you're the one that never died to begin with.

Anyway, the vast majority of uploading techniques seem to me to be nothing more than ways to create a shitload of intelligent agents that share your utility function... /for a little while./

Beyond that, the text is pretty good, if a bit limited in the exploration of what's possible. But then, it's an infopic. Depth isn't the point.