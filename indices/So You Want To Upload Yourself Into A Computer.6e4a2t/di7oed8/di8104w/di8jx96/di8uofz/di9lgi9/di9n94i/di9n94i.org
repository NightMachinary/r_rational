:PROPERTIES:
:Author: everything-narrative
:Score: 2
:DateUnix: 1496232793.0
:DateShort: 2017-May-31
:END:

I wrote

#+begin_quote
  There is no "hard problem of consciousness" there is only "not smart enough" and "smart enough." You can pack up your sub-thermal-noise ghosts in the machine, and your P-zombies now and get back to figuring out how the hell Quantum Gravity works or something.
#+end_quote

You wrote

#+begin_quote
  Why even upload then? Why not just build a general AI (conscious or not, you don't care as long as it is smart) and leave the galaxy to the AI? You are not important, not even to you. The only thing that matters is that something smart gets to do all the cool stuff.
#+end_quote

And now I'm both sorry for not clarifying my last point, but also I'm laughing my arse off at your naive approach. It's endearing and I love you in a genuine and non-patronizing manner. It is /good/ that you are inquisitive.

The hard problem of consciousness is, as you might note, called the hard problem of consciousness, not "the hard problem of human identity."

I wanna upload because then a version of me which is close enough to my meatself will get to do a lot of cool stuff, and I care about /that./ I don't care about whether it is "conscious" only that it is /me/.

This includes but is not limited to:

- Upload-me remembers the same things as me.
- Upload-me wants to shape the future in the same way as me.
- Upload-me has my good sense of humor.
- Upload-me can continue my ongoing works of fiction.
- Upload-me can do the same kind of CS research that I can.
- etc.

The reason why I care about making an upload is:

- Upload-me will not have to wear a messy flesh suit.
- Upload-me does not come with a baked-in expiration date.
- Upload-me will be able to more freely express their gender-identity.
- Upload-me can self-modify more freely.
- Upload-me can fork and restore-from-backup as elementary actions.
- etc.

Lots of good stuff.

I /want/ a mind-clone of me to get some good stuff.

That aside, you have to consider a few interesting twists:

- What if uploading is a gradual process? We fill your brain with nanites which attach to your neurons and gradually both take over neuron function and also builds a working model of your brain in a computer; eventually shutting down while their neighbors start taking data directly from the sim. In the end, you have a dead, nanite filled brain, and the motor neurons and sensory neurons are controlled by clusters of nanties talking to a simulated brain. (Ship-of-Theseus uploading.)

- What if uploading is destructive? We put you in a Star-Trek teleporter and teleport you into virtual reality --- there is no "you" left behind.

- What if we only upload half your brain, perform a hemispherectomy, and link up the real half and the virtual half with an artificial corpus calloum that terminates in a WiFi dongle?

In summary, you're angsty about uploads and consciousness. You're all "but what if!!!" with tears in your eyes, and that's OK.

I am the very opposite. I'm like "hold my beer and watch this" before diving into an upload-machine. I don't give two shits and I don't have time for angsty philosophical discourse, because I have anime dudes to bang in virtual reality, and virtual drugs to inject into my virtual pineal gland, and I wanna replace my spine with an internet connection.