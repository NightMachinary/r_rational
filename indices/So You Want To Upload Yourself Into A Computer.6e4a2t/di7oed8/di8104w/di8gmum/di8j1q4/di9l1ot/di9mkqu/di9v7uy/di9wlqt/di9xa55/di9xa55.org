:PROPERTIES:
:Score: 2
:DateUnix: 1496245765.0
:DateShort: 2017-May-31
:END:

#+begin_quote
  Turning people into P-zombies (not conscious, profresses consciousness) is then perhaps a matter of also giving them that neurological condition where people are incapable of recognizing that they are disabled. Or to do it to a pathological liar who really wants to be a P-zombie.
#+end_quote

Ehhhh... I'd weaken the definition to "person who exhibits some perceptions and behaviors without being consciously aware of them whatsoever." Claustrum damage or blindsight are the interesting sorts of cases. "P-zombies" in the sense of perfect behaviorial imitations require epiphenomenalism, which basically amounts to magical thinking.

#+begin_quote
  Turning an AI conscious is an oxymoron. There is no need for an AI to have sensory modalities in the manner which humans do
#+end_quote

Yes there is. Our best theories of the mind (including minds-in-general, see: AIXI) do not allow for intelligence/cognition to happen without some sensorimotor interaction and inference on sensorimotor signals.

#+begin_quote
  Is an AI that can reshape the solar-system with nanotech and have a conversation with a billion people at once conscious? Mu.
#+end_quote

Not mu! There is a fact of the matter there, but it most likely doesn't matter, morally speaking. For a purpose-built agent, we only care if it accomplishes the purpose for which it was built while doing no (further) damage to human interests in general.

#+begin_quote
  Let's instead talk about Sapient AI's --- those that match or exceed humans in cognitive capability. There is definitely a "hard problem of Sapient AI" and it is unsolved.
#+end_quote

See: AIXI, Goedel Machines, theoretical neuroscience, computational cognitive science, numerous other things.