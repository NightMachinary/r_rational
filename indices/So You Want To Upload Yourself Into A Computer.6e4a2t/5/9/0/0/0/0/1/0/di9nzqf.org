:PROPERTIES:
:Author: everything-narrative
:Score: 2
:DateUnix: 1496234065.0
:DateShort: 2017-May-31
:END:

I'm arguing that illusion of consciousness is caused by a brain center. I would look for the presence of that brain center and it's normal function with my virtual fMRI app.

It feels like you're passing the recursive buck: "how do you know an upload is /really/ experiencing the illusion of really experiencing things and aren't just behaving as if?"

Much better question is how you ascertain the accuracy of an upload. Do you ask it questions?

No. You use unit testing and unit verification.

Asking a question is tantamount to a systems test.

First, you get a working model of all the types of cells in the brain and which ones are computationally important and how they perform computation.

Second, you make a logically verified simulation of this model and run it on logically verified hardware.

Third, you make a scanner that can capture detail at the same resolution as the smallest computationally significant organelles of brain cells.

Fourth, you scan, instantiate, and simulate.

Once you know all the parts themselves individually are correct, the whole system will be as well. Then you can ask the upload some reference questions that touch on highly non-trivial specifics of the scanned individual and if they match, you're done. Can't fake massively emergent systems being 99% in accordance.