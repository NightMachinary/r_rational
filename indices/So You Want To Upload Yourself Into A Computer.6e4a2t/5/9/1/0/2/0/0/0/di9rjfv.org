:PROPERTIES:
:Author: ZeroNihilist
:Score: 1
:DateUnix: 1496239168.0
:DateShort: 2017-May-31
:END:

#+begin_quote

  #+begin_quote
    If your upload isn't capable of genuinely feeling emotion, what's the problem?
  #+end_quote

  It would defeat the purpose.
#+end_quote

I think there's a lot more utility to a simulated entity that mimics your thought processes than just whether or not it feels emotion, but ultimately that would be your decision.

#+begin_quote

  #+begin_quote
    You can say to yourself, "I think therefore I am." or "I feel conscious.", but so would a program that duplicates your thought processes
  #+end_quote

  The issue is exactly that - how do I verify that a program actually duplicates my thought process to that level of fidelity?
#+end_quote

Presumably by observing the simulation. It would be orders of magnitude easier to do so with a simulation than with a human, even.

If you can't find any difference by observation, then your upload would be closer in mental similarity to the current you than the version of you from last year. No point really sweating the issue at that point, I feel.