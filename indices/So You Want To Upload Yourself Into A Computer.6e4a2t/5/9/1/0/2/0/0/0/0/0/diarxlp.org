:PROPERTIES:
:Author: ZeroNihilist
:Score: 2
:DateUnix: 1496281208.0
:DateShort: 2017-Jun-01
:END:

#+begin_quote
  If you are just trying to make an AI, nevermind if it is an accurate copy of you, then I guess I understand your point. But I want an instance of me to continue, and not being able to feel happiness, curiosity, exhileration, lust, etc would be a dealbreaker.
#+end_quote

That's fair.

#+begin_quote
  Either way, you are trying to verify trillions of simulated chemical reactions against the source chemical reactions - that are already diverged - every second.
#+end_quote

Have you verified your own trillions of simulated chemical reactions against those of you from one microsecond ago, or five minutes ago, or ten years ago?

It seems highly likely that you've never attempted to verify your own continuity of identity. Very few people would bother, and literally none to the standard you suggested here.

There's a good reason for that: unless the test you propose has a huge tolerance for divergence, the only version of you that would ever succeed at that test is the one taking it. You from ten years ago would fail it without question, unless you've been in stasis for that time.

It raises the question about why your standards are so much higher for a digital version of yourself. You have absolutely no idea if you're the same person you were at any point in the past, except what you can glean from memories (and memories are fallible, incomplete, and liable to change).

I get that it's because you want to be sure your upload is a copy of you, but I'd argue that if your upload passes a KilotonDefenestrator version of the Turing test, they're closer to current you than 90% of your past selves. You don't seem worried by the fact that in ten years you'll be a radically different person, yet you're not taking steps to verify that you're not diverging.

Basically, if you actually need to analyse each individual simulated chemical reaction in order to say that something is not you, that thing is you.

It'd be like if there was a weather model that had never made a single false prediction over a million years of operation, then you found one line of input that differed by a single bit and said, "Aha! It's not a model of the weather at all, it's modelling something that just happens to be completely indistinguishable from the weather."

In actuality, the way you prove a model false is by finding incorrect output, not incorrect input. If you cannot differentiate between the output of the model and the thing being modelled, then the model is at least as accurate as your tests.

*TL;DR:* If your upload is indistinguishable from present!you in a Turing test scenario, any test sufficient to discover divergence from present!you would also disqualify the vast majority of your past and future selves.