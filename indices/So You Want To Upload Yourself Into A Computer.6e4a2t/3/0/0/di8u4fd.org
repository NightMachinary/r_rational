:PROPERTIES:
:Author: wren42
:Score: 4
:DateUnix: 1496181047.0
:DateShort: 2017-May-31
:END:

It seems we're having the same conversation across two subs =)

I'm pretty confident in this one point, however. Mathematically, in a Bayesian sense, I will always have more evidence that I am conscious than that another arbitrary agent is conscious.

I have 100% certainty that I am conscious. I do not have 100% certainty that an arbitrary program I am observing is conscious. Passing a Turing test is insufficient, as (sufficiently) correct answers could be selected at random from a hat, and provide no clue as to the underlying operation.

I can never have access to another agent's "sensory tap" as you put it, so the weight of evidence will always be imbalanced.