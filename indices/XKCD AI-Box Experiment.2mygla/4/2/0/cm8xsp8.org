:PROPERTIES:
:Author: scruiser
:Score: 4
:DateUnix: 1416579239.0
:DateShort: 2014-Nov-21
:END:

#+begin_quote
  an arbitrary idea that Less Wrong treats like such a huge threat
#+end_quote

I don't actually think recursive intelligence improvement will be as easy for the AI as lesswrong makes it sound, and I think the orthogonality of terminal goals and intelligence can be worked around without fully solving for "friendliness". However, if you do have a general artificial intelligence that surpasses human, then you do have an existential risk. If you have it confined or constrained in resources, then don't give it anything until you are sure you understand what it will do. I just don't see the humor in making fun of what seems like an obviously true idea.