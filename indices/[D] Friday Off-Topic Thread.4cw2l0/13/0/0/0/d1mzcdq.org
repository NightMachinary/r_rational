:PROPERTIES:
:Author: Roxolan
:Score: 2
:DateUnix: 1459607318.0
:DateShort: 2016-Apr-02
:END:

#+begin_quote
  Meanwhile, it's not entirely garbage. We get a bit of information each iteration
#+end_quote

If it is possible for entities to lie to us and make us believe the lie by force (or even without force, if we have no way to make an informed guess as to whether a statement is a lie or not), then no, we don't.

Like, say you devise a strategy A that works perfectly against a disutility ratchet X. Then I just introduce another entity Y that says the same things X says, but will, when confronted with strategy A, destroy the world.

When entities can lie about what they'll do, then no strategy is safe.