:PROPERTIES:
:Author: NotUnusualYet
:Score: 1
:DateUnix: 1442378897.0
:DateShort: 2015-Sep-16
:END:

Your first solution means having a creator AI without a well defined utility function, no?

As for the second point, the problem is that you said the AIs have a utility function of "enforcing the utility of the user". Even if the user doesn't find utility in ruling the world, the AI is still going to want maximum control of the world in order to better enforce the user's utility. Thus, hypercompetition. There needs to be a way for AIs to include in their utility function some measure of care for other humans besides their own user.

In fact, at any other degree than "care about humanity's utility function as a whole" there's going to be seriously negative multi-polar effects... until someone's AI wins and becomes a singleton, anyway. There might be a tricky way of networking all the AIs so that they can tolerate and trust each other, but that sounds suspiciously like a super-AI with a regular CEV utility function.