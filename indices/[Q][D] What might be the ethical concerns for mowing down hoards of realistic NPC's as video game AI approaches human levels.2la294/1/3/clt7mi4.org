:PROPERTIES:
:Author: Gurkenglas
:Score: 1
:DateUnix: 1415149430.0
:DateShort: 2014-Nov-05
:END:

A "code optimizer" takes a code and outputs the first code in an ordering of all codes that does the same thing on all inputs as the original one. I posit that this does not change the morality of running the code.

AI A +wants to be mowed down, and+ wants to pretend to want to not be mowed down. AI I wants to not be mowed down. A is damn good at what it does, and so when you feed A and I through an optimizer, both sources end up looking the same. Therefore, an AI not getting what it wants is not equivalent to running it being immoral.