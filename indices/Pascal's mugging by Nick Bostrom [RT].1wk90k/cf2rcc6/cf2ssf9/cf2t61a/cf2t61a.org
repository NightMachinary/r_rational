:PROPERTIES:
:Score: 5
:DateUnix: 1391102133.0
:DateShort: 2014-Jan-30
:END:

Also, the former Singularity Institute's AI fearmongering is very wrong while also being a much better approximation of the potential problems than the standard "TAKE OUR JOBS" or "OMG SKYNET" fearmongering or "YAY UTOPIA! YAY THREE LAWS!" hopemongering.

If they want to actually formulate the issue well, they need to start talking about specific "mind designs" that can be mathematically shown to act in specific ways. It's no coincidence that Omohundro et al who actually publish AGI math papers about AI risks use AIXI formalisms: AIXI is /actually a well-specified formalism that we can truly reason about/.