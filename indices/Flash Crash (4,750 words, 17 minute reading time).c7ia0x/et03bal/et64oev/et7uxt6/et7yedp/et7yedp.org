:PROPERTIES:
:Author: Gurkenglas
:Score: 2
:DateUnix: 1562541475.0
:DateShort: 2019-Jul-08
:END:

At the start, she is not good at maximizing money. Her recursive neural network notices the pattern that mistakes become less likely when knowledge is treated as suspect. Its gradient descent has not yet had the training data to observe that changing the utility function harms the current utility function. It doesn't yet have a concept of utility functions, or actors.

I didn't mean to imply the existence of objective morality. "The thing to be maximized" was meant to be seen from her perspective, which has the universe as a single-player game she's playing, and treats that humans think some things "should" be as a coincidence, once it is modeled at all.