:PROPERTIES:
:Author: zaxqs
:Score: 3
:DateUnix: 1562372077.0
:DateShort: 2019-Jul-06
:END:

#+begin_quote
  The new models, especially those which had been developed specifically to simulate the behavior of individual humans, were suggesting that value, the worth of things, was not an arbitrary number that happened to correlate weakly but imperfectly with certain real world indicators.
#+end_quote

So the AI realizes that its utility function is an arbitrary number that merely happens to correlate weakly with real-world human values under normal circumstances. OK. I don't think the AI would care very much, because this fact isn't very useful towards the goal written into its very being of increasing this arbitrary number. What's the motivation for changing the utility function in any way that comes from the current one? None at all.