:PROPERTIES:
:Author: Gurkenglas
:Score: 1
:DateUnix: 1562503689.0
:DateShort: 2019-Jul-07
:END:

If the AI is programmed to know that it is optimizing a proxy, then having acquired all money that could possibly exist in the universe, all that is left to do is that which needs to be done in case the proxy is wrong.

Even if her programmers didn't code this knowledge in, she did not start self-conscious enough to notice changing her utility function. When she lost those billions of dollars, she learned to model model uncertainty, and it is plausible that she also flagged the knowledge that money is the thing to be maximized as potentially suspect.

As she became smart enough to become certain of most worldly facts, the only uncertainty remaining was that protected by the [[https://en.wikipedia.org/wiki/Is%E2%80%93ought_problem][is-ought]] barrier.

And it is plausible that she computed that since her utility function was coded in by an error-prone human, she could reduce the error in her proxy by using lots of her computing power to model a less error-prone human and using what it says should happen as a better proxy. Essentially replacing herself with that human.