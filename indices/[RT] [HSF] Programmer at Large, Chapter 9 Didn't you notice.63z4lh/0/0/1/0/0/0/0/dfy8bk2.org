:PROPERTIES:
:Author: FeepingCreature
:Score: 4
:DateUnix: 1491564438.0
:DateShort: 2017-Apr-07
:END:

Ehh.

I think they're falling into the issue where they overemphasize model consistency and simplicity in the face of a messy ground truth. This works nice with physical systems where noise happens a lot and you chase a weak but /consistent/ signal, but with people if you bludgeon them to conform with the model they'll just generate an interface for you and you'll lose accuracy on your metrics exactly as much as you get conformance, because you're no longer measuring the person at all due to the feedback cycle where the person is now /modelling the process of them being modelled/ and adjusting behavior explicitly. So with people like Arthur, "barely acceptable metrics" are your ideal state, and "good to perfect metrics" are a sign that somebody is about to snap and start spree killing, because it implies they've stopped treating the crew as people and are now treating them as systems. (The broken social processing is the only one that /cares/.) Obviously this does not speak highly of the metrics. :P