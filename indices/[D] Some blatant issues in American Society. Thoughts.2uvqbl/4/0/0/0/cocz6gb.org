:PROPERTIES:
:Score: 3
:DateUnix: 1423222429.0
:DateShort: 2015-Feb-06
:END:

Excuse me, I think we need to play "if by politics".

- /If by politics/ you mean organizing the material substrate of society so that everyone can live their lives efficiently, FAI can do that.

- /If by politics/ you mean actual social relations between people, FAI /shouldn't/ do that.

Disentangling those two is going to be tough -- people have a lot of their lives tied up in using bits of matter to relate to each-other. Besides which, FAI is a long way away. The most I've seen done to bring it closer was Bostrom releasing /Superintelligence/, which seems to have raised the Very Serious Issue status of FAI from "those cranks at LessWrong think that's a thing" to "that's a thing".

I'm such a novicey novice at this that it'll take years before I can say, "oh yeah, a specific viable indirect-normativity design would generate an agent that would solve the problem /something like this way/", and even that would be a rough sketch, since you're talking about not only optimizing based on massive amounts of information about society /and/ well-approximating lots of computationally hard problems. An eventual FAI would probably have an advantage in both departments, but I'd bet we'll be surprised by some social problems that really do turn out subject to some hard complexity constraints.