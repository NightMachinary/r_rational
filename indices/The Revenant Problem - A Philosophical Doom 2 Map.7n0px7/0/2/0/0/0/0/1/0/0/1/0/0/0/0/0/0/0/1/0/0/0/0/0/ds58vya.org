:PROPERTIES:
:Author: ArgentStonecutter
:Score: 1
:DateUnix: 1515013126.0
:DateShort: 2018-Jan-04
:END:

OK, snowflake, now address the actual content without pearl-clutching over the side comment that triggered you.

#+begin_quote
  #+begin_example
    because you were already ensuring that there was no vehicle next to you
  #+end_example

  You don't have [entire] control over this.
#+end_quote

Even assuming the AV recognizes the obstacle as a human, the probability of the rare situation where /two/ asshole humans decide to box you in /at the exact moment/ someone "falls out of a car" in front of you /and/ there is light enough traffic that the car behind you isn't going to run them over anyway, is basically so close to zero that it's ignorable. It's a black swan, or as [[/u/stale2000]] called it, a zebra. Any code that's designed to deal with situations like this is more likely to cause crashes through false positives than save lives.

EVERY actual "trolley problem" scenario anyone has EVER presented me is just total bullshit like this.

Even with hundreds of millions of vehicles, this is an impossibly rare condition. Every step is rare. You need heavy enough traffic that two people box the vehicle in from either side despite software that is actively avoiding that situation. But it has to be light enough traffic that even if it avoids hitting the person they won't get killed by the vehicle behind them. AND just as this happens, someone falls out of a car in a way that is completely unpredictable (that is, for example, it's not kids in a truck bed because the AV would have avoided that as soon as it detected it). AND on top of all that, the AV has to be able to predict that the asshole human they decide to sideswipe will give way on being sideswiped instead of, for example, swerving crossways and hitting the human and a couple of other cars and creating a pileup.

No, it's not a credible scenario. It's bullshit. You know it's bullshit or you would have defended it.