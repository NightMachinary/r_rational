:PROPERTIES:
:Author: sparr
:Score: 2
:DateUnix: 1514727489.0
:DateShort: 2017-Dec-31
:END:

#+begin_quote
  Because properly programming an autonomous vehicle has to be about avoiding getting to that point
#+end_quote

And just give up if you encounter a situation you couldn't avoid?

#+begin_quote
  every time your software realizes it has fucked up.
#+end_quote

Ahh, spotted your mistake. You seem to be assuming that if the car needs to calculate how many people it will kill, it has [already] fucked up?