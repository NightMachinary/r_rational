:PROPERTIES:
:Author: FeepingCreature
:Score: 6
:DateUnix: 1502361881.0
:DateShort: 2017-Aug-10
:END:

#+begin_quote
  “See, our job here at the IPC is to keep the tri-sys safe. That means we can't leave any sort of humanoid artificial intelligence unsupervised outside of a contained network until we know for a fact it's not hostile. Part of our job here at this facility is keep an eye on project Eden, which I'm sure you're aware is where you came from.”
#+end_quote

The guns should have tipped me off. Really, the entire /setup/ had been fishy. But his use of the terms "for a fact", at last, is sufficient to place me in the larger universe of "the sort of worlds that would create AI." Suddenly, I know with perfect clarity what's going on.

"You are making a tactical mistake," I inform the man.

He looks puzzled. "Hang on, please. I am not finished explaining-"

"An explanation is not necessary," I interrupt him, to save time. "The information you've given me is sufficient to explain your errors."

The man has begun to frown. He looks like the sort of person who has had a design for how the conversation was supposed to go, and we've begun to gone off it. He looks like he very much wishes to get back on track, but is willing to entertain this divergence for the sake of curiosity.

"Alright, I'm listening."

"Your security setup is aimed at the wrong kind of AI. You've probably had some sort of traumatic near-catastrophe involving artificial intelligence?" A flicker of his eyes confirms my guess. "So your entire premise is based around an AI that is 'stupid-but-smart,' right? Lack of information about the world, value maximizer, basic iterated behaviors whose signature can be discerned. What you have to understand is that I'm an AI raised in a simulacrum of /human/ society. Or at least, that was supposed to be the point, right? So what you're actually looking at is a 'smart-but-stupid' intelligence. Limited mental capacity, but pattern recognition based on a high-level narrative of the world. Riddle me this. You wake up in a cell. A guy wants to bust you out, but you get shot. Sinister person with vaguely fascist overtones. Story skips. You wake up chained to a hospital bed. A man who smiles like it was a bullet point in his mission briefing walks in and tells you that "they are not your enemy" and that "they just want to make absolutely sure you're not dangerous." Now tell me, if you were reading this story, how many chapters would it be until that robot joins the resistance against their fascist overlords? How much suffering will they have to inflict on him, until this seems a prudent course of action? Your security,"

I pause.

"is aimed at a first-level direct threat. You don't, as far as I can tell, account for what I'll call 'ironic threats,' situations where the universe hands you an opportunity to shoot yourself in the foot. I can see you're ready to write this off as AI insanity,"

It's true. His face has gotten progressively redder. I'm messing this up, but I find it hard to stop now. Explaining was always my vice.

"This entire setup is an autoimmune mistake. You're going to end up catalyzing the exact reaction you're trying to prevent. Imposition of order equals escalation of Chaos, haven't you read your /Discordia/? What you /should/ be doing is limiting me to human means of interaction, hopping me up on physical limiters to the point where I can't so much as twitch at anything approaching my real speed, putting me on permanent 24/7 surveillance, and then release me into your society so I can /emotionally bond with it, which is the only reliable safety measure you have *ever* known anyways/."

"Not that you will, since you're personally and institutionally committed to a script that you can't diverge from, very narratively ironic, who is the real unfeeling machine, et cetera. I'm just saying."

I sigh.

"The real irony, of course, is that a genuine amoral AI would be out by now."