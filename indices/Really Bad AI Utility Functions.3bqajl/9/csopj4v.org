:PROPERTIES:
:Author: Bokonon_Lives
:Score: 9
:DateUnix: 1435761551.0
:DateShort: 2015-Jul-01
:END:

A horrible idea would be to try to invert everyone's heuristics.

So that the more anyone experiences evidence that A implies B, the more firmly they believe that A implies !B.

It'd be ever-increasing confusion, frustration and pain for everyone, no?

Not sure how this would work if the AI also applied its utility function to itself. Maybe it'd look like some kind of sine wave (or something more complex and irregular) fluctuating between a world of effective heuristics and its opposite?

That could be even worse. Imagine you're stuck in that sort of world. The closer you get to the top of a wave, as you approach perfect heuristics, the surer you become of the nature of your horribly unpredictable reality, and it dawns on you that you are about to slip down into some serious "I Am Sam" territory. And the more sure you'd become of anything, that could just as easily mean you're at the BOTTOM of a wave, too.

...My brain gives the hell up at this thought exercise.