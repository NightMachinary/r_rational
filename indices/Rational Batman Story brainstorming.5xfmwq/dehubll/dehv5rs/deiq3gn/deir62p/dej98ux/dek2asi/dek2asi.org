:PROPERTIES:
:Author: mcherm
:Score: 3
:DateUnix: 1488763672.0
:DateShort: 2017-Mar-06
:END:

Perhaps. I suppose there are (at least) three forms of ethical constraints. One is a kind of heuristic for one's fundamental values. For instance: "I base my fundamental values on maximizing total human welfare, but I have observed that it is nearly always better to let someone live than to kill them, so I'll use 'do not kill' as a reasonable presumption unless I find myself in a very unusual situation."

A second form is as a constraint for an untrustworthy reasoner. The superintelligent AI that has constraints programmed in is an example, but another would be "I, Bruce Wayne, have a terrible thirst for revenge against criminals lurking at the depths of my psyche. I suspect that if I ever really let loose, I would go on a huge murder spree. So I have laid down strict rules I must NEVER violate, such as 'do not kill'. If I ever made an exception, I fear I might lose the willpower that keeps me sane."

A third form is as part of one's underlying ethics. For instance, I am a strict Christian and I believe "God has specifically provided 10 commandments, one of which is 'do not kill'. My highest moral objective is to obey God's laws. Sometimes it appears that these laws cause more harm than good, but the ways of God are mysterious and the most ethical thing to do is to follow the rules regardless of apparent outcome."

In the first case (ethical constraints as an heuristic), Batman should realize that the Joker is a special exception and should change his ethical constraints. But for the second case (constraints on an untrustworthy reasoner) he should not. And for the third case (underlying ethics), the constraint IS his fundamental objective.