:PROPERTIES:
:Score: 1
:DateUnix: 1434495920.0
:DateShort: 2015-Jun-17
:END:

Well to me it's not about "how many hours", it's about "how much of my /natural/ lifespan as my /original/ self have I exhausted." You're positing a model in which there is only one way to extend the lifespan of anyone like me, and it involves a discontinuity that destroys one version of me and makes another. The second one can live quite long, but if we assume that /I just am/ the first one, then I should care about /my/ lifespan /as the original/, not out of any lack of "altruism" towards the next version, but precisely because if the two are separate individuals, then they're ethically equal and the one who's already vastly better-off should accept a trade-off to help the worse-off.