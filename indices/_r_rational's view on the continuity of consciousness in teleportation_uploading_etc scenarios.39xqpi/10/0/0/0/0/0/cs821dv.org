:PROPERTIES:
:Author: philip1201
:Score: 4
:DateUnix: 1434429827.0
:DateShort: 2015-Jun-16
:END:

#+begin_quote
  I wouldn't drive an hour to spit on you for that much,
#+end_quote

I'm fine with raising the stakes. How does $1,000 / $100,000 sound to you? If you don't have the money lying around, I'm fine if you pay at least $5,000 now and pay 4% interest rate over whatever you don't pay.

#+begin_quote
  especially not with that sort of weaselly risk profile on the other side
#+end_quote

Explain.

#+begin_quote
  Certainly not with your apparent ability to think rationally.
#+end_quote

The way you've phrased it, it almost seems like you're being sensible and acknowledging I'm capable of good. I'm pretty sure I'm misunderstanding you.

#+begin_quote
  I don't have time for your sophomoric internet dick-measuring wastes of time.
#+end_quote

But surely you have time for money? If you're confident, this would be the easiest $1,000 you ever make.

#+begin_quote
  You and your ilk don't value continued existence of intelligent beings, and only value the functional output of their processes.
#+end_quote

False. We value the content of the processes, not the output. (except to the extent that the content is a succession of infinitesimally separated outputs).

#+begin_quote
  A person is not matter running a program which can be copied at will, even with a magically perfect process. A person is the specific continuing collective process of the matter and the program running on it.
#+end_quote

Physics is a mathematical process of information exchange as well, which means matter can be simulated. If it is necessary to preserve the person - if it is necessary to have the program engage in the same fundamental behaviour - then the matter that makes up a person's brain would have to be simulated as well, and we would aim to do so.

#+begin_quote
  The same way rearranging every electrochemical connection in the brain kills a person, so does simply copying information (even perfectly) from them and then destroying their body.
#+end_quote

No. Rearranging the electrochemical connections changes the information-theoretical behaviour of the brain. Copying the brain perfectly means keeping the information-theoretical behaviour the same.

#+begin_quote
  but you still killed a living, thinking person to do it.
#+end_quote

I can't believe you're still upset about this. Surely you can understand that /if/ someone isn't dead after being killed, being killed isn't so bad?

#+begin_quote
  They don't "wake up" in the clone, or some other trashy sci-fi nonsense. Not that you've said so, but that's pretty typical a delusion for futurists to have, even subconsciously.
#+end_quote

Correct. In my way of viewing things, "me" isn't a conserved quantity: there may be several people in the future who all are equally me, or there may just be one. When I say I don't want to die, I mean that I want at least one of me to exist in the future. Teleportation creates one of me who is in the right location and kills one of me who is in the wrong location, so I'm okay with that trade. The wrong me does die, and for that reason I would want it to be quick and painless even if I don't remember it (though remembered pain does have priority). The decision to kill the wrong me is independent from the decision to create the right me, but if it's good for there to be several of me, it makes no sense to wait for them to be randomly created/not-killed in teleporters.

I don't want to die because I want to continue existing, because I think it is good for me to exist, and because it causes pain in me and those I care about. (1) is taken care of if there is another one of me elsewhere with all identity I care about preserving. (2) may be true or false depending on circumstances; but if true it's not a teleporter but a duplicator. (3) is also not true if there's another one of me.

I think one of the weird things about teleporters is that in most settings where they're used the answer to (2) is true: there really isn't a good reason to kill the originals. It's hard to imagine a universe so optimised, so /good/ that human beings are the morally best fuel source. At least to imagine something that would be that good; the consequences for physical humanity are a little more obvious.

#+begin_quote
  But if all you care about is having something that does the same things, why should it matter? Self-preservation. Obviously. Because you will die if you do that.
#+end_quote

I am not an extraphysical object with no physical method of detection or preservation, I am a process which is being "done". If I have something that "does" me exists, I exist.