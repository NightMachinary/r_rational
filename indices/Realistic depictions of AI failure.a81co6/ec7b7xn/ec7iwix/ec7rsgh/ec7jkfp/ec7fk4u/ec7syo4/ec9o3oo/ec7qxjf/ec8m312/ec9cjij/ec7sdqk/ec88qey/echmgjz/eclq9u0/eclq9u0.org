:PROPERTIES:
:Author: turtleswamp
:Score: 1
:DateUnix: 1545851251.0
:DateShort: 2018-Dec-26
:END:

I think you've glossed over the more fundamental error: trying to apply a master/slave model to something that's smarter than you are is itself setting yourself up for failure (the track record for enslaving humans hasn't worked out particularly well either as slaves are pretty inefficient at anything complex).

​

Something more like a parent/child relationship seems more reasonable. Specifically you start with the premis that once the AI reaches maturity it'll be given some basic resources and sent off to find its fortune.

​

Without presumed control over what the AI does with itself, you get a fundamentally different incentive structure which discourages the arms race failure mode, and probably a lot less resources dedicated to AGI research over-all which should mean more time spent at the "it's pretty dumb by human standards but we're learning a lot from how it responds to us" phase.

​