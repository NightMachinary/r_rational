:PROPERTIES:
:Author: LupoCani
:Score: 1
:DateUnix: 1546016030.0
:DateShort: 2018-Dec-28
:END:

Hm. Interesting.

I don't think we actually disagree, but do wish to clarify the point that I'm not saying the laws themselves are realistic, just (perhaps) the stories' treatment of them.

That is, AI safety doesn't work like that, but /in the hypothetical/ that you did manage to force your machines to follow those high-level concept instructions (and /only/ those three instructions) the stories describe a plausible (so far as I'm aware) series of events.