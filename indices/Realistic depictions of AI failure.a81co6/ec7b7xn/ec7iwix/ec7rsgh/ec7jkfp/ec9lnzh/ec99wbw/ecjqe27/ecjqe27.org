:PROPERTIES:
:Author: LupoCani
:Score: 1
:DateUnix: 1545777701.0
:DateShort: 2018-Dec-26
:END:

That's uncharitable, and at least somewhat untrue - I've heard nothing to indicate Asimov "didn't take the laws seriously".

His works were among the first to explore something /like/ serious AI safety - robots follow instructions, and the conflict revolves around how superficially sound directives cause them to act counter to our intentions in edge cases. The laws, in the accounts I've heard, were written with this in mind, and are essentially distillations of the principles we apply to /any/ tool - human safety first, usability of the tool second, durability of the tool third.

As for whether they're realistic, I'd say they're a fair exploration of an unlikely premise. The constraints placed on robots in the novels - they can understand high-level concepts like "human" and "harm", but only three fundamental directives have been given using this, and nobody can make a robot without these directives - are exceptionally unlikely to resemble real-world AI safety, but given them as a starting point, the novels take it (I hear) to a reasonable conclusion.