:PROPERTIES:
:Author: artifex0
:Score: 12
:DateUnix: 1437496999.0
:DateShort: 2015-Jul-21
:END:

Some good criticism here, although I have some quibbles.

First of all, the idea that an AI couldn't modify it's own programming. Obviously, there isn't any technical reason an AI couldn't do this- with access to a copy of its source code and a compiler, it could create a modified version of itself. So I have to assume that the researchers' objection is philosophical- all of a mind's decisions are intended to promote its fundamental values and directives, so it wouldn't have any motivation for deciding to change them.

I don't think that's the case, however. Say you had an intelligent AI with the singular motivation of convincing a researcher to say the word "pineapple" once. Suppose the researcher told the AI that he would say the word if the AI were to modify its motivation in some way. I think it would be rational for the AI to do so.

Say you were offered immortality in exchange for marginally decreasing the pleasure you receive from looking at sunsets. Even though enjoying sunsets is apparently an instinctive response, and the degree to which you do so constitutes a part of your identity (as opposed to being a means to some other end), I think that would be a reasonable trade.

In reality, we arguably do choose to modify our values and motivations- if only temporarily- every time we drink alcohol or get high. In a broader sense, whenever we choose to experience anything novel, we do so knowing that it could have permanent effects on our personality and disposition.

I'd say that a conscious being- AI or human- might choose to alter what it values if it thinks that the act of doing so would promote those values to a greater degree than continuing to value them.

Also, I'd be very curious to know why the researchers think that the digitization of human minds is impossible. I mean, I'm sure it would be much more resource-intensive than a similarly sentient AI, since you'd have to emulate a lot of biology. And, unless we could figure out a way to scan objects with an incredible amount of detail, it might be a lot more difficult to produce than an AI. But, surely, simulating any physical process is at least theoretically possible.