:PROPERTIES:
:Author: gjm11
:Score: 11
:DateUnix: 1616161816.0
:DateShort: 2021-Mar-19
:END:

#+begin_quote
  two or three strikes happening simultaneously
#+end_quote

Fair enough. But I don't think most of what Galt says makes sense if interpreted as being about the "other" strike, the one that arises from lots of sub-Gulch people being so offended by "Woke Classism" that they refuse to do good work any more. He says that "/I have/ stopped your motor", that "/I have/ withdrawn" those who live by the mind. He talks about the terms on which those people might be persuaded to return to sharing their productivity with the world as a whole. None of that makes any sense if applied to millions of ordinary-but-clever people across the world whose despair at "Woke Classism" has made them reluctant to work well. All of it makes sense if applied to the ~1000 people Galt has persuaded to run away to the Gulch.

(Pedantic note on population: AS was published in 1957, when the population of the US was about 170M. It's now about 330M. So less than a factor of 2. But let's stick with your numbers: 10k after adjustment to the present world population. In other words, about one millionth of the population.)

#+begin_quote
  Did you actually read the speech, or just scan through it for lines that seemed open to attack?
#+end_quote

Yes, I did actually read it. No, I didn't just look through for things that seemed open to attack. But yes, I /did/ look for things in the speech that make the particular points you were claiming Rand never makes; I don't see that there's anything wrong with that.

As to the actual point I was making there: if I've understood your response correctly, you're saying that Galt is saying not "if you ever want an industrial society again, you will need /us/ and therefore have to abide by our terms" but "if you ever want an industrial society again, it will need to be built according to our moral principles because that's the only way to build a moral society". I don't think that's credible at all, for two reasons.

First, look at how that paragraph begins. "In the name of all the producers who had kept you alive and received your death ultimatums in payment, I now answer you with a single ultimatum of our own: Our work or your guns." What's at stake, according to Galt, is "our work". That seems to me to fit my interpretation much better than it fits yours.

Second, the argument you say Galt is making /is not in any way credible/ and I think that should have been obvious even to Rand (in the real world) and Galt (in her imagined world). We have /had/ an industrial society. It's worked pretty well. And it /wasn't/ run according to strict Randian/Galtian principles. Sure, in AS we're asked to suppose that it's all gone terribly wrong; but even if so, in both the real world and the world of AS industrial society was built and sustained for many years on terms very unlike Galt's.

#+begin_quote
  In terms of moral obligations, at what point /do/ you actually get to just be happy?
#+end_quote

The argument I think you're making here is based on a very debatable premise, and one that I /think/ Rand would have been quite cross about. Namely, that somehow we know from the outset that morally speaking there /is/ some point at which you "actually get to just be happy". I think Rand would have said: morality is determined by reason, and the proper moral values are whatever they are, and the way to find out whether we ever get to just be happy is to work out what moral values are dictated by reason and then see what the consequences are.

Of course, if you hold that moral values are subjective -- that somehow we /choose/ our values -- then it is eminently reasonable to say "we should choose values that human beings can actually live by without going mad", and then you might indeed take "actually getting to just be happy" as a requirement. But I'm pretty sure Rand would have thought that was an appallingly wrong way of proceeding.

Personally, I don't care what Rand would have disapproved of and I am something like a subjectivist: I think we do in some sense get to choose our values, though we don't get to choose what human nature is like or what world we're living in, and therefore some sets of values we might pick have predictably awful consequences. I would distinguish between values simpliciter and moral values in particular; what I value /morally/ is something approximating to "the greatest good of the greatest number", but my moral values are not my only values, I also value (e.g.) taking care of my family and having fun; for good or ill, the things I value are many and varied and don't all pull in the same direction, so I end up compromising: I devote some of my time and effort and money to the general good (at least as I see it), and some to my own selfish enjoyment. I don't see any reason why there should be any point at which I literally stop caring about the world, nor any point at which I literally stop caring about myself, so no, I never get to /just/ be happy (nor ever get to /just/ work for the Greater Good and ignore my own needs and wants), but in practice it turns out that I can do quite a lot of good and have quite an enjoyable life and take pretty good care of my family and so forth, and I don't see why I should assume that -- the world being what it actually is -- anything better than that is possible. Note that this is /not/ either the extreme case of "the enslavement of all to all" /nor/ the extreme case of caring only for one's own happiness. I would find either of those rather monstrous.