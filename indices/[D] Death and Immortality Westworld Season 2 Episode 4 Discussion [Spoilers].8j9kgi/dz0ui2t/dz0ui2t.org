:PROPERTIES:
:Author: Sonderjye
:Score: 2
:DateUnix: 1526402373.0
:DateShort: 2018-May-15
:END:

I didn't initially look at this because I haven't seen westworld and didn't want spoilers in case I decided to.

A friend recommended it because they thought I'd enjoy the exploration of whether robots can be concious/sentient or not. It sounded like a consealed question in which they really asked whether robots could be morally valueable. And in my mind that answer is already set at something like 'less valueable than humans but far more valueable that you can't murder them for fun', and then it seemed less interesting. Is there more to the series that that?

Your questions resonate with me though. If immortality were invented today I don't think you could feasibly keep it from the rich and powerful, given our capitalist structure. Worse, wealth distribution would be even more concentrated on a few individuals since they would keep accumulating endlessly. I honestly think that you need a strong international organization similar to the EU for that society not to end up as a dystopia, however I have yet to think of a good structure to avoid corruption.

Don't focus as much on sadists though. There's plenty of consensual sadists and consensual masochists, and presumably there would be laws in place to punish people or remove people who caused nonconsensual pain in a post-scarcity society.

I don't know the specifics of the Delos copies(and don't want to know too much details in case I decide to watch the show), however there's a difference between consent and informed consent, and you should always be able to retract your consent at some point during the experiments. I'd take large quantities of pain and torture if it meant I were able to live forever afterwards, even if my body's reaction to said torture would be to do anything to make it stop. Would I sacrifice copies of myself though? I'm not so sure.