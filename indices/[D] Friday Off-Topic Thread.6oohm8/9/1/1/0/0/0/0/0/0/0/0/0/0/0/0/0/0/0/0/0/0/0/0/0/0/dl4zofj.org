:PROPERTIES:
:Author: CCC_037
:Score: 1
:DateUnix: 1501809978.0
:DateShort: 2017-Aug-04
:END:

#+begin_quote
  I don't think you got the point I was making, that any post singularity civ could easily run a sim of our civilization, provided they just simulated the minds. This isn't a point about the processing power within the sim, just that massive non-baseline sims aren't hard to run for post singularity civs even in universes with the same physics as we think our universe has.
#+end_quote

Ah, so you're saying that in a universe that actually /is/ as our universe /appears/, a sufficiently advanced and dedicated civilisation could run a mind-level sim of our universe, for at least a few minds (and, depending how much computing resources they decide to pursue, potentially quite a lot of minds).

Agreed, but this again leads us to the question of /why/.

#+begin_quote
  I can point out the specifics about why that's not a remotely simple or self consistent ethical system, but the larger problem here has to do with apparent versus actual complexity.
#+end_quote

Okay, noted, actually /implementing/ such an ethical system is a thorny minefield of problems and edge cases and complexity. I'm not proposing this idea as a complete or even a partial solution to AI safety. I'm merely suggesting that an ethical system that puts strong value on self-determination by other intelligent entities would have reason to not instantly obliterate any intelligent life it comes across.