:PROPERTIES:
:Author: vakusdrake
:Score: 2
:DateUnix: 1501463470.0
:DateShort: 2017-Jul-31
:END:

#+begin_quote
  Any universe which is running ours as a sim needs to have significantly more processing power than we have available.
#+end_quote

Given we were talking about a mind sim that's absolutely not true, deconstructing /even just the earth/ would give more than enough resources to run numbers of human level minds that are far too large to even really be comprehensible to humans and vastly dwarf the numbers of humans who've ever lived.

#+begin_quote
  As long as the probes to other star systems are sent out in time, I'm failing to see how it matters whether it takes ten year or ten million to absorb a given system.
#+end_quote

That would be true if we were living in a steady state universe, but our universe is expanding and so galaxies are constantly travelling over the cosmological horizon so that we will literally never be able to reach them even travelling at lightspeed. Plus if you care about not having large parts of your civ not forever isolated, then you will want to use star lifting to counteract galaxies movement away due to expansion

#+begin_quote
  I don't think that there's any way in which having grizzly bears on the planet with us is a significant benefit to humanity, yet we're willing (as a species) to go to quite some effort to ensure that they don't get wiped out. Maybe it's an AI interested in nature conservation?
#+end_quote

It's rather hard to imagine how exactly how you get an AI programmed with that sort of ethical system. After all drawing a distinction between digital and analog minds seems just a rather weird human thing to do. So it's hard to imagine what bizarre nonsensical goal alignment would lead an AI to decide to build nature sanctuaries as opposed to just uploading every living thing of moral significance, or deconstructing the planet in order to build habitats for the animals to live in.