:PROPERTIES:
:Author: RMcD94
:Score: 1
:DateUnix: 1523387501.0
:DateShort: 2018-Apr-10
:END:

#+begin_quote
  Lois tries to convince Superman to spend every hour of his every day improving life for everyone else, when she is unwilling to make such a commitment herself,
#+end_quote

But being unwilling doesn't mean she thinks that she is in the right.

Also depending on her ability to improve the lives of other peoples its perfectly conceivable that your effort you put in could not be adequate enough for a net utility gain though Lois as a first worlder probably could easily do so. If Lois ever said that superman has a moral obligation and she doesn't because they don't even fall under the same moral system and there is no context in which she can compare their morality then I missed that bit.

#+begin_quote
  Luthor thinks that Superman is obliged to kill himself because there's a miniscule chance that he snaps and decides to massacre humanity, which, even on average, outweighs all of the good he might possibly do.
#+end_quote

Again this is consistent. Luther thinks that extinction is worth infinite value. Therefore nothing Superman would be a net utility. They are both operating under the same system just with a different evaluation of utility.

#+begin_quote
  I would never try to teach a dog utilitarianism, but I can teach the dog to be friendly and obedient to his owner, which, given a dog's abilities, is about the best I can do, and, given a morally good owner, should be functionally equivalent.
#+end_quote

Well of course not but that's because if you personally are a utilitarian you want other people to maximise utility, not to be utilitarians. Those are two closely aligned but separate considerations.

Wait a second what on earth was I saying in my previous comment? Even egoists would not want everyone to be egoists they'd want everyone to care nothing for themselves at everything for the sole egotist.