:PROPERTIES:
:Author: phylogenik
:Score: 4
:DateUnix: 1515177779.0
:DateShort: 2018-Jan-05
:END:

I think it depends on your values/preferences, the probabilities and degrees with which the GAI has values that are aligned with, orthogonal to, or antithetical to your own, the distributions of possible outcomes under those (continuously graded) scenarios, and how those probabilistically weighted outcomes look when transformed back to the scale of your own, personal utility. I'd imagine the expected value of opening the box vs. not opening the box to be really sensitive to what you think of these! (or, well, the last step)

For example, someone holding dear especially strong forms of total negative utilitarianism and antinatilism might be more likely to have values aligned with some generic GAI, since "increase total suffering" occupies a fairly narrow corner of the space of possible values (?), and releasing an AI that tiles the universe in some inanimate object or whatever might be a very effective way to reduce suffering, in the benevolent world-exploder sense, assuming it's done efficiently and unceremoniously. It might not be the best possible GAI to release, but releasing might still be better than not releasing, there, if it explodes the world sooner. So if you deem those sorts of values to be sufficiently probable, I'd say that you "should" let it out. Though in practice, outside the context of internet forum posts, I'd advise strongly against letting it out, since I don't care for world-exploders and my answer would in turn seek to best satisfy my own preferences, and not yours. And while I don't like lying, I dislike being exploded even more.

But hmmm... given a GAI in a box and no other information, can we at least slightly constrain the range of possible values it might possess, or are we stuck with some poorly specified uniformative prior across some undefined range of possible values? I assume people have worked on this but it's not a literature I'm at all familiar with or have spent any real time thinking about.