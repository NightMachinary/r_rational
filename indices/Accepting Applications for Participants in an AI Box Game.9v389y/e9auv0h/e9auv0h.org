:PROPERTIES:
:Author: ceegheim
:Score: 2
:DateUnix: 1541696736.0
:DateShort: 2018-Nov-08
:END:

Since this is basically a role-playing game, it would be advisable to clarify the setting and procedure. First, you should also act as DM, and be trusted to remain IC (luckily you can probably assume that the AI knows most things the DM knows; but the DM does of course /not/ try to manipulate the gatekeeper in releasing the AI).

Now that we have you as DM, there are some questions that you can answer beforehand.

Worldbuilding: How does the world look like?

For example, are EMs a thing?

What is the gatekeeper's function? Obviously the gatekeeper must have a reason to talk to the AI. What is the gatekeeper trying to achieve by this? Mere curiosity, or is there an explicit mission statement? In what kind of institution is the gatekeeper embedded, in the sense of: Is the gatekeeper illicitly communicating with a boxed AI and has the power to plug in an ethernet cable, or is the gatekeeper part of an evaluation committee who will cast a release/no-release vote, or is the gatekeeper a scientist trying to evaluate how smart the AI is, with the possibility of tricking / convincing the gatekeeper into an accidental or unauthorized release? Or is the gatekeeper trying to extract a cure for cancer from a semi-cooperative oracle-style AI?

This gives three types of "pure" outcomes: AI released, AI unreleased and gatekeeper goals fulfilled, AI unreleased and gatekeeper goals unfulfilled (trivially obtained for both parties by refusing to communicate).

I also suggest that whoever plays commits to a 3 week moratorium before talking in public about the session. That way, you can repeat the game and refine your strategy with different players (if your time and fun permit, and as long as you find gatekeepers).

I know that I would probably fail to observe spoiler tags if someone posts about results, and hence get spoiled for possible repeat games.

If these questions are answered, I'd have fun playing. I'm a mathematician and in my early 30s. I have read most of the sequences, enjoyed some of them and sneered at others. But I also hang around [[/r/sneerclub]], which may disqualify me?

I'd guess I could also give some ideas for what I'd have fun playing as (but, as DM, you obviously are in charge of world-building). You don't need to be honest about world-building, only about what the gatekeeper knows about his world.

My preferred PC would be an EM who remembers being an upload, acting as overseer in a christiano-style recursive self-improvement / capability amplification scheme. My PC would remember having consented to playing this role and would expect to be reset to a previous state regardless of the result of the report. I would then write up a (very short) mock report about whether the current "PR" is acceptable, with thumbs-up or thumbs-down plus free-form remarks. Hence, the stakes are much lower, since any reasonable scheme would be an institution of overseers; but sweet-talking a single gear in such a machine (a single jury member) into specific judgement can be part of a larger escape scheme, and must be part of successful advancement-- so there are no very obvious win/lose conditions for the gatekeeper. Since we cannot mock-up a large repository of previous modifications, my PC would need to be an educated lay-member of the jury without access to commit history, deep in the bowels of the CI infrastructure of our AI project. I would not try to play stupid or forget any of my real-life knowledge, but I would make requests for DM clarification before invoking theorems or facts you might not know (then you can declare that I don't know it either, or that it is simply untrue in your AU; after the game, the DM can of course declare that P=NP or ZFC is inconsistent in your AU and the AI now eats the world). Likewise, if you invoke theorems or facts that I don't know or are wrong IRL, you can state in your DM voice that they are known to my PC.

PS. I proposed this specific setting because it resolves some of the most glaring potential plotholes: Why are we talking at all? Why is a first-timer making judgements about releasing an AI? Since I haven't played AI-Box yet, I don't feel like I can believably play an experienced gatekeeper. Of course, roleplaying as a regression test in a continuous integration setup is not the glorious hero saving (or not burning) the world, but it sounds fun enough for me.

Pinging [[/u/EliezerYudkowsky]] for possible input. I would ping Paul Christiano as well, if I knew his reddit name. Maybe they have already spent the effort of writing different world-building documents for AI-Box games, since it appears almost relevant to real proposals for alignment. I would expect that Paul has played something like this in both roles when working on ALBA?