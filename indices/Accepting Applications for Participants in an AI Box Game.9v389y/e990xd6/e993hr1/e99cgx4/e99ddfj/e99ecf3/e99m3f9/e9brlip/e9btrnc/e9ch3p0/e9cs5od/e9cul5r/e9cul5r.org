:PROPERTIES:
:Author: GopherAtl
:Score: 3
:DateUnix: 1541769976.0
:DateShort: 2018-Nov-09
:END:

I'm familiar with his article on meta-honesty, and I am highly confident guessing that he would consider the stakes in the issue of AI safety to be high enough to justify outright lying, at least in principle.

What I'm not so confident in is how he would assess the risk/reward ratio in this /specific/ case - would the benefits of /this/ lie be worth the risk of the consequences should the lie be found out? The risks, to me, seem very low, but my confidence in the correctness of that assessment is lower, mainly because I know almost nothing of his opponent, the only other person who knows and could reveal the truth. He obviously knows more and may estimate the risk differently.