:PROPERTIES:
:Author: MugaSofer
:Score: 1
:DateUnix: 1476266861.0
:DateShort: 2016-Oct-12
:END:

I've considered the idea of an existential risk boardgame before - my instinct was something like Risk, where there are cards for nukes, bio-engineered plagues, and of course AI (which grants more forces, but spawns a new hostile faction with superpowers if you're unlucky.)

I like the idea of "overshooting the mark is Failure, and stopping early is Partial Success". I'm not quite sure how to translate that into AI terms, though - general field advancement increases the die size (probably not a literal die), more safety-specific research increases the "success" window in one direction or another?

#+begin_quote
  sabotaging one-another's research
#+end_quote

Obvious possibility - that option is only available to the terrorist/criminal faction(s), and possibly the military/government faction(s).

Legitimate researchers have to ally themselves with Bad People if they want to reduce the risk of a Bad End that way.