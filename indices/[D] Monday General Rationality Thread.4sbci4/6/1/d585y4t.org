:PROPERTIES:
:Score: 8
:DateUnix: 1468261274.0
:DateShort: 2016-Jul-11
:END:

Well in the story, the creator had the technology in standard Macguffin form and was trying to avoid something obviously very bad like a standard Terminator/Skynet scenario, while also being themselves totally untrained in any notions about FAI or rationality and thus radically underthinking it. The result was accidental, not intended.

The point is not supposed to be, "design your post-Singularity utopias one way or another" but instead, "DO NOT casually employ technologies that can DESTROY THE WORLD ON THE FIRST PROTOTYPE."

For incrementalism versus radicalism, I kinda recommend reading Rosa Luxembourg or someone else like that. The general answer for "why take radical, high-risk measures?" is, "Because the status quo is bad, and getting worse, and /fights back/ against safe, incremental change faster and harder than we can push the safe, incremental change forward." Note that this theory originates in mere politics where a "catastrophe" is on the order of millions dead rather than /literal omnicide/.

DO NOT MESS WITH POTENTIALLY OMNICIDAL INTERVENTIONS.