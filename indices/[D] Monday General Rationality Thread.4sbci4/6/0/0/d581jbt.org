:PROPERTIES:
:Author: trekie140
:Score: 1
:DateUnix: 1468255482.0
:DateShort: 2016-Jul-11
:END:

First, I find it implausible that an AI could escape a box when the person responsible for keeping it in the box knows the implications of it escaping. Second, I do not see human intelligences make decisions based purely on utility functions so I find it implausible that an AI would. Third, and the point I am most willing to defend, if you think humans should not have self-determination then I'm concerned your values are different from most of humanity's.