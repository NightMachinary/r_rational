:PROPERTIES:
:Author: Chronophilia
:Score: 2
:DateUnix: 1468265451.0
:DateShort: 2016-Jul-12
:END:

I may have misread the story, but I thought it was a deliberate design decision for the AI to be unable to change its basic goals. Hannah knew that her design had the potential to take over the world, and so she made sure it would still behave in a predictable manner if it did. This is obviously preferable to an AI which can choose its own goals and which has no reason to keep humans around after the Singularity. And the slow, incremental approach was not an option because other groups were also experimenting with AI and she thought they risked accidentally releasing something like CelestAI. Which is not something that you want to do by accident.

Clever, but not as clever as she could have been.

Out of the story, I couldn't possibly comment. It's science fiction, not futurology.