:PROPERTIES:
:Author: BadGoyWithAGun
:Score: -1
:DateUnix: 1468264131.0
:DateShort: 2016-Jul-11
:END:

#+begin_quote
  Humans are not created with a fixed utility function.
#+end_quote

Wouldn't you say evolution imposes a kind of utility function - namely, maximising the frequency of your genes in the following generations?

#+begin_quote
  doesn't mean economically rational agents are impossible to build
#+end_quote

Why did you shift the goalpost from "definitely true" to "maybe not impossible"?

#+begin_quote
  nor that intellectual capability and goals or value functions are intrinsically related
#+end_quote

My primary claim against the OT isn't that they're "intrinsically related", but that a static/stable utility function in a self-modifying agent embedded in a self-modifying environment is an absurd notion.