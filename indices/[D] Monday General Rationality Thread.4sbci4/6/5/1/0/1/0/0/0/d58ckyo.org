:PROPERTIES:
:Author: gabbalis
:Score: 2
:DateUnix: 1468270061.0
:DateShort: 2016-Jul-12
:END:

#+begin_quote
  Using a faster heuristic isn't the same as changing utility function.
#+end_quote

Unless of course it is. In a well designed strong AI, of course you would make certain to form a distinction, and to ensure that the heuristic is the slave to the utility function. In Humans? Certainly we perceive a degree of distinction, but I am skeptical of the claim that the two are not interwoven to some degree. It seems likely that heuristics taint the pure utility function over time.

In any case, regardless of whether humanity is an example, it is still trivial to propose an intelligence whose psychology is incapable of separating the two, and is forced to risk goal drift in order to optimize its chances on achieving its initial goals.