:PROPERTIES:
:Author: BadGoyWithAGun
:Score: -9
:DateUnix: 1468254450.0
:DateShort: 2016-Jul-11
:END:

#+begin_quote
  I'm not convinced it's possible to create a Paperclipper-type AI because I have trouble comprehending why an intelligence would only ever pursue the goals it was assigned at creation.
#+end_quote

The [[https://wiki.lesswrong.com/wiki/Orthogonality_thesis][Orthogonality thesis]] is basically LW canon. It's capital-R Rational, you're not supposed to think about it.