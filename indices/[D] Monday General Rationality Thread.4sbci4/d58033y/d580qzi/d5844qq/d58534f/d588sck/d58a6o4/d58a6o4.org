:PROPERTIES:
:Author: gabbalis
:Score: 2
:DateUnix: 1468266871.0
:DateShort: 2016-Jul-12
:END:

Unless of course U1 and U2 are actually functionally identical with one merely being more computationally succinct. For instance, say I coded an AI to parse an english utility function into a digital language. It may be more efficient for it to erase the initial data and overwrite it with the translation for computational efficiency.

Similarly, replacing one's general utility guidelines with a comprehensive hashmap of world states to actions might also be functionally identical but computationally faster, allowing a better execution of the initial function.

A rational agent may make such a change if the odds of a true functional change seem lower than the perceived gain in utility from the efficiency increase.

This is actually entirely relevant in real life. An example would be training yourself to make snap decisions in certain time sensitive cases rather than thinking out all the ramifications at that moment.

This gives another possible point of irrationality in humans. A mostly rational agent that makes poor predictions may mistake U1 and U2 for functionally identical when they are in fact not, and thus accidentally make a functional change when they intended to only increase efficiency.