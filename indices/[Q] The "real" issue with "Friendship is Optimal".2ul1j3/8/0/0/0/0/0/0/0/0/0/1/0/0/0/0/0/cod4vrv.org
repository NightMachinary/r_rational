:PROPERTIES:
:Author: IomKg
:Score: 1
:DateUnix: 1423238079.0
:DateShort: 2015-Feb-06
:END:

#+begin_quote
  "Interacting with an AI is a problem that can be optimally solved without needing to play out all possible scenarios. This is a good thing, because playing out all possible scenarios is physically impossible. There's no point in even trying to do it; You can never make any meaningful progress. Doing it that way will never give you even the slightest advantage."
#+end_quote

Would it work the same if you changed "interacting with an AI" to "interacting with the world"?

If no what is the difference?

If yes then that seems to assume the universe, for all its unknowns would have a "solution" where solution is effectively Omniscience.

Now don't get me wrong, assuming Omniscience is possible is not much worse then assuming FTL drives are possible. And i definitely wouldn't hold an author as irrational if he\she included an FTL drive in the story.

Just the same as i wouldn't say an author is irrational because the universe included a subjective set of rules(i.e. that the universe favors heroic behavior, or if believing something should happen is enough to cause it), which would for example enable an MC to conveniently find a gun when he is in a pinch.

On the other hand if no such rule is even implied all throughout the story, and then at the final scene an event happens which i need to assume the rule is subjective as such i would consider that to be an issue.

Moreover even the assumption that an "optimal solution", or if Omniscience would be the default for a superAI it would not change the fact that i would further need to assume that the fact it has some very obviously abusable limitations it would not cause it a disadvantage.

You can find the optimal solution for tic-tac-toe, but if the game board you start with is with 2 moves already done, and the moves for your side are non optimal you are still going to lose.

To that you could say of course, "wouldn't deciding that said rules are a big enough disadvantage just another assumption that you hold?" to that i would answer that sure you could look at that as an assumption, similar to the assumption that given 2 AIs where one has a larger army it would at the very least not be at a disadvantage.

At the very worst this issue could be boiled down to the fact that without assuming humanity is first in the universe by multiple hundreds of thousands of years, no set of assumptions you can take on superAI warfare would result in CelestAI taking 15 galaxies.

If smaller AIs have advantage then celestAI would lose to some, if bigger AIs have advantage then it would lose to others, if the outcome is random then it would be extremely improbable that celestAI would win 15 in a row.

You would have to craft a lot of assumptions even if you ignore said disadvantages i mentioned, though i believe they are extremely reasonable.

#+begin_quote
  That is not an unreasonable plot device. That is a supposition. That is an axiom of the worldbuilding
#+end_quote

Just to clarify, there are plenty of world building assumptions that could have been made and changed the situation, but they were not made. some things are fine to assume implicitly, others are not. nerratively it wouldn't be reasonable for me to go over the story and try to find the most "efficient" assumption which would make it rational. If it were then we could make any story rational by crafting the right appropriate "world building" which was not done by the author.

In other words some effort needs to be done by the author to establish this information, other wise it is a problem.