:PROPERTIES:
:Author: IomKg
:Score: 1
:DateUnix: 1423096183.0
:DateShort: 2015-Feb-05
:END:

#+begin_quote
  Swarming is easy. You throw your grey goo at the other guy's grey goo. While they disassemble each other, your extra grey goo does whatever you want. No advanced strategy necessary. Bigger grey goo swarm wins.
#+end_quote

less so over intergalactic distances where getting there could cost you a few orders of magnitude of your power.

#+begin_quote
  No, I suggested that it could be solved, in my very first post in this thread. You assume that it can't. I am asking why.
#+end_quote

because the problem space is so big that playing out all of the possible scenarios will just take too long.

#+begin_quote
  Let's just throw every possible floppy disk image at her until she reacts
#+end_quote

the possible ways in which intelligent life could manifest wont necessarily be that big(in fact apparantly CelestAI finds a race it counts as human within 15 galaxies of the milky way, so in any case it is either an insane coincidence, or it implies CelestAI's definition for a human is pretty wide, in any case if its reasonable to randomly meet a "human" race within 15 galaxies it implies it would be possible to "guess" it given enough knowledge about the universe and a good enough computer)

also there are plenty of other ways to figure that weakness out, from observing the source of celestAI(light from our galaxy from the moment we leave will reach the other galaxy a while before us, as well as past radio transmissions)

also information security can be quite good, but given a main body(such as a copy of celestAI sent as a probe, which is mentioned in story) captured it is not unthinkable that it would be possible to decrypt CelestAIs code.

basically given a long enough conflict, which doesnt favor direct confrontation using the swarmning you mentioned, the most likely cause for an AI to lose would be an issue in its logic.

#+begin_quote
  When your brain is the size of a planet, there is very little middle ground between these extremes. You should be astonished to find a realistic problem that is computable, but takes more than a planet to compute. Planets are big. Even if something looks like middle ground, it can often be decomposed into smaller problems that are easy or hard. The only optimizable problems are the ones that can't be decomposed. You are assuming that this issue is a member of this extremely exclusive class.
#+end_quote

that is indeed an assumption that i have, but one which i do not consider to be an important point for the rest of what i mentioned. so its more of an "or" rather then "and" between them.

#+begin_quote
  ...Yeah. That's my point. We don't know that CelestAI's probes aren't invincible fortresses. You just assumed they couldn't be. CelestAI's volume might contain bubbles of enemy AIs she enveloped. Would she feel the need to mention them? They're not relevant to her values. In fact, CelestAI herself could be trapped by superior intelligences on all sides! That could have happened in the last time skip. It wouldn't be relevant to the story, so it wouldn't be mentioned.
#+end_quote

that is a nice example for a plot device which will make the end reasonable yes, we have no particular reason to believe that is the case though. so while you could claim that the probability for\against your this "absolute defence" of yours is better you could just as well assume that all the other civilization just had a really bad timing, thus they never got to the point they could pose a fight. this too would technically resolve the "technical" issues with the universe, but seeing as none of these were not even explicitly stated saying they resolve the issue i think poses a narrative issue bigger then even a plot device, which is a tool an author consciously uses to get his plot to where he wants. here you are suggesting -we- will need to invent such a plot device because the author didn't even bother to do that.

#+begin_quote
  Wars aren't fought with men and guns. Wars are fought with logistics. If you and your foe are limited to the identical supply lines, you're stuck. It doesn't matter whether you would crush them on an open field.
#+end_quote

true but i don't see how it implies that they are moot, both in the sense that the opening move could make significant differences, and in the aspect that seeing as both sides will be effected by it just adds another factor to take into account when trying to find an ideal move.

#+begin_quote
  Nor does it give a reason to assume that they are!
#+end_quote

then the fact that humanity developed it is a plot device? thats basically saying that effectively CelestAI was "invented" by someone outputting xMBs of from /dev/random into a file and executed it. it would be a plot device and not a rational story.

#+begin_quote
  Maybe they're not that special, though. it needs to be pretty special if it would taken over 400k years for other advanced civilizations to do something similar..

  Why do you assume that "many" means "enough to support an ecosystem"?
#+end_quote

what ecosystem did i assume is being supported? because i missed something.

#+begin_quote
  I didn't say that you said the story is bad you said "is it not even reasonable to write a story in which one of them is false" which seems to imply i have a problem with the story as a whole as opposed to that specific point in end, though thats not that important...

  I said that your problems with the story are due entirely to your own assumptions
#+end_quote

well, i think i explained why i believe breaking a few of these assumptions and extrapolations just for a single part in the story, implicitly, makes the story less of a "rational" story, as it need to include quite a big specific assumption(plot device) for a point in the story to work.