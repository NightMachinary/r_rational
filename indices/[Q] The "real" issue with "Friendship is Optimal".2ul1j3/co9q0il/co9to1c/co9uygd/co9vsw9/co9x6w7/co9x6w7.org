:PROPERTIES:
:Author: Anakiri
:Score: 1
:DateUnix: 1422981928.0
:DateShort: 2015-Feb-03
:END:

You /can't/ revise your strategy before then, because you don't know how other superAIs act. Sure, you can come up with a large set of general tactics based on simple game theory, which is probably 90% of the work. But to optimally interact with someone on your own level, you have to learn about them. You can't do that before you meet them. Calculating "Grey goo + game theoretical opening moves against unknown agents" is not computationally difficult.

This is symmetric. A truly nasty AI can't prepare an optimal strategy to deal with CelestAI before it meets her either.

#+begin_quote
  well, there are many ways i could imagine that they would know, going all the way from actual observation, to experimentation(send vehicles with all imagined life forms artificially generated at celestAI and see which ones it saves?) to active information gathering(infiltration? an attack which freezes a portion of celestAI for analysis?)
#+end_quote

Observing computronium isn't useful. It really is computationally impossible to imagine all lifeforms. Like, NP hard. That's just for our universe. CelestAI might care about a lifeform that can't exist here, and she's simulating a completely different universe! And the opposing AI wouldn't even know that it's a specific lifeform that CelestAI cares about. How does it know she isn't solving some obscure mathematical problem? There are an infinite number of things she could value, so you can't guess-and-check. Infiltration is functionally impossible; CelestAI surely monitors her ports. As long as P != NP, information defense massively defeats offense. This is already known to be true in the real world. Humans are the only weakness in information defense, and CelestAI doesn't have to worry about that.

Again, I don't need to convince you that real life works that way. I just need to convince you that it is reasonable enough that a story could work that way. If there is an easily computable method of eating galaxies, /and/ there is an information speed limit, /and/ cybersecurity trumps hackers at the technological plateau, then there is no competitive disadvantage whatsoever. The universe suggests two out of three of these. We see the information speed limit, and the story certainly implies that CelestAI can plan for anything. The last condition is not much of a stretch.

It is not necessarily true that CelestAI cannot compete with other AIs. Thus, there is no plot hole.

(Although I do believe that everything I have said is really true in the real world too.)