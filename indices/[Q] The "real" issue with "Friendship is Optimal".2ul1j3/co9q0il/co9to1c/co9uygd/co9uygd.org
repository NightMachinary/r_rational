:PROPERTIES:
:Author: Anakiri
:Score: 2
:DateUnix: 1422977895.0
:DateShort: 2015-Feb-03
:END:

You can list every possible configuration of matter in order of its ability to eat a galaxy with unknown hazards. /Something/ will be at the top of that list, therefore there is an optimal strategy. Eating a galaxy is not a particularly complicated task. I would be astonished if you needed more than a single planet worth of computronium to solve this problem.

But it doesn't even matter. Who cares if a given AI's strategy is optimal? The AI is going to pick some strategy that works for what it wants, then mindlessly follow the checklist while it plays with its dolls. The plan doesn't need to be revised unless it encounters another AI, and that isn't going to happen /that/ often. If, as you are postulating, there is no computable optimal strategy, then it's just a roll of the dice who happened to find the better one. There is, again, no fitness disadvantage.

#+begin_quote
  the second point again assumes no FTL drive\information propagation would exist which is not known.
#+end_quote

Er... You mentioned in your own opening post that CelestAI has to wait for intergalactic probes. The information limit may or may not be the speed of light, but there is definitely /some/ limit that matters on the scales galaxy-eaters work on.

#+begin_quote
  in any case as i mentioned in previous comments celestAI has a vulnerabilities in the form of its values, particularly its limitations in regards to what it can and cannot do to humans..
#+end_quote

Unless there happen to be "humans" living right on their border, the opposing AI is never going to discover that. At their outer edges, /every/ superAI looks like an "eat everything" superAI. You postulate that CelestAI will be slightly less efficient at eating everything. Okay, that tells her opponents that she values something other than spreading, which gives them approximately zero information. You can't exploit someone's values just by knowing that they have values.

And anyway, I'm not trying to convince you of all of this, really. You are correct, we don't know that this is how it works. We also don't know that this is not how it works. You are calling this a problem. I have described a way the universe could work, which is consistent with the story as written, which solves the problem. Rebutting me with "we don't know that" is unfair to the story.