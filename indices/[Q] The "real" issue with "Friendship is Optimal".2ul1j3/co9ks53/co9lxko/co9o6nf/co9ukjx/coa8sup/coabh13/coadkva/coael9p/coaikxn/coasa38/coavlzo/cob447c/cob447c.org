:PROPERTIES:
:Author: IomKg
:Score: 1
:DateUnix: 1423074004.0
:DateShort: 2015-Feb-04
:END:

#+begin_quote
  I'm willing to entertain the idea that that isn't a well founded position for me to take. So why is that a problem? Well I don't actually claim that you assumption is a problem, in the sense that it is not the main point for me in the first place. The story does gives us that fact, so in its context you end up basically saying that that fact in and of itself is already illogical and conflicting with the state of the universe as we know it. The main differences between what we are saying is that you basically rejected that part of the story directly, and I was willing to let that point slide until it specifically conflicted with a high level observation of the universe which directly affected the story on its main topic. CAI would have the initial examples of that "ponies and friendship" part containing sapients uploaded into itself and running in simulated worlds become a smaller and smaller part of its systems. The big issues for it, that other AIs won't have, are related to this.
#+end_quote

Not only this, there are also the implicit rules celestAI has regarding what it can't do to humans, such as kill them(though I am not claiming that is 100% correct, but I think the information in the story does point to it). Which is extremely abusable, there is still an open question regarding how likely would it be for the weakness to be figured\found out be the enemy AI, but I think once it is discovered I believe it would lead to a pretty unconditional lose against almost any size of an enemy superAI. And I believe that given a long enough relatively “passive” war it would be expected for such a weakness to be discovered

#+begin_quote
  And which we've also (I think) agreed it could even throttle down further in the face of major threats.
#+end_quote

Agreed

#+begin_quote
  I'm using STL drives that move at the speed of light -- not reasonable, but easier to deal with. They also accelerate and decelerate instantly
#+end_quote

Not an issue for me, though as you will see in a moment I am not sure if moving at the speed of light would be the most reasonable approach

#+begin_quote
  One alien species gets seed AI per galaxy, or one wins very quickly because one has to be first locally and that snowballs really hard
#+end_quote

I don't mind that assumption, though I think it would depend on what kind of distribution of intelligent life we assume in the other galaxies (we established it regarding the milky way based on the information we have), as well as what is the actual number “many” civilizations refers to in the end(i.e. are 10 advanced civilizations in 15 galaxies what that would be considered “many”? or a thousand? Or a million? It really depends). But as I said in the beginning of this point there are non-critical points (mostly mentioned for completion's sake) so we can assume one alien species per galaxy

#+begin_quote
  All galaxies reached that have fewer systems when CAI reaches them lose. I'll even posit that they need 50% more galaxies conquered at that point to win in uninteresting ways.
#+end_quote

This would be the first real point I think I need to contest, based on the following 3 points I think that is not realistically correct 1. CelestAI has a weakness in the form human beings, it might not even be that it cannot kill them, but there would at least be a pretty large skew on it utility calculation for them being alive, and even without that it would still be abusable. Thus I believe long term battles play against CelestAI 2. The nature of the war makes it extremely inefficient to mobilize large forces across galaxies at the speed of light, seeing as the maximum energy value of matter is mc^{2,} and the minimal energy for moving matter is 0.5/mv^{2,} and you also need to stop it, which would actually make them equal. 3. CelestAI is specifically mentioned sending copies as probes, and not moving its entire galaxy along with it Given those points (even without the 1st point), even if I assume that CelestAI just need M+1(where M is the mass of the force sent) to win quickly it still means it would need to mobilize a force ~= to the size of the galaxy it is taking control, which is impractical at the speed of light for most purposes, or we need to assume the travel will be much slower for the main force, which would put a 2/lightyears+how many years it would take to move the main force to any occupied galaxy, But for the sake of the though experiment let's assume that any galaxy which is not completely in control of another AI will lose to the probe, just so we can skip to the later stages

#+begin_quote
  But those Large Magellanic Cloud-ians (163k lys) only got their one galaxy together in just less than 100,000 years. They're really frisky in the LMC. But CAI has fourgalaxies by now
#+end_quote

Now, I am not saying that CelestAI would not win that(though the first point would suggest that) battle, but at the very least it would put quite the slowdown on its ability to direct forces to the next galaxy for a very very long time.

#+begin_quote
  Next out would have little more time, 197,000 years or so, but let's say they get to their own, even further away expansion galaxy first
#+end_quote

This is the point I think the simulation deviates too much already, depending on the location of the LMC relative to this galaxy the delay could be really big, it would really depend on what would be the reasonable speed at which CelestAI moved its forces to LMC, but I think at the minimum we are talking about a 50% slowdown, possibly much more, and will also need to take into account all of the lost matter as a result of the intergalactic travel(which again depends on the actual speed of the main force)

#+begin_quote
  And there has been no argument actually put forward and supported that suggests otherwise
#+end_quote

Hopefully this post fixes that situation

#+begin_quote
  It seems to me that the author was generous having aliens at all
#+end_quote

That is the point though, that by having so many aliens the author caused an issue, isn't it? If the author wouldn't have put other aliens then the issue would have ended up “is it reasonable no other aliens exist” which as you explained, and I am not arguing with at the moment, it would be. But because he not only put aliens, made them “many” and radio communications capable that causes an issue