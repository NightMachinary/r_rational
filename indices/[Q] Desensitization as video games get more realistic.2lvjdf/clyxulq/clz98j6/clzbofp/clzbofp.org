:PROPERTIES:
:Author: Escapement
:Score: 2
:DateUnix: 1415708905.0
:DateShort: 2014-Nov-11
:END:

Making the rational decision not to kill people is far easier for people than for strong AIs. Strong AIs of the sort commonly postulated by EY et al. have sufficient strength that they neither require humans to continue their own existence, nor are they meaningfully subject to any human authorities. Humans, on the other hand, well, there are almost no people on the planet who suffer no repercussions from other authorities when killing random people.

The rational decisionmaking /context/ is completely different. And this context makes the decisionmaking algorithms far more difficult.

For most random US citizens it is:

Choose to kill people: You have good chances (~60%, according to googling for unsolved murder statistics) of going to prison for a long time, lose all good economic prospects and are permanently ostracized from society when released.

For AIs of the sort postulated by EY et al:

Choose to kill people: People are dead, no meaningful chance of meaningful punishment other than being in a universe with slightly more dead people.