:PROPERTIES:
:Author: CCC_037
:Score: 3
:DateUnix: 1515077728.0
:DateShort: 2018-Jan-04
:END:

This is where we start to get into gray areas.

On the one end of the spectrum, we have a telephone; Alice talks to the telephone, and the telephone transmits her voice to Bob, and Alice tries to influence Bob's decision. In this case, there are very clearly no non-human decisions being made, and thus this is acceptable.

On the other end of the spectrum, there is an Persuasion Machine. Alice goes to the Persuasion Machine, and tells it "Persuade Ben to choose X", and it persuades Ben to choose X. In this case, there are several decisions (especially as regards how to persuade Ben) that the machine is making, and this is obviously disallowed.

Between the two, there is a spectrum of prediction bots and algorithms influencing human decisions - some of them influencing the decisions of their own designers, quite unintentionally (e.g. a weather prediction algorithm with an unintentional bias towards predicting rain might make someone less likely to go on a picnic). Even a large, colourful sign saying "Lowest Prices" will influence human decisions to some degree.

Hmmmmm.

Clearly humans must be permitted to influence each other, or there will be no communication at all. So the telephone is permitted. And Alice calling up Bob and saying "you should shop here, our prices are cheaper than the place down the road" is, in my view, pretty clearly permissible.

The question, then, comes in two parts. The first is whether or not Alice can call up Bob on the phone and say "you should shop here, /the computer says/ our prices are cheaper than the shop down the road". And the second is whether Alice can record herself saying "you should shop here, our prices are cheaper than the shop" and play that recording down every phone in the street at once.

I'd say yes to the first and no to the second; Alice can claim that the computer says anything to Bob, but she has to handle the process one-on-one, in a sense 'piloting' the conversation and making all the decisions (even if that involves pulling information from predictive algorithms), but she can't /automate/ the process.

Does that seem like a sensible place to draw the line to you?