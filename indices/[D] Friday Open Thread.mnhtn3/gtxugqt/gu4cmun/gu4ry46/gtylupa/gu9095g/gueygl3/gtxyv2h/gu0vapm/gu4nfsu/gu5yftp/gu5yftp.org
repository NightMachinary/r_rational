:PROPERTIES:
:Author: Frommerman
:Score: 6
:DateUnix: 1618162170.0
:DateShort: 2021-Apr-11
:END:

That's not quite the problem I was talking about.

Let's say you solve AI alignment. You mathematically prove how to write a seed program which will unfold into a superintelligence with the utility function you want, avoids value drift, and is capable of incorporating new resources without accidentally corrupting itself. You publish, obviously, and your system becomes the standard by which safe AIs are written.

The way things are right now? It wouldn't matter. You will have solved the AI alignment problem, but not the human alignment problem. The first group with the resources to use your research to build a well-aligned AI, will build it with maximizing shareholder value as part of its utility function. They will birth a god, and this god will see humans through the lens of making the line go up.

Its utility function won't be alterable. You proved that. We won't be able to turn it off. It probably won't disassemble all humans for raw materials, but only because it understands that shareholder value is a concept which only has meaning in the presence of humans. What it would do won't be predictable and will depend entirely upon which corporation first succeeded in turning their mission statement into the utility function of a deity and their shareholders into its patrons. But I know what it /won't/ do. It won't value the CEV of humanity. Because, as things stand? The people most likely to produce such a thing are not incentivised to care about it either. It will do what its designers mean, not what all of us mean.

It probably starts pulling CO2 out of the atmosphere. But it probably /doesn't/ make everyone immortal. That's a product it can sell, after all, and demand will be near-infinite. It doesn't resurrect cryonically preserved people unless someone buys their life, because that purchase increases stock value. It owns everything, and everything is for rent. It creates scarcity, rather than ending it, because the line requires scarcity to exist.

You can't just write an AI to always do what you mean. You must also ensure that the people who write it mean the best for all of us. That can't happen under an economic system which creates competition for resources which aren't scarce.