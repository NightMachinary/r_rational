:PROPERTIES:
:Author: Veedrac
:Score: 3
:DateUnix: 1595691038.0
:DateShort: 2020-Jul-25
:END:

#+begin_quote
  The question of cherry-picking is a crucial one and can't be swept away, because if the AI answers a true/false question right only half the time (no better than chance), then cherry-picking can make it seem like it's far more capable than it actually is.
#+end_quote

But if it answers a reasoning question right, where zero knowledge would imply ~zero chance of correctness, one in ten is already proof that it's capable. You do not get answers to “Name three words that start with the letter F” or “What jobs would you say these men have?” or “Suppose it's a cloudy day in New York City. Suddenly, the clouds all turn to solid lead. Write a story describing what happens next.” by cherry picking from a model that hasn't learned to reason.

It's true the quality of GPT-3 specifically depends on how much cherry picking is involved (the individual authors aren't rerolling much, but no doubt there's some degree of selectivity in what gets shown), but again that's only relevant if people stop building better models.