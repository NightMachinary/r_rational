:PROPERTIES:
:Author: alexanderwales
:Score: 6
:DateUnix: 1595653163.0
:DateShort: 2020-Jul-25
:END:

I've been playing with it. It's pretty good. It'll get better with a bigger context window, which is a serious limiter right now, but there are always going to be things that it will have problems with, at least until someone comes along and builds a framework that it can fit inside in order to address some of its issues.

I'm a bit of a GPT-3 skeptic. I think it's marvelous at what it does, but incredibly limited in a few ways, some of which can be addressed, some of which either can't due to how it was made and what it does, or which will take so much work that no one will invest the time and effort. One of the big issues is that within its enormous corpus are things that we don't particularly want, like bunk science, mis-interpretations, biases, poor writing, etc. Some of that you can overcome with sufficient prompting, but I've noticed a real tendency to regress the longer you let it go on without intervention. At best, that means it ends up talking in tropes and memes, at worst, that means hemming and hawing, going off into tangents, moments of (in-text) confusion, etc. And that's when it's actually working.

There are definitely some use cases for it, but a lot of what people are saying about it is, uh, quite overblown.

(I tried "centaur writing" with it, treating it like a co-author, and [[https://www.reddit.com/r/alexanderwales/comments/hvy8nv/cadmus_centuar_writing_with_gpt3_test/][this was the result]]. I don't think that I actually saved much labor though, and likely would have gotten a better, faster result without trying to have GPT-3 "help". Edit: [[https://www.reddit.com/r/alexanderwales/comments/hxhqqp/isles_centaur_writing_with_gpt3_test_unfinished/?][here's another, unfinished]], with some observations on GPT-3 as a writing partner.)