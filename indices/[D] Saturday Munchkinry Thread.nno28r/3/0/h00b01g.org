:PROPERTIES:
:Author: ArmokGoB
:Score: 1
:DateUnix: 1622405149.0
:DateShort: 2021-May-31
:END:

Presumably, create 10 AI alignment researchers and unleash them onto lesswrong, using their extra fields to maximize goodness and competence at and dedication to that research. Once they solve the problem, delete the least critical ones and replace them with experts and programers that will reverse engineer that very program. Also, make one of the alignment researchers programed to believe any claim you make to them directly over PMs, and explain this situation and ask what to do but don't reveal that /they/ are one of these bots.