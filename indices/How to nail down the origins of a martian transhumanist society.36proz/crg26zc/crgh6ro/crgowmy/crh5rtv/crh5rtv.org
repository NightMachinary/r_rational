:PROPERTIES:
:Score: 1
:DateUnix: 1432270693.0
:DateShort: 2015-May-22
:END:

You seem to be under a misapprehension about what I am claiming.

Whenever we do things, we are trying to modify the universe to better match the universe we want. That's our goal. We don't always succeed, obviously. Whoever tries to create an AI is doing so in the belief that it will get us closer to their preferred universe. If they succeed and end up with the strong AI they want, that AI will build the universe they wanted. That's the success condition. I haven't said anything interesting or surprising yet; I'm pretty much just rephrasing definitions. Rephrasing definitions isn't a mark of optimism.

If the group that first creates strong AI does a proper job of it, and they want a universe in which humans can undertake interesting and worthwhile activities, then the AI will ensure that humans can undertake interesting and worthwhile activities. Again, nothing interesting here. No wild optimism. It's just clarifying the success condition for any AI research group with a particular goal.

If I were claiming that /any/ strong AI created by humans would inevitably result in a universe in which humans routinely undertake interesting and worthwhile activities, that would be unreasonably optimistic.

You, conversely, were claiming that /any/ story that includes a strong AI cannot include humans undertaking interesting and worthwhile activities, at least nothing worth writing stories about.