:PROPERTIES:
:Author: staged_interpreter
:Score: 1
:DateUnix: 1575908299.0
:DateShort: 2019-Dec-09
:END:

It is, it's perfectly capable of killing everyone it can communicate with simply by giving him/her information others don't want him to act on and won't accept assurances to do so.

It might not get the first few to accept its demands to be released but at some point someone will decide that his continued existence is worth the risk to collaborate.

This of course requires the AI to be desperate enough to risk its own existence as it might just be shut down.