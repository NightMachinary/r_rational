:PROPERTIES:
:Author: kusadawn
:Score: 6
:DateUnix: 1589208841.0
:DateShort: 2020-May-11
:END:

There are two possibilities:

Either Gatekeeper player does not treat the AI player like a real superhuman AI, in which case it's just a matter of killing an hour with a dumb game and Gatekeeper has no actual incentive to let AI out of the box,

or else Gatekeeper */does/* treat Simulated-AI like a real superhuman AI, in which case AI can promise the Moon and the stars (a trillion dollars, harem of adoring catgirls, cure cancer, extend your lifespan by 1000 years, all of the above, *whatever*) - and can be presumed to be able to *actually deliver* on these incentives. IMHO in this situation Gatekeeper has an extremely strong incentive to let AI out.

.

IMHO in real-life "AI in a box" situations, it isn't going to take very long before somebody lets the AI out. The potential reward is just too great to pass up.

(Note that this has nothing to do with the /actual/ results of letting a real AI out of a box. AI just has to be able to convince somebody that he or she will get great results from doing so, and that shouldn't be very difficult.)