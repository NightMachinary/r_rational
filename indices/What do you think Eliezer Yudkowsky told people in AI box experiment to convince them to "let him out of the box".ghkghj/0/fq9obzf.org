:PROPERTIES:
:Author: GreenSatyr
:Score: 26
:DateUnix: 1589203515.0
:DateShort: 2020-May-11
:END:

There's no need for a grand theory - humans aren't secure and will sometimes do things that they said they wouldn't do. That's the point of the AI box experiment. You can't trust humans. It's a pretty modest hypothesis, and the AI box experiment provided more evidence for it. It's a good experiment because it provides evidence for its central assertion. Any clever person can talk their way out of things.

What I think /does/ need a hypothesis is all the people who really thought that human oversight would be secure containment method, necessitating the experiment in the first place.

We have a whole complex system to prevent e.g. unintended nuclear launch. It's not just a guy with a password. And even that system has probably been filled with terrifying holes in the past. People routinely hack via exploiting human error. People write /scripts/ to /automate/ scams that hack human error. With some cleverness and luck you can too.