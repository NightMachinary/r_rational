:PROPERTIES:
:Author: artifex0
:Score: 3
:DateUnix: 1497287770.0
:DateShort: 2017-Jun-12
:END:

#+begin_quote
  ...generate every possible sufficiently-unique brain that could correspond to a functional human...
#+end_quote

I feel like the math may not work out for that.

Imagine simulating every possible combination of a deck of cards- that's 52!, or about 8x10^{67} possible states. However, there are only 10^{50} atoms in the Earth. If it's possible to simulate every deck of cards with the material of our solar system, it would be pretty difficult.

Of course, when it comes to minds, you could simplify the problem by only simulating some relatively infinitesimal, but important or representative subset of possible minds- after all, a person might think of two technically different but extremely similar minds as the same person.

You could also get into some tough questions about where the line is between understanding a consciousness and simulating it actually is. If an AI has a perfect conceptual model of a mind, to what level of detail does it have to imagine that mind before it can be called individually conscious? What if an AI has a perfect abstract understanding of the sorts of minds that can arise? How abstract does something have to be before can no longer be called a consciousness? Depending on what consciousness actually is, you might be able to get away with simulating some abstract concepts instead of a lot of individual mental states.

Even so, I think it's easy to get over-awed by the vastness of the universe and our relative insignificance, and mis-judge how simple it would be to do something like simulating every possible mind.