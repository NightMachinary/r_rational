:PROPERTIES:
:Score: 2
:DateUnix: 1442815536.0
:DateShort: 2015-Sep-21
:END:

LessWrong tends to talk about ethics in extremely heterodox language, resulting in much confusion and flame-wars of mutual incomprehension when LWers encounter mainstream ethicists.

#+begin_quote
  Speaking of, my ethics teacher seems to be bewildered by the fact that rational justification is not required for an individual's terminal values, while at the same time saying that terminal values (the Good) are the thing that all moral judgements are relative to.
#+end_quote

There's no real contradiction here, but you're using extremely different meta-ethical positions. Most codes of normative ethics implicitly assume a realist meta-ethical position, in which case the Good is defined independently of people's opinions about it and moral judgements are made relative to the Good (even while an individual's own /personal preferences/ may simply /fail/ to track the Good).

Talking this way causes a whole lot of fucking trouble, because traditional ethicists have (usually) never been told about the Mind Projection Fallacy or considered that a mind could be, in some sense, /rational/ while also coming up with a /completely alien/ set of preferences (in fact, traditional ethicists would probably try to claim that such minds are /ethically irrational/), so, "The Good (as we humans view or define it (depending on meta-ethical view)) /must necessarily be causally related to/ the kinds of preferences and emotional evaluations that /humans specifically/ form" isn't so much an /ignored/ notion as one that's /so thoroughly woven into the background assumptions of the whole field/ that nobody even acknowledges it's an /assumption/.

Also, I do have to say, just calling oneself a subjectivist seems to duck the hard work of the field. If you treat the issue, "the LW way", then your meta-ethical view ought to give you a specification of what kind of inference or optimization problem your normative-ethical view is actually solving, thus allowing you to evaluate how well different codes of ethics perform at solving that problem (when treated as algorithms that use limited data and computing power to solve a specified inference or optimization problem). Declaring yourself a "subjectivist" is thus specifying very few bits of information about the inference problem you intend to solve: if it, whatever /it/ is, is about your brain-states, then which brain-states is it about, and how do those brain-states pick out an inference problem?

Whereas, in contrast, much of the work towards what's called "ethical naturalism" and "moral constructivism" seems to go to quite a lot of trouble, despite being "conventional" moral philosophy, to precisely specify an inference problem.