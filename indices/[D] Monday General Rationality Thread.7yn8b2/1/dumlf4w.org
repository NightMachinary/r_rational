:PROPERTIES:
:Author: Veedrac
:Score: 6
:DateUnix: 1519260437.0
:DateShort: 2018-Feb-22
:END:

There was a [[https://www.reddit.com/r/science/comments/7yegux/aaas_ama_hi_were_researchers_from_google/][Google, Microsoft and Facebook AI AMA]] a few days ago. I find these things interesting sources of information about what people generally think of the future of AI.

There were two quickly-dismissed responses to AI risk [[[https://www.reddit.com/r/science/comments/7yegux/aaas_ama_hi_were_researchers_from_google/dugqdwb/][a]], [[https://www.reddit.com/r/science/comments/7yegux/aaas_ama_hi_were_researchers_from_google/dug5bmi/][b]]], but the other parts were more interesting.

IMO, the most interesting answer was about [[https://www.reddit.com/r/science/comments/7yegux/aaas_ama_hi_were_researchers_from_google/dugl69a/][Superfetch and other under-the-hood ML systems]]. Alongside the recent paper [[https://arxiv.org/abs/1712.01208][The Case for Learned Index Structures]] and the general, unassailable hype for this stuff, I see a rather interesting future computing landscape where gradually more and more components of programs get swapped in for more general optimization procedures.