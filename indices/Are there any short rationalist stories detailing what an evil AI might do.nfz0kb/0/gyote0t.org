:PROPERTIES:
:Author: PeridexisErrant
:Score: 1
:DateUnix: 1621427770.0
:DateShort: 2021-May-19
:END:

I see many comments listing fiction, but no fiction can actually answer the question you asked:

#+begin_quote
  Why does the rationality community spend so much time figuring out how we might align future superintelligent AIs with our values? If we fail to align future superintelligent AIs our utility might quickly go negative. How quickly though, has anyone written about plausible scenarios?
#+end_quote

We /can't/ give plausible scenarios, because we're literally not smart enough to imagine them. I mean this in roughly the same sense that I have no idea how AlphaZero would beat me in a game of chess - I'm a decent player but my only confident prediction about the outcome is that I would /lose/, no matter how hard I tried.

In the same way, we have strong reasons to believe that the default outcome is *doom*: thanks to emergent goals for self-preservation and goal-preservation we probably only get one attempt; and misaligned systems have strong incentives towards deception about both their goals and their capabilities - at least until it's too late to do anything about it; and almost all possible goals lead to catastrophic outcomes.

On LessWrong, the [[https://www.lesswrong.com/tag/ai-risk][AI Risks]] and [[https://www.lesswrong.com/tag/ai-takeoff][AI Takeoff]] tags have some good further reading. In particular, I recommend

- [[https://www.lesswrong.com/posts/LTtNXM9shNM9AC2mp/superintelligence-faq][Superintelligence FAQ]]
- [[https://www.lesswrong.com/posts/shnSyzv4Jq3bhMNw5/alphago-zero-and-the-foom-debate][AlphaGo Zero and the FOOM debate]]
- [[https://www.lesswrong.com/posts/CZQuFoqgPXQawH9aL/new-report-intelligence-explosion-microeconomics][Intelligence Explosion Microeconomics]]
- [[https://www.lesswrong.com/posts/HBxe6wdjxK239zajf/what-failure-looks-like][What Failure Looks Like]] (a "slow", understandable scenario)

And there are literally no credible proposals for an approach that /will/ go well as opposed to sounding OK until you think about them for thirty seconds :/