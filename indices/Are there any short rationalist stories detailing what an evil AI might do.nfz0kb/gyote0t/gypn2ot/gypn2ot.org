:PROPERTIES:
:Author: Veedrac
:Score: 10
:DateUnix: 1621440605.0
:DateShort: 2021-May-19
:END:

I disagree. A skilled chess player can tell you what different chess engines are good at, and what the strengths of different positions are, or what advantages an engine has extracted from any given weakness in a game. They won't be able to /replicate/ the feats, or predict the precise manner in which those feats are enacted, but that's a different question.

As a more concrete example wrt. misaligned superintelligent AGI, it's reasonable to expect that such an AGI would want to take over computers to expand its control; the way to do that is easy to predict, even if the method is hard. It's natural to expect it would want to get rid of people at some point in, and while there are many known and unknown ways to do that, a simple one would be to engineer biological organisms to quickly kill life off; again, simple to predict, hard to execute. It would likely need some way to build things, so would most likely create some physical devices to do that, plausibly using hacked factory equipment to construct it, but also likely just by asking people to get it done. It would want to ensure energy supply at this stage, so would avoid doing things that disrupted that irreparably.

You can't tell the correct story in whole, but people can give at least plausible lower bounds for many different scenarios.