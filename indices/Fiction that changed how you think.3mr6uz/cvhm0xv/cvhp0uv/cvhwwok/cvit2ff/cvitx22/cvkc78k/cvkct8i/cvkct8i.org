:PROPERTIES:
:Author: Tsegen
:Score: 3
:DateUnix: 1443695833.0
:DateShort: 2015-Oct-01
:END:

#+begin_quote
  Surely the lesson here is not "biases and idiocy are awesome and an essential part of makes us human
#+end_quote

Why would that be the message? Is the message of Lovecraft that blindness to the massive forces that dwarf humanity is awesome and an essential part of what makes us human? Well...maybe, but no one said blindness is positive, only that the visceral reaction to the consequences of it being exposed is natural.

And it's not as if the fear that transhumanism or AI can go bad is crazy. If you already want it to happen you'll only take the note of caution for granted and forge on, but it isn't silly in and of itself.

#+begin_quote
  and more of "make sure powerful agents have friendly goals".
#+end_quote

Make sure how? He's not an AI and even that is not certain.

#+begin_quote
  I don't really remember what the overarching goal was, so it probably was some vaguely defined bullshit
#+end_quote

It wasn't. But it wasn't anything you'd value.

The sequel series deals exactly with that "worthy goal" situation should you [[#s][spoiler]] ironically though [[#s][major spoiler for second series!]]