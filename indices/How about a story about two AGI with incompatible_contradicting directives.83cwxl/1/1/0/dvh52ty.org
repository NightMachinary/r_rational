:PROPERTIES:
:Author: vakusdrake
:Score: 2
:DateUnix: 1520674870.0
:DateShort: 2018-Mar-10
:END:

You're assuming the AI just automatically identifies with any other AI sufficiently close to itself. However that obviously would never get programmed in because otherwise they would never fight in the first place since the initial two warring AI are almost certain to be extremely similar (designing two different AI frameworks here would be pointless and nearly double your work).

#+begin_quote
  I'm still not running them outside several layers of sandbox virtualization on servers with an ax man standing by
#+end_quote

I'm not sure if you're serious, but this is likely to be a counterproductive plan. Since the idea that you can create a virtual sandbox perfect enough to fool a GAI is dubious so it's behavior within it is likely to only serve to give you a false sense of security but tell you nothing. As for an ax man, well clever agents are never going to tip you off that something has gone wrong until you have no power to stop them.