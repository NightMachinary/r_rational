:PROPERTIES:
:Author: Uncaffeinated
:Score: 6
:DateUnix: 1457833012.0
:DateShort: 2016-Mar-13
:END:

People in the LW communities tend to be irrationally enamored of cryogenics (no, current technology doesn't preserve a brain in any meaningful way) and AI risk (AI is a danger, but not in the way that EY thinks).

It's also easy to get misled by EY due to his Dunning-Kruger when it comes to physics (yes, there is a reason why professional physicists reasonably disagree about many worlds).

If you define rational fiction as fiction where people make justifiable decisions and things don't happen for no reason, then that's almost inarguably a good thing. But the actual term is used by a very specific community with a bunch of extra baggage due to the influence of EY.