:PROPERTIES:
:Author: OutOfNiceUsernames
:Score: 1
:DateUnix: 1524849694.0
:DateShort: 2018-Apr-27
:END:

#+begin_quote
  and you think a sufficiently advanced system with extraordinary computing power couldn't create a 99.99999% perfect simulacrum of 99.9999999999% of all the people to have lived over the past several thousand years by triangulating all the decades of accumulated data? That It couldn't fill in the blank spots ("blank spots" being people who It doesn't even know exist due to a complete lack of data), just based on the way that everything else around that person bounced off of or bent around the "blank spot"? Isn't that the point of R's B, that in the even farther future It will be even more advanced than sufficiently advanced and have computing power even more extraordinary than extraordinary and be able to triangulate the placement of every individual particle at every point in space/time all the way back to the beginning of existence?
#+end_quote

That's the thing though, I'm not talking about Roko's basilisk, because some of the leaps of logic that the classical thought experiment makes can be rather dubious. They can end up being true, they can end up being false, but whatever the case my intention wasn't to start a debate about Roko's basilisk. It was to consider human agents as the triggers for generation of simulations --- no SAI --- and to consider how the availability of potential information for them can at least be minimised as much as possible.

Infiltrating corporations should be at least a little easier than infiltrating government networks (though, admittedly, governments themselves have been known to carelessly handle personal information as well), and infiltrating companies that specialise on targeted marketing should be easier still.

So I'm not asking about an all-or-nothing solution, but about steps that could be taken to at least prune somewhat the number of /people/ who could get their hands on the data-profiles about your person in the future.