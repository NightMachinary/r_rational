:PROPERTIES:
:Author: OutOfNiceUsernames
:Score: 4
:DateUnix: 1524843975.0
:DateShort: 2018-Apr-27
:END:

/(A question at least tangentially related to Roko's basilisk.)/

#+begin_quote
  Companies, whole industries, and governments are either already gathering data on users \ citizens to build psychological profiles, or will start doing so soon enough, when the ones that do so now will prove how useful this approach is for targeted advertisement, voter manipulation, riot prevention and control, etc.

  Among the biggest such entities are facebook and google, and if the recent developments with facebook and CA have made at least some people weary of it, the trust towards google (and that it won't be abusing its capabilities) is still rather high. Though even if google somehow manages to maintain some of its morality code down the line, there's still the possibility that some of its gathered data will get leaked or stolen.

  And given how large a presence google has on the internet (chrome, gmail, google search history, google analytics, etc), this data will be enough to rebuild a virtual copy of an internet user, even if that copy will not be a 100% accurate simulation.

  Besides google and facebook there are also many other companies that specialise on data mining like this, and their data too can be abused --- or stolen\leaked and /then/ abused.
#+end_quote

So what happens 10, 20, 50 years from now, when the technology of creating fake virtual people becomes a regular thing, and when this technology can use mined data to generate simulations of real-life users that, even if imperfect, will still have high resemblance to the originals?

If such a development occurs, there will be no need for a vengeful AI --- people will play the role on their own:

- governments --- targeting as many people as possible, level of simulation quality as high with the available funding (and current point on Moore's diagram) as possible
- advertisers --- targeting as many people as possible, level of simulation quality as high with the available funding as possible
- neo-religions \ neo-religious cults --- targeting only a few people as the minimum, but trying to make the simulations as high quality and accurate as possible. Such religions will have real, self-made “evidence” to back up their afterlife consequences blackmail for influencing believers and non-believers alike.
- [[https://en.wikipedia.org/wiki/Rolling_coal][“rolling coalers”]] --- people who don't think simulated minds should have any rights, and are pointedly simulating people on machines available to them to underline that point
- gameplayers, lonely people, etc --- imagine people 50 years from now who want to play a multiplayer game released in 2010s. How many of them will be ready to populate that game with simulated players, if they will have the means for it? Depending on the type of the MP game, the number of targets and the quality of simulations will vary.
- etc, etc

So my question is, doesn't this mean that by our current point in time it should already be an advisable decision to delete all the social media accounts, make backup copies of all past e-mail correspondence and then delete the versions stored on the cloud, and to start taking online privacy much more seriously, [[https://stallman.org/stallman-computing.html][Stallman-style?]]

And what other measures would you see worth applying in addition, if this were the case?

--------------

p.s. I don't know if during the period when Roko's basilisk was all the rage, the discussion was revolving mainly around a blackmailing AI or if it was more widespread than that. If if was the latter, and the subject of my comment has already been discussed --- please link to the relevant discussion pages.