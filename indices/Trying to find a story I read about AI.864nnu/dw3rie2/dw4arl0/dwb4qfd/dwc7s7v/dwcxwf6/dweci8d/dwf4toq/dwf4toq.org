:PROPERTIES:
:Author: wren42
:Score: 1
:DateUnix: 1522247582.0
:DateShort: 2018-Mar-28
:END:

#+begin_quote
  I don't think consciousness arises from the interaction between neurons, so it's not really a big question for me.
#+end_quote

so you believe consciousness is not a physical phenomenon? you are a mind-body dualist? or do you believe there is some physical cause other than the brain for consciousness?

#+begin_quote
  I take the position that what makes two things the same thing is that you cannot differentiate between them.
#+end_quote

I would only agree with this if you append the qualifier "with perfect knowledge of all attributes of the concerned 'things'."

Otherwise, it is an assertion that relies on your own ignorance. If cave men couldn't tell the difference between a rock and a radioactive isotope, does that make them the same thing? Surely you are not asserting that to believe something is to /make it true/?

The mind doesn't create the universe. The universe creates the mind. So, what we know about something doesn't change its nature or properties. "I think therefore I am" doesn't mean "I think and thereby shape the nature of reality and produce my own existence ex nihilo."

If you agree with the above -- which is really just admitting that there is an objective physical reality /at all/-- then I can clarify what I mean by "we can be fooled" and why it's important.

If we do not have clear understanding of the physical laws that necessarily produce consciousness for certain configurations of matter, then it is possible we could have incorrect beliefs about the consciousness or lack thereof in an arbitrary subject.

Behavior is not the same thing as internal experience. Just because something seems to behave in a way similar to a consciousness to an ignorant observer does not make it necessarily conscious.

Consider a simple chatbot generating responses from a lookup table (ie - a chinese room.) A child might be fooled by an unsophisticated program, but a savvy adult can recognize the irregularities and realize this is not a conscious mind they are interacting with.

Does this make the chatbot conscious to the child, but not the adult?

Now extend the scenario. The chatbot is made more sophisticated, with a larger set of responses, without changing its fundamental nature -- it's still just a lookup table. The adult is now fooled over the course of a short conversation, but the programmer of the bot knows it for a fake.

Is the bot now conscious to the adult Turing test subject, but not to the programmer?

Finally, consider a bot that can fool anyone - its lookup table is enormous, it has a plausible sounding response for just about any line of conversation, but it is still just a dumb pattern matching program.

again, is our ignorance of the nature of and requirements for consciousness sufficient cause to just /declare/ this Bot to suddenly be conscious?

Saying "good enough" because something /seems/ conscious is not acceptable. This is because the stakes of this declaration are the survival of all known conscious life.

We are talking about deciding what form uploaded minds should take - and these could potentially in the future comprise the entirety of humanity. If you "guess" that a lookup table that seems to behave like a person is "good enough" for consciousness, and we dissect all of humanity's brains and tile the solar system with these lookup tables, it could mean the end of consciousness in the universe.

So, how confident are you in your guess? Is it enough that you can't tell the difference? Or would you want to know more about what, at a fundamental physical level, is required to create a conscious mind?

I am of the later opinion. I /do/ acknowledge my ignorance of what, at a bare minimum, is /necessary/ to create consciousness. This /is/ the big question. I only know that human brains are /sufficient/, and propose that - until we know exactly what laws give rise to consciousness - that should be our minimum requirement for uploading or preserving a human mind.