:PROPERTIES:
:Author: derefr
:Score: 9
:DateUnix: 1513045849.0
:DateShort: 2017-Dec-12
:END:

Remember that rationalist stories are also---/almost/ always---rational stories. In a rational story, you /don't/ just win by author fiat; you win because the things you do would mean that you "logically should" win; you would win with high probability in most universes where you "were" that character facing that problem at that time. (Compare: win probabilities from a given board-state in chess.)

HPJEV didn't win in HPMoR /because/ the story is "a story where rationalism wins." Instead, HPJEV wins because the story begins with altered axioms (highly exploitable conditions) and then proceeds along with a highly simulationist storytelling stance from there, letting things just happen as they may. The only reason HPJEV wins is because, under those particular exploitable conditions, HPJEV is the "right person for the job." The only author fiat is in choosing to focus on a character with those traits in the first place.

For an analogy: say that you create a fighting game. Say, then, that you program an AI fighter for that game. If the bot just "got lucky" and won, then narrativizing that success would be author fiat in storytelling. There's no reason to highlight that story over all the cases where the bot lost, so telling it anyway is sort of a selection effect; the "moral" it implicitly communicates is "be more like this", but whatever the audience thinks "this" was, it wasn't what helped the bot win. There's no applicability to your own life, no useful data to update on. So that's bad, in the way you're talking about here.

But if, on the other hand, the AI fighter was programmed in such a way that it can /take advantage/ of the rules of the game, such that it /usually/ wins given its programming, then there is no author fiat in telling a story about the program winning. The resulting story wouldn't be the result of a selection effect, it's just a central demonstration of a lesson: that under these conditions, these traits /do/ help the AI---and you, if you copy them---to win. The AI is still playing by the rules of the game; and the author isn't "fudging" anything by telling the story. The only special thing that happened, was for the programmer to make the AI what it was.

The point of stories like HPMoR---similar to stories about successes in competitive tactics---is that you can learn lessons from them about what kinds of ways particular situations can be exploited to your advantage. If those situations never come up in your life, then those lessons might not be directly applicable. But if those lessons are abstract or general enough, you might be able to find /analogous/ or /isomorphic/ situations in your own life that can be exploited for /similar reasons/.