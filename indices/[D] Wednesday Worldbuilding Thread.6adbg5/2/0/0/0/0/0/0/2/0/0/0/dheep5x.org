:PROPERTIES:
:Author: 696e6372656469626c65
:Score: 1
:DateUnix: 1494462337.0
:DateShort: 2017-May-11
:END:

#+begin_quote
  There's ways of getting around a direct engineering of value system. Just specify that that genes are changed such that people invariably end up with nearly the same moral instincts. Then define that moral instinct in terms of being one which would if replacing your current one cause you to make the exact same moral decisions you would normally make. Point is you can easily use conditionals that basically rely on a simulation of oneself.
#+end_quote

This is the standard definition of reflective consistency, yes. Unfortunately, /it doesn't work as an answer to the question I posed/, which asks you to describe a /specific/ type of mind. Does this mean I want a source code for a computer program written out in C that, when compiled, produces the mind in question? No. What it /does/ mean, however, is that "a mind that shares my values, whatever those happen to be" is sufficiently vague that I consider it underspecified.

#+begin_quote
  As for the objection about not having the sufficient engineering knowledge, well that objection could apply to pretty much any mind engineering including the hivemind example, since we just don't understand enough about human brains. So it's not clear in what way mind-clones are more complicated than inventing some new hivemind psychology.
#+end_quote

The hivemind psychology is just that: a /psychology/. It's a general property that can exist across a variety of possible minds, and even if we don't know how to make one, it's at the very least plausible that an entire species might possess such a psychology. Mind-clones, on the other hand, are all copies of a /single/ mind by definition, which is biologically impossible without external engineering. It's in this sense that I say we don't have the engineering knowledge to do what you're saying.

Or, to put things another way: you can tell the genie to create a species with an extremely high level of empathy, and this will be a /species-wide property/--if two members of the species reproduce, their offspring will also possess a high level of empathy. If you try to tell the genie "every person in this society has an exact copy of my mind", on the other hand, your society falls apart the instant a baby is born because /that baby will not be a mind-clone/, and there's no way to /make/ it be a mind-clone without engineering knowledge that /we don't have/.

#+begin_quote
  Also I never said we need hardcoded rules, the basic idea is simply to replace the genes that usually result in people developing moral systems with genes that are far more specific and less open to environment in developing their function, to cut down variation.
#+end_quote

This is not how genes work. Like, I get what you're trying to do here, I really do, but this is simply not how genetics works. There /are/ no "genes that usually result in people developing moral systems", and there's no genetic arrangement specific enough to hardwire a particular /brain design/ into every member of a species. The best you can do is provide a tendency for people to be sociopaths, or to consume large amounts of glucose, or to want multiple sexual partners, etc. But trying to specify a full /moral system/ in the genes of a particular species is an impossible task.