:PROPERTIES:
:Author: vakusdrake
:Score: 1
:DateUnix: 1494466619.0
:DateShort: 2017-May-11
:END:

#+begin_quote
  This is not how genes work. Like, I get what you're trying to do here, I really do, but this is simply not how genetics works. There are no "genes that usually result in people developing moral systems", and there's no genetic arrangement specific enough to hardwire a particular brain design into every member of a species. The best you can do is provide a tendency for people to be sociopaths, or to consume large amounts of glucose, or to want multiple sexual partners, etc. But trying to specify a full moral system in the genes of a particular species is an impossible task.
#+end_quote

I disagree with the claim you couldn't arrange genetics such that the resulting neurology would consistently develop into a particular range of desired moral systems. Mainly I think you're forgetting just how much information is already encoded. From the perspective of a truly alien amoral entity it would likely appear that most humans are already hard coded with a relatively small range of moral systems. I think it's underappreciated just how similar most people's moral beliefs already are once you strip away differing models of reality and just how complex people's moral instincts are, and i'm sure you're aware that some of these things like a desire for fairness are present in other animals. If genetics can consistently produce complex intuitions about fairness than why exactly is it such a stretch that you could change things so that the moral systems that would arise would contain less variations? I'm not talking about something quite as complex as anything you're likely imagining either, after all most of my moral judgements are based on the most self consistent interpretation of my gut feelings anyway, I'm not proposing that you somehow biologically encode some bizarre kantian ethics system. It's only necessary for my purposes that people be much more skeptical (to avoid bizarre models of reality confounding things) and have gut feelings about ethics very similar to my own.\\
Also I don't think you should really be so confident that even something like genetic memory is totally beyond what DNA is capable of producing. It can already be used to encode arbitrary computer data, so building a system that builds complex memory systems based on that information doesn't seem impossible (even if it might not be the type of system that would evolve naturally). To say that such genetic code that built a specified memory structure wasn't /possible/ would seem to be to make a rather bold claim about the fundamental limits about how complex and detailed a structure can be made via biological processes.

#+begin_quote
  This is the standard definition of reflective consistency, yes. Unfortunately, it doesn't work as an answer to the question I posed, which asks you to describe a specific type of mind. Does this mean I want a source code for a computer program written out in C that, when compiled, produces the mind in question? No. What it does mean, however, is that "a mind that shares my values, whatever those happen to be" is sufficiently vague that I consider it underspecified.
#+end_quote

What I said is hardly vague, since all you would need to do is run simulations of a vast number of minds and compare them to simulations of my own mind in order to determine which conditions will lead to minds within a range that produce informed moral judgements the simulations of me deem acceptable. That's why I mentioned the bit about using conditionals based on simulations of yourself.