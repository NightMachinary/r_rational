:PROPERTIES:
:Author: AntiTwister
:Score: 5
:DateUnix: 1509525597.0
:DateShort: 2017-Nov-01
:END:

#+begin_quote
  lots of game theory suggesting the existing system +can't improve+ /isn't optimizing what you want it to optimize/
#+end_quote

The impression I get is that this is about better identifying which sorts of optimizations are incentivized or impeded by large scale systems. This allows you to form better priors about the value of reasoning from first principles in a particular domain, and whether this is likely to yield an improvement in your optimization criteria over whatever group consensus is currently systemically supported.