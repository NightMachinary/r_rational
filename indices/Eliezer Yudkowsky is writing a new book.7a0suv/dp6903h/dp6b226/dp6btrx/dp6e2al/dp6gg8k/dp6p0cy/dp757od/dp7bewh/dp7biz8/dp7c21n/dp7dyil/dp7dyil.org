:PROPERTIES:
:Author: GaBeRockKing
:Score: 1
:DateUnix: 1509566179.0
:DateShort: 2017-Nov-01
:END:

#+begin_quote
  First, automation will be socially disruptive before string superhuman ai. There are degrees of separation there.
#+end_quote

I have no doubt it's going to be disruptive, I just very much doubt it'll be "kill 3.5+ billion people" disruptive. Or rather, "kill significantly more than 3.5 billion people" disruptive, counting replacement rates. At least, that is, before we get fully sapient machines.

#+begin_quote
  Second intelligence -or in this case effectiveness at performing a task- is not the same as having personhood or moral weight. Further, this doesn't DEvalue human moral weight. Adding more people doesn't make many dying ok.
#+end_quote

The point where you can run human-level AI is the point where you can scan human brains (if not necessarily at high fidelity) and emulate them. Regardless of how expensive such an operation would be, it only needs to happen once to get a whole bunch of distinct EMs so long as the EMs, after being spun up, get put in different situations.

#+begin_quote
  Further, this doesn't DEvalue human moral weight. Adding more people doesn't make many dying ok.
#+end_quote

It devalues human moral weight as a proportion of the total moral weight of living things. It the utilitarian premise that the needs of the many outweigh the good of the few. You can disagree with utilitarianism, of course, but that doesn't stop the majority from acting self-interestedly.