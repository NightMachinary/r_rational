:PROPERTIES:
:Author: wren42
:Score: 1
:DateUnix: 1509626260.0
:DateShort: 2017-Nov-02
:END:

You are thinking too black and white. There will be suffering long before any "apocalypse where everyone is killed off". Would you personally like lose your job, home, access to the internet, and transportation? Could you survive? Maybe. Is it a good outcome? No.

And your ethics are very messed up. The fact that you could create artificial minds at some future point doesn't alleviate or invalidate current suffering. It doesn't excuse it in any way, especially if they aren't even causally connected. This isn't a trolly problem where some must suffer or die for others to exist. This is like a trolly problem where good policy could stop the trolley, but instead you just suggest we create more people on one side so the others become inconsequential. It's madness.