:PROPERTIES:
:Author: GaBeRockKing
:Score: 1
:DateUnix: 1509606862.0
:DateShort: 2017-Nov-02
:END:

#+begin_quote
  It is an ideal substrate. It is the only system capable of perfectly emulating a brain at full speed.
#+end_quote

That's not even true right now. The Human Brain < The Human Brain on Coffee < The Human Brain on Amphetamines. Evolution is fundamentally a tinkerer-- it takes a thing we can already do, it tries changing it in a bunch of different ways, and then some of the things stick and get passed on to the next generation. But while evolution is great at finding /local/ maximums, it's fundamentally incapable of finding /global/ maxima.

Well, perhaps I should take a step back. Yes, human brains are and likely will be the best device for emulating an absolutely 100% accurate human brain, but there's a difference between a "brain" and a "person". There's a bunch of stuff in my brain that I need, but isn't exactly me. A slightly different autonomic response system wouldn't change who I am. So if you remove that "100%" constraint, even in favor of a 99.99% constraint instead, there's a fair bit of leeway with regards to implementation details.

#+begin_quote
  You'll need specialized hardware, specially prepared for the intense multi-tasking operations that are called for. Brains of metal and stone.
#+end_quote

I don't necessarily disagree, but that doesn't actually preclude the existence of massive amounts of EMs. The demand for them would be simply massive, if only for the simple reason that the kinds of people comfortable with virtualizing themselves are the kind of people comfortable with spinning up as many variations of themselves as allowed by budget and computing power.

#+begin_quote
  Some back-of-the-envelope calculations: 2^{47} synapses, with an update period of 1ms. Call it 250 updates per second. Each update requires multiple calculations. Let's call it 2^{52} flops.
#+end_quote

That works out to ~4.5*10^{15} flops, which is actually /more/ permissive than my estimate. And remember, my estimate was for desktop chips.

When it comes to clusters of computers, well, [[https://plus.google.com/+JamesPearn/posts/gTFgij36o6u][as of 2012, google had ~40*10^{15} petaflops of processing power available to it]], and of course that number has only grown (exponentially) since then. Yeah, that was the computing power of a megacorporation, but currently, [[https://arstechnica.com/information-technology/2017/06/us-doe-the-machine-exascale-supercomputer/][the US and China are competing to build an exascale (10^{18} flops) supercomputer]]. And again, computers have been getting better, cheaper, and more efficient for more than forty years straight, and the process shows no signs of stopping (even if it does show signs of slowing down.)

Sure, we don't have the means with /today's/ technology to handle the shared cache, but that's an engineering issue I'm more than confident will eventually be fixed. After all, there's no point to having technology to handle that massive cache when we don't have the tech for it anyways.

#+begin_quote
  Oh, and my timeframe for an AI-induced technological revolution? I don't think it will happen. I doubt very much that AGI is more than a failed dream.
#+end_quote

Then do you believe the majority of people will die in a techno-revolution without the use of AI? Because the whole premise of the OP was that the only way the majority of people would survive the techno revolution would be through subsistence farming, and my counter was that any techno-revolution that would kill off the majority of meatspace would have so many EMs around that the majority of people period would still be alive.

Also, AGIs exist now. We call them "humans". Facetiousness aside, we know that AGI is /possible/ and because of evolution, we know that it's possible for lesser minds to develop more intelligent minds. Sure, the natural processes for AGIs to arise take a few billion years, give or take, but we already have a good starting point.