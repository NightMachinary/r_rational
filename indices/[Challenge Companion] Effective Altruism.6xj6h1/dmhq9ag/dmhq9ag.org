:PROPERTIES:
:Author: trekie140
:Score: 3
:DateUnix: 1504403897.0
:DateShort: 2017-Sep-03
:END:

Effective altruism is always an idea I've had trouble with implementing. As an economist, I believe the thing that would do the most good in the world is altering current behavioral incentives to encourage optimization of utilitarian humanism. However, even if you can do that, you have to contend with at least some people not knowing how, not understanding how, or simply not choosing to optimize the values you want.

Then you're up against the basic flaws of human psychology that have always hampered progress. Not everyone has empathy for everyone else, not everyone is willing to make the same sacrifices for the good of others, and not everyone's flawed reasoning can be corrected the same way. So in the end, I concluded that the most effective mindset of an altruist is to use whatever power you personally have to help people when you have the opportunity.

If you decide to alter human psychology so that these are no longer a problem, you then run into the problem of violating people's right to self-determination. If optimizing human well-being requires fundamentally changing what it means to be human, then I think you should reconsider your values and methods of optimizing them. One solution could be to make such alterations voluntary, though you'd have to be careful about inequality between these groups.

So some possible scenarios that come to my mind: sell sentient robots programmed to be rationalists and good samaritans when not working, give people the option of uploading into an altruistic hive mind, or construct an AI-operated communications network dedicated to sharing information about altruistic activities that people can do. All have potential failure states, but present opportunities for good things to happen that currently aren't without directly causing harm to humans.