:PROPERTIES:
:Author: Predictablicious
:Score: 4
:DateUnix: 1454720410.0
:DateShort: 2016-Feb-06
:END:

There's an idea called "Basic AI Drives"[1] that states a number of instrumental values that are convergent to many (maybe most) terminal values. That is even if you don't explicitly give theses value to an agent it would "acquire" those values because they're useful to achieve its terminal values.

Trying to program an AI to explicit go against one or more of those instrumental values while it should also maximize some terminal values is impossible in usual utility maximizing models.

1. [[http://selfawaresystems.com/2016/01/18/the-basic-ai-drives-in-one-sentence/]]