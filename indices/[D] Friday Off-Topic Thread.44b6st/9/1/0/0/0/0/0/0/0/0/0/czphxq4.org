:PROPERTIES:
:Author: Fresh_C
:Score: 2
:DateUnix: 1454719535.0
:DateShort: 2016-Feb-06
:END:

Okay I think I get what you're saying. I think the main issue would be how would we read it?

This AI is the most advanced software humanity has ever created. It's a computer so it probably has a thousand thoughts in the time it takes us to contemplate one.

It's outputting a massive amount of data in thoughts so we wouldn't be able to comb through the data and look for red flags manually. Maybe we could have another program that looks through the text and tries to find patterns that would be problematic... but that's assuming that the AI is thinking in a way that we can easily put together and understand.

I'm going to say, maybe it's possible we'd find a way to effectively police its thoughts. But I'd have many reservations about it if I actually thought this AI was a risk. I think because its processing power is always going to be faster than us, we would still be at a great disadvantage. But I suppose as long as there's no reason that we need to hurry to take the AI's advice, we'd be able to look over it's thoughts and try to determine its intentions. It just might take us a very long time.