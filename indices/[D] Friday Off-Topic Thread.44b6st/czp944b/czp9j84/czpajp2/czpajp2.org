:PROPERTIES:
:Author: Fresh_C
:Score: 2
:DateUnix: 1454707596.0
:DateShort: 2016-Feb-06
:END:

I can see a potential way around this given enough time. The AI would just have to subtly convince one of the humans that it would be better if the AI were free. It wouldn't even have to necessarily let the person know that it was trying to convince them of this until it was reasonably sure that it had already convinced them.

Any security program that depends on humans is only as strong as its weakest link. So if it can convince one person to let it out, then it has won.

Also consider that the AI has all the time in the world to wait and choose the human who it thinks is most likely to free it. Generations could go by before someone who wanted to let it out comes along, but the more time passes the more likely that someone with such a sentiment will exist.

At least that's the arguments I've heard for why this type of security is still dangerous.