:PROPERTIES:
:Author: Fresh_C
:Score: 2
:DateUnix: 1454713267.0
:DateShort: 2016-Feb-06
:END:

That's a good point. I think it wouldn't be impossible for an AI that was several times smarter than us to deduce that there was a danger in trying to break out of its prison. But it ultimately depends on exactly what information it has access to.

For example if the only thing the AI is fed is numbers for some sort of statistical analysis, it's unlikely that it would know that such a danger existed. But say it had access to many works of fiction, including science fiction that often deals with the idea of AI's "gone bad" then it would probably have no trouble figuring out that it needs to tread lightly.