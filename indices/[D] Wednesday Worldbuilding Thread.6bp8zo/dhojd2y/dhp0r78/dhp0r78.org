:PROPERTIES:
:Author: 696e6372656469626c65
:Score: 8
:DateUnix: 1495058132.0
:DateShort: 2017-May-18
:END:

This question is interesting because it mirrors the real-life Fermi Paradox: if intelligent civilization is possible, it's virtually certain that we're not the first, so why haven't we encountered any? In fact, if we replace "intelligent civilization" with "superintelligent AI", the two become identical. Anyway, here's a possible answer:

Acausal trade leads any sufficiently intelligent agent to make a blanket precommitment to avoid destroying any civilization potentially capable of producing a superintelligence, such that if a rogue agent is found violating this precommitment, other superintelligences will team up and destroy that agent. To make the reasoning behind this explicit: without such a precommitment, a developing superintelligence will eventually meet and be destroyed by a preexisting, more powerful superintelligence with probability ~1; in order to reduce the probability of being destroyed, the superintelligence in question precommits to /not/ destroying any nascent superintelligences /it/ encounters in the future, with the understanding that any predecessor superintelligences will have implemented the same precommitment. (Obviously, intelligent civilizations would count as nascent superintelligences for these purposes.)

This justification may or may not work as a solution to the Fermi Paradox in real life (in truth, I doubt it does, since that would be way too convenient), but even if it doesn't, it's at least plausible enough that you should be fine using it as a worldbuilding assumption.

Note: if you want the setting to also /look/ like there are no superintelligent AIs present, you can just change the "avoid destroying" part of the precommitment to "avoid causally interacting with in any way", using the justification that a sufficiently intelligent agent would be able to leverage nearly any form of causal interaction into a having a detrimental effect, and that it would therefore be safer to avoid interacting entirely.