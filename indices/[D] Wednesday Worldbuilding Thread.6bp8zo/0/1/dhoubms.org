:PROPERTIES:
:Author: ulyssessword
:Score: 6
:DateUnix: 1495050945.0
:DateShort: 2017-May-18
:END:

- Recursive self-improvement is a /negative/ feedback loop (self-stabilizing), not positive (self-perpetuating). If you create an AI with intelligence 100, it can use its skills to optimize itself to 150, then optimize itself again to 175, and again to 187.5, etc, but it will never be able to break past intelligence 200 without a revolutionary idea that it isn't smart enough to discover.

- It turns out that we are nearing the physical limits for computer processors and memory, and our current desktops can only shrink to the size of phones, not the size of watches or smaller. Our current AI algorithms are also nearly the best they can be. Many problems only have solutions in O(n^{2} ) time or worse, so simply throwing hardware at large problem sets won't help very much. Crucially, /networking/ many things together is also hard: the communication overhead grows exponentially but the computation power grows linearly, making a soft cap in the computation speed/power of any one system.