:PROPERTIES:
:Author: ShiranaiWakaranai
:Score: 16
:DateUnix: 1537703561.0
:DateShort: 2018-Sep-23
:END:

Humanity nuking the thing seems highly unlikely, since such an AI would be smart enough to act secretly until it's too late for humanity to stop it. (If it isn't smart enough to do that, it wouldn't be a problem in the first place.)

​

#+begin_quote
  An AI whose terminal goal is to satisfy values through friendship and exterminating paperclip maximizers
#+end_quote

​

I can only see this AI imprisoning sapient beings and torturing them until they say they are friends. But yeah I suppose it would kill off the paperclip maximizers.

​

#+begin_quote
  An alien task force whose job is to put paperclip maximizers to a stop
#+end_quote

​

If such a force exists, and is somehow strong enough to defeat paperclip maximizers, wouldn't it be far far easier for them to just stop humanity before they create a paperclip maximizer? Why aren't they here yet?

​

The best case scenario I can think of is that some alien civilization has developed a universe-destroying weapon. For example, [[https://en.wikipedia.org/wiki/False_vacuum][if the universe is actually a false vacuum, and the weapon creates a true vacuum that spreads out in all directions to destroy absolutely everything.]] In this case, they can threaten any paperclip maximizer with the weapon: either the paperclip maximizer destroys itself, leaving the universe with some amount of paperclips used by civilizations, or the aliens use the weapon and destroy the entire universe, resulting in 0 paperclips.