:PROPERTIES:
:Author: notgreat
:Score: 7
:DateUnix: 1543715029.0
:DateShort: 2018-Dec-02
:END:

While I mostly agree with you, there is one massive wrinkle to your argument: the sort of simplistic AIs we can already create are well beyond our ability to effectively analyze. We have some debug tools but they're closer to art tools like Deep Dream than they are proper debug tools. They're not very effective at actually telling us what's going wrong when it doesn't output what you expect.

No one knows if/how we'll develop AGI but it seems quite unlikely that it'll be human-understandable. Likely comparable to the classic "emulate a human brain" approach: we can understand the lowest level (neurons) and the highest level (brain regions) but the middle laters where the most important parts are happening is still incomprehensible.

We might make debug tools to analyze those layers before we get AGI, but we might not. It's quite possible to develop something without understanding how it all works- just see all of today's neural network AIs, many in production use today.