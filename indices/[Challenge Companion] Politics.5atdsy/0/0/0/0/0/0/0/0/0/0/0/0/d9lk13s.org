:PROPERTIES:
:Score: 2
:DateUnix: 1478272294.0
:DateShort: 2016-Nov-04
:END:

*for a definition of "rational" in which a generative model and utility function are given a priori, all sensory information is perfectly precise, and economic utility-maximization is the assumed normative standard

In short, people are not "rational" if by "rational" you mean "AIXI". Of course, AIXI has numerous flaws listed out in the literature about it, /and/ can't exist in the physical world. When you try to come up with definitions of rationality that /can/ in principle apply to physical, embodied beings with no a priori knowledge beyond their learning algorithms, you get definitions under which human beings are approximately rational. It is, of course, possible to /make/ something /more/ rational than a human, but that requires building in additional information, literally writing more bits of code into the learning algorithms.

I'll post links late in the evening today.