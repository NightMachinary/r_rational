:PROPERTIES:
:Author: OutOfNiceUsernames
:Score: 2
:DateUnix: 1516750020.0
:DateShort: 2018-Jan-24
:END:

Yes, gbear605 has already mentioned SA in his subcomment. In all fairness, I should've composed my comment more in tones of “what has the rationalist community said on this issue so far?” rather than “why isn't it saying much about it?”.

Regarding the inaccuracies when comparing meta-entities like corporations with AIs, I'd like to clarify that what I was saying wasn't that corporations should be classified as a subtype of an artificial intelligence. I was saying that corporations are doing what an emerging AI is partially so feared for: reshaping the world according to their primary goals with little regard for the individuals enhabiting it --- even if they do it much slowly than an AI would (or because of it, since the slower pacing of the changes creates a boiling frog effect regarding the possible resistense against them).

And since they are having the same effect on the world, they should be treated with similar caution. And when talking about restrictions for them they should be regarded as entities that have no moral \ ethical judgement of thier own, as an AI would. This in contrast, for instance, to expecting them to “stand up for human rights on their own” (e.g. common expectation towards Google, Netflix, Amazon, etc), [[https://en.wikipedia.org/wiki/Corporate_social_responsibility][have a sense of social responsibility on their own,]] etc.