:PROPERTIES:
:Author: crivtox
:Score: 3
:DateUnix: 1504699490.0
:DateShort: 2017-Sep-06
:END:

Well they seem think that if they give unfriendly ai to everyone it wont be a problem.I think this comes from too many people discussing only what happens if one ai takes o ver the world . So people like the ones in open ai decide that the one entity taking over is the main problem, and that if there are multiple Ai in competition that's a problem we can deal whith(even if all of them are unfriendly, and often whith similar utility functions) or worse they decide that having a lot of inteligences whith diferent values is enough like us to be ok if the ai replace humanity(open ai only makes the first mistake but I 've seen too many people making the second by antrophomorficig the ai to not rant about it) .

At least it seems that open ai now wants to employ ai safety people so , maybe they will notice that value alignment Is important and will stop trying to kill everyone, even Yudkowsky wanted to make the singularity happen as soon as posible when he started(until he realized that if he had succeeded he would have destroyed the world)so maybe there is still hope for them(this is before reading the presentation, let's see how horrible it is)