:PROPERTIES:
:Author: crivtox
:Score: 1
:DateUnix: 1504710708.0
:DateShort: 2017-Sep-06
:END:

At first it didn't seem so horrible , although I was having trouble understanding what the idea was exactly , maybe if i heard the talk i would have understood sooner how horrible it is.

First the presentation talks about the bigger neural networks aproach, and kind of describes what's basically narrow ai that imitates humans , and Im not sure how you can get from that to an actual GAI , this was superposed to be a list of ways to to create one , but fine lets continue. then the unsupervised learning aproach basically has ??? in the part thats actually the important part that requires you to get the ai to understaand what you want . At this point I have the impression that the presentation is actually proposing creating something that is not an agent , its jut that it uses agency as something thats only bad and puts agents whith non agents in the same category of "AGI", and then he doent know hot to get from unsupervised neural net aplied on internet data , to actually getting what we want whithout havving something that its an agent so it puts question marks on that point .

Then it talks about ais based on AIXi and then the presentation actually talks about perverse incentives, but for some reason the presentation talks about it like if that was a problem only of that approach. Until now my metal model says that the presentation is actually just proposing creating an actual agi on the AIXi approach where it actually says that creating a god reward signal is difficult. then it talks about brain emulations , nothing to coment in here. Then I reach the artificial life part.......... I realise that my assumption that the person writing the presentation actually undestanding ai safety before were mistaken It literally says the plan is be just create ai and then try to train it to Love(in bold letters ) us.

sarcastic rant/* Because who needs math when you can have empirical data about what basically amounts to a black box , you don't even need to know what you are doing , you just need to train the ai to Love( again in bold letters , this word obviously has 0 hidden complexity) us , what could go wrong ? , it worked whit dogs so I can't why it wouldn't work for human level ai which is clearly like a dog. then it proposes obviously workable solutions to the problem of people training evil ai , such as closely controlling all the computational resources of the planet , or forbidding evolving ai strains. */sarcastic rant.

And it ends with the mmo thing...

So yes it was as horrible as you said and way more that I expected , and even if this ends up being representative of how open ai people thing(And I think at least some actually competent people has to be there but maybe that's just optimist bias) .I still have hope that they will realise (before dooming the world ) that human values are complicated and that solutions that work when the ai is less intelligent and contained wont necessarily work in the real world once it is smarter . whoever wrote the presentation apparently knows that those problems exist, he seems to think that this problems like perverse incentives only happen when you have an actual mathematical model , and not in"magical neural network training " but at least he knows something about it .And the people in deep mind actually know about Ai safety and they are probably more likely to develop an AGi first that open ai , the problem is that they have bigger incentives to develop it soon instead of waiting to do more AI safety research, being part of a bigger company where the decisions aren't made by them .