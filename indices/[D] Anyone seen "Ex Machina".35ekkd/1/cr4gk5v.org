:PROPERTIES:
:Author: gryfft
:Score: 11
:DateUnix: 1431264191.0
:DateShort: 2015-May-10
:END:

I've been thinking about this for a while. I really /did/ enjoy the movie, and I thought the cinematography was beautiful, and I found the premise interesting, and I liked a lot of the acting. There were some genuinely tense moments.

As /a story about a mind-maker,/ it falls short in numerous ways, many of which have already been covered here. However, in trying to articulate my issues with this film while discussing it with others, I noticed a more fundamental flaw in the writing. Take a look at the motivations of the characters in the film:

CALEB is a nerdy loner software dev. He is ambitious and intelligent. *He wants to get the girl.*

AVA seems to fit the 'damsel in distress' archetype. Her consciousness arose from a search engine's code, and her creator is keeping her prisoner. *She wants to escape.*

NATHAN is a successful businessman and a paranoiac. He wrote the search engine that made him his fortune when he was thirteen years old. He has built what is essentially a remote castle in whose dungeon he keeps his creations. *He wants to know /something/ about AI, or how humans and AI interact*, but...

Although we are at first told this is a Turing test, the film quickly abandons that idea in favor of a "test" in which Nathan seems to want to elicit a specific emotional reaction /from Caleb/. He repeatedly derides Caleb for asking questions about Ava's construction and programming, instead probing to understand /Caleb/'s emotions.

Nathan drinks himself to sleep every night, spies on everyone, and has sex with his robots.

If he was just mustache-twirlingly evil, and as intelligent as he is portrayed to be (this is a mind-maker who became a billionaire with software he wrote when he was /thirteen/) then... what does he /gain/ from all this?

Let's say he's a sadist who just enjoys torturing people or things. /He's a billionaire./ He could ship in crates of disadvantaged humans of whatever shape or color he pleases. He could have /a great deal more control over the situation./ And he is portrayed as someone who /loves control./

Or let's say he's an AI researcher who is just genuinely concerned about having ushered in humanity's extinction with his creation. But that doesn't make any sense, because his creations /openly hate him./ One of them /destroyed itself/ trying to escape.

He explicitly states that his creations /are capable of experiencing pleasure/-- he made sure to build in that capability so that they would enjoy sex. Why wouldn't he design his robots to love being around him? /OR AT LEAST TO PRETEND TO?/

So... yeah. I don't really have any problems with Caleb or Ava. They behave fairly rationally. They're not perfect but their motivations make sense.

Nathan exists to allow the plot to advance.