:PROPERTIES:
:Score: 1
:DateUnix: 1433658379.0
:DateShort: 2015-Jun-07
:END:

Basically anything I might say will get this sub raided by [[/r/badphilosophy]]. [[http://www.reddit.com/r/badphilosophy/comments/38tw27/why_is_having_a_philosophy_degree_under_my_belt/][Alas, now they're attacking their own, as Scott has a philosophy degree.]]

Strong-naturalist philosophy can be useful. So far, I'm a fan of Peter Railton, the two Churchlands, and maybe I've read dribs and drabs of other stuff.

At one point I also started asking some of my friends who had more education in the humanities than I do if I'm just a dirty STEM wanker or if philosophy really just does seem to everyone like, as one friend put it, "atheistic mysticism." They said it wasn't just me. I sometimes find myself nodding along to the [[http://lesswrong.com/lw/4zs/philosophy_a_diseased_discipline/][extremist]] [[http://lesswrong.com/lw/4vr/less_wrong_rationality_and_mainstream_philosophy/][anti-philosophy]] [[http://lesswrong.com/lw/tg/against_modal_logics/][articles]] on LW, which tends to freak me out since I normally find /something/ to object to in anything I read (contrarian dick by nature).

/shrug/

Edit: Actually, no, there /is/ something to object to. Many of the "extremist" articles on LW against the philosophical field, especially in relation to AI, /don't go too far enough/. Comparing philosophy and AI is a kind of bad joke, since /each/ field can accuse the /other/ of having produced nothing and completely failing to live up to its goals, and each is justified within its own framework of thinking. And yet: consciousness is implemented by the brain, and we don't have superintelligent AIs. To make a stronger statement, I think if AI and ML keep going the way they're going at the moment, we will not have superintelligent AIs any time soon. So really, I think both of them should probably get their eyes back on the ball of actual reality.

Overall, you ought to reach for the field of knowledge that best guides you in mapping the actually-existing reality around you. Be ruthless: if you can gain by reading philosophers, do so, and if you can't, don't. One thing philosophers are distinctly good at is challenging your preconceptions; the only problem is finding someone who will challenge already somewhat-accurate preconceptions in favor of /radically/ accurate preconceptions rather than in favor of even-more-nonsensical preconceptions. If you are trying to be "epistemically rational", in LWian terms, then your job is to maximize the degree to which your theories allow you to predict your experiences of the world inside and around you, /not/ to start questioning the nature of reality when it fails to suit your predictions (that's called /depression/).