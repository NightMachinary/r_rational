:PROPERTIES:
:Author: Chronophilia
:Score: 13
:DateUnix: 1475524018.0
:DateShort: 2016-Oct-03
:END:

#+begin_quote
  At the top level of DWIM is Coherent Extrapolated Volition
#+end_quote

To fit the naming convention established by the previous entries, I suggest Do What's Best. Terminology from fringe theories sounds weird in futuristic sci-fi, it puts me in mind of 1970s stories that assumed psychic powers would be discovered in the future. Besides, CEV has some theoretical flaws and MIRI thinks they can improve on it.

--------------

#+begin_quote
  I tend to hate elements of chance in board games
#+end_quote

I like them best when there's a chance to mitigate the situation /after/ a bad roll. Chance serves to add unpredictability, not to decide the game on-the-spot. It forces you to adapt your plans to changing circumstances, not throw them out the window.

One imagines, for example, that the researchers could realize that their weather forecasting program is googling "how many nukes does the US have", and pull the plug. Or disconnect it from the Internet, or activate some programmed failsafe, assuming they had the time and foresight to put one in. As the AI gets more advanced, they have less warning that it's deviating from its programming and less tricks that'll work. A finished AGI can escape any box - but if you have a finished AGI, you've won the game.

A single Risk roll to decide the whole thing seems... inelegant. The game should be beatable. Is your message that we should only do AI research if we do it right, or that we shouldn't do it at all? If you want to show that there is a "correct" way to do AI in reality, then make there be one in the game - the overly conservative, needlessly cautious approach should be possible and theoretically should eventually produce a stable AGI every time (or at least lose less than one time in a billion), but be impractically slow and beaten by an opponent with a more aggressive strategy. I think that's the message you're shooting for.