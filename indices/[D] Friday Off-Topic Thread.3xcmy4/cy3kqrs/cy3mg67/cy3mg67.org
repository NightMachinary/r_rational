:PROPERTIES:
:Author: alexanderwales
:Score: 6
:DateUnix: 1450462157.0
:DateShort: 2015-Dec-18
:END:

That's a result of the 90-90 rule. The first 90% of the code accounts for 90% of the development time, while the last 10% of the code accounts for the remaining 90% of the development time. The less tongue-in-cheek version is a version of the Pareto principle; 80% of the effects come from 20% of the causes. My experience with software development suggests that OCR is /still/ not going to be truly done in another ten years, but it will probably be good enough for /most/ use cases, with development effort slowly dropping off after that.

One of the arguments given by Bostrom, Yudkowsky, et. al. is that we don't really have any idea where superintelligence lies on the scale of effort for AI development. It might be that once we have a proper model, the jump to 1000 IQ is equivalent to getting a computer to read text in a single font and a single color from a page situated the perfect distance away from the camera under ideal conditions. Or it might be that /100 IQ/ is that equivalent. Or /50 IQ/. If we assume that there are big easy chunks and small hard chunks, then that still doesn't really help us because we don't know what our curve of difficulty/effort looks like.