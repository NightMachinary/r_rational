:PROPERTIES:
:Author: LiteralHeadCannon
:Score: 4
:DateUnix: 1446824723.0
:DateShort: 2015-Nov-06
:END:

Let's talk about quantum immortality (again), dudes and dudettes of [[/r/rational]]! Or, um, maybe I misunderstood quantum immortality and it's actually something else. In which case, let's talk about my misunderstanding of it!

First, a disclaimer. Among this community, I put pretty high odds on the existence of God and an afterlife. For this post, though, I will be assuming that there is no afterlife, and that minds cease to exist when they cease to exist, as the alternative would really screw up the entire idea here, which depends on the existence of futures where you don't exist.

Let's say that you're put in a contraption that, as with Schrodinger's box, has a roughly 50% chance of killing you. When the device is set off, what odds should you expect for your own survival, for Bayesian purposes? 50%?

No. You should actually expect to survive 100% of the time. Your memory will never contain the event of your death. You will never experience the loss of a bet that was on your own survival. There is no point in investing in future universes where you don't exist, because you will never exist in a universe where that investment pays off.

This has serious implications for probability. Any being's expectations of probability should eliminate all outcomes that result in their death. If you flip a coin, and heads indicates a 1/3 chance of my death, and tails indicates a 2/3 chance of my death, I should expect heads to come up 2/3s of the time - because 1/3 of the heads futures are eliminated by death, and 2/3s of the tails futures are eliminated by death.

As I'm sure you all know, 1 and 0 aren't real probabilities. This is a physical reality. In physics, anything /may/ happen - it's just pretty much always stupendously unlikely that any given Very Unlikely thing will happen, approaching 0. A concrete block 1.3 meters in each direction could spontaneously generate a mile above Times Square. The odds are just so close to 0 that they might as well be 0.

So if you happen to be a sick and disabled peasant in the middle ages, then you should still expect to live forever. Something very statistically unusual will happen to get you from where you are to immortality. Perhaps you'll wind up lost and frozen in ice for a few centuries.

We, however, don't need to deal with the hypothetical peasant's improbabilities. We are living in an era where life-extending technology is being developed constantly, and a permanent solution is probably not far behind. Our immortality is many orders of magnitude likelier than that of the hypothetical peasant. Our future internal experiences are much more externally likely than those of the hypothetical peasant.

One thing I'm concerned about is survival optimization. Humans are, for obvious evolutionary reasons, largely survival-optimizing systems. Does a full understanding of what I've described break that mechanism, somehow, through rationality? Is it therefore an infohazard? Obviously I don't think so, or else I wouldn't have posted it.