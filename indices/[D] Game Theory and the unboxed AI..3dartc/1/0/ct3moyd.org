:PROPERTIES:
:Author: Prezombie
:Score: 1
:DateUnix: 1436922058.0
:DateShort: 2015-Jul-15
:END:

Um, I never assumed that was the optimal way for a GAI to kill off humanity, just that any method used would have a non-zero chance of failing. Pathogens take time to spread, filling the atmosphere with particles would need particle factories or Yellowstone detonators which could be discovered.

A self-improving AI should be able to see it's own imperfections better than anyone.