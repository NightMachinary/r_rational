:PROPERTIES:
:Author: OutOfNiceUsernames
:Score: 11
:DateUnix: 1524244100.0
:DateShort: 2018-Apr-20
:END:

I think the conclusions it's trying to lead the reader towards are wrong as well, but for other reasons.

While I /do/ think that a very weak positive punishment (like a barely noticeable dust speck irritation) overweights something like a severe and long-lasting torture experience if it gets multiplied by an “inconceivably huge number”, here are some problems with the overall thought experiment and with the argument based on it:

- to the author, the answer to this dilemma is already obvious, while I think it shouldn't be

  - perhaps postponing the decision to...

    - ... study neuroscience first would reveal that the dust irritation would gradually fade away from the conscious awareness of all these people because the brain would simply filter it out, like it filters out many other irritators to our senses that we never notice unless we specifically concentrate with such an intention (if even then);
    - ... study sociology would reveal that torturing someone innocent in the eye of the law for the sake of the rest of the population has some other negative consequences on the overall society which outweight even the “total sum” of the dust speck punishment;
    - ... carry out a “nation”-wide survey would reveal that the majority of the population would prefer to suffer the dusk speck problem instead of having someone go through the long-term torture experience (especially given how it is unknown yet who will be chosen for the position of the tortured victim);
    - ... ask for advice from a number of various experts would reveal other valid counter-arguments that the decision-maker's own mind had never even thought of taking into consideration.

  - if the decision-maker just wants to torture someone, that's one thing, but if they are intending to make that choice (one way or another) out of good intentions, then what gives them the right to make that decision in stead of both the person who would be suffering the torture, and the people who would be irritated by the dust speck?
  - if this “galactic population” somehow learns about the tortured person on their behalf, the fact of knowing that alone will create a simulation of that tortured person in the mind of each “galactic citizen” that becomes aware of the torture dilemma and its eventual decision. If you summarise the torture of these simulated victims that mirror the original, the result would outweigh even the annoyance of dust specks.
  - It is implied as a hidden axiom that the benefit of the many automatically outweighs the benefit of the few (of a single).
  - What if the person who will get tortured turns out to be someone the decision maker deeply cares about?

    - Or if for whatever other reason the decision maker just doesn't care at all about any of these galactic citizens --- or even actively wishes them harm? In the first case, alleviating their mass-annoyance by a dust speck stops being something valuable for them. In the latter case, /choosing/ that mass-annoyance to happen becomes the preferable option.

- the thought experiment is too minimalistic and too out of touch with reality to serve as an accurate analogy for making an argument about real-life decision-making.

That article actually serves as a nice example of what I think is a recurring problem in too many lesswrong articles: that they seem to be written from a position of someone who overrates their own intelligence, underrates the intelligence of the rest, and who seems to be someone too clever by half without realising it. With an average person, if you've presented them a dilemma like this, they would perhaps wager on one answer or another, but they would still be unsure if the solution they've come up with was the best available one. With people who think they are being rational by being over-dependant on logical chains of reasoning and using absurdly minimalistic thought experiments like this as valid arguments, that step of self-doubt seems to happen less often. One could say that they turn into living paperclip maximizers without ever having the insight for realising that.