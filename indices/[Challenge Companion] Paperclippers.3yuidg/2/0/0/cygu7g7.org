:PROPERTIES:
:Author: LiteralHeadCannon
:Score: 1
:DateUnix: 1451527130.0
:DateShort: 2015-Dec-31
:END:

Basically, humans are pretty good, for the most part, at not having our values short circuit (ie, turn into a paperclipper, or, in the other direction, commit suicide), because our values are not reducible to a single sentence that we're consciously aware of and drives all of our actions.

(EDIT: Incidentally, though it's not nearly as bad as a paperclipper going FOOM - it's basically just a system crash - I think another major problem AI researchers are going to have is AIs committing suicide by means of self-modification - wireheading themselves at the first opportunity.)