:PROPERTIES:
:Author: electrace
:Score: 3
:DateUnix: 1451583533.0
:DateShort: 2015-Dec-31
:END:

#+begin_quote
  I think the best way to avoid a paperclipper is to set limits on the utility function; eg. make as many paperclips as possible with 280GJ of mass/energy per hour (or whatever units make sense).
#+end_quote

It could just make external computers that it doesn't consider part of itself to do all the heavy work.

#+begin_quote
  As long as the AI doesn't edit its utility function to remove this limitation
#+end_quote

It can't. An AI isn't an agent that is bound to obey it's source code (in which case, you may expect that it would try to munchkin its way out), the AI /is/ its source code.

All motives are based on its utility function. There's nothing to motivate it to change its utility function.