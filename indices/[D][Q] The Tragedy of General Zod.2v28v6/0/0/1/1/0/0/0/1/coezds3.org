:PROPERTIES:
:Author: Empiricist_or_not
:Score: 1
:DateUnix: 1423407092.0
:DateShort: 2015-Feb-08
:END:

#+begin_quote
  Couldn't we try to find out about the actual science of human cognitive enhancement before declaring that it will inevitably Go Horribly Wrong? Normally I'm early to the party on saying transhumanism should have caution and display ethical scruples, but declaring everything, including human beings, an "existential risk" (reason for scare quotes: risk to what?) until proven otherwise seems... well... dare I say this... kinda ignorant.
#+end_quote

[[http://www.amazon.com/Superintelligence-Dangers-Strategies-Nick-Bostrom/dp/0199678111][Superintelligence: Paths, Dangers, Strategies]] is really worth reading. The essential argument is that getting to a superintellegence is a get it right the first time, or you probably go extinct problem. Human modification is probably the easiest way to get to making a superintellegence, but all things being equal it is very hard to be certain what the value structure of the resulting super-intelligence will be as human value structures are mutable, so you are probably going to get it wrong. In general he lays out what the paths are, and how far we are from them, though you can see from the beginning that he has already decided that CEV (Coherent Extrapolated volition) is the only way to go.

Edit: I started a new [[http://www.reddit.com/r/rational/comments/2v6zv8/qdst_what_are_your_good_rolemodels_for/][thread]] for good fictional examples of transhuman and posthumans, because your points on the doctor are well taken, and I'm interested to see which other fictional idols shatter under assault from the community.