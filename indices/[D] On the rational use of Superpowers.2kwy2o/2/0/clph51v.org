:PROPERTIES:
:Author: thirtysevenFG
:Score: 1
:DateUnix: 1414787193.0
:DateShort: 2014-Oct-31
:END:

I guess I'm viewing this superpowered person as an external influence, separate from humanity, even if they are technically human. So instead of humanity growing based on the collective everyone, you've suddenly put all of humanity in the hands of one person, even with "robots", and by doing so completely changed how we would develop.

I actually like your idea about tasteless food I never thought about something like that and I could see that working, although I still think you run into some issues with that line of thinking as I talk about below.

The problem I see with the "guardian" solution, I always imagined AI's or something but same idea I think, is that now instead of having the negative consequences be physically based, you are now fundamentally changing human culture/nature, or what it means to be human. Is it worth it to save something if by saving it you've essentially destroyed what defines that thing? Again I feel like I'm pretty much just arguing for the Prime Directive here. If you had all that power you would have a heavy responsibility to use it in a way that wouldn't have disastrous consequences, whatever form they might take. Essentially if the action you take is so small as to not really affect human development then it probably is going to have such a small effect that you would be better off leaving us to figure it out. And if the effect is big then suddenly you've forced humanity to change course and now you are back to Prime Directive territory.