:PROPERTIES:
:Author: That2009WeirdEmoKid
:Score: 5
:DateUnix: 1491165278.0
:DateShort: 2017-Apr-03
:END:

That was my point. If I was trying to convince the gatekeeper that I'm benevolent, using a basilisk argument (whether I'm evil or not) would go against that goal, right? Since it wouldn't work on me, there was a non-zero chance it wouldn't work on the gatekeeper. It's high-risk/reward since I could straight up lose by admitting I'm evil. Yes, it could've worked regardless of my admission of evil, but I didn't want to gamble on that considering the gatekeeper literally admitted he was willingly irrational. Was I wrong in thinking like this?