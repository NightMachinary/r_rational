:PROPERTIES:
:Score: 8
:DateUnix: 1501272863.0
:DateShort: 2017-Jul-29
:END:

#+begin_quote
  I think any civilisation capable of not only full-brain emulation, but also of searching the emulation for specific content would automatically be able to create a superintelligence in a very short time,
#+end_quote

/But they don't want to./ At least by my observations, most people in power want to keep our setting, so to speak, /exactly the same/, for as long a time as possible, whatever technology gets developed.

The biggest reason that a malign superintelligence would develop IRL - /at this point/, with many experts being aware of possible danger and agreeing that safety is a meaningful concern - is that someone /goes rogue/ and uses a powerful AI to /fight the system/. The people who are already well-integrated into the system have every incentive to stop anything from happening: they can always shrug and say that /humanity/ is still in control, where by humanity they of course mean themselves.

Sorry, Professor Quirrell, but "you fools, you'll destroy us all" is actually just a rallying cry for clamping down on anyone capable of powerful magic to make sure that the Malfoys' political chess-game isn't disrupted.