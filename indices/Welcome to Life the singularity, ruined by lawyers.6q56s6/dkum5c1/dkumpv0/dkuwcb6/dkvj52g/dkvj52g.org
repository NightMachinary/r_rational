:PROPERTIES:
:Author: TheConstipatedPepsi
:Score: 6
:DateUnix: 1501304841.0
:DateShort: 2017-Jul-29
:END:

#+begin_quote
  But they don't want to. At least by my observations, most people in power want to keep our setting, so to speak, exactly the same, for as long a time as possible, whatever technology gets developed.
#+end_quote

This works if you ignore all the people in power at Google, Facebook, Amazon, Microsoft, etc. who are all desperately dumping money into AI capabilities research. They do want to build super-AI, every civilisation which still has problems to solve wants to build a super-AI which listens to them, because that's basically equivalent to solving every problem. So unless the civilisation implied by the video does not have any more problems, they would still be trying to build ever more capable problem-solving agents.

#+begin_quote
  The biggest reason that a malign superintelligence would develop IRL - at this point, with many experts being aware of possible danger and agreeing that safety is a meaningful concern - is that someone goes rogue and uses a powerful AI to fight the system.
#+end_quote

I think you underestimate both the number of experts who don't take superAI concerns seriously and the difficulty increase in building a safe superAI vs. a typical superAI.