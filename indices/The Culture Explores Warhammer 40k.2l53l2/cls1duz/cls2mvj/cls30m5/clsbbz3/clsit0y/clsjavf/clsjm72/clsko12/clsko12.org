:PROPERTIES:
:Author: starfries
:Score: 2
:DateUnix: 1415103451.0
:DateShort: 2014-Nov-04
:END:

On a personal level I do agree with you and I'd like to be as smart as I can be, but I'm not sure it's self-evident that this is a good thing or a meaningful pursuit. Even if you look at our society, one that emphasizes growth a lot more than the Culture, you find that a lot of people value things like friends, family, shared experiences and those sorts of things above pure mental self-improvement and studying by yourself in the library. And who's to say that's a bad thing? I think it's a false dichotomy to say that you must engage in exponential self-improvement to lead a meaningful existence and labeling the alternative as solipsistic masturbation. It's very telling that death is an accepted part of Culture society even though immortality is easily attained because that sort of thing would be unthinkable to a society that values progress and improvement above all.

To me, self-improvement is more of a means to an end, and you hope that the increased understanding you attain by becoming more intelligent helps you find a pursuit that /is/ meaningful. Otherwise, what's the point? You convert all matter in the universe into computing hardware for your ginormous brain and then what? It's just as meaningless as the human who lives and dies a human. I think you'd end up a lot like a Culture Mind, and most of your vast intelligence goes towards thinking up things to do to occupy your vast intelligence.

Whether or not you buy that, let's pretend for a moment you did and set aside the goal of intelligence for its own sake. What value would a Culture citizen derive from massively upgrading his or her mind? Any question that requires superhuman brainpower to solve can be answered immediately through neural lace by a Mind. Personal danger is immediately recognized and deflected or undone by the Mind. You already get a vote, worth as much as a Mind's, so what else is there to be gained? On the other hand, your personality and everything that's "you" is nearly indestructible because it's small enough that you can have nigh-unlimited backups and versatile because you can insert it into just about any sort of physical form and you can indulge in very human things like falling completely in love and not have to worry about the effect that might have on your sanity. As a Mind the stakes are much higher because if you mess up, there's no one to rescue you. And people might die, or worse. To me, it's the difference between being an adult and being a kid... and I bet there are a lot of adults who wish they could be kids again.

Regarding the earthworm thing: it's not a technical challenge, it's the fact that in order to make a human brain you need to fill it up with /something/. There just isn't enough /stuff/ in an earthworm's brain to fill a human brain, so the majority of this human's personality will have to be created on the spot or derived from some other source. I mean, what kind of movies does an earthworm like? Who does this earthworm vote for? And at this point the brain is that of a human, even if you remove the original, tiny earthworm bit from it, so if you downgrade by discarding the stuff you added you are essentially killing a human.

#+begin_quote
  The Culture seemingly falls on the side of letting the addict drug himself into a coma as long as it's his personal choice. I think that kind of freedom works only when you have a society of truly rational agents, otherwise it really is sometimes better to force things on individuals for their own good.
#+end_quote

Ooh boy... not sure I wanna touch this one. Although... if you're going to force him to decide according to an algorithm, why don't you just run the algorithm for him and tell him the answer?

Lastly, I'm as interested as you in reading a book that does superhuman intelligence well. Unfortunately it might be asking the impossible. Many people have tried (and not just with AI, but with superheroes, aliens, etc.) and I don't know if I've ever seen one that's really convincing because, well, human writers. And would you really recognize it when you see it?

I hope you do read the books. I'm glad you value my opinion but I make no promises that anything I wrote even resembles anything written by Banks and even if it does, he's a far better writer than I am.