:PROPERTIES:
:Author: starfries
:Score: 2
:DateUnix: 1415121392.0
:DateShort: 2014-Nov-04
:END:

I meant consistently improving in an asymptotic way :p Suppose that the calculations for successive improvement take longer for each iteration so that your technology follows an atan curve or something. Is it worth continuing to run on this treadmill if your advancement is fundamentally limited?

Some more hypotheticals - what if someone else whom you trust as sharing your values has hit the singularity before you? What do you do when you've reached a level where no further improvement is possible? What if further self-improvement directly conflicts with your values (if for example you need to destroy another civilization to continue). Is there a need for self-improvement if you /can't/ make the universe better, or when you already have all the capabilities you need?