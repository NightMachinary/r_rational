:PROPERTIES:
:Author: Veedrac
:Score: 4
:DateUnix: 1519727887.0
:DateShort: 2018-Feb-27
:END:

#+begin_quote
  It isn't because it is correct, but because it is so ridiculously weak that I don't see how you could convince me that it's wrong.
#+end_quote

This reminds me a lot of [[http://lesswrong.com/lw/up/shut_up_and_do_the_impossible/][the AI box experiment]]. First someone said "a superintelligence can't possibly convince me of X, no matter how smart it is", then Eliezer (not superintelligent) convinced him. Then an onlooker said "I know you just convinced someone who was convinced he couldn't be convinced even by a superintelligence, but I'm still convinced a superintelligence can't convince me of X", then Eliezer (still not superintelligent) did it again.

Not seeing an argument doesn't mean there isn't one.

#+begin_quote
  The belief that "I exist" (in the weakest possible sense of the word) is like a single block. There aren't any other assumptions necessary for it as far as I can tell.
#+end_quote

I've already said why I disagree with this. I can certainly imagine myself not believing I exist.