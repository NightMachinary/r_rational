:PROPERTIES:
:Author: OutOfNiceUsernames
:Score: 1
:DateUnix: 1519828978.0
:DateShort: 2018-Feb-28
:END:

- (0) Things, the counter-arguments to which would instantly be proven false the moment I tried considering the accuracy of those counter-arguments that the world has presented to me:

  - “I believe I can believe.”;
  - “I believe I can change my beliefs.”; (?)
  - “I believe in my ability to think.”;
  - “I believe in my ability to understand what a belief is.”; “... what believing is.”; etc;
  - “I believe currently the flow of time (laws of physics, etc) around me is such that it makes it possible for my mind to continue being functional.”;
  - “I believe at least some sort of consciousness exists inside of what I am used to think of as my mind.”

- tautological statements:

  - 1) I believe statement X is True OR False OR Invalid. Example statement X: the pen is blue. Normal world: the pen continues to be blue (statement True). Stress-test world: the pen suddenly turns out to be red for whatever reason (statement False). Stress-test world: turns out there is no pen at all, there's no me, there's no colour blue, etc (statement Invalid). In all possible cases, however, the higher-level statement still continues to hold true.
  - 2) Building (or acquainting oneself with) a logical system and then believing in a property of the said logical system. E.g. with binary counting system taken as the logical system, and the statement 1+1=10 taken as the belief, I think there'd be no way to convince me that this statement will not hold true inside that system. And even if I did somehow get convinced that there is some way for 1+1=10 to hold false inside binary counting system, I can create an even more minimalistic logical system which only states that inside this system, 1+1 is equal to 10, and then I can say that I have absolute belief that inside this system 1+1 will always be equal to 10. I think [[/u/1337_w0n]]'s example was an imperfect example of this.

- “I believe at least some of my beliefs are not axiomatic beliefs.”
- “I believe belief X can't be an axiomatic belief.”
- “I believe there is a chance --- however small --- for X to be true.”; “... for X to be false.”
- “I believe at least something exists.”
- “I believe at least something is possible.”

Possible candidates:

- “On the relatively same intensity scales, last time I checked pain was more difficult to tolerate than pleasure.”;
- Find such a state of being X that 1) it would be impossible for my current self to turn into that state, no matter how many incremental changes happened between now and that final state (to deny the Sorites paradox) and 2) I define my “I” of the current state in such a way that it would be incompatible with being state X. In other words, if it turned out that I was in state X, my image of I would collapse instead. Then: “I believe I am not in state X.”;

  - possible examples: “I believe I am not omnipotent.”, “I believe I can not comprehend the world in its entirety.”

--------------

I'd also like to point out a certain difference. Compare: (1) “I believe that I axiomatically believe in X” and (2) “I axiomatically believe that I axiomatically believe in X.”

Since we are talking about beliefs being changed through /arguments/, the changes happening to the world should stay limited to the domain of the axiomatical belief that's part of the statement. That is, if I said (3) “I believe that I axiomatically believe in X” and the world suddenly changed in such a way that I developed a very specific kind of brain tumour that made me stop believing in X, that wouldn't count as a failed stress-test against statement #3, because mind-controlling me into shifting my belief is not the same as arguing me into changing it.

This is not to say, however, that mind-controlling me would never be a part of a stress-test world. For instance, if my statement was (4) “I believe that I have memories of X”, then since my mind itself becomes the domain of the axiomatic belief, for the world to mind-control me into forgetting that memory would indeed become a valid counter argument against statement #4.

This is why I think axiomatic beliefs would by their nature mostly be limited to relatively pure, abstract logical statements, or to such properties of the believer's mind that they don't additionally make the believer's mind itself part of the domain of the axiomatic belief (with the #0 group of bullet-point statements being exceptions to this due to the “paradox immunity”, so to speak).

p.s. This could be a fun game to play at parties once or twice!