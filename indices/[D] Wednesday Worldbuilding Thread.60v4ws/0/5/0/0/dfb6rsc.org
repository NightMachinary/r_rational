:PROPERTIES:
:Author: BadGoyWithAGun
:Score: 1
:DateUnix: 1490284232.0
:DateShort: 2017-Mar-23
:END:

I doubt that. You could set hard limits on its lifespan, growth and kill count, and make it maximise the given utility function within those constraints. Given the situation you've outlined above, you wouldn't even need to completely kill AI research, just buy yourself some time and possibly terrorise some researchers into helping you solve the control problem.