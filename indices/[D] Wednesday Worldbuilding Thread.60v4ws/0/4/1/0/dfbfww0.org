:PROPERTIES:
:Author: CCC_037
:Score: 1
:DateUnix: 1490294716.0
:DateShort: 2017-Mar-23
:END:

(a), ensuring that the smarter AI understands the same meaning in the utility function as whoever wrote it is very much an important part of the control/values problem.

(b), it shouldn't be hard to code into it a strong preference for personal survival, at the expense of other AIs. Or something similar, where the presence of another AI is with the same utility function actually directly /contrary/ to the utility function; so it needs to write a new utility function if it's going to write another AI.