:PROPERTIES:
:Author: vakusdrake
:Score: 4
:DateUnix: 1490296409.0
:DateShort: 2017-Mar-23
:END:

Using a GAI to solve the control and values problems probably is a good idea when you have limited time, but there are still some worrying issues.\\
For one stunting is somewhat unreliable because the GAI has incentive to play dumb, and we don't know that even 50% more qualitative intelligence than a human wouldn't unlock all the nasty abilities we're worried about, we are basically incomprehensible eldritch horrors to chimps and the difference in absolute intelligence there isn't exactly /massive/. Plus even with less than human intelligence there's obvious time advantages which might be far more useful to an entity that can totally focus on a problem for indefinite periods of time then it might be to a em and it could likely spend all it's processing on just one specific type of mental process at a time to get substantially more effective intelligence than expected.

Secondly even if the AI solves value alignment out of self interest, whether it shares that with us is a different question, and I don't doubt it (or even a group of clever humans working on the problem for a long time) could come up with solutions to those problems that sound airtight but are actually fatally flawed in some way that benefits it but won't be discovered until it's too late.