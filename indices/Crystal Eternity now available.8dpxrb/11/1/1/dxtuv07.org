:PROPERTIES:
:Author: Sailor_Vulcan
:Score: 2
:DateUnix: 1524492365.0
:DateShort: 2018-Apr-23
:END:

Really. You think it's at all plausible that a superintelligence could actually be tricked into believing that kind of obvious nonsense? We're talking about something that any regular human with common sense who understands reductionism should be able to recognize is bs. I don't buy it.

This honestly feels like the author wrote himself into a corner and couldn't come up with a plausible way to resolve the plot with a happy ending without a weird unrealistic metaphysics hack which makes AI alignment in the story unrealistically much easier than it should be, and that's even AFTER a bunch of unaligned superintelligences have already taken off.

If it were real life, humanity WOULD have been doomed as soon as they made an unaligned superintelligence, or at least as soon as it gained access to the internet.

It would not have taken until book 3 for Face or the rest of the crystal society to suddenly realize that their advanced alien hardware would allow them to drastically improve their processing speed and efficiency. They would have realized it pretty much as soon as they started investigating body, which would have happened much earlier.

The big metaphysics hack towards the end actually kind of reminds me of when EY put legalized rape in his otherwise genuine human utopian setting in Three Worlds Collide just to morally shock the readers into seeing the futuristic humans with an outsider's perspective instead of identifying with them too strongly. This is almost as bad as that.

The mistake both authors are making looks like "well we gotta be totally wrong about /something/ that were really sure of, but we just don't know what. So have we considered pretending in story that this totally arbitrary fact that we are extremely certain of in real life, like that rape is wrong, or that 1+1=2, has been falsified in the distant future?

No. Just no.