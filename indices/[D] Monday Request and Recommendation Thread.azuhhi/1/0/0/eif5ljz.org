:PROPERTIES:
:Author: Veedrac
:Score: 1
:DateUnix: 1552473537.0
:DateShort: 2019-Mar-13
:END:

Since I'm revisiting this anyway, the other half of my unwritten response was to distinguish my use of ‘hyperintelligence' from the standard term ‘superintelligence'. I consider superintelligence reached whenever the best humans are outperformed at a task; I use hyperintelligence to distinguish those superintelligences that are most acute, such that no practical quantity of humans provide even modest competition.

A real-world example would be bitcoin mining, where a single GPU may outperform the entire planet of humans, despite the task being readily parallelizable. A non-example might be chess, since humans still evaluate some positions better than any current AI, and human-AI hybrids still outperform pure AI players at long time controls, albeit increasingly modestly.