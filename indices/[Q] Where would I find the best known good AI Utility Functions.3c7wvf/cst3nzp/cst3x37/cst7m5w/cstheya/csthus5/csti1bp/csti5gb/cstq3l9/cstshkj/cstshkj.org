:PROPERTIES:
:Author: eaglejarl
:Score: 1
:DateUnix: 1436190797.0
:DateShort: 2015-Jul-06
:END:

First of all, the universe doesn't hate anything. It's not sapient.

Second, there are lots of unsolvable problems. I refer you to GÃ¶del, Heisenberg, and Cantor for examples.

Third, you're missing my point. Sure, /maybe/ we can figure out how to program a terminal goal. Expecting that goal to /remain/ terminal is ludicrous when stacked against something as simple as corruption caused by substrate error/failure, bit-flips due to cosmic rays or other random chance, and the simple fact that an AI immensely smarter than us might try to get around its programming. For example, one method of self-improvement would involve genetic algorithms, which could very easily disturb the terminal goals -- and that could even be an accident.