:PROPERTIES:
:Author: eaglejarl
:Score: 1
:DateUnix: 1436156599.0
:DateShort: 2015-Jul-06
:END:

Are you suggesting that we could program a self-modifying eventually-superhumanly-intellgent AI sufficiently well that we could specify its terminal goal and ensure that that goal would never be modified, accidentally or on purpose, as the AI evolved?