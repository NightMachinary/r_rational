:PROPERTIES:
:Author: Salivanth
:Score: 1
:DateUnix: 1436227173.0
:DateShort: 2015-Jul-07
:END:

So we're on the same page; are you thinking of a utility function for an actual FAI, or a story FAI? If the former, there isn't anything good yet. For instance, in your definition above, you would have to define all those concepts such as "self-regulation of attention", "awareness in the present moment" and so on rigorously enough for a computer to know what it was.

If the latter, you can assume all this troublesome work has already been done for you, which makes it actually possible to come up with a utility function. Your Dukkha idea might work in this case, though I think "Satisfy the values of sentient beings" is better. If a super-intelligent being attempted to create your environment in such a way as to maximally satisfy your values, I doubt you'd be discontent all that often anyway.

Friendship is Optimal explores a similar idea, where the utility function of the AI is "Satisfy values through friendship and ponies". Whether or not this AI is friendly is a disputed issue among the fans of the story, so I'd make up my own mind.

[[http://www.fimfiction.net/story/62074/friendship-is-optimal]]

It's a My Little Pony fanfiction, technically, but it's set in our world, where MLP is just a TV show, and doesn't refer to canon much if at all. A quick skim of the Friendship is Magic wikipedia article ought to be more than enough background material.