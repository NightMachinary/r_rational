:PROPERTIES:
:Author: xamueljones
:Score: 1
:DateUnix: 1436164683.0
:DateShort: 2015-Jul-06
:END:

Thanks for the call out!

I wasn't planning on posting any sort of answer, because I've only studied enough cognition to understand how complex goal systems can be without having any idea of how to 'translate' into AI utility functions.

But I'll take a stab at it anyway. Wish me luck.

The main problem I see here is the fact that no one actually follows a single goal 24/7. We have a series of priorities ordered in some sort of process that looks like a list of lists. For example, we tend to focus on securing survival first by getting a job and earning enough money to support our selves, then comes social status to have connections through friends and family, and with entertainment as a competing priority. And that was an extremely simple example of how we order three separate goals all with their own subgoals which can shift in importance over time. We act dramatically different when chasing different goals and many goals can require you to fulfill a different goal first (ever have to complete a task for someone else before they help you?).

This complexity in our goal-completion process is the reason IMHO why we have convoluted moral philosophies and a 'way of life' instead of something simple like a single guiding principle or a 'Prime Directive'. Even if a single goal could be used to determine everything we do, this can't happen in real life, because we have to make trade-offs between several competing needs instead of being simple maximizers.

Therefore, I believe (while keeping in mind I could be horribly wrong) that AIs would need to have sets of utility functions as probabilistically weighted requirements rather than one single goal to strive for.

Disclaimer: Keep in mind that everything I said was the idea of translating how humans appear to structure and pursue goals mapped onto AI utility functions. The space of possible minds are /huge/ and it's possible that everything I said isn't relevant in the slightest.

PS Of course I say all of this before I take 'Neuroeconomics' in a month on how we make social decisions. ;)