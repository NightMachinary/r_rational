:PROPERTIES:
:Author: Areign
:Score: 1
:DateUnix: 1492619497.0
:DateShort: 2017-Apr-19
:END:

thats not really an answerable question because values aren't a countable set. What we call valueing X is really just us describing that if feels like our utility function increases when you get more X. It doesn't describe how it increases (logarithmically, linearly,...etc) or how it interacts with other things. A better way to look at it is if every person is going to get 1% less utility under the superhappy compromise (1% less in terms of their pre compromise values) then the question you should be asking is 'will hummanity ever be numerous to wipe out that finite loss of utility from the death of X people at Y utility' Well that number is pretty easy to calculate, its just 1.5 trillion under some basic assumptions.

Further, more generally, if the compromise would result it a loss of 1/L utility per person, and avoiding it requires killing Z people, you just need to have avoided converting Z*L people for it to be worth it. This doesn't seem hard with a spacefaring civilization.