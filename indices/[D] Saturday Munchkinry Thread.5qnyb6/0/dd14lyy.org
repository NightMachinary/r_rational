:PROPERTIES:
:Author: DRMacIver
:Score: 7
:DateUnix: 1485638275.0
:DateShort: 2017-Jan-29
:END:

I'm looking to expand the "age of failed dreams" rules for Programmer at Large to get a sense of the boundaries of technology and what I should be looking out for. What I'm looking for are rules that essentially guarantee that technology in the long-run is a plateau.

Here are the rules I have so far (in no particular order, editing to add new ones as they get suggested or I remember/think of them - I've failed to write these down so far):

- FTL is outright physically impossible
- Ditto most things that would require physics that is currently "exotic" - e.g. no antigravity, no stasis fields
- There are relatively fundamental scaling constraints on intelligence - you can probably get something twice as intelligent according to some reasonable metric as a peak baseline human, but you can't get anything 10x as intelligent.
- No "sci-fi level" nanotech. there's plenty of molecular manufacturing, etc. but self-repairing machines, nanofog construction are all somewher between hard and impossible, with the more exciting the application sounds the closer it is to impossible.
- Intelligence is fragile and tends not to copy well - if you try to copy a brain you'll end up with a brain at most roughly similar to the original, and it might well just not work
- Intelligence is chaotic - it's very hard to produce an intelligence to order and tends to be very sensitive to initial conditions
- AI is possible within the above constraints but tends to be quite expensive to run (the human brain may not be the smartest, but as far as intelligence : resource efficiency ratios go it's doing rather well). The best AI are not substantially smaller than a human brain, are tied to their hardware, and are the same order of magnitude speed and intelligence as a smart human (though they may be off the high end of that spectrum many aren't). AI should be approximated as "like very smart humans that use more resources and have faster interfaces to non-sentient computers".
- Brains are hard to interface with in a reliable way. /Some/ direct nerve stimulation is possible, but if you want to fake senses you're more or less required to go via the organs that are designed for that - e.g. implanted screens in contact lenses are viable, but just plugging into the optic nerve isn't.
- Some as of yet unspecified sociological mechanism (some combination of factors including resource efficiency and level of infrastructure required for maintenance) means that pure AI civilizations tend to be less stable than human civilizations.
- No non-sentient technological civilization is possible long-term. They tend to run into outside context problems too quickly because so many problems count as such for them
- Sentient civilization tends to collapse when it grows too large in a confined space like a solar system - resource contention and coordination problems rise pretty sharply with the population.
- Bodies are hard to repair and eventually break down no matter what you do. Life extension is possible, but it tends to hit some pretty hard limits after 200-300 years no matter how good you are at it.

(Note: I make no claim that these are necessarily /realistic/ constraints)

Now, you have 10,000 years to play with. How do you push the boundary of what's possible? Can you effectively bootstrap your civilization to godhood?