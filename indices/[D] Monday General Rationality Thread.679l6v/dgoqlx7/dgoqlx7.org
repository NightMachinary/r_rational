:PROPERTIES:
:Author: captainNematode
:Score: 15
:DateUnix: 1493048737.0
:DateShort: 2017-Apr-24
:END:

Does it make any sort of sense to artificially couple a difficult (global) decision with a substantially less difficult one (globally, but perhaps more difficult locally), in order to enhance your perspective on the former? And to help ensure that you're acting primarily with the global outcomes in mind? Yesterday as I was driving home from the grocer I was, for whatever reason, reminded of Roger Fisher's [1981] thought experiment re: the storage of nuclear launch codes, instead of the more conventional [[https://en.wikipedia.org/wiki/Nuclear_football][nuclear football]] in use today. He writes:

#+begin_quote
  My suggestion was quite simple: Put that needed code number in a little capsule, and then implant that capsule right next to the heart of a volunteer. The volunteer would carry with him a big, heavy butcher knife as he accompanied the President. If ever the President wanted to fire nuclear weapons, the only way he could do so would be for him first, with his own hands, to kill one human being. The President says, “George, I'm sorry but tens of millions must die.” He has to look at someone and realize what death is---what an innocent death is. Blood on the White House carpet. It's reality brought home.

  When I suggested this to friends in the Pentagon they said, “My God, that's terrible. Having to kill someone would distort the President's judgment. He might never push the button.“
#+end_quote

Of course the exact details here might obscure the essence of the thought experiment -- having to carve the codes out of someone takes time, and if hypothetical enemies know of that delay they might capitalize upon it. The president might be deterred from action due to personal squeamishness or a weak tummy or hemophobia or something, which wouldn't do. But those can be changed trivially -- put the codes in a false tooth that, when wrenched out of the aide's mouth (locked in such a way that only direct contact with the wholly secure RFID chip in the president's finger allows for its release, IDK), directly injects deadly poison into that person's blood stream. Something like that, then: would it serve to clarify the president's thoughts (e.g. if ordering the death of millions of innocents -- now millions +1 -- to plausibly save the lives of 10s of millions more), or to cloud them?

What about other scenarios where you might trade short-term prevention of suffering for potentially setting a bad and easily abusable precedent? Say, torture -- if a torturer (or those directing them), motivated by a commitment to what they judge to be the lesser evil, had to undergo the same agony they inflict on others (or themselves be executed after, say), would that allow for a less damaging precedent? Or maybe some official who wants to violate important privacy norms, but must then commit to a life lacking in privacy thereafter? I think in general the idea would be to disinsentivize possible abuse of the system for nefarious personal ends by imposing personal costs that exceed probable personal gains, so only those guided by their pureness of heart and intention go through with it.

This relates to another idea I'd had with the latest US election -- what if part of the Presidential Oath were a binding and strictly enforced, lifelong vow of poverty (or, idk, middle class-itude) subsequent to their term(s) -- it might filter out those genuinely well-qualified candidates who have so much money they wouldn't want to sacrifice it to serve the nation, but would we “really” trust them to act in the best interests of that nation, anyway? And it could rid us of plenty of emoluments-related issues (they can still use the office to benefit their friends and family, ofc).

I also see this sort of idea pop up in fiction occasionally, e.g. consider [[http://tvtropes.org/pmwiki/pmwiki.php/Main/NoPlaceForMeThere][No Place for Me There]], with opening quote from the movie /Serenity/:

#+begin_quote
  [[#s][The Operative:]]

  [[#s][Capt. Malcolm Reynolds:]]

  [[#s][The Operative:]]
#+end_quote

I think I'd be more inclined to trust that a Well Intentioned Extremist were Doing the Right Thing and Choosing the Lesser Evil if [[#s][their attitude were]]