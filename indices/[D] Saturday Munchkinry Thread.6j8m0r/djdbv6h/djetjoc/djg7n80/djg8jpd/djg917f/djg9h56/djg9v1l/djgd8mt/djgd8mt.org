:PROPERTIES:
:Author: CCC_037
:Score: 2
:DateUnix: 1498547585.0
:DateShort: 2017-Jun-27
:END:

Neural interface could be good, but we don't need to go /that/ far. What we need is an interface that doesn't take your full attention away from everything else.

Another way to accomplish this is an entirely sound-based interface. (Sight has to be focused in a direction - sound can be heard no matter where it is, so it's a better sense to interface with when the person's attention is elsewhere). But there's two halves to an interface; having the phone talk to you is easy. Ideally, you still have to provide input to the phone. Now, for something like a GPS system, the input is provided (through an attention-stealing eye/touch interface) almost entirely at the start of the journey; and then audio output is provided until the destination is reached.

One solution to applications that need on-the-spot input without stealing attention is an audio-only input. Modern phones are halfway there - I can tap on the bar at the bottom of my phone, drag, and input a voice query prefaced with "OK Google" to get a Google-search response. Now I just need to be able to turn that on without looking at my phone.

(Mind you, the direct neural interface would be more useful than a pure-audio one. But not, I think, /that/ much more useful - the pure-audio interface has the look of something with a fair degree of untapped potential)