:PROPERTIES:
:Author: xileine
:Score: 1
:DateUnix: 1589393233.0
:DateShort: 2020-May-13
:END:

#+begin_quote
  So I'm assuming you want examples of paperclip optimizers that are harmful and yet can still get what they want consistently without getting caught.
#+end_quote

Not exactly. I was trying to talk about the interactions of metaethical models between eusocial sibling-civilizations that have incomptaible terminal preferences.

Like, humans civilizations have, after bumping into one-another for a bit, developed a metaethical model that suggests that there are certain "human universal" social mores that are okay to insist on, because no neurotypical human is okay with violating them; while other things are merely cultural mores, and are left up to the members of that culture if not seen as harmful by other cultures, but trod over in the name of "human progress" if they /are/ seen as harmful.

But this doesn't sound like what would happen if two civilizations with truly incompatible sets of terminal preferences (the herbivores and carnivores in Beastars; or humans and some form of eusocial paperclip-optimizers) collided.

What would happen instead, /in terms the development of a shared metaethics/, if we ignore the large parts of the possibility space where one or both civilizations decide that a positive-sum relationship is impossible and just blow one-another up? What social mores would be generated---would be considered foundational? Would the paperclippers agree to not turn humans into paperclips, just other things? Would the carnivores agree that they /should/ be shackled in some way, and do so voluntarily even when there are no herbivores around?

Or, to put this in simpler terms: what do religions in the world of Beastars preach about?