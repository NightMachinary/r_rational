:PROPERTIES:
:Author: LunarTulip
:Score: 11
:DateUnix: 1606230048.0
:DateShort: 2020-Nov-24
:END:

You don't need to trust that every change you make will be an improvement, though, just that the net effect of /all/ the changes you make will remain in S'.

Personally, I self-modify /a lot/, and sometimes very quickly. (It took me maybe a minute or two, once I figured out self-hypnosis, to remove longstanding aversions to the smell of vinegar and the taste of ginger which had up to that point been plaguing me since childhood.) And it seems very plausible that some of the changes I make go against the values of the earliest me who decided that self-modifying a lot was a good thing to do. But nonetheless /my life, overall/, is far more in accord with her values than a more restrained approach to self-modification would have left me.

(And this holds even given a shift in /terminal values/ at one point. The me who got into self-modification was something vaguely resembling an egoist. After some consideration, a later me decided that the optimally-selfish thing to do would be to turn into a utilitarian. And she was right; the change made me notably happier.)

In short: you don't just need to account for the risk of ending up in not-S', you also need to account for the /reward/ of ending up in a /better/ part of S'. If a given change has an 80% chance of increasing utility by 2, and a 20% chance of enabling undesired value drift in such a way as to decrease utility by 4, that's still a change worth making. And risk of undesired value drift /is/ predictable; I'm a lot more cautious when I go anywhere near editing my terminal values than I am when I edit how much I like foods, for example, because a clumsy perturbation to the former will potentially pretty thoroughly derail my future actions, whereas a clumsy perturbation to the latter will most likely just change my liking of the relevant foods in the wrong direction, generally fixably.