:PROPERTIES:
:Author: Nepene
:Score: 1
:DateUnix: 1418246614.0
:DateShort: 2014-Dec-11
:END:

You're welcome.

#+begin_quote
  An AI would be, by definition, self-modifying.
#+end_quote

Like a computer. Core files would presumably be off limits, so their behavior would mostly be the same. They could run new programs and such, but not modify their underlying key files or hardware. I don't imagine most would want an uncontrollable AI, and it likely wouldn't be very effective.

#+begin_quote
  Also, an AI does not need to have "exterminate, exterminate" as its utility function in order to be an extinction risk. Paperclippers (or the equivalent) are a far more probable threat.
#+end_quote

I'd imagine there would be military grade AIs protecting society, a paper clipper likely wouldn't be well evolved to defeat potential threats.

#+begin_quote
  Killing nanotech depends on how much of it has generated and where before people become aware and start fighting back.
#+end_quote

It needs appropriate resources like anything. It's not very smart. It can grow like a disease, by infecting new things.

I'd imagine that by the time it was easy to weaponize people would have a variety of defensive nanotech things to oppose a spread. There'd be accidents, but it's not that hard to stop it.

#+begin_quote
  I don't know enough about the subject to speak authoritatively, but "point a flamethrower at it" sounds a bit too casual for my comfort.
#+end_quote

Low volume means a high surface area to volume ratio which makes it easy to cook the insides.