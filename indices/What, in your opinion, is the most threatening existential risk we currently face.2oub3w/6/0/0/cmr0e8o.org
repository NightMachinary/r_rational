:PROPERTIES:
:Author: Nepene
:Score: 2
:DateUnix: 1418237891.0
:DateShort: 2014-Dec-10
:END:

[[http://en.wikipedia.org/wiki/Asteroid_impact_avoidance]]

#+begin_quote
  Following the 1994 Shoemaker-levy 9 comet impacts with Jupiter, Edward Teller proposed to a collective of U.S. and Russian ex-Cold War weapons designers in a 1995 planetary defense workshop meeting at Lawrence Livermore National Laboratory (LLNL), that they collaborate to design a 1 gigaton nuclear explosive device, which would be equivalent to the kinetic energy of a 1 km diameter asteroid. This 1 Gt device would weigh about 25-30 tons being light enough to be lifted on the Energia rocket and it could be used to instantaneously vaporize a 1 km asteroid, divert the paths of extinction event class asteroids (greater than 10 km in diameter) within a few months of short notice, while with 1 year notice, at an interception location no closer than Jupiter, it would also be capable of dealing with the even rarer short period comets which can come out of the Kuiper belt and transit past Earth orbit within 2 years.
#+end_quote

You can basically scale up nuclear bombs as much as you like, they just add more weight and are less effective than many smaller bombs at killing cities. As noted, you can do this with far less warning than for most weapons. You'd probably use existing crafts as much as possible, maybe build extra engines if necessary.

All the heat you dump into an asteroid vaporizes the material and is ejected. It causes the asteroid to fly off in a different direction.

#+begin_quote
  What safeguards would we build on a fast-takeoff AI that would ensure our safety?
#+end_quote

You'd probably program them with a certain set of ethics and desires that excluded mass death of humans, as appropriate for the application.

#+begin_quote
  What safeguards would we build on nanotech that would ensure our safety?
#+end_quote

A kill switch, need for some rare resources to grow, variants of that.

#+begin_quote
  Assuming such safeguards exist, once nanotechnology / AI is real, it will become cheap enough to be accessible to construction by small groups and corporations. With enough labs building it, someone will be careless or crazy or stupid or evil enough not to incorporate the safeguards.
#+end_quote

For the most part I'd imagine people would use standardized ones like microsoft or linux or apple, and ones that would resist any insane AIs.

For nanotech, it's fairly cheap to kill it, not as big an issue. Flamethrower kills pretty much any nanotech, emp.