:PROPERTIES:
:Author: EthanCC
:Score: 1
:DateUnix: 1587862263.0
:DateShort: 2020-Apr-26
:END:

#+begin_quote
  Yes I linked the SMBC comic I thought it was quite clear.
#+end_quote

That's supposed to be a joke lmao.

#+begin_quote
  Yes as I said the only thing that makes it more justifiable is that my system never has to argue with someone about why happiness is arbitrarily worth 5.425 and not 5.421.
#+end_quote

Your argument isn't more justifiable just because you haven't bothered to quantify things, in fact that makes it /less/ justifiable since you can't actually define the ends you're trying to reach. Without quantification you have trouble arguing between two qualitatively similar ends.

You haven't solved the problem. You've ignored all existing axioms, constructed an entirely different problem, and solved that. A theory that includes existing widely held intuitions and is internally consistent is inherently more justifiable since that would have less to argue against. If you want to argue something has no ethical value, you need to do more than assert it.

#+begin_quote
  Anything else is good because it causes happiness.
#+end_quote

That's a circular argument. You need to argue against things like justice, self-determination, right to life, and so on before you can reduce the whole problem purely to happiness. You've ignored the hard part of the problem, skipped to the 'solution', then worked backwards assuming the solution was true. The argument only works if the conclusion is correct- a conclusion can't be a premise, QED the argument is meaningless.

#+begin_quote
  Quite clear to me.
#+end_quote

Because you've begged the question. This is only an argument if happiness is the only good but you've done nothing to support that idea.

#+begin_quote
  ??? Virtue ethics is more popular than deontology and consequentialism among philosophers, the more this conversation goes on the more I feel like you're just wasting my time
#+end_quote

I went to the [[https://philpapers.org/surveys/results.pl][original source]] and these are the actual results:

Other 301 / 931 (32.3%)

Accept or lean toward: deontology 241 / 931 (25.9%)

Accept or lean toward: consequentialism 220 / 931 (23.6%)

Accept or lean toward: virtue ethics 169 / 931 (18.2%)

Virtue ethics is literally the least popular. So either the source you used is using old data or reported wrong, either way you stopped as soon as you found something that agreed with you and ended up being wrong.

#+begin_quote
  I've repeated a hundred times that people intuitively were okay with slavery
#+end_quote

Ok... explain all the people who /weren't/. Slavery did actually violate some widely held moral axioms at the time (to be clear this is Enlightenment and right afterwards)- right to liberty being a big one. The recognition of this became more widely spread among philosophers, but putting it into practice in areas where slaves were held ran into economic barriers.

Justifications based on self-deception are nothing more or less than that, and a problem of any ethical system. The counterargument is to show the hypocrisy, not to try to convince them of a completely new arbitrary system, and the only way to consistently prevent self-deceptive action is to create hard limits on what you can do... something utilitarianism ignores. Utilitarians also constructed arguments to support slavery, your system isn't privileged in that way (that was the source I gave, not sure what you mean when you say I denied that... *I literally gave an example of a philosopher supporting slavery* in Thomas Cooper, so we can add 'not reading sources' to your list of rationality sins).

#+begin_quote
  I'm done with this conversation.
#+end_quote

Translation: "I realized I fucked up and got into an argument about something I don't understand."