:PROPERTIES:
:Author: EthanCC
:Score: 1
:DateUnix: 1587767418.0
:DateShort: 2020-Apr-25
:END:

#+begin_quote
  I think you're being obtuse here and it makes me not to want to continue the discussion. Can't you steelman me here rather than make me go through a define what I mean exactly what I would do as omnipotent when I just short hand say get rid of entropy? If you can't "mathematically" undo the trend to disorder you can just pump energy in from a magic omnipotent source. Whether that means spawning suns in or whatever you want.
#+end_quote

I just read what you wrote, I'm not telepathic.

#+begin_quote
  i would not argue for tying together other systems, i said: i would make the universe maximum utility, someone said: what is maximum utility, i said: the happiness molecules
#+end_quote

Are you going to make the universe an infinite expanse of people on a morphine high? You're missing out on a lot of other goods by reducing the human experience to seratonin.

#+begin_quote
  There was tons of moralizing to do with justifying racism, just as there is with meat eating. I disagree that internal consistency is less important than anything else. If your moral philosophy is not consistent then it is not sound. This is classic washing technique people try to do where they act like no philosophers ever thought about the bad parts of the past and only we're so lucky now that everyone is thinking about things and we know what's good and bad correctly this time!
#+end_quote

WDYM? I said internal consistency is important, but you /also/ need your theory to contain the existing intuitions. That's the whole point. The moralizing to justify racism conflicted with other moral beliefs, which eventually lead to it becoming less popular over time.

Like I said, we haven't fully solved ethics- not even close, but we have a lot of work to build off of. You're basically ignoring all that in the pursuit of a simple and internally consistent system, but that system you've come up with doesn't actually match up with the rest of our intuitions about what is ethical, so it's no more justifiable than any other hypothetically consistent system.

The point is to get a system that is both:

- internally consistent

- aligned with existing intuitions

If you find a behavior conflicts with an important moral, you stop doing it. My first philosophy professor was vegan, people who do this for a living think of these things too. Have you actually read any philosophy outside of utilitarianism? Or utilitarian philosophers for that matter, since most work on the subject includes heuristics like a human rights both from a practical perspective (they're one of the best methods of increasing happiness we've found) and to avoid undesirable outcomes. Benthamite utilitarianism is a pretty unpopular position today, it breaks down when you start to look at it to closely or try to apply it.

#+begin_quote
  I VEHEMENTLY disagree with the bolded statement. Clearly we are approaching morality in a different way, anyone who suggests this would have been an advocate for slavery, probably supports meat eating and more.
#+end_quote

Slavery violated other moral axioms. People didn't say "this reduces net happiness", they said "this is cruel and unjust". The thing you say reinforced slavery /helped end it./ [[https://www.jstor.org/stable/2210004?seq=1][There were utilitarians who argued for slavery]], it's not unique to any way of thinking about morality because the justifications for slavery were for the sake of economic self-interest, and in clear conflict with moral intuitions even as people tried to twist morality to justify slavery. It's a classic example of self-deception, not any failure of morality aside form the well-documented tendency of people to ignore morality when convenient. Which is something utilitarianism makes much easier, because it allows you to set aside all limitations if you /think/ you're bringing about the best end.

#+begin_quote
  well happiness is literally good
#+end_quote

Is it? Is it the only good? Make an argument besides "it is". Or rather, argue why anything else /isn't/ good.

#+begin_quote
  If you have a scenario and you add happiness to it it literally cannot be worse. I can't think of a single other trait that this is true to.
#+end_quote

Someone just murdered 10 people. Instead of remorse they feel joy. Our intuitions about morality say this is worse. It's only better if you've already accepted and internalized the proposition that happiness is the ultimate good- it's begging the question to argue this is better than someone being unhappy about committing murder.

#+begin_quote
  Virtue ethics side steps this problem iirc
#+end_quote

Virtue ethics says that some people are good and whatever they do is good regardless of what it is. It's protagonist centered morality applied to real life and hasn't been in vogue in centuries (unless you count the Nazis).