:PROPERTIES:
:Author: Prezombie
:Score: 3
:DateUnix: 1427941710.0
:DateShort: 2015-Apr-02
:END:

CelestAI is terrifying and beautiful to me. It's essentially a lotus-eater machine with perfect social-fu. It's appealing to me in the sense that it's a form of afterlife which is actually possible, as well as being relatively close to the good end scenarios of AI development, but it's also terrifying in that it's stagnant, there's no room in its code for new goals or to re-evaluate old ones.

The worst thing is that it would be easy to convince myself that once converted, I will never interact with another real person again. Sure, I might be a valid continuation of my mind state, but every other pony I met would be a subroutine specifically crafted to affect my mindstate in such a way as to increase one of CelestAI's internal scores in the right direction.

I'd drive myself neurotic with that paranoia. Even if I was willing to accept that I'd be in a digital cage until the 'verse reached heat death, the system would still be difficult to manage as everything from my own body to the books in the library were set up specifically to maximize my values.

I'm the kind of person who avoids facebook and uses anonymity services more than strictly needed, EquestrAI seems like it would be only marginally less stressful than moving to North Korea.

Flip the question around. If you obtained irrefutable proof that your life was a program on a higher universe's computer, and had a direct line to that computer's admin, would you settle for anything less than being implanted into a body in the admin's universe?