:PROPERTIES:
:Author: SimoneNonvelodico
:Score: 3
:DateUnix: 1536682299.0
:DateShort: 2018-Sep-11
:END:

True, but at a difference with economy, no one can truly say to be an expert on what a "true" AI would be like - experience with modern ML systems hardly helps much in assessing that. Doesn't mean that there aren't necessarily any risks of course, just that in this case it's all a lot more speculative for all parts involved.

And of course there's also a lot of cross-disciplinary stuff involved. For example, as a physicist, regardless of whether an AI can develop malicious intent, or otherwise be willing to overstep its boundaries, I am highly dubious that there is room in the laws of physics to allow some sort of cataclysmic scenarios (such as grey goo). My impression is that there are so many fundamental limits once you try to go beyond a certain level of performance you just stop achieving meaningful results. You can only munchkin Nature so much.