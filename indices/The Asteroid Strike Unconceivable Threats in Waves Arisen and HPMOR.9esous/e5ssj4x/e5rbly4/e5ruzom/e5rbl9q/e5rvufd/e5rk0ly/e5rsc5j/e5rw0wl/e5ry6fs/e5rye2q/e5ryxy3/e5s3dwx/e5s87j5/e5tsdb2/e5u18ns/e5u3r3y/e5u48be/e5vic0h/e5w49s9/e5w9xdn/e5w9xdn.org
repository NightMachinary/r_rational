:PROPERTIES:
:Author: SimoneNonvelodico
:Score: 3
:DateUnix: 1536832400.0
:DateShort: 2018-Sep-13
:END:

#+begin_quote
  If I'm insulting all the people who didn't figure it out and you're insulting the person who did, then I don't really see why I should care about what's "insulting" rather than what's accurate. Again, intelligence is not the thing I'm pointing at. Rationality is far more than that.
#+end_quote

It's not about insulting this or that. I'm just saying, I don't feel like the reason why more people don't try the SAD cure with lamps is because they can't logically come up with it. Some of them might just be unwilling to take that financial risk (even though a lot of people have $600, not a lot of people are in condition to spend and potentially sink them on a hunch), for example. Some might have done it, but not said it on the internet. Some might have done it /and it might not have worked for them/. Or they had other logistic problems, people or pets in the house who couldn't put up with it, couldn't afford the electricity bill, and so on. There's a bunch of reasons why people don't do this sort of thing that aren't as simple as "they're just not clever enough". In this case, EY's application of rationality is to the idea that there are perfectly good reasons why, without considering yourself better at medicine than doctors, you can imagine coming up with a good therapy for this specific thing. It's not in /actually doing the thing/. In fact, his rationality was used to overcome a hurdle /that only moderately rational people to begin with/ encounter: the "wait, but wouldn't doctors know better if the solution was really this obvious?" one. A less rational or knowledgeable person might just enter full Dunning-Kruger mode and string their house with lamps without ever wondering about that - and just happen to stumble upon the solution.

#+begin_quote
  Should make it pretty obvious that you're not actually talking about social intelligence, but something else, because if the attribute you're pointing at is actually a premium in social intelligence then him being "negatively affected by it" is pretty nonsensical, right? Like, you wouldn't say "This person is super intelligent at math, but he gets affected negatively by it sometimes by not being able to remember his multiplication tables."
#+end_quote

I suppose what I meant was more that "it belongs to the social intelligence sphere". It's not like any type of intelligence is a single D&D like stat anyway - there's a complex landscape of possible skills and axes which will give you bonuses in certain situations and maluses in others. That's what I meant, more or less.

#+begin_quote
  If what you actually meant by this was simply that the phrase irks you for all of what you said after that, specifically because it lulls people into a false sense of security about "okay here's this really smart person so they will know how to solve X super complex problem that everyone's being stuck in," then that's much more sensible, but also seems like less of a concern than the failure mode that's actually occurring in the world.
#+end_quote

That's pretty much it; also I think the phrase itself carries a lot of that connotation already. We're all nerdy-ish people here I expect; "high level rationalist" to me evokes the image of a level system, so a linear scale of skill of sorts. I think that's the wrong way of thinking about pretty much any real world skill outside of relatively easily gauged and consistent ones like how good you are at chess or go (but those tend to be very specialised). It irks me also because when talking about a "rationalist" there's already an implication we're talking about an expert in /meta/-knowledge, which in itself establishes a sense of primacy.

So, if I have to be rational about it: yes, I appreciate EY's writings. I think a lot of them can be insightful, if only in helping me put into words things that I only understand at an intuitive level. I don't think it's even in dispute that I would have a lot to learn from him both in the field of AI and in general in that of statistics and probability (which I know, but probably not quite as well as I should or could). However, I think there's a problem when dealing with someone who's very good at making rational arguments (including myself): they'll also be very good at making rational-/sounding/ arguments with subtle, almost undetectable fallacies. I don't mean in bad faith; usually the person we're out to deceive the most is ourselves. So there's a double edge to this weapon. As you improve your defences, you also improve your own ability to attack them and wreck them. I don't know EY as a person. I know him from what he writes. To call him truly a "rationalist" in the sense of one who's able to /put in practice/ what he talks about (rather than just, say, an expert in logic, or Bayesian epistemology) I would need to, well, run the test; which would require me knowing him in person and getting a feel for whether he really is better at avoiding fallacies or at thinking outside of his own perspective than me (I don't have any doubt that he's better at these things than the /average person/; but 50% of the people are, so that's not much).

In other words, I think it's important to always take claims, ideas and teachings with a pinch of salt - which is the whole point of rationality, after all. As such I guess you could say I feel like attaching certain special labels to people - and especially a label such as "high level rationalist", with the implied meanings it carries - tends in itself to be a mechanism that favours the arising of certain biases we want to avoid inside our minds. I do have a classification of course, but I think not attaching names to things sometimes is a useful strategy to keep them more fluid and think about them in a more elastic way. You could say I prefer having in mind a gaussian curve of rationality where EY may place somewhere around plus three or four sigmas above the average, maybe, but not reduce the gaussian to a binned histogram and give big bold names to the classes. In /my/ mind, I think that helps me keeping a more elastic perspective and putting less resistance to any need to move a point up or down the curve. I assume a similar process may happen in other minds as well, especially as I see a lot of situations in which attaching names and labels seems to cement the status quo in people's mental models of reality and exacerbate divisions. BTW thanks for bringing this up, putting it into words actually helped me clear my feelings on the topic.