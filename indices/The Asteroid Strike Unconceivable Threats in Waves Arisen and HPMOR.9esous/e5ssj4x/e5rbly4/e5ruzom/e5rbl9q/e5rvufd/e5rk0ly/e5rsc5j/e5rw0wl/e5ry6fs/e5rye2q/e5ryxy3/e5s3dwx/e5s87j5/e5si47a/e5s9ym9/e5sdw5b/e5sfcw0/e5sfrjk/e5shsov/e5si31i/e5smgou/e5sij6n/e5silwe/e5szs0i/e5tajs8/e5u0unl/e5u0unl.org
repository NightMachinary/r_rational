:PROPERTIES:
:Author: SimoneNonvelodico
:Score: 3
:DateUnix: 1536741076.0
:DateShort: 2018-Sep-12
:END:

#+begin_quote
  He even criticizes the scientific method for not focusing on testing out the most probable theories first, and basically accepting any theory no matter how unlikely to be worth tested before more statistically likely theories, while at the same time seeing this type of failure as good and productive.
#+end_quote

I think this involves another really deep rabbit hole, which is having a theory of how probable theories are. These sort of heuristics are very tricky. I cited earlier "Lost in Math", that looks exactly at how people in particle physics built up this notion of "naturalness" to discriminate likely from unlikely theories based simply on aesthetic criteria and the vague notion that it's sort of similar to the theories that worked until now. Even though it can be shown that in fact it's not really that way - rather, /our aesthetic sense/ about theories is now shaped by existing ones. So basically we're just looking for more stuff resembling what we already know, like people in the late XIX century were looking for the luminiferous aether because mechanical waves through material mediums was all they knew.

So yeah, not disagreeing that we would need to rethink our methods, especially in some fields. And I've never been very enthusiastic on Popper's notion of falsifiability, that while useful, sort of dumps the entire complexity of the induction problem into the "theory proposing" step, which becomes the really critical one for the /speed/ of scientific development. I'm just not sure a unique way to determine which theories are /more probable/ exists. Of course, in some cases it's obvious. If I meet a new phenomenon, I first try to explain it with existing models than with some novel never-heard-before energy-conservation-violating new quantum theory of matter.