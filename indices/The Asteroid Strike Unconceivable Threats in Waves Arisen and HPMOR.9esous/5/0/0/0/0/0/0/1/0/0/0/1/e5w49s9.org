:PROPERTIES:
:Author: DaystarEld
:Score: 2
:DateUnix: 1536820658.0
:DateShort: 2018-Sep-13
:END:

(edit to make sure I let you know ahead of time that I don't mean this comment nearly as antagonistically as it might come off, but it's late and I'm tired so I hope you believe me if I just say that :P)

#+begin_quote
  It's insulting to suggest that all those people lack the intelligence to deduce that if "some light" is helpful, then "more light" is even more helpful.
#+end_quote

If I'm insulting all the people who didn't figure it out and you're insulting the person who did, then I don't really see why I should care about what's "insulting" rather than what's accurate. Again, intelligence is /not the thing I'm pointing at./ Rationality is far more than that.

#+begin_quote
  In fact, a more clever person could know more about non-linear functions and start making up excellent rationalizations for why that might not be the case. I am confident that EY would back me up on this.
#+end_quote

I'm happy to have [[/u/eliezeryudkowsky]] himself show up and tell me I'm wrong, but I still think you're missing my point. And we definitely need to veto "cleverness." I only kept using that word because I thought it was being used by others in this thread as an offhand substitute for rationality. This whole thing:

#+begin_quote
  EY wasn't the only one clever enough to try it. He was the only one who actually shrugged and went "why the hell not"... Which is in itself a quality, but it's not "cleverness". More, like... willingness to break the mold? Unconventional-ness? Resistance to peer pressure? It's a social intelligence thing, not a smarts thing, though it often happens that science-smart people also possess this trait. In fact it's a trait that might be disadvantageous in some contexts...
#+end_quote

Just seems wrong. "Social intelligence" makes no sense here. What you're actually pointing at seems to fit more with what I'd call "agency." I'm having a hard time picturing what you think a socially-intelligent person looks or acts like, but "let me try this experiment because I think it might work and it's not enough to just trust that smarter people would have published on it if it did or didn't" is not what I would fit under that label, and I think most people wouldn't either.

Also, saying this afterward,

#+begin_quote
  but he also might be affected negatively by it when he comes off as too smug or self-assured to others, because going along with the majority is a powerful bonding mechanism important to social trust. It's why utilitarianism isn't quite as popular as virtue ethics.
#+end_quote

Should make it pretty obvious that you're not actually talking about social intelligence, but something else, because if the attribute you're pointing at is /actually/ a premium in social intelligence then him being "negatively affected by it" is pretty nonsensical, right? Like, you wouldn't say "This person is super intelligent at math, but he gets affected negatively by it sometimes by not being able to remember his multiplication tables."

I get that the idea you're working with is more nuanced than that, I'm just trying to point out that there are sensible joints in that nuance that make it clearly two different domains.

#+begin_quote
  The idea of "high level rationalists" in general also just irks me. It feels like simply sliding back in basic primate mode: find a pack leader, someone to respect and admire, and defer to them.
#+end_quote

If that's your idea of high level rationalists then I get why this is bothersome to you, but I think you're "doing it wrong," or the people you're thinking of are, or something, because this is not how it works in my head or in the rationalist social circles I've been part of.

When I see someone smarter than me, I want to /feed/ off them. I don't want to follow them and dress like them and get their autograph, and I don't want to signal allegiance so I'll survive the tribal purge that will inevitably result from their ascent to power. I'm not trying to share in the spoils of their conquest, or have them tell me what to do so I don't have to think about it. I want to /absorb the patterns their brainwaves form/ in whatever medium they demonstrate their intelligence and rationality in, and then I want to merge /my/ ideas with theirs and see what other awesome stuff might come out. Because it measurably improves my life and the lives of those I interact with.

I don't give EY's facebook or blog posts a high priority spot in my attention list because he's a "pack leader," I do it because he's demonstrated value. Same with others who can teach me new things that make a difference in my life or others'. If you're not willing to accept frames like "high level rationalists" then I don't really know how your internal system of cached attention-direction works. My suspicion is that you have one of some sort, I would be very surprised if you just paid equal attention to everyone because the idea of recognizing that some people actually have more valuable things to say than others is offensive to you somehow.

If what you /actually/ meant by this was simply that the phrase irks you for all of what you said after that, specifically because it lulls people into a false sense of security about "okay here's this really smart person so they will know how to solve X super complex problem that everyone's being stuck in," then that's much more sensible, but also seems like less of a concern than the failure mode that's actually occurring in the world.