:PROPERTIES:
:Author: philip1201
:Score: 1
:DateUnix: 1442661782.0
:DateShort: 2015-Sep-19
:END:

#+begin_quote
  but [if] we took a path that prevented us from learning it
#+end_quote

Not uplifting all dogs doesn't do that. Even killing all dogs doesn't do that. Destroying all information about dogs might do that, but it seems unlikely because there is such a flood of information in the natural world that it's probably redundant somewhere. Destroying all information about all non-human life might be sufficient.

To put it more clearly: all information to make the perfect ethical strategy/CEV (according to you) is contained within you. For all combinations of the state of knowledge and the possible choice, the you can already select the best possible option (according to you) using nothing but your brain.

The non-existence of dogs may change the state of your knowledge and therefore your actions and possibly even your believed moral statements, but the CEV operates under the assumption of perfect knowledge, and I don't know of any evidence of value drift that fundamental in human history. Meanwhile, attaining sufficiently detailed information about dogs to reconstruct them still seems likely in case of a well-meaning xenocide, and an obvious certainty if they are merely not uplifted before we get fAI, which obsoletes our moral knowledge.

#+begin_quote
  I am objecting to the society in which that happened. You are objecting to my objection.
#+end_quote

Objectively false. Check the comment history.

#+begin_quote
  I am supporting my argument.
#+end_quote

In that case you're guilty of a false dichotomy. The fact that irreversible actions (unlike exterminating a species, which can be reverted with a little 21st century bio-engineering and a full DNA sample) limit future choices has no impact on whether we should take the positive action of uplifting dogs, which you're arguing for.

#+begin_quote

  #+begin_quote
    Other than low-level fuss (people liking a dog or not liking any, people knowing they like dogs or not knowing it)
  #+end_quote

  That's kind of a big thing.
#+end_quote

Neither destroys information for the CEV. They are indeed big, but they are just elements of a xenocide, not a permanent darkening of the future. People can learn to like dogs again and find dogs to like, if killing them was a mistake.

#+begin_quote
  How about a human with biological or cybernetic enhancements. Would you call that human any more?
#+end_quote

If they replace or supplant the seat of conscious reasoning, identity, and abstract (including moral) thought, i.e. the frontal cortex, without preserving its contents, I would not.