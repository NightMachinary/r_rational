:PROPERTIES:
:Author: OutOfNiceUsernames
:Score: 9
:DateUnix: 1497044252.0
:DateShort: 2017-Jun-10
:END:

#+begin_quote
  And if we're not going to last, what was the point? To enjoy what happiness we've had? Nonsense. Our history wasn't exactly a happy one, not even a net positive, far from a net positive. If only we've succeed in creating eternal utopia, it would've all been worth it, but... If humanity isn't going to last, if everything we value, everything we've accomplished and everyone we know are going to be simply erased, there was no fucking point at all. Will humanity have lived in pain for millenia, only to have a moment's respite right before death? If so, it would've been better off never existing.
#+end_quote

** 
   :PROPERTIES:
   :CUSTOM_ID: section
   :END:

#+begin_quote
  what was the point
#+end_quote

--------------

/Disclaimer one: these are just my current opinions on this./

/Disclaimer two: this isn't intended as a complete answer, more like a continuation \ contribution to the discussion./

--------------

TL;DR: The world doesn't care about creating meaning that humans would judge and find satisfactory --- humans assign meanings for themselves.

If you tie your (life's, worldview's) meaning to things like reaching a utopia or ending /all/ suffering in the world, it will not survive due to the systematic problems you've mentioned (akin to trying to maintain faith in an omnibenevolent and omnipotent being, etc). Choosing a more modest meaning --- for example, “making my here-and-now enjoyable and preventing the gradual degradation of my here-and-now into an existence of suffering” --- at least won't leave you with unfixable logical contradictions. You can play with various definitions to find the most complicated and ambitious one that both suits you and doesn't fall apart under the laws of our universe.

Also, some un-ordered bullet-points that either support my previous two paragraphs or are just somehow relevant to something else from your comment:

- all-encompassing surveillance isn't by itself a bad thing, since it can serve as one of very few possible tools for averting many of the Bed Ends. The real problem is how to build a political system that won't be abusing such surveillance capabilities and won't turn into draconian totalitarian regime that cares about itself and its elite more than the general happiness of its population.
- our current morality and views on what is normal and what is dystopian are subjective to our civilization, they will likely die with us and get replaced with a new frame of standards if our civilization fails to survive.
- similarly, seeing suffering as something bad is subjective to humanity --- other animals mostly don't care about inflicting suffering (e.g. eating prey alive), and the universe in general doesn't care about allowing systems that generate suffering.

  - that being said, the only way I see [[https://en.wikipedia.org/wiki/Citizen_of_the_Galaxy][the propagation of human suffering through space]] possibly curtailed is through a new world order ([[https://www.youtube.com/watch?v=bW7Op86ox9g][cue conspirologists)]] with total surveillance and some current human rights rescinded.

- the world doesn't revolve around humanity --- maybe we'll become obsolete, maybe we'll change into something else, maybe we'll just destroy ourselves; and the universe will keep going, with likely some other alien species spawning up somewhere else and having to deal with the same set of rules derived from laws of the universe, entropy, the principles of evolution, etc
- most of the problems you mention are not unsolvable /in principle/. That is, they are not reliant directly on the laws of nature but rather on the laws of human psychology. I have no idea what can be done to change the psychology of 7+ billion people though.

  - as an example, Gorkavyi [[https://www.goodreads.com/author/show/3494893][in his books (RU)]] solved that partially through an almost-omnipresent benevolent AI and partially through a deus ex machina of making his protagonists into billionaires. Maybe IRL something like that could work as a group effort spearheaded by several very influential people, if the friendly AI attempt lands on a natural 20.\\

- I recommend you reading [[http://tvtropes.org/pmwiki/pmwiki.php/Sandbox/DocFuture][/the Doc Future trilogy./]] It doesn't give any answers to the problem of multitude of likely Bad Ends (not ones that would work in real world anyway), but the problem itself still plays a major part in the storyline and narrative, and so you may find the story interesting.