:PROPERTIES:
:Author: vakusdrake
:Score: 5
:DateUnix: 1507069528.0
:DateShort: 2017-Oct-04
:END:

I think it's also relevant that FAI are likely to want to grab resources as quickly as possible in a way that would look nearly the same as a UFAI (after all very few utility functions are going to care about not exploiting dead systems when that energy/matter can be used on other things) to an outside observer. And hell when you consider von-neumann probes then exponential expansion seems inevitable even without AI.

So I guess my point is that the Fermi paradox is a problem pretty much regardless of what you believe (provided you don't believe in something crazy like the supernatural).\\
Still I think as Isaac Arthur's great filter videos demonstrate, without any massive questionable singular great filters. You can still whittle down the probability of civilizations arising enough to make it plausible we are the only civs in our past light cone just using a great many smaller filters.

Another interesting (if terrifying) idea, is that GAI's that end up becoming the only conscious mind in existence (whether through killing off their creators or having their creators eventually merge with them) are the norm. So were that the case, a GAI could have only one if not a handful of separate "observers" as it were so most minds that ever existed would actually be among the precursor biological civilization and thus we shouldn't be surprised to be in the majority of minds to ever exist.\\
Actually I'm rather disturbed at how plausible that seems, especially given it would also set a great filter ahead of us, which is the worst possible case scenario..