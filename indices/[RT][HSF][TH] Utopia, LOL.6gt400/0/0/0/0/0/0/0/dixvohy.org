:PROPERTIES:
:Score: 3
:DateUnix: 1497538936.0
:DateShort: 2017-Jun-15
:END:

#+begin_quote
  fucking up is also relative.
#+end_quote

Mass extinction is not relative. We are causing one. This is fucking up.

#+begin_quote
  the AI in that story feels like being on the "too little control" end of one. (Granted, we don't know the world, just this micro interaction. But these individual humans clearly have very little agency.)
#+end_quote

It does seem to me like they have little agency, but I'm not sure if that's because of the AI. It could also be because they reached an [[https://en.wikipedia.org/wiki/The_End_of_History_and_the_Last_Man][End of History]]. Just because /we/ haven't reached one, and won't any time soon, doesn't mean that people many hundreds or thousands of years into the future /won't/.

That is, there may come a time when high-level agency just isn't useful for much. I kinda hope not, but I also can't help but do the thought experiment and think: what happens when we /do the right thing/? Is our agency useful after we've already used it well, so to speak?

Sure, blah blah journey not destination, but there are physical limits we run into as well.

So I'm kinda unsure about whether an End of History can really happen. I'm also /worried/ that should even an approximate End of History happen, people will start trying to destroy its arrangements out of sheer nihilism for no longer having Grand Causes to which to devote themselves. I think I detect a little of that today: we kinda know how to run a workable society, but people have been steadily pushing the notion that it's meaningless to do so.