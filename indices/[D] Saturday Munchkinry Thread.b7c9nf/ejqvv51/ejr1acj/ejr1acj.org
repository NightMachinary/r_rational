:PROPERTIES:
:Author: ShiranaiWakaranai
:Score: 4
:DateUnix: 1553970377.0
:DateShort: 2019-Mar-30
:END:

#+begin_quote
  You can process all the different points of view at one but get no other extra multitasking.
#+end_quote

To clarify, this means that you can react to each view as well as you could if you were only looking at a single view?

Does it work on yourself?

I mean, say you had two cameras pointed at you, and they showed on two screens in front of you. Do you now see 3 identical views from your own eyes, allowing you to react to them 3 times better?

Also how big does the screen showing yourself need to be? Can it be a single pixel really far away?

If so, it's time to singlehandedly run your own shadowy mass surveillance organization. Point countless cameras at yourself and have them feed into countless tiny screens in your own field of vision, letting you get countless views from your own eyes, letting you multi task insanely and analyze everything in your field of view. Where everything in your field of view can be tons of other screens showing other places and other people, all over the city/country/globe.