:PROPERTIES:
:Author: Radioterrill
:Score: 3
:DateUnix: 1490649602.0
:DateShort: 2017-Mar-28
:END:

I was recently thinking about the issue of deactivating a strong AI, as a complete amateur on the topic, and I was wondering whether it would be viable to adjust its utility function so that it would always be indifferent between deactivation and continued operation. I can't immediately see why you couldn't simply set the expected utilityâ€‹ of being deactivated to always be equal to the AI's expected value of continued operation, so that it would not have any incentive to prevent or encourage its deactivation. Am I missing something obvious here?