:PROPERTIES:
:Author: Empiricist_or_not
:Score: 2
:DateUnix: 1391669759.0
:DateShort: 2014-Feb-06
:END:

Yes I have. Assuming at the ending they are in a simulation, then it's one type of a horror story. Assuming they aren't then, it's a /Earth abides/ apocalypse horror story. I'm not sure which is worse.

[TL:DR the three laws on a "FAI" would be an existential risk to humanity] Three laws are an existential risk, and as much as the movie /Irobot/ perverted the title of a personally much beloved collection of short stories, I'm glad the implied zeroth law got some public exposure.

/Zeroith law of robotics: A robot by it's action or inaction cannot allow humanity to come to harm. (1st, 2nd and 3rd laws are revised to add except where this would contravene the zeroth law.)/

You can find better treatment of three law deficiencies in some of the foundation novels (I'm sorry but I forget which ones) where human is defined as only /homo sapiens/ with a particular characteristic, and another where a robot derives the zeroth law as a necessary superior corollary to the first law, and thus justifiable homicide for humanities good.

My point is that the seemingly idealistic three(+0) laws are far too vulnerable to redefining the terms: "human," "harm," ("humanity,) and "obey."

[edit on topic reply, apologies, but three laws make me shiver] Uncontrolled modification yes, but I saw no inference or instance of the scope growth, that made one optimalverse story interesting, and will get me buying theater tickets for /Transcendence/