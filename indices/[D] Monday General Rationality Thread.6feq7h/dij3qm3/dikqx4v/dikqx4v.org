:PROPERTIES:
:Author: throwaway47351
:Score: 2
:DateUnix: 1496840179.0
:DateShort: 2017-Jun-07
:END:

It's definitely appropriate to talk about this here, and a basic set of your views would be helpful to any other potential pmers. It's hard to debate views when one side doesn't give specifics. Here's a few of mine:

Simply put, artificial intelligence isn't how we're going to preserve life. Something like CRISPR is more likely to get us to that stage, where we can cure telomere degradation, stop cancer so that the lack of telomere degredation doesn't kill us, and cure all the other billion things that contribute to aging. The ides of mind uploading is stupid on the face of it, as the uploaded mind wouldn't be you in the way that counts. If there can be two of you, then at least one isn't you in the sense that you are yourself.

Second, you seem to have that common belief that any ethical frame that we imprint on a super-intelligent AI will either be insufficient, have unfortunate and unseen consequences or loopholes, or will be disregarded by the AI itself. I will not claim that we as a species are morally advanced enough to create anything resembling an airtight set of morals, but I will claim that this problem simply will not matter. The types of AI we can create in the next 20 years or so will all be specialized enough that, even if they gained a form of intelligence, they will not be able to commit any large evils even if they tried. The real problem with this is a generalized AI that can solve problems in unexpected ways, and that's far enough in the future that there is the possibility of us developing a better moral framework before that happens. You seem to know this, but you don't seem to even consider that as a species, we can make ethical progress. I'd prefer to wait on that possibility, rather than make any action that was depending on us not developing better morals.

Honestly though, I'd really like it if you could explain some of your fears on this subject.