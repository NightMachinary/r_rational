:PROPERTIES:
:Author: SimoneNonvelodico
:Score: 2
:DateUnix: 1536761852.0
:DateShort: 2018-Sep-12
:END:

That seems a weirdly fatalistic viewpoint, IMHO. I don't buy in the idea that anything smart as or slightly smarter than humans will necessarily snowball into some sort of godlike threat. There's a bunch of intermediate scenarios where you'd just deal with more realistic human-ish level AIs that have their own motives and agendas but don't necessarily outclass us. In any of those scenarios, "existing hackable machine-controlled killing methods" would be a potential asset to them.

And yeah, I don't have /much/ faith in a ban working. Just like nuclear weapons ones don't exactly work. But at least it's a taboo to toss tactical nukes left and right in any sort of armed exchange, and I can't see that as being a bad thing.