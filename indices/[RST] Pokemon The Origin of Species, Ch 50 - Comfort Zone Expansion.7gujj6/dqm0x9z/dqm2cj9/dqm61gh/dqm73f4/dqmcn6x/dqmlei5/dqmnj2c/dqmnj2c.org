:PROPERTIES:
:Author: Iijil
:Score: 2
:DateUnix: 1512163994.0
:DateShort: 2017-Dec-02
:END:

Yes, data about only Tyranitars would be preferable, but in the absence of that data why do they estimate it in the specific way they do?

If they had the data that 20% of reported Tier 1 Tyranitar rampages are actually Tier 2, they wouldn't need to use bayes anymore, because that statistic is exactly what they are looking for. The high likelihood of Tyranitars being Tier 2 would be automatically considered during data collection. We would have very few Tier 1 Tyranitars being reported in the first place, but once we encounter that situation we go to the statistic we have.

So in the situation where they have the statistic that 21% of reported Tier 1s are actually Tier 2, why is it not justified to assume that will hold for Tyranitars?

And if we think Tyranitars are different, then why, after figuring out the reporting error rates for given actual classification, is it justified that those error rates will be the same for Tyranitars?

Ahh, I think I got it while writing this post. If the world suddenly changed to a world where the ratio of Tier 1 to Tier 2 is 2 to 15 instead of 36 to 64 it would make sense for reporting errors for a given classification to stay constant, but not for reporting errors for a given report. So it would be correct to treat the change to Tyranitars like that as well. Am I making sense with that?