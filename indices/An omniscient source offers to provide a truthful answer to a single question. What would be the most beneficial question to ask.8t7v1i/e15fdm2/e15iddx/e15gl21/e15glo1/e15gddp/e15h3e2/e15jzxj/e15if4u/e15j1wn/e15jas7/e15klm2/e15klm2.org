:PROPERTIES:
:Author: ShiranaiWakaranai
:Score: 2
:DateUnix: 1529743012.0
:DateShort: 2018-Jun-23
:END:

This seems dangerous, because maybe the policy that maximizes the probability of an FAI is to spur people into recklessly rushing out AIs, and so also increase the probability of a UFAI.

E.g. Maybe before your message, the probability of FAI in 100 years is 10%, UFAI is 20%, and no AI is 70%. There could be a message advocating careful coding that leads to 15% FAI, 5% UFAI and 80% no AI, which is what you would want. But then there could be a message advocating rushed coding that leads to 20% FAI 80% UFAI, which has a higher FAI probability and so is the message you are given.