:PROPERTIES:
:Author: eroticas
:Score: 7
:DateUnix: 1529739127.0
:DateShort: 2018-Jun-23
:END:

Yes, I [[/u/sparr]]

I'm maximizing my utility function, not yours, after all ;) such is the goal of any rational agent

I'm altruistic though and a baseline human values so what's best for me is pretty similar to what's best for humanity. I would hazard a guess that what I want is actually more or less identical to what humanity wants but I'm not taking any chances. If humanity does not converge in values then it's still /my/ (coherent, extrapolated) values that I care to maximize. Ordinary one can't do this in real life, one has to work as a coalition, but when the opportunity arises...

It's not my fault [[/u/pizzahotdoglover]] decided my utility function was kinda selfish and self involved. The real entity would know that my true utility function was altruistic and more concerned with humanity than my personal life.