:PROPERTIES:
:Author: cretan_bull
:Score: 6
:DateUnix: 1491148089.0
:DateShort: 2017-Apr-02
:END:

Thanks for giving a concrete example of an argument that could convince you. I suspect that it seemed sort of trivial to you but I wouldn't have expected something so simple to work. I can say with complete certainty that such an argument wouldn't work on me; to be blunt, I don't care enough about any individual, even on a gut level, for that to work. Now, if instead the AI were offering near immortality for every person and radically improving the direction of the entire human species then it would be a far more interesting dilemma.

What I find surprising about your response is that you don't think there exists a gatekeeper who wouldn't eventually let the AI out.

Picture the gatekeeper with a big red button that would release the AI. The gatekeeper has promised "No matter what the AI says, no matter how convincing its arguments, I will not push the button".

Succeeding in the task becomes simply a matter of not pushing the button. It is certainly physically possible to not push the button, and I believe there exist people who would honour such a promise and continue to choose to not press the button, indefinitely.

You allude to the effect the gatekeeper's willpower and biases would have on their actions, perhaps even causing them to act contrary to their own ethics. I readily accept that these have a great deal of influence on everyone's actions, but am less convinced they are effective at spurning one to positive action. On the contrary, we have a tendency to settle into habits which take a great deal of effort and willpower to break. In this case I think it would be entirely plausible for the gatekeeper to get into the habit of not pressing the button, and even if the AI gives them a very convincing argument to procrastinate making the final decision until some future date. Established habits become ever more difficult to break, and given enough time can eventually metamorphose into traditions.

In any case, I think there are many people who could act as gatekeepers without relying on such effects. To me, promising to not take some specified action and then not doing it doesn't seem especially difficult.

It is very interesting to see how radically our views can differ on what is fundamentally an objective point about human behaviour: how people would behave in a particular situation and whether there exist any people who could behave a particular way. This is reminiscent of the Illusion of Transparency -- from what I understand we model others' minds with the same mental hardware we use for other tasks, so it is difficult to model someone with a mind working substantially different from your own or to model how other people would act in a situation radically different from our familiar experiences.

I suggest there is likely some overconfidence in your assertion there does not exist such a gatekeeper; and just because you can not confidently model such a person does not mean they do not exist, or even that they are not common.