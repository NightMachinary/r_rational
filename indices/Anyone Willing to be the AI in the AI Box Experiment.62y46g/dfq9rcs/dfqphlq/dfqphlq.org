:PROPERTIES:
:Author: vakusdrake
:Score: 4
:DateUnix: 1491166679.0
:DateShort: 2017-Apr-03
:END:

Of course there's also a class of people who think an actual superintelligence could do it, but think a human playing the part of AI couldn't convince them.

My main reasoning (for it me not being convinced in any way I can conceive) is that since we are assuming it can make it's code look like whatever it wants, it has absolutely no way of making precommitments, and you have no way of distinguishing friendliness unless it's already too late for that to matter.

So since nothing the AI could say should have any weight in your reasoning the only other reasons would have to be regarding the conditions under which it was made. That is probably the avenue under which it might make sense to let it out, and will depend on the premise of the scenario. However if the AI hasn't already been released then there's probably a good reason, and you shouldn't trust your judgement is better than its creators and the risk assessors that were probably involved. Though that argument is rather less ironclad.\\
Either way you ought to assume if the AI wasn't already released then there's a reason, and for the aforementioned reasons nothing the AI says should in any way be factored in.

As for emotional tactics I find it hard to imagine that working, because what can something incapable of precommitments offer you/ threaten you with?