:PROPERTIES:
:Author: Lightwavers
:Score: 3
:DateUnix: 1491150217.0
:DateShort: 2017-Apr-02
:END:

Definitely agree with you. The problem is I don't see the chain of argument that would lead me to letting the AI out if I precommited otherwise, and that's a glaring hole in my self-awareness. I assign an AI super intelligence a 99-100% probability of convincing me to let it out within a minute even if I know it's an unfriendly AI because I intellectually know that such a thing would be orders of magnitude more intelligent than Einstein---but I don't know how it would do it.