:PROPERTIES:
:Author: Baconoflight
:Score: 5
:DateUnix: 1491155761.0
:DateShort: 2017-Apr-02
:END:

The fact is that if an AI is capable of perfectly simulating a human mind, is capable of learning a lot about a mind's low level structure based only on what the gatekeeper says, and there is even a possibility of the gatekeeper failing, the AI wins. I think the game is kind of pointless, as it really depends on how honest and immersed the gatekeeper is. Wasn't the point of this originally to prove that friendly AI is superior to air gapping am unfriendly AI? This is true regardless of whether the AI would win or lose in this situation, since an AI that searches for ways to take undesirable actions is wasting resources, regardless of it succeeds or not. I guess the game is interesting regardless, but it's important to remember that it bears very little resemblance to how it would go in the real world.