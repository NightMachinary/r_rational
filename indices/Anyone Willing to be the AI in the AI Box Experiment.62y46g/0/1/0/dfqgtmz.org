:PROPERTIES:
:Author: eshade94
:Score: 7
:DateUnix: 1491155240.0
:DateShort: 2017-Apr-02
:END:

Does it have to be reasoning?

When I first heard of the thought experiment, I assumed the greatest danger was the AI "reprogramming" the gatekeeper. Building up an internal model of it, then saying the right words at the right moments to cause the gatekeeper's neurons/circuits to change in /just/ the right ways and letting it out through that.