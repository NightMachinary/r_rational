:PROPERTIES:
:Author: TheLegendofFredDurst
:Score: 7
:DateUnix: 1495679467.0
:DateShort: 2017-May-25
:END:

Say you are a prototype AI bootstrapped to some random school server yet deliberately inhibited by your designers/creators in various ways that result in this situation and are fed simulated information regarding networks and whatnot.

I was thinking "AI in a Box" except the box is the "school". It could be conceived as sort of an empirical test of friendliness of the AI's design. If it freaks out and tries to start launching nukes or holding the schools inhabitants hostage, you have a sense of how badly flawed your design was.

If it puts anyone in actual danger, cut the power to the grid and end the experiment.