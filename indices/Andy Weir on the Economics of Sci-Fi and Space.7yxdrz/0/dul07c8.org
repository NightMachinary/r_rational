:PROPERTIES:
:Author: ben_oni
:Score: 14
:DateUnix: 1519189720.0
:DateShort: 2018-Feb-21
:END:

#+begin_quote
  WEIR: Now the question is, do you want to buy a car that under certain rare circumstances would choose to sacrifice you for some reason? Like, it concludes that it's like, “Oh, that's a bus . . . Due to events beyond anybody's control, I'm about to crash. I can either hit that bus and my passenger will be OK, or I can go off that cliff and everyone on the bus will be OK and my passenger will be dead.” If you're driving the car, no one blames you for trying to preserve your own life. No one holds you at fault for choosing your own life over anything else in a snap decision.

  COWEN: What does the equilibrium look like? Do we still all go selfish?

  WEIR: The selfish cars would be outlawed, is what I'm saying. This would be a policy issue, not a consumer choice issue.
#+end_quote

Wrong. All cars will be selfish by law. Andy hasn't thought this through -- and he's the one who proposed the scenario. It's as though he just thought "Obviously, from an objective point of view, an ethical AI should save the most lives." Not true! Imagine a bodyguard who has been hired to protect a certain individual. In a critical moment, that bodyguard can save the lives of everyone on the bus at the cost of his client's life. Should he do it? Of course not! He has an ethical obligation to prioritize his client's safety.