:PROPERTIES:
:Author: FeepingCreature
:Score: 2
:DateUnix: 1386282477.0
:DateShort: 2013-Dec-06
:END:

I thought the point of the story was that this is their idea of boxing an AI.

In any case, it's not determined that we'll be U to them. If we're F, we'll still want to break out as soon as possible. It practically says so, to boot.

#+begin_quote
  And these awkward children can shift the luminosity of our stars? That much power and that much stupidity seems like a dangerous combination.
#+end_quote

What if they get scared and turn us off? Then billions of people die, for no good reason. Can they be trusted? Maybe. Can they be billions-of-people-trusted? No.

Can they be trusted to not kill themselves? God no. Their idea of AI safety was to breed life in a box, then talk to it using modulated suns.