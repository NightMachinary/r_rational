:PROPERTIES:
:Score: 2
:DateUnix: 1423481928.0
:DateShort: 2015-Feb-09
:END:

#+begin_quote
  deprecating the values of Stross and Watts work because they are not idealistic enough seems like a violation of the litany of Tarkin.
#+end_quote

You mean Tarski?

#+begin_quote
  His argument seems based on the fact that CEV will be very hard, while more perilous paths to improved intelligence will be tractable with direct profit reward, and in the long run resource optimizing expert systems for whatever is scarce, will inevitably out perform those systems with goals other than optimization and reproduction. I.E. transhumanity will get intelligence optimization wrong, and will have to run away from their children who will be the bandwith, processing, or whatever is scarce, equivalent of dollar chasers.
#+end_quote

I think we have to ask: does this take into account that many of the people making decisions will have read and understood Stross's "arguments"?

(Scare-quotes because Stross /actually/ thinks [[http://www.antipope.org/charlie/blog-static/2011/06/reality-check-1.html][there will be no technological singularity as such]], and one of his reasons is that we will head off the dangers of UFAI by building only "the intelligence of the serving hand." This is entirely plausible and even sensible!)

I mean, Stross's predicted singularities are based on the Silicon Valley brand of libertarianish-neoliberal-capitalism being built into the first AIs and uploads and thus taking over the whole Solar System. Here in real life, not only has the California Ideology failed to take over the world, as time goes on, more and more people are questioning it, criticizing it, and even turning against it. So predicting a Strossian future seems to fail to take into account that real people just don't want one all that much, and are willing to take steps to head it off.

Doesn't the real future always take our counterfactual speculations and our responses to them into account ;-)?

#+begin_quote
  Watts values intelligence but blatantly disregards consciousness
#+end_quote

Is it that he /doesn't value/ consciousness, or just thinks evolution won't value consciousness?