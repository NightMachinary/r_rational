:PROPERTIES:
:Author: freshhawk
:Score: 1
:DateUnix: 1479103509.0
:DateShort: 2016-Nov-14
:END:

#+begin_quote
  Try building a brain and see how far you get with that ;-). Heuristics-and-biases models are currently disfavored because there's just too damn many of them. How do you even program (from the AI/ML perspective) or predict (from the cognitive-scientific perspective) which heuristic or bias to apply in which situation?
#+end_quote

Well, it's obviously not a suitable approach to use if you are trying to build one, like you say, /way/ to complex for our naive understanding of what's going on in our brains. But in terms of understanding how our brains work ... how hard it would be for our primitive selves to replicate doesn't tell me anything about the likelihood of it being true.

I mean, obviously it's the best evolved decision making machine on earth, so that's pretty good. And obviously it carries some serious evolutionary baggage making it remarkably crappy at a lot of things. So this seems like a disagreement over where in the middle we fall. And I fall further and further on the side of us being much less rational than we think we are as time goes on. Every time we learn a new way to manipulate people, new ridiculous biases and perceptual illusions, it's striking just how much more shallow our abilities are compared to how it feels they are. Same with vision, hearing, memory. All turn out to be much less effective than we feel they are, and our brain just papers over the massive holes and confabulates as much as necessary, while hiding this from the conscious mind and giving us a completely misplaced certainty. I see no reason to expect that reason or consciousness should be any different, and plenty of reasons to expect this pattern to be found yet again.

I just think the optimism a lot of pundits and researchers have is profoundly misplaced. It's not a neural network. It's a whole bunch of them, overlapping, there are very specialized areas of the brain that do very specialized things. That likely function completely differently at a "software" level (for lack of a better metaphor) because they evolved at a completely different time in our evolution.

I like the quote quite a bit, especially the recognition of the importance of embodied cognition, but anyone who feels that the approach is to build a brain instead of building one of the huge number of specialized subsystems seems very optimistic to me. Not that it isn't important work in improving machine learning or creating vastly useful tools of course, it's just not anywhere close to even the simplest conceivable AI. /And/ this is with me thinking that humans brains are far less capable than we generally consider them, /even that/ is going to be much more difficult than generally expected. Certainly more than what this round of optimistic AI researchers are promising (just like last time).

tldr; In terms of the estimate of the complexity of the project I tend to side with the neuroscientists rather than the AI researchers. Even though I write software for a living and feel like I'm disparaging "my side" :)