:PROPERTIES:
:Score: 5
:DateUnix: 1434045105.0
:DateShort: 2015-Jun-11
:END:

See, I'd be willing to buy the Lotus Lord position if someone could provide /definitive/ reasons why moral reality /can be no other way/, and why there's no genuinely preferable alternative action for someone /trying to do good/ other than to Lotusify people.

Like, with a misprogrammed AI, ok, the AI has an autistic fixation on this one /fiction/, due to its programming. I buy that it is motivated to fulfill the fixation which was programmed into it. But that fixation on a work of fiction is not a /moral position/ -- it's not related to what people prefer for themselves and others on full information and reflection. It's basically just the fic's author inserting a conceit to help him show why programming AIs with harmless-sounding utility function is a Really Bad Idea.

So, like, a Lotus Lord /could/ just try /improving real life/ if they /didn't/ have some programmed-in fixation on a dream world of some kind. They could work to alleviate poverty, mediate political conflicts, fight gang violence, and just generally make living a rich, full life more preferable than taking drugs or any metaphor for taking drugs. In fact, with reality-warping, superintelligence, massive mana reserves, or any other commonly-attributed villain power, they'd have an easy time of it.

Or hell, they could just offer the dream-world /without the brainwashing, memory erasure, and compulsion/. [[http://www.ribbonfarm.com/2015/01/16/on-the-design-of-escaped-realities/][There's a decent argument that a /mediated/ dream-experience /which is understood to be mediated/ is closer to reality-as-such than an unmediated but low-tech delusional worldview.]]

But somehow I'm supposed to believe we have some radical, Knightian uncertainty that makes these villains really sympathetic.