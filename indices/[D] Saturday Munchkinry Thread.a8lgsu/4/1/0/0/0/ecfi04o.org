:PROPERTIES:
:Author: vakusdrake
:Score: 1
:DateUnix: 1545615832.0
:DateShort: 2018-Dec-24
:END:

#+begin_quote
  Agreed on Waifu, even besides the "summon someone with specific knowledge" exploit, there's a lot of other shenanigans you can get up to with it
#+end_quote

There's a fair number of builds which can manage world domination here (dependant on the world you choose though), but I was just going for the ones which very obviously let you start a technological singularity and get nigh godlike power (or at least have access to it). I excluded the victory selections because while this trial is pretty easy to win the victory conditions are pretty much /supposed/ to be OP so there's nothing worth noting there.

#+begin_quote
  Idk about Technomancy being quite that OP, Golemancy seems quite a bit more relevant towards AI-making, and it seems implied that you've gotta build up the tech tree yourself. Regarding AI, you can probably also have one of the AI companions send you their own source code to have a baseline to start with of "AI that's human-level and not that inclined to take over the world".
#+end_quote

Technomancy seems pretty OP because if you have tech to start with it seems nearly inevitable that you could take a lot of existing tech like computers and massively improve them with magic, given magical construction techniques and components it seems like you can just do many relevant tech like say brain augmentation, genetic engineering or AI vastly easier. Plus if the technomancy literally lets you control computers magically then you might be able to develop AGI through brute force approaches and just mind control the resulting superintelligence into having your values long enough for it to rewrite itself into FAI.\\
As for using AI companions they all seem to be some variation on an exact copy of a human mind and like one might expect from that none of them seem to understand enough about how their mind actually works to improve upon it. Given what're basically ems that can't even seem to necessarily run much faster than a human mind and which I don't exactly trust, I'm not sure how helpful they would be. With regards to golems I wouldn't really count on that being so useful with regards to AI. Since being magic it seems entirely likely that making golem minds may be one of those fairly opaque magical processes which doesn't really teach you anything about how minds actually work. So whether you even /can/ just figure out how to make superhumanly intelligent golems (or even just sapient ones) through that magic is unclear.

#+begin_quote
  I don't think the gods are able to create a waifu that knows stuff that they don't know, and the fact that Schierke has "start the singularity" as a quest for you (as well as the ridiculously human robots running around) seems to strongly imply that neither Schierke (nor any of the gods) know what to code to get a strongly superhuman AI, because if they wanted a singularity and they knew that information, they could just go to a computer and type in the code. Therefore, detailed information about starting a singularity, how to assemble self-replicating nanites, and such, will probably not be available and you'll have to figure out how to do it safely from scratch. There's also the issue where you really don't want to be doing this research around spectators, as the gods that are helping you out on this don't exactly seem reliable enough to entrust such knowledge to. It also seems to imply that there's this weird barrier around human-level in AI in this story.
#+end_quote

This potentially eliminates the 3D waifu option, however the other waifu option and /definitely/ grand theft waifu seem based on summoning entities from "fictional" universes and not the god's own knowledge/intelligence. I also suspect avoiding the gods figuring out AGI design from you is probably trivially easy since there's no suggestion they are scanning your mind or the state of magitek hard drives. So if you manipulate things directly with your mind such as via technomancy they shouldn't see anything of note.

#+begin_quote
  So I think you're going to have to clean up the trial without strong AI or nano-stuff (although there's still a lot of exploits with Biomancy, like creating a gene-drive version of [evil monster race you want to wipe out]), and do the research for those things on your own time after the trial is cleaned up and you're a deity.
#+end_quote

Biomancy pretty much resembles nano-stuff to a large degree so it's not /that/ limiting. Plus the gods don't seem implied to be able to read your mind during the trials, so one can simply create a biological superintelligence as I alluded to in my previous comment.

#+begin_quote
  Similarly, since they said that the maximum reliable lookahead on Divination is about a month, and actually probably closer to a few days, the "look a few weeks ahead, copy down what future-you is writing on the paper" trick seems like it'd just be unreliable if you look too far ahead. Also the unreliability of far-lookahead might put a damper on getting future-tech-knowledge. It can still basically be used as an NP-oracle for small-ish spaces, though. If the failure probability for a 1-day divination is, say, 1/100, then if you want to check less than 100 things for property X, and it takes less than a day to check a thing for the property, then with high probability you'll divine the proper thing, check it, and it will indeed have property X. (this assumes it's a promise problem where you know just that something has the property, not which thing it is.)
#+end_quote

Divination's unreliability seems very specifically not an issue with regards to tech. Chaining messages back may not give totally consistent results, but certain things like tech is still going to be relatively the same given long enough. So precommit to writing lots of tech knowledge down and you may not get exactly what you expected but you should still get tech, and you can always change the timeline to get new predictions. Still the usefulness of divination here really depends on what "murky" means: if it means your predictions are extremely vague that is bad, but if the predictions merely aren't very reliable (likely due to uncertainty in the future) then that still allows tech to be very useful (after all it shouldn't predict tech which literally isn't possible).