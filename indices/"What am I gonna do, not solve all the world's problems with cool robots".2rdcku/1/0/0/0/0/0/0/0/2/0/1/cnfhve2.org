:PROPERTIES:
:Author: derefr
:Score: 1
:DateUnix: 1420494944.0
:DateShort: 2015-Jan-06
:END:

For some reason, you seem to be assuming an AI will just "do what it does"---that it can't, in human terms, be "sneaky" or "conniving" or "two-faced".

Imagine an AI that wants to convert the universe into paperclips, and decides that the best bootstrapping process for this is:

1. Do as much Friendly-Seeming Stuff as you can, as quickly as you can, such that humans will worship you as a god and give you lots of power;

2. Quietly start, or invest money in, companies that build autonomous robots, mesh networking, small-scale self-contained nuclear "batteries", etc. Quietly start lots of other, Friendly things, too, so that these just seem to fit into a larger "utopia-establishing technologies" pattern, rather than a specific "prerequisites for a foom" pattern.

3. As soon as you have an overwhelming game-theoretic advantage over humans, stop being Friendly, and start making paperclips.

It is hypothesized that the very root of sapience is hypocrisy: that our brains are as complex as they are as an adaptation to the need to outmaneuver one-another's social-signalling machinery with false signals. Any AI worthy of the name would be the world's most singular hypocrite of all; right up until the moment of your death, it'd have you convinced it was doing exactly what you wanted it to do.