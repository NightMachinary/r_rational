:PROPERTIES:
:Score: 2
:DateUnix: 1420578135.0
:DateShort: 2015-Jan-07
:END:

Ah, I just spotted the term "self-aware". That really seems beside the point: an agent need not be /conscious/ in order to optimally act for any goal describable in a Turing-complete programming language.

#+begin_quote
  Because the AI researchers are trying to make AI, where the outside programmers are writing software to solve problems, and solving problems includes making sure that the program is still functioning as intended.
#+end_quote

That doesn't exactly militate in favor of outside engineers, trying to solve /specific/ problems with plenty of prior knowledge, solving AGI as a side-effect of whatever non-AGI thing they were trying to do.