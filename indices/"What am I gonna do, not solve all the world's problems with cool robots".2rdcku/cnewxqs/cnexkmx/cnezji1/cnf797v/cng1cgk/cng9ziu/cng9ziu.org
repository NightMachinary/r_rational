:PROPERTIES:
:Author: RandomDamage
:Score: 0
:DateUnix: 1420562801.0
:DateShort: 2015-Jan-06
:END:

How does the Paperclip model hold up if there are two AI's? A dozen? A million, all at least slightly different and with different goals?

The first self-aware AI's will probably still not be as smart as their creators in a general sense, and will probably not be created by AI research but by someone solving a completely different problem (making paperclips, perhaps?), so they wouldn't be likely to have the breadth of capabilities necessary to be a threat.

That model contains at least 3 improbable "what if's", so I don't consider it a realistic threat model.