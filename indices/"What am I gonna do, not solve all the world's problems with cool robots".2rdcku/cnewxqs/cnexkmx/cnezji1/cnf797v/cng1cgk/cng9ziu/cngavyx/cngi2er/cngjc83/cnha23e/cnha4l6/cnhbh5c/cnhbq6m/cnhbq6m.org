:PROPERTIES:
:Score: 1
:DateUnix: 1420646193.0
:DateShort: 2015-Jan-07
:END:

No, it just has to take actions in order to obtain utility, according to world-models and utility-functions describable in Turing-complete languages. There's nothing ontologically basic about human minds, so no resemblance to the seemingly "special" or "magic" properties of such is necessary for AI.