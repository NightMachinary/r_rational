:PROPERTIES:
:Author: superliminaldude
:Score: 1
:DateUnix: 1420490420.0
:DateShort: 2015-Jan-06
:END:

I imagine a clever AI could optimize stealthily, until it had access to sufficient resources/automation to carry on without humans as part of its infrastructure. From what I understand, part of the point of Yudkowsky's AI box experiment is that an AI isn't limited by /our lack of imagination/, and it's extremely difficult to predict what a sufficiently high intelligence is capable of.