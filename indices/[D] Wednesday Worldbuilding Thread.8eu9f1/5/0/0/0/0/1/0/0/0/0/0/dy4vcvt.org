:PROPERTIES:
:Author: vakusdrake
:Score: 1
:DateUnix: 1524954414.0
:DateShort: 2018-Apr-29
:END:

#+begin_quote
  No, human values aren't random, but they are complex. Part of the difficulty of alignment is that we don't actually know what the target looks like exactly.
#+end_quote

I guess my main disagreement with extending that logic too far is that it seems like evolved social animals have a lot more constraints on their evolved traits, and more pressure for convergent evolution than you might expect from computer programs.\\
Another point would be that while human values are complex they show a staggering amount of variety in values, so you might not need to be /that/ close to human psychology in order to indoctrinate the creatures into a desired set of values/goals.