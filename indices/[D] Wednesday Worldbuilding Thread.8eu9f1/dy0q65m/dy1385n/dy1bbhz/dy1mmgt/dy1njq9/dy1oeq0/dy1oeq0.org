:PROPERTIES:
:Author: Nulono
:Score: 1
:DateUnix: 1524807622.0
:DateShort: 2018-Apr-27
:END:

A major difficulty of the alignment problem is that very small differences can end up being amplified. Even if your simulated beings aren't carrying out some huge ploy to mislead you, you're not a superintelligence, and there's always the chance that you'll just miss something. And the aforementioned amplification effect means that you really need "identical", not "close enough, as far as I can tell."

There's also the ethical issue of subjecting quadrillions of simulated beings to the inevitable simulated Unfriendly nightmares implied by such a process.