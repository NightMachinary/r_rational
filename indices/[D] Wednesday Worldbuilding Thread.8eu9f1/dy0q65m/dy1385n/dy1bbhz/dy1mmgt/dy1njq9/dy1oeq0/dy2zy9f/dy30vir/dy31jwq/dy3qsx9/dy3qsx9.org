:PROPERTIES:
:Author: Nulono
:Score: 1
:DateUnix: 1524895366.0
:DateShort: 2018-Apr-28
:END:

/"A system that is optimizing a function of n variables, where the objective depends on a subset of size k<n, will often set the remaining unconstrained variables to extreme values; if one of those unconstrained variables is actually something we care about, the solution found may be highly undesirable."/

/-- Stuart Russell/

No, human values aren't random, but they are complex. Part of the difficulty of alignment is that we don't actually know what the target looks like exactly.