:PROPERTIES:
:Score: 2
:DateUnix: 1426528566.0
:DateShort: 2015-Mar-16
:END:

Easiest to answer in reverse.

#+begin_quote
  What is your position? Does it tolerate the creation of no suffering whatsoever?
#+end_quote

What Scott Alexander once called "post-hoc consequentialism": "There is a pie and two people. We each take half the pie, and don't have to calculate anything about unboundedly large numbers of imaginary people for complicated mathematical reasons."

I find it hard to state a complete algorithm or anything like that, since I don't know enough about cognition to give anything like a psychologically or normatively realistic algorithm that can actually be implemented by a real agent.

#+begin_quote
  I don't understand this objection. Don't those scenarios mean something like 'going to war against Nazi Germany', which yes creates suffering in order to prevent more suffering?
#+end_quote

I meant more like, creates suffering because it sets up power relations and otherwise systematically neglects certain actual individuals in pursuit of utility. To give a nice counterexample, average utilitarianism says that if I spend all my efforts on creating very happy people, mean utility goes up, and I didn't have to do /anything/ about the starving villagers Over There.

You can outlaw creating people /and/ suppose that we only deal with psychologically realistic humans in order to make pathological counterexamples or repugnant conclusions of utilitarianism go away, but those are such flagrantly ad-hoc moves that the best we can say is that average-utilitarianism is an admissible heuristic for a good moral code in those (unrealistic: birth and death are regular events) situations, rather than that average utilitarianism is normatively correct in all situations.