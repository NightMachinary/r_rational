:PROPERTIES:
:Author: AugSphere
:Score: 1
:DateUnix: 1426527688.0
:DateShort: 2015-Mar-16
:END:

I weakly expect the existence and nature of human happiness set-points would lead to the outcome I predict, but it's not a sure thing by any means. In cases when I'm not sure what a proper utilitarian calculation would give me, I prefer to fall back on some sane course of action.

In any case, naive utilitarianism is a pretty flimsy theory in practice, since the calculations needed to actually use it are intractable, so arguing about some hypothetical paradoxes in it is a waste of time.