:PROPERTIES:
:Author: Valeide
:Score: 1
:DateUnix: 1614368488.0
:DateShort: 2021-Feb-26
:END:

#+begin_quote
  But is that the case because religion is a social structure and social structures are prone to being weaponized by those who have power, or is it the case because the concept of Heaven is inherently toxic, inherently suited to siphoning effort away from creating a heaven on Earth?
#+end_quote

I don't think that there are "inherently toxic ideas", at least not in a supply sufficient for something you identify as "inherently toxic" by sorting through globally popular human memes to be expected to actually be inherently toxic. At the very least, error rates are high enough- at most, calling something an "inherently toxic idea" is a fundamental mistake. I expect that the idea of Heaven would have the effect you mention in some really large majority of historical human societies, and in some privileged sense is rife for abuse in many counterfactual worlds, too.

#+begin_quote
  As an entirely separate thought, I've been likening AGI-boosterism to this concept in my head for a while now. There's this feeling I get from a lot of AGI boosters that there's no point in striving for a better tomorrow, because that's nothing compared to the post-singularity Good AI Overlord future (aka Heaven), so you might as well do nothing. It's extremely disorienting because metaphorically adjacent to those folks you have EAs who are all about "do the most effective thing for a less bad tomorrow".
#+end_quote

The AGI booster idea is that developing aligned AGI is the best way to strive for a better tomorrow, not that the optimal strategy is to buy a straightjacket and wait for Robot God to save you.