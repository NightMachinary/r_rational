:PROPERTIES:
:Author: Noumero
:Score: 5
:DateUnix: 1471284112.0
:DateShort: 2016-Aug-15
:END:

Why would AIs decide that the best course of action is to destroy one another?

The easy and boring answer is that because they are buggy/quirky.

Why would a pair of rational agents, let's name them A and B, decide to do that? If continued existence of A is more harmful for B than nonexistence of B, and vice versa, and there's no other course of actions.

As example, if A values paperclips (1 paperclip = 1 utilon) and greatly values nonexistence of pens (1 pen = -100 utilons), while B values pens (1 pen = 1 utilon) and greatly values nonexistence of paperclips (1 paperclip = -100 utilons), then productive existence of either agent is harmful for another one. If they have an equal amount of resources and neither of them can destroy another one and survive, then killing each other is a net gain for both.

I think. I'm not an expert.