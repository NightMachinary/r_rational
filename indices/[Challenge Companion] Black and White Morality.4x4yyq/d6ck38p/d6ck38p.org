:PROPERTIES:
:Author: LiteralHeadCannon
:Score: 2
:DateUnix: 1470873476.0
:DateShort: 2016-Aug-11
:END:

I don't think anyone in real life actually has a utility function inverted from anyone else's. But I do think there is real evil in the world. I wouldn't describe evil as an alignment, though, but rather a misalignment. It's a failure condition in forming an intelligence, analogous to failures to make a friendly AI. I think there is a single friendly utility function derivable from first principles, and that evil is a product of our failure to get to that good. (Compare and contrast learning disorders, where the effective route to getting things done fails to come together, rather than the proper goal failing to come together.)

In short, evil is a failure of intelligence to assemble good.