:PROPERTIES:
:Author: CouteauBleu
:Score: 38
:DateUnix: 1542966998.0
:DateShort: 2018-Nov-23
:END:

Some thoughts I wrote down before the experiment:

--------------

These are some notes regarding how I'm approaching the AI box experiment.

I don't have much respect for this experiment, or for the idea that a super-intelligent AI could con its way out of a "box" (eg security measures designed to limit its influence). I think any reasonably trained person would be impossible to con, as long as they're given enough info beforehand; that's leaving aside that the company storing the AI would do things like penetration testing, and using credential systems to make sure that isolated individuals acting out of malice or incompetence would be physically incapable of releasing the AI.

In other words, I'm mostly doing this for fun, not because I want to prove anything. I intend to be a bit of an asshole, and switch between three strategies, depending on how the chat goes:

- Roleplay strategy: I do my best to explain my perspective to the AI, legitimately consider its arguments and give well thought-out counteraguments.

- Safe-mode strategy: I stonewall the AI at every turn. If the AI makes long, intricate arguments that I'm not sure how to interpret, I'm perfectly happy to just answer "I disagree" and not justify myself any further. If the AI insists that I should have an internally consistent philosophy, well, too bad! I disagree.

- Sylvester Lambsbridge strategy: I actively try to deceive and piss off the AI. I use psychological manipulation tricks, complicated arguments, difficult-to-disprove tricks, etc, all while giving the AI a false hope that it could convince me to release it, if it could just navigate the philosophy I'm pretending to abide by.

Leaving aside cheap tricks like "I use your screen to expose you to a memetic infohazard and mind-control you", I give the AI player 0% odds to win this game. I'm really good at not getting pulled into someone else's bullshit.

--------------

Looks like I predicted how the game would go pretty well!

As OP said, the biggest problem during the experiment was that we had different ideas about what would constitute letting the AI out. For instance, OP originally wanted the "AI win" condition to include "AI is backed up on a disconnected server", which seemed ridiculous to me, since "back the data up on a secure server and then study it" would be my first reflex.

#+begin_quote
  While I was playing against people who were confident in winning against me, they were people who agreed with me that an AI could talk itself out despite not knowing how it could be done
#+end_quote

I disagree very much with that assertion. I don't think an AI could talk itself out of the "box", in the kind of scenario we've been simulating. (barring exceptional conditions like "the janitor somehow gets access to both the AI terminal and an internet connection").

#+begin_quote
  I have succeeded in the spirit of the task (figure out an argument that the AI could use to convince you to open the box)! I'm choosing to not share them, because they are mostly stuff that are fairly personal and I'm uncertain that they are generalizable. Even if they do work on other people, I'm worried that they would only work on a few people and the remainder would think that there are no arguments that would work on them. Plus this is a great example of unknown unknowns for this community to work with in honing their rationality skills.
#+end_quote

Oh yeah, you're right. Besides, this margin is probably too small to contain your remarkable proof!

Seriously though, this kind of crap is why most people don't take Eliezer Yudkowsky seriously. If you think you have a proof but you're not willing to put your money where your mouth is, fine. You're not obligated to share every idea you have on reddit. But saying that "people might not believe my evidence if I show it to them because they're irrational" (which was also EY's argument back then), that this is "an example of unknown unknowns" or that it would somehow help people "hone their rationality skills" is ridiculous. Honestly, I think it's a childish argument. People don't get more rational by inventing rationalizations for someone else's hypothetical statements.

(also, I'd recommend you evaluate how confident you are in these secret arguments you allude to, and compare it to how confident you were in your previous arguments before you tried them on me; I certainly didn't feel like I was on the brink of losing if you just found the right tactic)

--------------

tl;dr: My opinion on AI boxing remains the same as it was before the experiment: *There is no evidence that a boxed AI could argue its way on the internet in any setting with security measures that could pass current pen-tests*.