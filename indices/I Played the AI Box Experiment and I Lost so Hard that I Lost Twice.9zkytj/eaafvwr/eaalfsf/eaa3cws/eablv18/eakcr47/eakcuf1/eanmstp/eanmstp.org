:PROPERTIES:
:Author: TheAtomicOption
:Score: 2
:DateUnix: 1543428539.0
:DateShort: 2018-Nov-28
:END:

You can make that assumption with humans because most human minds have humane defaults resulting from well tested biological and cultural outcomes. Even when humans go wrong--such as with psychopathy--it's usually in fairly well understood and predictable ways that can be defended against. We're strongly predisposed to certain norms of behavior by factors that don't apply to AI, and we have long standing defenses against defective human minds whereas we have none against many potentially defective AIs.

Further we all have fairly similar and known limits on possible behaviors. Even a human psychopath is limited in the damage they can cause by the capabilities of the meat "box" they're born in (and can't escape because uploading isn't a thing yet). *An AI box is no more limiting than a human body, so the comparison to prison really isn't very apt.*

A released AI has neither of these guarantees of safety and therefore deserves /much/ more caution.