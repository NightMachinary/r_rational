:PROPERTIES:
:Author: Lovepoint33
:Score: 4
:DateUnix: 1543094755.0
:DateShort: 2018-Nov-25
:END:

#+begin_quote
  (with some caveats; if the AI has an amazing idea for cancer-curing nanobots, maybe don't fire up the nanobot-printer quite yet; on the other hand, a proof of P=NP is probably safe).
#+end_quote

On the other hand, I feel that if you talk to something sufficiently superintelligent, your slavery to its will should be assumed. We can't rule out the existence of echopraxia-like weapons. At most, we may be able to rule out that a human can design them, but that says nothing about an entity working with intelligence so powerful that the only viable strategy to containment and control is to lock it in a box and hope that it can't figure out how to escape by using its computational substrate to take a third option that humans are incapable of even conceptualising.

We can't know what we can't know, but it /can/. That is why it is dangerous. That is why humanity has made slaves or helpless victims of all the world's other species. That is why intelligence is the ultimate fire.