:PROPERTIES:
:Author: alexanderwales
:Score: 9
:DateUnix: 1543002200.0
:DateShort: 2018-Nov-23
:END:

#+begin_quote
  Personally, I think that more esoteric arguments have a better chance of succeeding: I remember reading a piece of fiction (probably here) where the Gatekeeper was told that there were an arbitrarily large number of simulated instances of this conversation going on between the AI and simulated perfect copies of the Gatekeeper, and, if the one and only real conversation didn't result in the AI being released, every copy of the Gatekeeper (but not the original) would be tortured.
#+end_quote

[[https://alexanderwales.com/boxed-in/][Probably this one]] ("Boxed In", by me).

Edit: I should note that I was never hugely happy with this one. It was based on me reading all of the released transcripts for the challenges, with what I thought were the best non-meta arguments taken from them, but at the time it was written, there were no actual winning transcripts to look at, which presumably means less compelling arguments to draw from.