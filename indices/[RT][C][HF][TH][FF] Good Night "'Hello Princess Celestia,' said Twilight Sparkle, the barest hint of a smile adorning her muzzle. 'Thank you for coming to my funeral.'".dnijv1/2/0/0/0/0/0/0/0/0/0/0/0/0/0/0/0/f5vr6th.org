:PROPERTIES:
:Author: Nimelennar
:Score: 2
:DateUnix: 1572496996.0
:DateShort: 2019-Oct-31
:END:

#+begin_quote
  The latter is but a subset of the former.
#+end_quote

The latter isn't "but" anything when compared to the former.

#+begin_quote
  People donate their bodies to science, which is not seen as disrespectful.
#+end_quote

Yes. /They/ donate /their own/ bodies to science. Generally, when people ask to be buried or cremated, their relatives don't donate their bodies to science; that /is/ seen as disrespectful.

#+begin_quote
  Let's say I'm stuck in a cage. I shoot myself in the head. Are my motives irrelevant when considering whether to attempt resuscitation on my now brain-damaged body?
#+end_quote

If you're "stuck in a cage" and have received a point-blank GSW to the head, you'll almost certainly be dead (from exsanguination, if nothing else) before you can be rushed to a hospital to be resuscitated.

That said, there is a directive for first-aiders called "implied consent" stating that, if someone is in a state where they are incapable of granting or denying consent to be assisted (e.g. unconsciousness), it is assumed that they have granted consent for you to assist them. So, given that a GSW would almost certainly render you unconscious, yes, your motives are irrelevant. I'm not sure how that changes for doctors; I'm sure that I'd have to take an ethics course lasting at least one full semester to give anything resembling an educated opinion.

#+begin_quote
  If Twilight is not a fully-trained scientist
#+end_quote

You need more than one (more than two, actually).

#+begin_quote
  That is why they would use the scientific method
#+end_quote

Which includes such concepts as "independent replication." "Peer review." "Blinded studies." And so on; much of the scientific method is in place *specifically* to counteract the researcher's bias. And yet we /still/ have stuff like oil companies paying for research that undersells the impact of carbon in the atmosphere and cigarette companies paying for research that undersells the carcinogenic nature of tobacco.

If you want to get the /right/ results (/especially/ with a subject which presents an existential threat like a self-improving consciousness), your researchers can't feel pressured to come up with one set of results or another, and I can't see a way that that would be possible with either Celestia or Twilight in charge.

I can't see it safely accomplished without at least a team of dozens, all fully trained, with a support structure in place. And then there are going to be all of the other needs that those people have, and are you just going to murder the /most/ of the people you create who, through sheer probability, don't fit the mold of the kind of scientist you need for this research?

In the end, it works out to a civilization you'd need to create to do it properly, and that's exactly what Twilight /doesn't/ want to do.

#+begin_quote
  Depression literally makes the world less colorful.
#+end_quote

Well, no, not literally; visual processing is usually unaffected (unless you get into the schizophrenic variants, which are pretty rare). /Figuratively/, sure.

#+begin_quote
  It has a massive impact on the thought process, one which promotes unhelpful trains of thought and sluggishness.
#+end_quote

That's one kind of depression, yes. That is not true for all kinds of depression.

#+begin_quote

  #+begin_quote
    which has nothing whatsoever to do with intelligence or rationality
  #+end_quote

  Yes it does. Enormous debates have been had on the matter.
#+end_quote

About... anhedonia being irrational? Do you have a citation about that? I can't comprehend the idea that a lack of emotional reaction to stimulus can be irrational. Especially as emotional reaction isn't a rational thing in the first place.

#+begin_quote
  You're ignoring how common each type is.
#+end_quote

Weren't you the one who was going on and on about how we can't generalize a base rate from one example? It applies here, too: you can't assume that Twilight is representative of the most common form of depression, either.

#+begin_quote
  Subset of modifications, suggesting safe cures for depression or unsafe one if the ennui surges. If she does not know enough to perform this it is strong evidence for her possessing a type of depression which promotes stupidity.
#+end_quote

This is, in fact, suggested in the story, and rejected because artificially induced hedonism to counter anhedonia is deemed to be on a slippery slope to Cadence's condition.

And, sure, that slippery slope might be fallacious, but I submit that Twilight knows her own personality a lot better than either of use do, and is thus in a better place to make that determination.

#+begin_quote
  Mentally healthy people have jobs. Extrapolating the ability of the average individual to experience decades of routine with no noticeable increases in the average level of ennui
#+end_quote

I'm sorry, can you offer evidence to your claim that people don't get increasingly bored spending decades doing exactly the same job?

#+begin_quote
  Contrast her with Celestia for further evidence.
#+end_quote

Twilight, who is, again, in a better position to observe Celestia than we are, claims that Celestia is experiencing the same problem Twilight is, only to a lesser extent and/or is hiding it better. Celestia does not contradict this statement.

#+begin_quote
  Should mentally unwell people be allowed to commit suicide when there is a cure for the cause of their suffering?
#+end_quote

What are the other options? That they are forced to take a cure against their will (a violation of all medical ethics) or to endure suffering eternally?

#+begin_quote
  At one end is death. That is bad.
#+end_quote

Value judgement.

#+begin_quote
  At the other is life and happiness for eternity. That is good.
#+end_quote

Another value judgement. Consider that Cadence, arguably, has "life and happiness for eternity," which you say is good. Consider that you also characterize what she has as "death," which you say is bad.

#+begin_quote
  Conclusion: experiment until answer is reached.
#+end_quote

Which, again, takes /time/. Time spent suffering. Let's do some napkin math here.

Let's say that, based on the idea that "the first result you get from a process is likely to be a likely result of that process," Twilight concludes that there is a 1% chance that you can safely conduct research that will ultimately prove that safe ascension (i.e. ascension where the personality and values of the pre-ascension individual survive the process wholly intact) is possible. You're free to disagree with this next part, but from the "more and more," "less and less," I'm getting the impression that Twilight feels like her problem is getting worse over time. So, let's be really conservative. We'll say that she's maybe a hundred times as bored as she was a hundred thousand years ago, for a rate of .0046% increase of ennui every year, or ennui that doubles every 15,000 years.

Let's call the current point the point where the pleasure of just being alive is exactly balanced out with the pain of ennui, because it has /just/ gotten bad enough that she wants to end it.

If the AI research lasts 15,000 years, and leaves her with the same level of pleasure for being alive but with no pain, then she will have to live another 30,000 years to get an amount of pleasure equal to the amount of pain. Figuring in 1% probability of success in order to get the expected return, you get 3,000,000 required years to recoup the expected time spent on research, if 15,000 years are required. Which is 30 times longer than she's already been alive (and that number doubles every 15,000 years).

Factor in that I think you'll need a civilization to accomplish this, and that there have been seven Equestrias over 100,000 years, and it looks like just /setup/ for the experiment might take 14,000 years. Not to mention the time spent on the research itself (and who knows how long /that/ will take).

it's not a coin flip (two endpoints, equally probable, with one being exactly as good as the other is bad). There /are/ two endpoints, but the one data point you have is showing the good ending to very possibly be a lot less likely than the bad solution, and either ending gets exponentially worse the longer you try for the good ending.

#+begin_quote
  And yet not one of these alternatives were brought up.
#+end_quote

Did you /read/ the story? Your "remake Equestria, but make them all alicorns" alternative was brought up ("Every time we rebuild Equestria, *no matter how new and exciting we try to make it,*"), your "fix her depression" alternative was brought up ("I don't want to edit away my capacity to be bored so that I can be eternally satisfied by the raise and fall of ever new Equestrias, Princess; that just seems like a more round-about method of doing what Cadence did,") and then there was the superintelligence solution we've been arguing about.

#+begin_quote
  unless a possibility that the characters could have taken to resolve a conflict was explicitly mentioned and discarded, its existence can only mean either a plot hole or stupidity on the case of the character who didn't think of it.
#+end_quote

That sounds like the road to a very uninteresting story. If you want to write about your characters trying and failing to storm a castle, you have to write a hundred-page treatise on siege tactics in medieval warfare.

This is a /short story/. The discussion of the three alternatives presented already comprises more than 1/3 of the total word count. You couldn't go much further without making the /reader/ bored.

#+begin_quote
  Because all of them live less than a century and Celestia has fallen into old patterns that don't bring novelty.
#+end_quote

Again, they've tried novel versions of Equestria, which Twilight has stopped finding novel.

#+begin_quote
  Perhaps you are suggesting that she is too depressed for even novelty to fix her ennui,
#+end_quote

No, I'm not suggesting that at all; she herself seems to think that novelty will fix her issue (or that's how she describes the path of intelligence augmentation); she's just unconvinced that novel versions of Equestria will provide sufficient novelty, and she's not willing to risk becoming a superintelligence that doesn't retain her personality/values.