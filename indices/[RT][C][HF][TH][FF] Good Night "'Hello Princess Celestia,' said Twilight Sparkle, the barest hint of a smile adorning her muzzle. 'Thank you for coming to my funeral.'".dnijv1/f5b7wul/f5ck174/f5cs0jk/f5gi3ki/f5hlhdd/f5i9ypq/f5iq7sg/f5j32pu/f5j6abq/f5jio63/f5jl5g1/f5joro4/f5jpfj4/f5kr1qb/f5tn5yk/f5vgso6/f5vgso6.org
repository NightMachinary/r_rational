:PROPERTIES:
:Author: Nimelennar
:Score: 2
:DateUnix: 1572489005.0
:DateShort: 2019-Oct-31
:END:

#+begin_quote
  How did intelligence naturally rise? We have another data point in every intelligent being, of which, in Equestria, there are many species.
#+end_quote

Beings which are not capable of exponential self-improvement. There is only one data point in terms of beings which /are/.

#+begin_quote
  There is a body writhing right there. You're going to treat the twitching corpse of a friend with respect whether or not you believe it's dead.
#+end_quote

I find it hard to reconcile "treat the twitching corpse of a friend with respect" with "Wipe it clean and start over."

#+begin_quote

  #+begin_quote
    Cadence's were to be stimulated into bliss for eternity.
  #+end_quote

  Explicitly, or are we just guessing? It seems as if she did it for lack of anything else to do.
#+end_quote

I don't get the point you're trying to make. You seem to be presenting Cadence's motives for making the choice of "stimulated with pleasure into mindlessness," but I don't see how her motives are relevant to the fact that this is how she has chosen to spend eternity.

#+begin_quote
  Pre-ascension Twilight can create life out of nothing.
#+end_quote

Life, sure. But a fully-trained scientist, specializing in artificial intelligence, and the infrastructure that person would need to support the research required to definitively determine how to safely upgrade someone?

Surely you're not suggesting that either Twilight or Celestia, two people who each have a large personal stake in the outcome of the research, conduct that research (or even oversee it) themselves? That seems like an excellent way to pressure the researchers to come down on the side of, "Yes, safe upgrading is possible" (Celestia), or "No, it's not possible, end it already" (Twilight), even if some data has to be massaged to get that result.

#+begin_quote
  Depression makes you stupid. I speak from experience.
#+end_quote

It /can/, yes. It doesn't /necessarily/, and I am /also/ speaking from experience. Heck, take a look at all of the creative individuals who have suffered through depression and yet created /masterpieces/ of intellectual and creative accomplishment.

Depression /may/ be accompanied by cognitive distortion that trap you in a state you think that things are hopeless when they're not, but it can also be a rational reaction to a prolonged period in an /actually/ hopeless situation. Or it could merely be a state ("anhedonia") where the things that used to bring you pleasure, don't anymore (which has /nothing whatsoever/ to do with intelligence or rationality), and that seems to be the state Twilight finds herself in.

There are a lot of different manifestations of major depressive disorder; the only thing they all have in common is that someone is experiencing a prolonged state of a depressed mood.

#+begin_quote
  This is not what is happening. Twilight is an Alicorn at peak physical health.
#+end_quote

/Physical/ health, yes. Emotional health? Mental health? Surely someone who can speak from experience about depression wouldn't say that mental or emotional anguish isn't a thing. I've never experienced ennui on that level, but, then, I've never experienced /centuries/ (or longer) of it.

#+begin_quote
  You're also forgetting that there is no jailer. She can end herself at any time.
#+end_quote

I'm not forgetting. If the goal /is/ achievable, why not end herself when the goal is at its furthest? If it's not, why not end it before she goes through all of the hassle proving that it isn't?

#+begin_quote
  She's stupid for not considering alternatives.
#+end_quote

*SHE HAS HAD CENTURIES TO CONSIDER ALTERNATIVES*, and that's just the time period given since she last saw Cadence. She has lived for a /hundred thousand years./

The fact that a prolonged introspection about all the possible alternatives isn't happening on-page /does not mean it didn't happen./ The fact that her conclusion, after all that time, isn't the same as the one you reached instantly, doesn't mean that there's something wrong with her thought processes.

#+begin_quote
  Here's one: make everyone an Alicorn. Simple, free of AI risk, creates novelty and new social situations that simply can't happen with people that aren't even a century old. Another: mirror pool.
#+end_quote

How does any of that help with "I just don't care about any new ponies I meet?"