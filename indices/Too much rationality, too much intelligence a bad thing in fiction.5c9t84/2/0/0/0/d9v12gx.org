:PROPERTIES:
:Author: OrzBrain
:Score: -2
:DateUnix: 1478818343.0
:DateShort: 2016-Nov-11
:END:

#+begin_quote
  I'm not sure why you're linking intelligence with near-omnipotence, but it really seems like you are, and I don't think that's his or my point.
#+end_quote

Um, that's axiomatic, isn't it? Sufficient intelligence is equivalent to near-omnipotence (because you can accomplish anything it is possible to accomplish within your light cone) and near omniscience (because you can deduce any fact about reality, baring possible quantum interference on small scales/ too much precision).

That's the whole point of the power of AI, of the idea of an intelligence Singularity, darn near everything Eliezer Yudkowsky has ever written, the reason why the words "Artificial Intelligence" are words to conjure with, like the "AI in a box" thought experiment where the AI can mind control a human using text on a screen. That's why many people think a Strong AI will be the last thing humanity ever builds. That's why the emphasis on getting it right and making it friendly.

Intelligence is directly equivalent to omnipotence and omniscience.