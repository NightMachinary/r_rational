:PROPERTIES:
:Author: DeepTundra
:Score: 19
:DateUnix: 1598479008.0
:DateShort: 2020-Aug-27
:END:

I liked this. It's very in the vein of the classic sci-fi short story to take technology, or possible technology, think about its possible impact for a bit, and then just run with the implications as far as you can. Fun thought exercises are a decent vehicle for story concepts.

I would argue that some meaningful amount of societal pre-digestion of the ethics of technology is done in this fashion, actually. We certainly don't have perfect cloning or immortality serum or AGI or consciousness-presenting machines, but we've been preparing for the possible reality of them for so long that modern culture has a weirdly solid grounding in questions about the ethics of shooting androids.

For a writing-specific review, I thought that you did a decent job here. IMO, the short story is the writing format that lends itself best to a tight focus, good pacing, and a functional narrative. So you're doing well right off the bat. Going from highest-level concerns downwards:

The "retrospective historical narrative" structuring is a good balance between getting across the central idea you're working with and restraining the amount of work you have to do. Of course as a writer there's a struggle about "where" the best place to showcase your idea is in the world you build. That is, what type of narrative best gets across the most interesting possible cross-section of the story concept.

On one hand, presenting it this way allows you to use a larger amount of your worldbuilding for the writing, as well as most straightforwardly presents the idea. But tension is harder to maintain when the only sense of ongoing action comes from a clearly retrospective chronological explanation of the procession of events, especially if the speaker's situation seems unpleasant but not immediately dire. Maybe there are other points here that would be interesting for you to further explore, like the viewpoint of a "AI risk denialist" or a western internet libertarian.

This leads nicely into my next point, which is that I'm not such a fan of the speaker/viewpoint character here. Like, we get enough hints to construct a decent character profile, but his voice isn't particularly interesting to me. Which seems like it's on purpose, obviously. The writing is very historically impersonal, even when the tone isn't, and there are only a few spots where the actual presumably human character actually peaks through. Again, this seems like it's on purpose, but I don't know if it does you any favors.

When Sam says:

> This is a human fact, on which humans must deliberate.

It's really strong. But I didn't get such a strong feeling of deliberation or grappling with ideas from the text itself. More of a straightforward presentation of historical fact that deliberately elides explicit values-based discussion or presentation of personal thoughts until the very, very end. I know that the speaker cares a lot about the subject, to an unusual degree, because he tells me.

So...I didn't feel too attached to him, even at the end when we see him struggle a bit. The dystopian feeling I was getting while reading was a sense of empathetic general malaise for the situation. I think the impact would have been stronger if I felt more connected to the character in question. I'm not saying this idea isn't engaging or good, because it is, but if the viewpoint character's voice primarily expresses a mild, resigned discontent, then that's what I'll feel too. Maybe that tone or feeling is natural for someone born into the situation, or for someone that has only been exposed to GPT-3 writing in-universe, and maybe there's more intellectual horror there for the reader from viewpoint dissonance, but in terms of emotional impact it felt a little flat. I might just be overtrained by movies with hollywood soundtracks, though.

The horror of the situation is indeed buttressed a little by the total lack of realism in having governments take decisive world-saving action when presented with a clearly real and apocalyptic technological or scientific problem (*O O F*). IRL nobody would do anything and ASI would obliterate the world. But getting an unlikely but technically fortuitous resolution that nonetheless feels like a bad end still works, mostly because the bad end here is unique to the speculation you're doing rather than yet another ASI apocalypse.

Of course, there's some reasonable doubt to be had about whether ASI is a really a deathly risk in-universe, or if a greater than human AGI already exists. Both seem like somewhat plausible theories to have about the singular phenomena of a language modeler writing an "ASI Bad" paper so convincing that it utterly changes the course of human history.

The paranoia of wondering if the story is written by GPT-3 (both in and out of universe, oof) adds a stimulating spice. Obviously, due to the subject matter, an explicit clarification appended to the story that it isn't GPT-3 doesn't do anything, lmao. I suppose the scene at the end clarifies whether it's GPT-3 or another modeling software in-universe, though.

I didn't notice any problems with paragraphing or structure or pacing or repetition. The occasional spelling mistakes were a nice touch; I was Noticing them whenever they happened, which I hope was intentional.

Feignman is a good pun.