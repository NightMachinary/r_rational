:PROPERTIES:
:Author: ArgentStonecutter
:Score: 1
:DateUnix: 1453600670.0
:DateShort: 2016-Jan-24
:END:

#+begin_quote
  If an AI has the ability to hide their source code, they won't be able to make precommitment deals with other AIs.
#+end_quote

"Source code" includes actual code, implicit models, explicit models, neural nets and associated weightings, and so on. It's really making a whole lot of assumptions to think that any AI can make sufficient sense of their own code or that of an AI of comparable complexity to be able to encode "I won't go to the cops" into that system.

#+begin_quote
  If a superintelligence is first built with a utility function, they will continue to have that utility function because of the nature of utility functions
#+end_quote

The concept of a utility function, as something more than a metaconcept used for modelling an AI that's necessarily smaller than us, is something that's unlikely to map to anything in reality.

An actual, working, conscious AI is likely to be at least as messy as the most complex meta-systems we know of.