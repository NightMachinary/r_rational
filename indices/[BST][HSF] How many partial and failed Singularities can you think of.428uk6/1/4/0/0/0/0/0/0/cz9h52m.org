:PROPERTIES:
:Author: ArgentStonecutter
:Score: 1
:DateUnix: 1453594396.0
:DateShort: 2016-Jan-24
:END:

#+begin_quote
  That wouldn't happen with 2 AIs (given they have access to each other's source codes, and the ability to change their own).
#+end_quote

I know you made that assumption explicit. I am challenging that assumption.

#+begin_quote
  An AI with a utility function is indifferent regarding its own continued existence. All that matters is that the utility function gets maximized.
#+end_quote

Another assumption that treats artificial superintelligences as somehow fundamentally simpler than humans, when it's likely they will be more complicated, and their utilitity functions will be at least as messy as ours.

#+begin_quote
  Now who's making assumptions :P
#+end_quote

I'm assuming that an intelligence that is more capable than a human is unlikely to be simpler than a human.

#+begin_quote
  Simplifications are needed in any model
#+end_quote

That's of course a problem when dealing with entities that are more complex than you.