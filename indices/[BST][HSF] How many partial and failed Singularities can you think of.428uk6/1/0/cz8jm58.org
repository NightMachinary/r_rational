:PROPERTIES:
:Author: DataPacRat
:Score: 6
:DateUnix: 1453516386.0
:DateShort: 2016-Jan-23
:END:

The model I based this idea on was that each initial AI "owned" a certain portion of the CPU cycles per unit time, but could trade them away. A market could result in which each AI faces an incentive to streamline its mental processes, to reduce the CPU overhead spent on keeping itself alive, in order to have a larger "bank account" of spare cycles to perform financial transactions of various levels of risk with. Even if the original AIs were of human-level intelligence, or even outright ems, then depending on the details, it seems possible for some versions of this model to result in ever-stupider AIs.

(I'm afraid that I don't have the economic chops to prove anything about this model, I'm only proposing it at the level of detail required for fiction. I'm looking forward to whatever Robin Hanson might say on the topic in his forthcoming book.)