:PROPERTIES:
:Author: electrace
:Score: 1
:DateUnix: 1453602754.0
:DateShort: 2016-Jan-24
:END:

#+begin_quote
  It's really making a whole lot of assumptions to think that any AI can make sufficient sense of their own code or that of an AI of comparable complexity to be able to encode "I won't go to the cops" into that system.
#+end_quote

Not sure what you're arguing with, I already covered that possibility.

#+begin_quote
  then that's just an unfortunate fact of the universe, and pre-commitments wouldn't be possible.
#+end_quote

--------------

#+begin_quote
  The concept of a utility function, as something more than a metaconcept used for modelling an AI that's necessarily smaller than us, is something that's unlikely to map to anything in reality.
#+end_quote

I think you're more sure of that than the evidence suggests that you should be. So I ask, how do you think that you know this?