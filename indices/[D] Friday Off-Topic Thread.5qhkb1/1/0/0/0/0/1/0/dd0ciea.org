:PROPERTIES:
:Author: 696e6372656469626c65
:Score: 3
:DateUnix: 1485581640.0
:DateShort: 2017-Jan-28
:END:

Well, there are a couple of formal measures for complexity in computer science and information theory. The most relevant measure here is probably [[https://en.wikipedia.org/wiki/Kolmogorov_complexity][Kolmogorov complexity]]. The simplest way to think of it would be this: to determine how complicated a mathematical object is, you write out a computer program capable of simulating that object in its entirety, compile it into binary, and then count the bits of the resulting program. The more bits there are, the more complex the object is. By this metric, quantum mechanics (that is to say, the Schrodinger equation)--as well as any other physical theory--is actually quite simple, since mathematical equations are remarkably easy to reproduce in code. To figure out whether a particular physical theory is simpler than another, of course, would require you to actually perform the task I described above (not an easy thing to do by any stretch of the imagination), but one thing is clear enough: because physicists only consider hypothesis that can be described by mathematical equations, the sort of hypotheses they tend to consider are simpler /by far/ than any other competing set of hypotheses. This is actually where the divide between "naturalistic" and "non-naturalistic" hypotheses comes from: not from some sort of rigid rule that unfairly discriminates against certain hypotheses, but just because there's a certain class of hypotheses that /starts out/ with an advantage, merely by virtue of being simpler.