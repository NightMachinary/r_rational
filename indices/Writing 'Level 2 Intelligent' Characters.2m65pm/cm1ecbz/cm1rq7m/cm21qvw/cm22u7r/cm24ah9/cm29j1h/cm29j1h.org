:PROPERTIES:
:Author: philip1201
:Score: 3
:DateUnix: 1415967509.0
:DateShort: 2014-Nov-14
:END:

[[https://web.archive.org/web/20140910200630/http://www4.ncsu.edu/%7Etenshi/Killer_000.htm][The wayback machine works]].

I've only read the first third, but so far I find myself agreeing with Card's supposed viewpoint. Your ethics and your factual beliefs are orthogonal elements in making a decision, so you can have an agent with perfect ethics do an arbitrary harmful thing by giving it specific factual beliefs. Ender's game is specifically constructed in-universe to give Ender specific false factual beliefs.

The reason the justification "I thought I was doing the right thing" breaks down is because people have the choice to research whether they are mistaken or what the cost of being mistaken would be, and that choice is very often failed for moral reasons like intellectual laziness, beliefs as attire, etc. Not because your reasons are morally irrelevant.

The question of whether Ender is morally guilty or not does not rest on whether he committed genocide or not, it rests with whether he should be expected to know better; whether it can be reasonably stated that he made a deliberate choice towards his committing (statistical) murder/genocide, be it by declining to do research when he reasonably could have or by making more directly related choices.

In that regard, given the facts we have, Ender IMO /is/ guilty of the +murder+ [edit after 2 comments:] voluntary manslaughter of both bullies; he can reasonably be expected to know enough about how people work that massive blunt force trauma has an unacceptable risk of causing permanent damage and even death, given his intelligence and (alleged) general level-headedness.

The genocide is more ambiguous: aliens are a priori expected to be inherently [[http://lesswrong.com/lw/y4/three_worlds_collide_08/][evil]], because of the fragility of value, and these aliens never gave any signal contrary to the hypothesis that they sought the annihilation of humanity - not even something as obvious as /not shooting every human ship they could/. He had all information directly relevant to the situation. To avert genocide, humanity would have to put fleets of ships in danger - each failure opening up the possibility of another genocidal retaliation - trying to establish means of communication despite their opponents not risking anything or making any apparent efforts to do the same.