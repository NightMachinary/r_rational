:PROPERTIES:
:Author: vakusdrake
:Score: 4
:DateUnix: 1518313532.0
:DateShort: 2018-Feb-11
:END:

What you're doing seems to be sort of the opposite of anthropomorphizing (assuming humans will act like ruthless inhuman AI).

Yes I will be kept at a secure compound, however there's no reason to think that would necessarily be unpleasant. For one they would want to preserve my psychological well being for obvious reasons, and secondly given I am considered to have the moral value of perhaps hundreds of millions/billions of people they would also want to make my life very comfortable.\\
Also remember that in addition to holding a disproportionate amount of moral value (which was partially intended as a safety measure for exactly this sort of thing) my judgement is also disproportionately valued, so they will be extremely hesitant to act against my will.

Sure I would spend all my time in a secure compound (which is actually what I'd want in the first place to protect myself from assassination), but there's no reason to think that I couldn't have access to many luxuries and be visited by people who were well screened and checked so they couldn't pose a threat to me.\\
Also security wouldn't need to be /that/ amazing, because the only people who would be trying to harm me would be crazy people (since even psychopaths not bound by my ethical rules still wouldn't think trying to kill me would be worth it unless they were completely insane) so protecting against lone crazies shouldn't be that hard and neither would vetting my visitors to be confident they wouldn't try to kill me.

Plus it's not like they would even necessarily want to spend all my time questioning me, since once they had gotten enough information from me (not to mention they start out with a pretty good baseline when it comes to approximating my ethics) situations where my ethical response to something would be ambiguous aren't really likely to be that common.