:PROPERTIES:
:Author: vakusdrake
:Score: 4
:DateUnix: 1518294377.0
:DateShort: 2018-Feb-10
:END:

Well a lot of other people have tried to go over some of the many ways this sort of things can go horribly wrong, however I'll go over some ways you might actually get this to work.

The first and easiest solution may be to just encode your own ethical system into everyone's DNA, after all it doesn't say you need to specify things in exact detail.

However if you need to give more detailed instructions then I would encode a desire for everyone to adopt my ethical system, this would result in me being well protected and constantly questioned to try to puzzle out my exact ethical system. Until then however I would replace everyone else's genetic basis for their moral intuitions with my own since I suspect many of my unique moral intuitions are genetically based (like a strong distaste for authoritarianism beyond what I could have gotten from my parents/peers), but make this able to be overruled by the other stuff I mention in this comment.

Another component to create the baseline for morals (pending a more detailed understanding of my ethics) would probably include a bunch of stuff copied from the sequences and SSC in order to increase the sanity waterline and thus decrease the chance of my moral commandments being misinterpreted, as well as a instinct to feel obligated to become more rational and think those previously mentioned sources of info were a good place to start.

As for the starting commandments themselves they would tend to want to error on the side of wanting to give people more freedom even if that doesn't maximize their happiness (since though both preference and normal utilitarianism break down when it comes to wireheading I definitely still prefer the former generally).\\
Then of course I would go on to include a bunch of stuff from [[http://slatestarcodex.com/2014/08/24/the-invisible-nation-reconciling-utilitarianism-and-contractualism/][this SSC article]] (and the three other articles linked at the beginning of that article as a starting point for the ethical system itself.

Also while I'm at it I would stick in a clause about treating my personal well being as substantially more important than any other single persons (though not so much more important that this allocates /so/ many resources towards myself as to cause significant suffering or anything like that). Plus I would put in something that would make people treat my opinion with a massive amount of reverence, so that I can have disproportionate influence over how the world will reshape itself in light of the changes I've made. Of course that might turn out to be somewhat unnecessary anyway since I would probably get a massive amount of reverence due to the fact I'm literally the standard for ethics.

Anyway while this might seem slightly selfish of a solution I don't think you could make any better solution if your goal is to make the world maximize your criterion for moral goodness.