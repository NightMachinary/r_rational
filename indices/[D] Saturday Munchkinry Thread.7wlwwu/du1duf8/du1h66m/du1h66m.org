:PROPERTIES:
:Author: sicutumbo
:Score: 12
:DateUnix: 1518281887.0
:DateShort: 2018-Feb-10
:END:

"Maximize intelligence, knowledge, autonomy, happiness, and sociability of all sapient beings." Problems could occur with this definition, in large part because this is a Reddit comment instead of an autobiography or thesis, and I'm not going to put a ton of time into it, so I may be missing something, potentially something important.

I don't want to sound super arrogant, but if the choice is between me choosing a human morality system and some random person doing so, it's not really even a choice. There are people, past or present, who could think of a better definition for morality than I can, but a random person would either say something either less thought out or horrifying. "Don't kill people" would be a complete mess, and something like "Worship God/Allah" would be horrifying on a number of levels. Also, a significant portion of humanity is comprised of children, and having an 8 year old decide what human morality will look like is something I don't even want to contemplate.

I think significant problems would arise with any deontological morality definition. Restricting specific acts sounds ok, but it runs into problems immediately when you get to edge cases. If your morality dictates that you can't kill people, you would have no reason to choose an action that kills less people so long as both options result in some level of human death.