:PROPERTIES:
:Score: 1
:DateUnix: 1386178641.0
:DateShort: 2013-Dec-04
:END:

#+begin_quote
  Who said the number of other people is infinite? We live in, as far as we know, a strictly finite universe. There is a finite amount of torture versus a finite amount of other people.
#+end_quote

Nope. The current cosmological model (lambda-CDM) has the Universe being spatially flat and infinite in all directions.

#+begin_quote
  Now, we're preventing the heat-death of the universe, so we're at least hypothetically talking about being able to transform that finity into infinity, but come on. Surely we should be looking for ways to take the infinite torture in shifts, or make do without it entirely.
#+end_quote

Naturally, we'd find a third alternative, that's what I said.

#+begin_quote
  But doesn't that mean that, again, through proof by induction, you'll sacrifice everyone to save everyone? How many people, at minimum, must be actually enjoying their lives to make the sacrifices worthwhile?

  If I have a Kyubee torture everyone else in the universe all the time so that I and I alone can a perfect life forever, is that worth it?

  Where's your sense of individual rights? Where is the cross-over point in your utilitarian spectrum at which this becomes unacceptable? And by the way, doesn't sum-total utilitarianism result in the Mere Addition Paradox, also known as Robin Hanson's Malthusian dystopia?
#+end_quote

The cross-over point is when the number of tortured people actually becomes infinite. Since there are different sizes of infinity, when you have comparable infinities you can start measuring it.

As I said, our current best model for the Universe has it as spatially infinite. That also implies that there is an infinite number of copies of me elsewhere in the universe, and so there will likely be an infinite number of copies of me /not/ being tortured.

As for sum-total utilitarianism, I'm not sure it's the best way to go. Average utilitarianism sounds more useful in a spatially infinite inflationary quantum universe.

#+begin_quote
  Isn't the whole point of "rationalism" that instead of just looking away from things and saying, "That's magical!" we actually clarify our thinking, unpack our questions, do mathematical and empirical examinations, and come to some freaking answers?
#+end_quote

Yes, we /are/ doing it. It's part of the unsolved problems of FAI, with a lower priority than "making sure it won't go Unfriendly somewhere during its self-updating."