:PROPERTIES:
:Author: owenshen24
:Score: 11
:DateUnix: 1492460097.0
:DateShort: 2017-Apr-18
:END:

#+begin_quote
  (Most) humans don't have a well-defined utility function. Is that sufficient? If we could work out the formula for the human utility function, would that automagically make all humans into paperclippers?
#+end_quote

I think that we generally use "paperclipper" to talk about things that maximize a sole thing, relative to our human perspective.

If you're calling "anything that works to maximize its values" a paperclipper, I think the definition stops being very useful.

Once we extend the definition, everything starts to look like it maximizes stuff.

Sure, I think that humans can probably be modeled as maximizing some multi-variate, complex function that's cobbled together by evolution.

It's generally agreed upon, though, that we're not demonstrating the single-minded focus of an optimization process. (Esp. as paperclipping tends to be defined relative to humans, anyway.)

One could argue that the satisficing actions we take in life actually maximize some meta-function that focuses on both maximizing human values plus some other constraints for feasibility, morals, etc., but then /everything/ would be defined as maximizing things.