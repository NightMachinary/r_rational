:PROPERTIES:
:Author: waylandertheslayer
:Score: 2
:DateUnix: 1492463162.0
:DateShort: 2017-Apr-18
:END:

A 'paperclipper' is an AI that has a utility function which is aligned with some goal that isn't very useful to us, and then pursues that goal relentlessly.

It's from an example of what a failed self-improving general artificial intelligence could look like, where someone manually types in how much it 'values' each item it could produce. If they accidentally mistype something (e.g. how much the AI values paperclips), you end up with a ruthless optimisation process that wants to transform its future light cone into paperclips.

From our point of view, a paperclip maximiser is obviously bad.