:PROPERTIES:
:Author: Jinoc
:Score: 2
:DateUnix: 1390945830.0
:DateShort: 2014-Jan-29
:END:

Even for rationalist science fiction that's limiting the options a bit too much. For one, you could assume that FAI is hard, and hence there is a wealth of possibilities before FAI become widespread but during, say, a post-scarcity time. Or before post-scarcity but after some measure of space exploration.

Or even with AI, the utility function needs not be something so simple that it wouldn't allow for storytelling. Imagine an AI has decided it would have its fun simulating (or creating) a futuristic civilization without AI ? (which is basically similar to having no AI in the first place, but is somewhat realistic).