:PROPERTIES:
:Author: Traiden04
:Score: 1
:DateUnix: 1407792503.0
:DateShort: 2014-Aug-12
:END:

So I have been talking with friends that I game with and have asked thier opinion on this topic a few times. They are unconvinced of the potential threat an AI optimizer could cause, stating that there is a lot of hand waving going on in the fact of an AI being unable to change its own goals so that they might only just optimize themselves instead of perusing the noble goal of converting all matter into paperclips. I have been unsuccessful at reasoning with them about how an AI is not the same as human intelligence and that it would not see the benefit in changing its own goals.

Edit: Further clarification on the subject brings forth the question on wether an AI could independently question its own goals and values and change them.