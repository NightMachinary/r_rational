:PROPERTIES:
:Author: TBestIG
:Score: 3
:DateUnix: 1447886913.0
:DateShort: 2015-Nov-19
:END:

The situations I remember Asimov writing in which the three laws are broken in some way, they all were caused by human error. If anybody has counterexamples please tell me, it's been a while since I last read those.

The guy in the video talks about how defining "human" and "harm" would require uploading the entire field of ethics into the robot, but won't most of that need to be in there anyway of you want a moral robot?

He mentions that there are a lot of problems with it, but goes off on a tangent and talks only about ethics, something which can be encoded simply with further instructions, the three laws aren't the sole thing programmed into a robot's brain.

One final thing that is more of a headcanon to be honest but it makes sense to me, he says that the laws are written in English. Is that explicitly stated anywhere? In my opinion the laws are complicated structures encoded in the positronic brain, which are simplified into what we see in the books, because nobody wants to read a long detailed computer manual in their science fiction.