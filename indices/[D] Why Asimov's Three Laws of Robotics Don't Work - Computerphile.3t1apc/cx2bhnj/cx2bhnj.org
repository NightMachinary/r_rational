:PROPERTIES:
:Author: electrace
:Score: 9
:DateUnix: 1447699021.0
:DateShort: 2015-Nov-16
:END:

The three laws break down when you start applying real situations to them. And by that, I mean literally any real world situation to them.

Example: A robot stands in a room, having been given no orders.

You are also in the room. The robot considers that you may be in danger, and (by the first law) turns towards you so that it can scan the area for danger, and act if danger arises.

You tell the robot to turn away from you (it's creeping you out). If it turns away, you may be harmed by something that it could have prevented by staring at you, and scanning the area for danger. The robot neglects the order, it contradicts with the first law. You tell the robot to power down. If it powers down, you may come to harm. The robot neglects the order, it contradicts with the first law. You pull a gun on the robot. If the robot allows itself to be killed, without it there to protect you, you may come to harm. The robot takes the gun from you.

Notice, the second law is completely useless because following an order means doing something different than you are already doing. Since you are already acting in accordance to the first law, any deviation would mean a greater probability of violating the first law, so all orders are ignored.

Also notice, oddly, that the third law, while useless as a law by itself via the same reasoning, it can actually be derived from the first law (If the robot ceases to exist, a human may be harmed, and so a robot should protect it's own existence). /nitpick:/ there are scenarios where dying will cause a greater probability for the human not to be harmed. In those scenarios, the robot will choose to die.