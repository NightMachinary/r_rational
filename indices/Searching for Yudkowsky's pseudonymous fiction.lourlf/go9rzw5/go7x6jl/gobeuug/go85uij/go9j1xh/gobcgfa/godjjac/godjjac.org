:PROPERTIES:
:Author: holyninjaemail
:Score: 6
:DateUnix: 1614023346.0
:DateShort: 2021-Feb-22
:END:

The stated rules of the AI Box experiment are here: [[https://www.yudkowsky.net/singularity/aibox]]

Notably, the first rule is "The AI party may not offer any real-world considerations to persuade the Gatekeeper party". While I cannot prove that what you describe didn't happen, I wouldn't expect Yudkowsky to lie about if he followed the rules laid out for his experiment or not.