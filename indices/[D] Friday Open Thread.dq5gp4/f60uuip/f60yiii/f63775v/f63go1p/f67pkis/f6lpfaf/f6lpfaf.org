:PROPERTIES:
:Author: Roxolan
:Score: 2
:DateUnix: 1572956543.0
:DateShort: 2019-Nov-05
:END:

#+begin_quote
  Turing Test: I suspect we'll see a few AGIs pass in the next ten years. A bot that spouts frequently misspelled crap about antivaxxing, contrails, flat earth, Jewish conspiracy, pro-Trump, anti-immigration, pro-Russia shit, etc. is rather likely to be deemed a human.
#+end_quote

Turing didn't define an exact procedure for the test, so people have been trying to [[https://en.wikipedia.org/wiki/Eugene_Goostman][munchkin it for cheap publicity]] for a while.

But from his [[http://www.alanturing.net/turing_archive/pages/Reference%20Articles/TheTuringTest.html][sample dialogue snippet]], the intent was to have a bot that could hold its end of an intellectual conversation and would cooperate with the examiners (who, in turn, must be educated and doing their best to ferret out the bot). [e: [[https://www.scottaaronson.com/blog/?p=1858][Scott Aaronson says it better.]]]

At the very least, the human control ought to do that. So if only one of the two can string a coherent reply together, the bot will be easy to find.

An AI that can pass a genuinely challenging Turing test, even if it's not a true AGI, could likely take over a ton of human service jobs - and finally realise the promised dream of everyone having their own personal assistant in their pocket. An AI that manages to be indistinguishable from a rambling madman... not so much.