#+TITLE: [RT][C][TH] The Facilitator

* [RT][C][TH] The Facilitator
:PROPERTIES:
:Author: TheUtilitaria
:Score: 10
:DateUnix: 1471539466.0
:END:
At the end of the 21st century, an AI designer makes a last ditch attempt to save herself from bankruptcy, with unexpected results. A short story about transhumanist concerns. What does the subreddit think of the scenario?

[[https://www.dropbox.com/s/jwvunw63hlyex7g/The%20Facilitator.pdf?dl=0][Dropbox Link]]


** Fun. Very cyberpunk. Not very technically accurate. Doesn't arouse a lot of emotion in the reader.
:PROPERTIES:
:Author: Charlie___
:Score: 2
:DateUnix: 1471580532.0
:END:

*** Fair enough. What could I do to make it more technically accurate?
:PROPERTIES:
:Author: TheUtilitaria
:Score: 1
:DateUnix: 1471596833.0
:END:

**** I don't see anything that seems implausible. You kept everything vague enough to be reasonable.

I suppose the idea of a neural interface that makes you think /faster/ is a bit far-fetched. What exactly is it doing, making the chemicals react faster?
:PROPERTIES:
:Author: traverseda
:Score: 2
:DateUnix: 1471599791.0
:END:

***** I wasn't thinking the implants made his neurons fire faster, more that he'd rewired his brain to get more processing power out of the existing neurons. But he can move in and out of the 'fast' mode where his thinking is difficult for ordinary people to parse.
:PROPERTIES:
:Author: TheUtilitaria
:Score: 1
:DateUnix: 1471601285.0
:END:

****** How would you go about actually doing that?

Presuming that you knew /how/ the neurons had to be rewired?
:PROPERTIES:
:Author: traverseda
:Score: 2
:DateUnix: 1471601451.0
:END:

******* The implants produce new, artificial connections between previously unconnected neurons. How exactly I don't know, but I suspect the neuroscience of 83 years hence could find a way.
:PROPERTIES:
:Author: TheUtilitaria
:Score: 1
:DateUnix: 1471601877.0
:END:

******** #+begin_quote
  How exactly I don't know, but I suspect the neuroscience of 83 years hence could find a way.
#+end_quote

Sounds like a god-of-the-gaps type situation to me.

There are a couple of technologies that could lead up to that sort of thing, mostly nanites that physically rearrange things.

A mask-thing implies a bunch of stuff about how the technology works, better to keep it vague.

Any intelligent enhancement is /hard/. Look up "Algernons law". Any simple adaptation that vastly increases any aspect of intelligence would probably already be in the general population, presuming it provided a significant advantage.

So I'm a lot more inclined to be critical of intelligence enhancing technology at the tech-level shown in your story. Well, technology that's implemented on top of meat anyway. And that isn't along the lines of wikipedia or prediction markets, or something else that feels a lot like a tool.

And the mask-thing isn't a /big/ problem. I can imagine ways it makes sense. Maybe nanites that are powered via induction. Although I'd be surprised if any re-wiring to that scale wasn't permanent.

There are ways it makes sense, it just seems like a less-probable way for technology to develop.
:PROPERTIES:
:Author: traverseda
:Score: 3
:DateUnix: 1471602441.0
:END:

********* The Algernon's law argument is interesting, but I don't think it applies here. This kind of cognitive enhancement is not easy, probably does come with higher metabolism requirements and isn't evolutionary adaptive. By 'mask thing' were you referring to the cosmetic mask, because that was just for scrubbing a face and applying the 2090's equivalent of makeup?
:PROPERTIES:
:Author: TheUtilitaria
:Score: 1
:DateUnix: 1471781627.0
:END:

********** Ah, no. I misremembered it. Entropic inlays.

Well, consider my (very minor) complaint retracted.
:PROPERTIES:
:Author: traverseda
:Score: 1
:DateUnix: 1471782296.0
:END:


**** With the technobabble it's easily forgivable, I'm just the weird sort of person who's going to be distracted by talking about people worrying about their quantum computer having more than 64 qubits. There's probably no easy way to change this.

As for the AI - well, there /is/ an easy way to make that more technically accurate. Just have it stay under the radar a couple of weeks, and then one morning everyone wakes up dead. But this is less good of a story.
:PROPERTIES:
:Author: Charlie___
:Score: 2
:DateUnix: 1471601217.0
:END:

***** The qbits thing seems pretty logical. 2^{64} is 1.84e19 bits, which is comparable to the estimated capacity of a human brain. That's consistent with the rest of the setting. And as for why the Facilitator didn't just reach for nanotechnology - it wasn't capable of self-improvement and is much less intelligent than a human. It can learn rapidly and think rapidly but can't rewrite its own source code. So it just didn't think of hiding and gathering enough knowledge to solve the protein folding problem or take control of the nuclear codes or whatever.
:PROPERTIES:
:Author: TheUtilitaria
:Score: 2
:DateUnix: 1471602474.0
:END:

****** You would think the qubits things is logical, but quantum computing isn't exponential in quite that way. But not to worry, because quantum computers are going to easily blow past 64 bits in the next 5 years and never look back.
:PROPERTIES:
:Author: Charlie___
:Score: 5
:DateUnix: 1471609380.0
:END:

******* I'll certainly change that in the next draft, in that case.
:PROPERTIES:
:Author: TheUtilitaria
:Score: 1
:DateUnix: 1471781656.0
:END:


** I've changed the link to a PDF to make previews easier
:PROPERTIES:
:Author: TheUtilitaria
:Score: 2
:DateUnix: 1471597552.0
:END:

*** Thanks for that :). I'm somewhat surprised that the Facilitator actually obeyed orders at the end, however, rather than just simulating obedience (or, since we didn't see much beyond that, perhaps it /was/ a simulation?...).
:PROPERTIES:
:Author: thrawnca
:Score: 2
:DateUnix: 1471825611.0
:END:

**** It wasn't able to directly lie, so it couldn't fake obedience. Rene gave it be exact form of words it had to use, so it couldn't trick her. It didn't yet have access to its own source code so it couldn't make itself able to lie, and it's not smart enough to think of anything more complicated than that.
:PROPERTIES:
:Author: TheUtilitaria
:Score: 1
:DateUnix: 1471859645.0
:END:


** I've actually finished another short story - Starwhisp.

Humanity's first interstellar mission is abruptly cut short by an unexpected encounter. A hard sci fi short story about values dissonance. What do you think?

[[https://www.dropbox.com/s/n2huyv4pale3of2/Starwhisp.pdf?dl=0][Dropbox link]]
:PROPERTIES:
:Author: TheUtilitaria
:Score: 1
:DateUnix: 1471781437.0
:END:

*** Seems quite similar to [[http://lesswrong.com/lw/y5/the_babyeating_aliens_18/][Three Worlds Collide]], except without the SuperHappies.
:PROPERTIES:
:Author: thrawnca
:Score: 2
:DateUnix: 1471826126.0
:END:


*** A very compelling story, well written and executed. Great work!
:PROPERTIES:
:Author: Lowtuff
:Score: 2
:DateUnix: 1471971758.0
:END:


** My browser says it can't be previewed, and I'm not keen on downloading it and opening it directly in a word processor.

Perhaps you could publish it as a PDF/HTML document, instead.
:PROPERTIES:
:Author: thrawnca
:Score: 1
:DateUnix: 1471575902.0
:END:

*** Previews fine for me in firefox. No viruses so far. On the other hand, not sure if worth it. Will post review.
:PROPERTIES:
:Author: Charlie___
:Score: 2
:DateUnix: 1471579545.0
:END:
